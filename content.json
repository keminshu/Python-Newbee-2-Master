{"初识": "##  初识Python\n\n### Python简介\n\nPython（英式发音：/ˈpaɪθən/；美式发音：/ˈpaɪθɑːn/）是由荷兰人吉多·范罗苏姆（Guido von Rossum）发明的一种编程语言，是目前世界上最受欢迎和拥有最多用户的编程语言。Python 强调代码的可读性和语法的简洁性，相较于 C、C++、Java 这些同样影响深远的编程语言，Python 让使用者能够用更少的代码表达自己的意图。下面是几个权威的编程语言排行榜给出的 Python 语言的排名，其中第1张图由 TIOBE Index 提供，第3张图由 IEEE Spectrum 提供。值得一提的是第2张图，它展示了编程语言在全球最大代码托管平台 GitHub 上受欢迎的程度，最近的四年时间 Python 语言都占据了冠军的宝座。\n\n<img class=\"lazy\" data-src=\"/res/day01/tiobe_index.png\" style=\"zoom:40%;\">\n\n<img class=\"lazy\" data-src=\"/res/day01/github_pypl_and_ieee_spectrum.png\" style=\"zoom:60%;\">\n\n#### Python编年史\n\n下面是 Python 语言发展过程中的一些重要时间点：\n\n1. 1989年12月：吉多·范罗苏姆决心开发一个新的脚本语言及其解释器来打发无聊的圣诞节，新语言将作为 ABC 语言的继承者，主要用来替代 Unix shell 和 C 语言实现系统管理。由于吉多本人是 BBC 电视剧《*Monty Python's Flying Circus*》的忠实粉丝，所以他选择了 Python 这个词作为新语言的名字。\n2. 1991年02月：吉多·范罗苏姆在 alt.sources 新闻组上发布了 Python 解释器的最初代码，标记为版本0.9.0。\n3. 1994年01月：Python 1.0发布，梦开始的地方。\n4. 2000年10月：Python 2.0发布，Python 的整个开发过程更加透明，生态圈开始慢慢形成。\n5. 2008年12月：Python 3.0发布，引入了诸多现代编程语言的新特性，但并不完全向下兼容。\n6. 2011年04月：pip 首次发布，Python 语言有了自己的包管理工具。\n7. 2018年07月：吉多·范罗苏姆宣布从“终身仁慈独裁者”（开源项目社区出现争议时拥有最终决定权的人）的职位上“永久休假”。\n8. 2020年01月：在 Python 2和 Python 3共存了11年之后，官方停止了对 Python 2的更新和维护，希望用户尽快切换到 Python 3。\n9. 目前：Python 在大模型（GPT-3、GPT-4、BERT等）、计算机视觉（图像识别、目标检测、图像生成等）、智能推荐（YouTube、Netflix、字节跳动等）、自动驾驶（Waymo、Apollo等）、语音识别、数据科学、量化交易、自动化测试、自动化运维等领域都得到了广泛的应用，Python 语言的生态圈也是相当繁荣。\n\n> **说明**：大多数软件的版本号一般分为三段，形如A.B.C，其中A表示大版本号，当软件整体重写升级或出现不向后兼容的改变时，才会增加A；B表示功能更新，出现新功能时增加B；C表示小的改动（例如：修复了某个Bug），只要有修改就增加C。\n\n#### Python优缺点\n\nPython 语言的优点很多，简单为大家列出几点。\n\n1. **简单优雅**，跟其他很多编程语言相比，Python **更容易上手**。\n2. 能用更少的代码做更多的事情，**提升开发效率**。\n3. 开放源代码，拥有**强大的社区和生态圈**。\n4. **能够做的事情非常多**，有极强的适应性。\n5. **胶水语言**，能够黏合其他语言开发的东西。\n6. 解释型语言，更容易**跨平台**，能够在多种操作系统上运行。\n\nPython 最主要的缺点是**执行效率低**（解释型语言的通病），如果更看重代码的执行效率，C、C++ 或 Go 可能是你更好的选择。\n\n### 安装Python环境\n\n工欲善其事，必先利其器。想要开始你的 Python 编程之旅，首先得在计算机上安装 Python 环境，简单的说就是安装运行 Python 程序需要的 Python 解释器。我们推荐大家安装官方的 Python 3 解释器，它是用 C 语言编写的，我们通常也称之为 CPython，它可能是你目前最好的选择。首先，我们需要从官方网站的[下载页面](https://www.python.org/downloads/)找到下载链接，点击“Download”按钮进入下载页面后，需要根据自己的操作系统选择合适的 Python 3安装程序，如下图所示。\n\n<img class=\"lazy\" data-src=\"/res/day01/python_download_page_1.png\" style=\"zoom:40%;\">\n\n进入下载页面后，有些 Python 版本并没有提供 Windows 和 macOS 系统的安装程序，只提供了源代码的压缩文件，对于熟悉 Linux 系统的小伙伴，我们可以通过源代码构建安装；对于使用 Windows 或 macOS 系统的小伙伴，我们还是**强烈建议**使用安装程序。例如，你想安装 Python 3.10，选择 Python 3.10.10 或 Python 3.10.11 就能找到 Windows 或 macOS 系统的安装包，而其他版本可能只有源代码，如下图所示。\n\n<img class=\"lazy\" data-src=\"/res/day01/python_download_page_2.png\" style=\"zoom:36%;\">\n\n#### Windows环境\n\n下面我们以 Windows 11为例，讲解如何在 Windows 操作系统上安装 Python 环境。双击运行从官网下载的安装程序，会打开一个安装向导，如下图所示。\n\n<img class=\"lazy\" data-src=\"/res/day01/install_python_1.png\" style=\"zoom:50%;\">\n\n首先，一定要记得勾选“Add python.exe to PATH”选项，它会帮助我们将 Python 解释器添加到 Windows 系统的 PATH 环境变量中（不理解没关系，勾上就对了）；其次，“Use admin privileges when installing py.exe”是为了在安装过程中获得管理员权限，建议勾选。然后，我们选择“Customize Installation”，使用自定义安装的模式，这是专业人士的选择，而你就（假装）是那个专业人士，不建议使用“Install Now”（默认安装）。\n\n接下来，安装向导会提示你勾选需要的“Optional Features”（可选特性），这里咱们可以直接全选。值得一提的是其中的第2项，它是 Python 的包管理工具 pip，可以帮助我们安装三方库和三方工具，所以一定要记得勾选它，然后点击“Next”进入下一环节。\n\n<img class=\"lazy\" data-src=\"/res/day01/install_python_2.png\" style=\"zoom:50%;\">\n\n接下来是对“Advanced Options”（高级选项）的选择，这里我们建议大家只勾选“Add Python to environment variables”和“Precompile standard library”这两个选项，前者会帮助我们自动配置好环境变量，后者会预编译标准库（生成`.pyc`文件），这样在使用时就无需临时编译了。还是那句话，不理解没关系，勾上就对了。下面的“Customize install location”（自定义安装路径）**强烈建议**修改为自定义的路径，这个路径中不应该包含中文、空格或其他特殊字符，注意这一点会为你将来减少很多不必要的麻烦。设置完成后，点击“Install”开始安装。\n\n<img class=\"lazy\" data-src=\"/res/day01/install_python_3.png\" style=\"zoom:50%;\">\n\n安装成功会出现如下图所示的画面，安装成功的关键词是“successful”，如果安装失败，这里的单词会变成“failed”。\n\n<img class=\"lazy\" data-src=\"/res/day01/install_python_4.png\" style=\"zoom:50%;\">\n\n安装完成后可以打开 Windows 的“命令行提示符”或 PowerShell，然后输入`python --version`或`python -V`来检查安装是否成功，这个命令是查看 Python 解释器的版本号。如果看到如下所示的画面，那么恭喜你，Python 环境已经安装成功了。这里我们建议再检查一下 Python 的包管理工具 pip 是否可用，对应的命令是`pip --version`或`pip -V`。\n\n<img class=\"lazy\" data-src=\"/res/day01/install_python_5.png\" style=\"zoom:50%;\">\n\n> **说明**：如果安装过程报错或提示安装失败，很有可能是你的 Windows 系统缺失了一些动态链接库文件或缺少必要的构建工具导致的。可以在[微软官网](https://visualstudio.microsoft.com/zh-hans/downloads/)下载“Visual Studio 2022 生成工具”进行修复，如下图所示。如果不方便在微软官网下载的，也可以使用下面的百度云盘链接来获取修复工具，链接: https://pan.baidu.com/s/1iNDnU5UVdDX5sKFqsiDg5Q 提取码: cjs3。\n>\n> <img class=\"lazy\" data-src=\"/res/day01/vs_build_tools_download.png\" style=\"zoom:50%;\">\n>\n> 上面下载的“Visual Studio 2022 生成工具”需要联网才能运行，运行后会出现如下图所示的画面，大家可以参考下图勾选对应的选项进行修复。修复过程需要联网下载对应的软件包，这个过程可能会比较耗时间，修复成功后可能会要求重启你的操作系统。\n>\n> <img class=\"lazy\" data-src=\"/res/day01/vs_build_tools_install.png\" style=\"zoom:50%;\">\n\n#### macOS环境\n\nmacOS 安装 Python 环境相较于 Windows 系统更为简单，我们从官方下载的安装包是一个`pkg`文件，双击运行之后不断的点击“继续”就安装成功了，几乎不用做任何的设置和勾选，如下图所示。\n\n<img class=\"lazy\" data-src=\"/res/day01/install_python_6.png\" style=\"zoom:50%;\">\n\n安装完成后，可以在 macOS 的“终端”工具中输入`python3 --version`命令来检查是否安装成功，注意这里的命令是`python3`不是`python`！！！然后我们再检查一下包管理工具，输入命令`pip3 --version`，如下图所示。\n\n<img class=\"lazy\" data-src=\"/res/day01/install_python_7.png\" style=\"zoom:50%;\">\n\n#### 其他安装方式\n\n有人可能会推荐新手直接安装 [Anaconda](https://www.anaconda.com/download/success)，因为 Anaconda 会帮助我们安装 Python 解释器以及一些常用的三方库，除此之外还提供了一些便捷的工具，特别适合萌新小白。我个人并不推荐这种方式，因为在安装 Anaconda 时你会莫名其妙安装了一大堆有用没用的三方库（占用比较多的硬盘空间），然后你的终端或命令提示符会被 Anaconda 篡改（每次启动自动激活虚拟环境），这些并不符合软件设计的**最小惊讶原则**。其他关于 Anaconda 的小毛病此处就不再赘述了，如果你非要使用 Anaconda，推荐安装 Miniconda，它跟 Anaconda 在同一个下载页面。\n\n还有萌新小白经常会听到或说出，“我要写 Python 程序，安装一个 PyCharm 不就可以了吗？”。这里简单科普一下，PyCharm 只是一个辅助写 Python 代码的工具，它本身并不具备运行 Python 代码的能力，运行 Python 代码靠的是我们上面安装的 Python 解释器。当然，有些 PyCharm 版本在创建 Python 项目时，如果检测不到你电脑上的 Python 环境，也会提示你联网下载 Python 解释器。PyCharm 的安装和使用我们放在了下一课。\n\n### 总结\n\n总结一下我们学到的东西：\n\n1. Python 语言很强大，可以做很多的事情，所以值得我们去学习。\n2. 要使用 Python语言，首先得安装 Python 环境，也就是运行 Python 程序所需的 Python 解释器。\n3. Windows 系统可以在命令提示符或 PowerShell 中输入`python --version`检查 Python 环境是否安装成功；macOS 系统可以在终端中输入`python3 --version`进行检查。\n", "第一个程序": "## 第一个Python程序\n\n在上一课中，我们对 Python 语言的过去现在有了一些了解，我们准备好了运行 Python 程序所需要的解释器环境。相信大家已经迫不及待的想开始自己的 Python 编程之旅了，但是新问题来了，我们应该在什么地方书写 Python 程序，然后又怎么运行它呢？\n\n### 编写代码的工具\n\n下面我们为大家讲解几种可以编写和运行 Python 代码的工具，大家可以根据自己的需求来选择合适的工具。当然，对于初学者，我个人比较推荐使用 PyCharm，因为它不需要太多的配置也非常的强大，对新手还是很友好的。如果你也听说过或者喜欢 PyCharm，可以直接跳过下面对其他工具的介绍，直接快进到讲解 PyCharm 的地方。\n\n#### 默认的交互式环境\n\n我们打开 Windows 的“命令提示符”或“PowerShell”工具，输入`python`然后按下`Enter`键，这个命令会把我们带到一个交互式环境中。所谓交互式环境，就是我们输入一行代码并按下`Enter`键，代码马上会被执行，如果代码有产出结果，那么结果会被显示在窗口中，如下所示。\n\n```Bash\nPython 3.10.10\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n>>> 2 * 3\n6\n>>> 2 + 3\n5\n>>>\n```\n\n> **说明**：使用 macOS 系统的用户需要打开“终端”工具，输入`python3`进入交互式环境。\n\n如果希望退出交互式环境，可以在交互式环境中输入`quit()`，如下所示。\n\n```Bash\n>>> quit()\n```\n\n#### 更好的交互式环境 - IPython\n\n上面说的交互式环境用户体验并不怎么好，大家使用一下就能感受到。我们可以用 IPython 来替换掉它，因为 IPython 提供了更为强大的编辑和交互功能。我们可以在命令提示符或终端中使用 Python 的包管理工具`pip`来安装 IPython，如下所示。\n\n```bash\npip install ipython\n```\n\n> **提示**：在使用上面的命令安装 IPython 之前，可以先通过`pip config set global.index-url https://pypi.doubanio.com/simple`命令或`pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple/`将下载源修改为国内的豆瓣镜像或清华镜像，否则下载安装的过程可能会非常的缓慢。\n\n接下来可以使用下面的命令启动 IPython，进入交互式环境。\n\n```bash\nipython\n```\n\n> **说明**：还有一个网页版的 IPython 名叫 Jupyter，我们在用得着它的地方再为大家介绍。\n\n#### 文本编辑神器 - Visual Studio Code\n\nVisual Studio Code 是由微软开发能够在 Windows、 Linux 和 macOS 等操作系统上运行的代码编辑神器。它支持语法高亮、自动补全、多点编辑、运行调试等一系列便捷功能，而且能够支持多种编程语言。如果大家要选择一款高级文本编辑工具，强烈推荐 Visual Studio Code，关于它的[下载](https://code.visualstudio.com/)、安装和使用，有兴趣的读者可以自行研究。\n\n<img class=\"lazy\" data-src=\"/res/day02/visual_studio_code.png\" style=\"zoom:50%;\">\n\n#### 集成开发环境 - PyCharm\n\n如果用 Python 语言开发商业项目，我们推荐大家使用更为专业的工具 PyCharm。PyCharm 是由捷克一家名为 [JetBrains](https://www.jetbrains.com/) 的公司针对 Python 语言提供的集成开发环境（IDE)。所谓集成开发环境，通常是指提供了编写代码、运行代码、调试代码、分析代码、版本控制等一系列强大功能和便捷操作的开发工具，因此特别适合用于商业项目的开发。我们可以在 JetBrains 公司的官方网站上找到 PyCharm 的[下载链接](<https://www.jetbrains.com/pycharm/download>)，如下图所示。\n\n<img class=\"lazy\" data-src=\"/res/day02/pycharm_download_page.png\" style=\"zoom:40%;\">\n\n官方提供了两个 PyCharm 的版本，一个是免费的社区版（Community Edition），功能相对弱小，但对于初学者来说是完全够用的；另一个是付费的专业版（Professional Edition），功能非常强大，但需要按年或按月支付费用，新用户可以免费试用30天时间。PyCharm 的安装没有任何难度，运行下载的安装程序，几乎全部使用默认设置进行安装就可以了。对于使用 Windows 系统的小伙伴，其中有一个步骤可以按照下图所示勾选“创建桌面快捷方式”和“在右键菜单中添加\"Open Folder as Project\"”就可以了。\n\n<img class=\"lazy\" data-src=\"/res/day02/using_pycharm_1.png\" style=\"zoom:50%;\">\n\n第一次运行 PyCharm 时，在提示你导入 PyCharm 设置的界面上直接选择“Do not import settings”，然后我们就可以看到如下图所示的欢迎界面。此处，我们可以先点击“Customize”选项对 PyCharm 做一些个性化的设置。\n\n<img class=\"lazy\" data-src=\"/res/day02/using_pycharm_2.png\" style=\"zoom:45%;\">\n\n接下来，我们可以在“Projects”选项中点击“New Project”来创建一个新的项目，此处还可以“打开已有项目”或“从版本控制服务器（VCS）获取项目”，如下图所示。\n\n<img class=\"lazy\" data-src=\"/res/day02/using_pycharm_3.png\" style=\"zoom:45%;\">\n\n创建项目的时候需要指定项目的路径并创建”虚拟环境“，我们建议每个 Python 都在自己专属的虚拟环境中运行。如果你的系统上还没 Python 环境，那么 PyCharm 会提供官网的下载链接，当你点击“Create”按钮创建项目时，它会联网下载 Python 解释器，如下图所示。\n\n<img class=\"lazy\" data-src=\"/res/day02/using_pycharm_4.png\" style=\"zoom:45%;\">\n\n当然，我们并不推荐这么做，因为我们在上一课已经安装过 Python 环境了。在系统有 Python 环境的情况下，PyCharm 通常会自动发现 Python 解释器的位置并以此为基础创建虚拟环境，所以大家看到的画面应该如下图所示。\n\n<img class=\"lazy\" data-src=\"/res/day02/using_pycharm_5.png\" style=\"zoom:45%;\">\n\n> **说明**：上面的截图来自于 Windows 系统，如果使用 macOS 系统，你看到的项目路径和 Python 解释器路径会跟上面有所不同。\n\n创建好项目后会出现如下图所示的画面，我们可以通过在项目文件夹上点击鼠标右键，选择“New”菜单下的“Python File”来创建一个 Python 文件，在给文件命名时建议使用英文字母和下划线的组合，创建好的 Python 文件会自动打开，进入可编辑的状态。\n\n<img class=\"lazy\" data-src=\"/res/day02/using_pycharm_6.png\" style=\"zoom:50%;\">\n\n接下来，我们可以在代码窗口编写我们的 Python 代码。写好代码后，可以在窗口中点击鼠标右键，选择“Run”菜单项来运行代码，下面的“Run”窗口会显示代码的执行结果，如下图所示。\n\n<img class=\"lazy\" data-src=\"/res/day02/using_pycharm_7.png\" style=\"zoom:50%;\">\n\n到这里，我们的第一个 Python 程序已经运转起来了，很酷吧！对了，PyCharm 有一个叫“每日小贴士”的弹窗，会教给你一些使用 PyCharm 的小技巧，如下图所示。如果不需要，直接关闭就可以了；如果不希望它再次出现，在关闭前可以勾选“Don't show tips on startup”。\n\n<img class=\"lazy\" data-src=\"/res/day02/using_pycharm_8.png\" style=\"zoom:50%;\">\n\n### 你好世界\n\n按照行业惯例，我们学习任何一门编程语言写的第一个程序都是输出`hello, world`，因为这段代码是伟大的丹尼斯·里奇（C 语言之父，和肯·汤普森一起开发了 Unix 操作系统）和布莱恩·柯尼汉（awk 语言的发明者）在他们的不朽著作《*The C Programming Language*》中写的第一段代码，下面是对应的 Python 语言的版本。\n\n```python\nprint('hello, world')\n```\n\n> **注意**：上面代码中的圆括号、单引号都是在英文输入法状态下输入的，如果不小心写成了中文的圆括号或单引号，运行代码时会出现`SyntaxError: invalid character '（' (U+FF08)`或`SyntaxError: invalid character '‘' (U+2018)`这样的错误提示。\n\n上面的代码只有一个语句，在这个语句中，我们用到了一个名为`print`的函数，它可以帮助我们输出指定的内容；`print`函数圆括号中的`'hello, world'`是一个字符串，它代表了一段文本内容；在 Python 语言中，我们可以用单引号或双引号来表示一个字符串。不同于 C、C++ 或 Java 这样的编程语言，Python 代码中的语句不需要用分号来表示结束，也就是说，如果我们想再写一条语句，只需要回车换行即可，代码如下所示。此外，Python 代码也不需要通过编写名为`main`的入口函数来使其运行，提供入口函数是编写可执行的 C、C++ 或 Java 代码必须要做的事情，这一点很多程序员都不陌生，但是在 Python 语言中它并不是必要的。\n\n```python\nprint('hello, world')\nprint('goodbye, world')\n```\n\n如果不使用 PyCharm 这样的集成开发环境，我们也可以直接调用 Python 解释器来运行 Python 程序。我们可以将上面的代码保存成一个名为`example01.py`的文件，对于Windows 系统，我们假设该文件在`C:\\code`目录下，我们打开“命令提示符”或“PowerShell”并输入下面的命令就可以运行它。\n\n```powershell\npython C:\\code\\example01.py\n```\n\n对于 macOS 系统，假设我们的文件在`/Users/Hao`目录下，那么可以在终端中输入下面的命令来运行程序。\n\n```Bash\npython3 /Users/Hao/example01.py\n```\n\n> **提示**：如果路径比较长，不愿意手动输入，我们可以通过拖拽的方式将文件直接拖到“命令提示符”或“终端”中，这样会自动输入完整的文件路径。\n\n大家可以试着修改上面的代码，比如将单引号中的`hello, world`换成其他内容或者多写几个这样的语句，看看会运行出怎样的结果。需要提醒大家的是，写 Python 代码时，最好每一行只写一条语句。虽然，我们可以使用`;`作为分隔将多个语句写在一行中，但是这样做会让代码变得非常难看，不再具备良好的可读性。\n\n### 注释你的代码\n\n注释是编程语言的一个重要组成部分，用于在代码中解释代码的作用，从而达到增强代码可读性的目标。当然，我们也可以将代码中暂时不需要运行的代码段通过添加注释来去掉，这样当你需要重新使用这些代码的时候，去掉注释符号就可以了。简单的说，**注释会让代码更容易看懂但不会影响代码的执行结果**。\n\nPython 中有两种形式的注释：\n\n1. 单行注释：以`#`和空格开头，可以注释掉从`#`开始后面一整行的内容。\n2. 多行注释：三个引号（通常用双引号）开头，三个引号结尾，通常用于添加多行说明性内容。\n\n```python\n\"\"\"\n第一个Python程序 - hello, world\n\nVersion: 1.0\nAuthor: 小明\n\"\"\"\n# print('hello, world')\nprint(\"你好，世界！\")\n```\n\n### 总结\n\n到此，我们已经把第一个 Python 程序运行起来了，是不是很有成就感？！只要你坚持学习下去，再过一段时间，我们就可以用 Python 语言做更多更酷的事情。今时今日，编程就跟英语一样，对很多人来说都是一项必须要掌握的技能。\n", "语言中的变量": "## Python语言中的变量\n\n对于想学习编程的新手来说，有两个问题可能是他们很想知道的，其一是“什么是（计算机）程序”，其二是“写（计算机）程序能做什么”。先说说我对这两个问题的理解：**程序是数据和指令的有序集合**，**写程序就是用数据和指令控制计算机做我们想让它做的事情**。今时今日，为什么有那么多人选择用 Python 语言来写程序，因为 Python 语言足够简单和强大。相较于 C、C++、Java 这样的编程语言，Python 对初学者和非专业人士更加友好，很多问题在 Python 语言中都能找到简单优雅的解决方案。接下来，我们就从最基础的语言元素开始，带大家认识和使用 Python 语言。\n\n### 一些常识\n\n在开始系统的学习 Python 编程之前，我们先来科普一些计算机的基础知识。计算机的硬件系统通常由五大部件构成，包括：**运算器**、**控制器**、**存储器**、**输入设备**和**输出设备**。其中，运算器和控制器放在一起就是我们常说的**中央处理器**（CPU），它的功能是执行各种运算和控制指令。刚才我们提到过，程序是指令的集合，写程序就是将一系列的指令按照某种方式组织到一起，然后通过这些指令去控制计算机做我们想让它做的事情。存储器可以分为**内部存储器**和**外部存储器**，前者就是我们常说的内存，它是中央处理器可以直接寻址的存储空间，程序在执行的过程中，对应的数据和指令需要加载到内存中。输入设备和输出设备经常被统称为 I/O 设备，键盘、鼠标、麦克风、摄像头是典型的输入设备，而显示器、打印机、扬声器等则是典型的输出设备。目前，我们使用的计算机基本大多是遵循“冯·诺依曼体系结构”的计算机，这种计算机有两个关键点：一是**将存储器与中央处理器分开**；二是**将数据以二进制方式编码**。\n\n二进制是一种“逢二进一”的计数法，跟人类使用的“逢十进一”的计数法本质是一样的。人类因为有十根手指，所以使用了十进制计数法，在计数时十根手指用完之后，就只能用进位的方式来表示更大的数值。当然凡事都有例外，玛雅人可能是因为长年光着脚的原因，把脚趾头也都用上了，于是他们使用了二十进制的计数法。基于这样的计数方式，玛雅人使用的历法跟我们平常使用的历法就产生了差异。按照玛雅人的历法，2012 年是上一个所谓的“太阳纪”的最后一年，而 2013 年则是新的“太阳纪”的开始。后来这件事情还被以讹传讹的方式误传为“2012 年是玛雅人预言的世界末日”的荒诞说法。今天有很多人猜测，玛雅文明之所以发展缓慢跟使用了二十进制是有关系的。对于计算机来说，二进制在物理器件上最容易实现的，因为可以用高电压表示 1，用低电压表示 0。不是所有写程序的人都需要熟悉二进制，熟悉十进制与二进制、八进制、十六进制的转换，大多数时候我们即便不了解这些知识也能写程序。但是，我们必须知道，计算机是使用二进制计数的，不管什么样的数据，到了计算机内存中都是以二进制形态存在的。\n\n> **说明**：关于二进制计数法以及它与其他进制如何相互转换，大家可以翻翻名为《计算机导论》或《计算机文化》的书，都能找到相应的知识，此处就不再进行赘述了，不清楚的读者可以自行研究。\n\n### 变量和类型\n\n要想在计算机的内存中保存数据，首先得说一说变量这个概念。在编程语言中，**变量是数据的载体**，简单的说就是一块用来保存数据的内存空间，**变量的值可以被读取和修改**，这是所有运算和控制的基础。计算机能处理的数据有很多种类型，最常见的就是数值，除了数值之外还有文本、图像、音频、视频等各种各样的数据类型。虽然数据在计算机中都是以二进制形态存在的，但是我们可以用不同类型的变量来表示数据类型的差异。Python 语言中预设了多种数据类型，也允许我们自定义新的数据类型，这一点在后面会讲到。我们首先来了解几种 Python 中最为常用的数据类型。\n\n1. 整型（`int`）：Python 中可以处理任意大小的整数，而且支持二进制（如`0b100`，换算成十进制是4）、八进制（如`0o100`，换算成十进制是64）、十进制（`100`）和十六进制（`0x100`，换算成十进制是256）的表示法。运行下面的代码，看看会输出什么。\n\n    ```python\n    print(0b100)  # 二进制整数\n    print(0o100)  # 八进制整数\n    print(100)    # 十进制整数\n    print(0x100)  # 十六进制整数\n    ```\n\n2. 浮点型（`float`）：浮点数也就是小数，之所以称为浮点数，是因为按照科学记数法表示时，一个浮点数的小数点位置是可变的，浮点数除了数学写法（如`123.456`）之外还支持科学计数法（如`1.23456e2`，表示$\\small{1.23456 \\times 10^{2}}$）。运行下面的代码，看看会输出什么。\n\n    ```python\n    print(123.456)    # 数学写法\n    print(1.23456e2)  # 科学计数法\n    ```\n\n3. 字符串型（`str`）：字符串是以单引号或双引号包裹起来的任意文本，比如`'hello'`和`\"hello\"`。\n\n4. 布尔型（`bool`）：布尔型只有`True`、`False`两种值，要么是`True`，要么是`False`，可以用来表示现实世界中的“是”和“否”，命题的“真”和“假”，状况的“好”与“坏”，水平的“高”与“低”等等。如果一个变量的值只有两种状态，我们就可以使用布尔型。\n\n### 变量命名\n\n对于每个变量，我们都需要给它取一个名字，就如同我们每个人都有自己的名字一样。在 Python 中，变量命名需要遵循以下的规则和惯例。\n\n- 规则部分：\n  - 规则1：变量名由**字母**、**数字**和**下划线**构成，数字不能开头。需要说明的是，这里说的字母指的是 Unicode 字符，Unicode 称为万国码，囊括了世界上大部分的文字系统，这也就意味着中文、日文、希腊字母等都可以作为变量名中的字符，但是一些特殊字符（如：`！`、`@`、`#`等）是不能出现在变量名中的。我们强烈建议大家把这里说的字母理解为**尽可能只使用英文字母**。\n  - 规则2：Python 是**大小写敏感**的编程语言，简单的说就是大写的`A`和小写的`a`是两个不同的变量，这一条其实并不算规则，而是需要大家注意的地方。\n  - 规则3：变量名**不要跟 Python 的关键字重名**，**尽可能避开 Python 的保留字**。这里的关键字是指在 Python 程序中有特殊含义的单词（如：`is`、`if`、`else`、`for`、`while`、`True`、`False`等），保留字主要指 Python 语言内置函数、内置模块等的名字（如：`int`、`print`、`input`、`str`、`math`、`os`等）。\n- 惯例部分：\n  - 惯例1：变量名通常使用小写英文字母，多个单词用下划线进行连接。\n  - 惯例2：受保护的变量用单个下划线开头。\n  - 惯例3：私有的变量用两个下划线开头。\n\n惯例2和惯例3大家暂时不用管，讲到后面自然会明白的。当然，作为一个专业的程序员，给变量命名时做到**见名知意**也是非常重要，这彰显了一个程序员的专业气质，很多开发岗位的面试也非常看重这一点。\n\n### 变量的使用\n\n下面通过例子来说明变量的类型和变量的使用。\n\n```python\n\"\"\"\n使用变量保存数据并进行加减乘除运算\n\nVersion: 1.0\nAuthor: 小明\n\"\"\"\na = 45        # 定义变量a，赋值45\nb = 12        # 定义变量b，赋值12\nprint(a, b)   # 45 12\nprint(a + b)  # 57\nprint(a - b)  # 33\nprint(a * b)  # 540\nprint(a / b)  # 3.75\n```\n\n在 Python 中可以使用`type`函数对变量的类型进行检查。程序设计中函数的概念跟数学上函数的概念非常类似，数学上的函数相信大家并不陌生，它包括了函数名、自变量和因变量。如果暂时不理解函数这个概念也不要紧，我们会在后续的内容中专门讲解函数的定义和使用。\n\n```python\n\"\"\"\n使用type函数检查变量的类型\n\nVersion: 1.0\nAuthor: 小明\n\"\"\"\na = 100\nb = 123.45\nc = 'hello, world'\nd = True\nprint(type(a))  # <class 'int'>\nprint(type(b))  # <class 'float'>\nprint(type(c))  # <class 'str'>\nprint(type(d))  # <class 'bool'>\n```\n\n可以通过 Python 内置的函数来改变变量的类型，下面是一些常用的和变量类型相关的函数。\n\n- `int()`：将一个数值或字符串转换成整数，可以指定进制。\n- `float()`：将一个字符串（在可能的情况下）转换成浮点数。\n- `str()`：将指定的对象转换成字符串形式，可以指定编码方式。\n- `chr()`：将整数（字符编码）转换成对应的（一个字符的）字符串。\n- `ord()`：将（一个字符的）字符串转换成对应的整数（字符编码）。\n\n下面的例子为大家演示了Python中类型转换的操作。\n\n```python\n\"\"\"\n变量的类型转换操作\n\nVersion: 1.0\nAuthor: 小明\n\"\"\"\na = 100\nb = 123.45\nc = '123'\nd = '100'\ne = '123.45'\nf = 'hello, world'\ng = True\nprint(float(a))         # int类型的100转成float，输出100.0\nprint(int(b))           # float类型的123.45转成int，输出123\nprint(int(c))           # str类型的'123'转成int，输出123\nprint(int(c, base=16))  # str类型的'123'按十六进制转成int，输出291\nprint(int(d, base=2))   # str类型的'100'按二进制转成int，输出4\nprint(float(e))         # str类型的'123.45'转成float，输出123.45\nprint(bool(f))          # str类型的'hello, world'转成bool，输出True\nprint(int(g))           # bool类型的True转成int，输出1\nprint(chr(a))           # int类型的100转成str，输出'd'\nprint(ord('d'))         # str类型的'd'转成int，输出100\n```\n\n> **说明**：`str`类型转`int`类型时可以通过`base`参数来指定进制，可以将字符串视为对应进制的整数进行转换。`str`类型转成`bool`类型时，只要字符串有内容，不是`''`或`\"\"`，对应的布尔值都是`True`。`bool`类型转`int`类型时，`True`会变成`1`，`False`会变成`0`。在 ASCII 字符集和 Unicode 字符集中， 字符`'d'`对应的编码都是`100`。\n\n### 总结\n\n在 Python 程序中，我们可以**使用变量来保存数据**，**变量有不同的类型**，常用的类型有`int`、`float`、`str`和`bool`。在有需要的情况下，可以通过 Python 内置的函数对变量进行类型转换。变量是可以做运算的，这是解决很多问题的先决条件，我们会在下一课中为大家详细介绍变量的运算。\n", "语言中的运算符": "##  Python语言中的运算符\n\nPython 语言支持很多种运算符，下面的表格按照运算符的优先级从高到低，对 Python 中的运算符进行了罗列。有了变量和运算符，我们就可以构造各种各样的表达式来解决实际问题。在计算机科学中，**表达式是计算机程序中的句法实体，它由一个或多个常量、变量、函数和运算符组合而成，编程语言可以对其进行解释和计算以得到另一个值**。不理解这句话没有关系，但是一定要知道，不管使用什么样的编程语言，构造表达式都是非常重要的。\n\n| 运算符                                                       | 描述                           |\n| ------------------------------------------------------------ | ------------------------------ |\n| `[]`、`[:]`                                                 | 索引、切片                  |\n| `**`                                                         | 幂                             |\n| `~`、`+`、`-`                                              | 按位取反、正号、负号         |\n| `*`、`/`、`%`、`//`                                       | 乘、除、模、整除            |\n| `+`、`-`                                                    | 加、减                        |\n| `>>`、`<<`                                                  | 右移、左移                    |\n| `&`                                                          | 按位与                         |\n| `^`、`|`                                                   | 按位异或、按位或              |\n| `<=`、`<`、`>`、`>=`                                      | 小于等于、小于、大于、大于等于 |\n| `==`、`!=`                                                   | 等于、不等于                  |\n| `is`、`is not`                                               | 身份运算符                     |\n| `in`、`not in`                                                | 成员运算符                     |\n| `not`、`or`、`and`                                             | 逻辑运算符                     |\n| `=`、`+=`、`-=`、`*=`、`/=`、`%=`、`//=`、`**=`、`&=`、`\\|=`、`^=`、`>>=`、`<<=` | 赋值运算符             |\n\n>**说明**： 所谓优先级就是在一个运算的表达式中，如果出现了多个运算符，应该先执行什么再执行什么的顺序。编写代码的时候，如果搞不清楚一个表达式中运算符的优先级，可以使用圆括号（小括号）来确保运算的执行顺序。\n\n### 算术运算符\n\nPython 中的算术运算符非常丰富，除了大家最为熟悉的加、减、乘、除之外，还有整除运算符、求模（求余数）运算符和求幂运算符。下面的例子为大家展示了算术运算符的使用。\n\n```python\n\"\"\"\n算术运算符\n\nVersion: 1.0\nAuthor: 小明\n\"\"\"\nprint(321 + 12)     # 加法运算，输出333\nprint(321 - 12)     # 减法运算，输出309\nprint(321 * 12)     # 乘法运算，输出3852\nprint(321 / 12)     # 除法运算，输出26.75\nprint(321 // 12)    # 整除运算，输出26\nprint(321 % 12)     # 求模运算，输出9\nprint(321 ** 12)    # 求幂运算，输出1196906950228928915420617322241\n```\n\n算术运算需要先乘除后加减，这一点跟数学课本中讲的知识没有区别，也就是说乘除法的运算优先级是高于加减法的。如果还有求幂运算，求幂运算的优先级是高于乘除法的。如果想改变算术运算的执行顺序，可以使用英文输入法状态下的圆括号（小括号），写在圆括号中的表达式会被优先执行，如下面的例子所示。\n\n```python\n\"\"\"\n算术运算的优先级\n\nVersion: 1.0\nAuthor: 小明\n\"\"\"\nprint(2 + 3 * 5)           # 17\nprint((2 + 3) * 5)         # 25\nprint((2 + 3) * 5 ** 2)    # 125\nprint(((2 + 3) * 5) ** 2)  # 625\n```\n\n### 赋值运算符\n\n赋值运算符应该是最为常见的运算符，它的作用是将右边的值赋给左边的变量。赋值运算符还可以跟上面的算术运算符放在一起，组合成复合赋值运算符，例如：`a += b`相当于`a = a + b`，`a *= a + 2`相当于`a = a * (a + 2)`。下面的例子演示了赋值运算符和复合赋值运算符的使用。\n\n```python\n\"\"\"\n赋值运算符和复合赋值运算符\n\nVersion: 1.0\nAuthor: 小明\n\"\"\"\na = 10\nb = 3\na += b        # 相当于：a = a + b\na *= a + 2    # 相当于：a = a * (a + 2)\nprint(a)      # 大家算一下这里会输出什么\n```\n\n赋值运算构成的表达式本身不产生任何值，也就是说，如果你把一个赋值表达式放到`print`函数中试图输出表达式的值，将会产生语法错误。为了解决这个问题，Python 3.8 中引入了一个新的赋值运算符`:=`，我们称之为海象运算符，大家可以猜一猜它为什么叫这个名字。海象运算符也是将运算符右侧的值赋值给左边的变量，与赋值运算符不同的是，运算符右侧的值也是整个表达式的值，看看下面的代码大家就明白了。\n\n```python\n\"\"\"\n海象运算符\n\nVersion: 1.0\nAuthor: 小明\n\"\"\"\n# SyntaxError: invalid syntax\n# print((a = 10))\n# 海象运算符\nprint((a := 10))  # 10\nprint(a)          # 10\n```\n\n> **提示**：上面第 8 行代码如果不注释掉，运行代码会看到`SyntaxError: invalid syntax`错误信息，注意，这行代码中我们给`a = 10`加上了圆括号，如果不小心写成了`print(a = 10)`，会看到`TypeError: 'a' is an invalid keyword argument for print()`错误信息，后面讲到函数的时候，大家就会明白这个错误提示是什么意思了。\n\n### 比较运算符和逻辑运算符\n\n比较运算符也称为关系运算符，包括`==`、`!=`、`<`、`>`、`<=`、`>=`，我相信大家一看就能懂。需要提醒的是比较相等用的是`==`，请注意这里是两个等号，因为`=`是赋值运算符，我们在上面刚刚讲到过。比较不相等用的是`!=`，跟数学课本中使用的$\\small{\\neq}$并不相同，Python 2 中曾经使用过`<>`来表示不等于，在 Python 3 中使用`<>`会引发`SyntaxError`（语法错误）。比较运算符会产生布尔值，要么是`True`，要么是`False`。\n\n逻辑运算符有三个，分别是`and`、`or`和`not`。`and`字面意思是“而且”，所以`and`运算符会连接两个布尔值或者产生布尔值的表达式，如果两边的布尔值都是`True`，那么运算的结果就是`True`；左右两边的布尔值有一个是`False`，最终的运算结果就是`False`。当然，如果`and`运算符左边的布尔值是`False`，不管右边的布尔值是什么，最终的结果都是`False`，这时运算符右边的布尔值会被跳过（专业的说法叫短路处理，如果`and`右边是一个表达式，那么这个表达式不会执行）。`or`字面意思是“或者”，所以`or`运算符也会连接两个布尔值或产生布尔值的表达式，如果两边的布尔值有任意一个是`True`，那么最终的结果就是`True`。当然，`or`运算符也是有短路功能的，当它左边的布尔值为`True`的情况下，右边的布尔值会被短路（如果`or`右边是一个表达式，那么这个表达式不会执行）。`not`运算符的后面可以跟一个布尔值，如果`not`后面的布尔值或表达式是`True`，那么运算的结果就是`False`；如果`not`后面的布尔值或表达式是`False`，那么运算的结果就是`True`。\n\n```python\n\"\"\"\n比较运算符和逻辑运算符的使用\n\nVersion: 1.0\nAuthor: 小明\n\"\"\"\nflag0 = 1 == 1\nflag1 = 3 > 2\nflag2 = 2 < 1\nflag3 = flag1 and flag2\nflag4 = flag1 or flag2\nflag5 = not flag0\nprint('flag0 =', flag0)     # flag0 = True\nprint('flag1 =', flag1)     # flag1 = True\nprint('flag2 =', flag2)     # flag2 = False\nprint('flag3 =', flag3)     # flag3 = False\nprint('flag4 =', flag4)     # flag4 = True\nprint('flag5 =', flag5)     # flag5 = False\nprint(flag1 and not flag2)  # True\nprint(1 > 2 or 2 == 3)      # False\n```\n\n> **说明**：比较运算符的优先级高于赋值运算符，所以上面的`flag0 = 1 == 1`先做`1 == 1`产生布尔值`True`，再将这个值赋值给变量`flag0`。`print`函数可以输出多个值，多个值之间可以用`,`进行分隔，输出的内容默认以空格分开。\n\n### 运算符和表达式应用\n\n#### 例子1：华氏温度转摄氏温度\n\n要求：输入华氏温度将其转换为摄氏温度，华氏温度到摄氏温度的转换公式为： $\\small{C = (F - 32) / 1.8}$ 。\n\n```python\n\"\"\"\n将华氏温度转换为摄氏温度\n\nVersion: 1.0\nAuthor: 小明\n\"\"\"\nf = float(input('请输入华氏温度: '))\nc = (f - 32) / 1.8\nprint('%.1f华氏度 = %.1f摄氏度' % (f, c))\n```\n\n> **说明**：上面代码中的`input`函数用于从键盘接收用户输入，由于输入的都是字符串，如果想处理成浮点小数来做后续的运算，可以用我们上一课讲解的类型转换的方法，用`float`函数将`str`类型处理成`float`类型。\n\n上面的代码中，我们对`print`函数输出的内容进行了格式化处理，`print`输出的字符串中有两个`%.1f`占位符，这两个占位符会被`%`之后的`(f, c)`中的两个`float`类型的变量值给替换掉，浮点数小数点后保留1位有效数字。如果字符串中有`%d`占位符，那么我们会用`int`类型的值替换掉它，如果字符串中有`%s`占位符，那么它会被`str`类型的值替换掉。\n\n除了上面格式化输出的方式外，Python 中还可以用下面的办法来格式化输出，我们给出一个带占位符的字符串，字符串前面的`f`表示这个字符串是需要格式化处理的，其中的`{f:.1f}`和`{c:.1f}`可以先看成是`{f}`和`{c}`，表示输出时会用变量`f`和变量`c`的值替换掉这两个占位符，后面的`:.1f`表示这是一个浮点数，小数点后保留1位有效数字。\n\n```python\n\"\"\"\n将华氏温度转换为摄氏温度\n\nVersion: 1.1\nAuthor: 小明\n\"\"\"\nf = float(input('请输入华氏温度: '))\nc = (f - 32) / 1.8\nprint(f'{f:.1f}华氏度 = {c:.1f}摄氏度')\n```\n\n#### 例子2：计算圆的周长和面积\n\n要求：输入一个圆的半径，计算出它的周长（ $\\small{2 \\pi r}$ ）和面积（ $\\small{\\pi r^{2}}$ ）。\n\n```python\n\"\"\"\n输入半径计算圆的周长和面积\n\nVersion: 1.0\nAuthor: 小明\n\"\"\"\nradius = float(input('请输入圆的半径: '))\nperimeter = 2 * 3.1416 * radius\narea = 3.1416 * radius * radius\nprint('周长: %.2f' % perimeter)\nprint('面积: %.2f' % area)\n```\n\nPython 中有一个名为`math` 的内置模块，该模块中定义了名为`pi`的变量，它的值就是圆周率。如果要使用 Python 内置的这个`pi`，我们可以对上面的代码稍作修改。\n\n```python\n\"\"\"\n输入半径计算圆的周长和面积\n\nVersion: 1.1\nAuthor: 小明\n\"\"\"\nimport math\n\nradius = float(input('请输入圆的半径: '))\nperimeter = 2 * math.pi * radius\narea = math.pi * radius ** 2\nprint(f'周长: {perimeter:.2f}')\nprint(f'面积: {area:.2f}')\n```\n\n> **说明**：上面代码中的`import math`表示导入`math`模块，导入该模块以后，才能用`math.pi`得到圆周率的值。\n\n这里其实还有一种格式化输出的方式，是 Python 3.8 中增加的新特性，大家直接看下面的代码就明白了。\n\n```python\n\"\"\"\n输入半径计算圆的周长和面积\n\nVersion: 1.2\nAuthor: 小明\n\"\"\"\nimport math\n\nradius = float(input('请输入圆的半径: '))  # 输入: 5.5\nperimeter = 2 * math.pi * radius\narea = math.pi * radius ** 2\nprint(f'{perimeter = :.2f}')  # 输出：perimeter = 34.56\nprint(f'{area = :.2f}')       # 输出：area = 95.03\n```\n\n> **说明**：假如变量`a`的值是`9.87`，那么字符串`f'{a = }'`的值是`a = 9.87`；而字符串`f'{a = :.1f}'`的值是`a = 9.9`。这种格式化输出的方式会同时输出变量名和变量值。\n\n#### 例子3：判断闰年\n\n要求：输入一个 1582 年以后的年份，判断该年份是不是闰年。\n\n```python\n\"\"\"\n输入年份，闰年输出True，平年输出False\n\nVersion: 1.0\nAuthor: 小明\n\"\"\"\nyear = int(input('请输入年份: '))\nis_leap = year % 4 == 0 and year % 100 != 0 or year % 400 == 0\nprint(f'{is_leap = }')\n```\n\n> **说明**：对于格里历（Gregorian calendar），即今天我们使用的公历，判断闰年的规则是：1. 公元年份非4的倍数是平年；2. 公元年份为4的倍数但非100的倍数是闰年；3. 公元年份为400的倍数是闰年。格里历是由教皇格里高利十三世在1582年10月引入的，作为对儒略历（Julian calendar）的修改和替代，我们在输入年份时要注意这一点。上面的代码通过`%`来判断`year`是不是`4`的倍数、`100`的倍数、`400`的倍数，然后用`and`和`or`运算符将三个条件组装在一起，前两个条件要同时满足，第三个条件跟前两个条件的组合只需满足其中之一。\n\n### 总结\n\n通过上面的讲解和例子，相信大家已经感受到了运算符和表达式的力量。实际编程中的很多问题，都需通过构造表达式来解决，所以变量、运算符、表达式对于任何一门编程语言都是极为重要的基础。如果本节课的内容有什么不理解的地方，一定不要着急进入下一课，先在评论区留言讨论，我会及时解答大家的问题。\n", "分支结构": "## 分支结构\n\n迄今为止，我们写的 Python 程序都是一条一条语句按顺序向下执行的，这种代码结构叫做顺序结构。然而仅有顺序结构并不能解决所有的问题，比如我们设计一个游戏，游戏第一关的过关条件是玩家获得1000分，那么在第一关完成后，我们要根据玩家得到的分数来决定是进入第二关，还是告诉玩家“Game Over”（游戏结束）。在这种场景下，我们的代码就会产生两个分支，而且只有一个会被执行。类似的场景还有很多，我们将这种结构称之为“分支结构”或“选择结构”。给大家一分钟的时间，你应该可以想到至少5个以上类似的例子，赶紧试一试吧！\n\n### 使用if和else构造分支结构\n\n在 Python 中，构造分支结构最常用的是`if`、`elif`和`else`三个关键字。所谓**关键字**就是编程语言中有特殊含义的单词，很显然你不能够使用它作为变量名。当然，我们并不是每次构造分支结构都会把三个关键字全部用上，我们通过例子加以说明。例如我们要写一个身体质量指数（BMI）的计算器。身体质量质数也叫体质指数，是国际上常用的衡量人体胖瘦程度以及是否健康的一个指标，计算公式如下所示。通常认为 $\\small{18.5 \\le BMI < 24}$ 是正常范围， $\\small{BMI < 18.5}$ 说明体重过轻， $\\small{BMI \\ge 24}$ 说明体重过重， $\\small{BMI \\ge 27}$ 就属于肥胖的范畴了。\n\n$$\nBMI = \\frac{体重}{身高^{2}}\n$$\n\n> **说明**：上面公式中的体重以千克（kg）为单位，身高以米（m）为单位。\n\n```python\n\"\"\"\nBMI计算器\n\nVersion: 1.0\nAuthor: 小明\n\"\"\"\nheight = float(input('身高(cm)：'))\nweight = float(input('体重(kg)：'))\nbmi = weight / (height / 100) ** 2\nprint(f'{bmi = :.1f}')\nif 18.5 <= bmi < 24:\n    print('你的身材很棒！')\n```\n\n> **提示**：`if`语句的最后面有一个`:`，它是用英文输入法输入的冒号；程序中输入的`'`、`\"`、`=`、`(`、`)`等特殊字符，都是在英文输入法状态下输入的，这一点之前已经提醒过大家了。很多初学者经常会忽略这一点，等到执行代码时，就会看到一大堆错误提示。当然，认真读一下错误提示还是很容易发现哪里出了问题，但是**强烈建议**大家在写代码的时候**切换到英文输入法**，这样可以避免很多不必要的麻烦。\n\n上面的代码中，我们在计算和输出 BMI 之后，加上了一段分支结构，如果满足 $\\small{18.5 \\le BMI < 24}$ ，程序会输出“你的身材很棒！”，但是如果不满足条件，这段输出就没有了。这就是刚才提到的，代码可以有不同的执行路径，有些代码不一定会执行到。我们在`if`关键字的后面给出了一个表达式`18.5 <= bmi < 24`，之前我们说过，关系运算会产生布尔值，如果`if`后面的布尔值为`True`，那么`if`语句下方，有四个空格缩进的`print('你的身材很棒！')`就会被执行。我们先输入几组数据运行上面的代码，如下所示。\n\n第一组输入：\n\n```\n身高(cm)：175\n体重(kg)：68\nbmi = 22.2\n你的身材很棒！\n```\n\n第二组输入：\n\n```\n身高(cm)：175\n体重(kg)：95\nbmi = 31.0\n```\n\n第三组输入：\n\n```\n身高(cm)：175\n体重(kg)：50\nbmi = 16.3\n```\n\n只有第一组输入的身高和体重计算出的 BMI 在 18.5 到 24 这个范围值内，所以触发了`if`条件，输出了“你的身材很棒”。需要说明的是，不同于 C、C++、Java 等编程语言，Python 中没有用花括号来构造代码块而是**使用缩进的方式来表示代码的层次结构**，如果`if`条件成立的情况下需要执行多条语句，只要保持多条语句具有相同的缩进就可以了。换句话说，若干行连续的语句如果保持了相同的缩进，那么它们就属于同一个**代码块**，相当于是一个执行的整体。缩进可以使用任意数量的空格，但**通常使用4个空格**，强烈建议大家**不要使用制表键（Tab键）来缩进代码**，如果你已经习惯了这么做，可以设置你的代码编辑器自动将 1 个制表键变成 4 个空格，很多代码编辑器都支持这项功能，PyCharm 中默认也是这样设定的。还有一点，在 C、C++、Java 等编程语言中，`18.5 <= bmi < 24`要写成两个条件`bmi >= 18.5`和`bmi < 24`，然后把两个条件用与运算符连接起来，Python 中也可以这么做，例如刚才的`if`语句也可以写成`if bmi >= 18.5 and bmi < 24:`，但是没有必要，难道`if 18.5 <= bmi < 24:`这个写法它不香吗？下面用 Java 代码做了同样的事情，看不懂 Java 代码没关系，感受一下它和 Python 语法的区别就可以了。\n\n```java\nimport java.util.Scanner;\n\nclass Test {\n\n    public static void main(String[] args) {\n        try (Scanner sc = new Scanner(System.in)) {\n            System.out.print(\"身高(cm): \");\n            double height = sc.nextDouble();\n            System.out.print(\"体重(kg): \");\n            double weight = sc.nextDouble();\n            double bmi = weight / Math.pow(height / 100, 2);\n            System.out.printf(\"bmi = %.1f\\n\", bmi);\n            if (bmi >= 18.5 && bmi < 24) {\n                System.out.println(\"你的身材很棒！\");\n            }\n        }\n    }\n}\n```\n\n> **说明**：上面就是 BMI 计算器 1.0 版本对应的 Java 代码，很多人喜欢 Python 语言不是没有道理的，通常它都能用更少的代码解决同样的问题。\n\n接下来，我们对上面的代码稍作修改，在 BMI 不满足 $\\small{18.5 \\le BMI < 24}$ 的情况下，也给出相信的提示信息。我们可以在`if`代码块的后面增加一个`else`代码块，它会在`if`语句给出的条件没有达成时执行，如下所示。很显然，`if`下面的`print('你的身材很棒！')`和`else`下面的`print('你的身材不够标准哟！')`只有一个会被执行到。\n\n```python\n\"\"\"\nBMI计算器\n\nVersion: 1.1\nAuthor: 小明\n\"\"\"\nheight = float(input('身高(cm)：'))\nweight = float(input('体重(kg)：'))\nbmi = weight / (height / 100) ** 2\nprint(f'{bmi = :.1f}')\nif 18.5 <= bmi < 24:\n    print('你的身材很棒！')\nelse:\n    print('你的身材不够标准哟！')\n```\n\n如果要给出更为准确的提示信息，我们可以再次修改上面的代码，通过`elif`关键字为上面的分支结构增加更多的分支，如下所示。\n\n```python\n\"\"\"\nBMI计算器\n\nVersion: 1.2\nAuthor: 小明\n\"\"\"\nheight = float(input('身高(cm)：'))\nweight = float(input('体重(kg)：'))\nbmi = weight / (height / 100) ** 2\nprint(f'{bmi = :.1f}')\nif bmi < 18.5:\n    print('你的体重过轻！')\nelif bmi < 24:\n    print('你的身材很棒！')\nelif bmi < 27:\n    print('你的体重过重！')\nelif bmi < 30:\n    print('你已轻度肥胖！')\nelif bmi < 35:\n    print('你已中度肥胖！')\nelse:\n    print('你已重度肥胖！')\n```\n\n我们再用刚才的三组数据来测试下上面的代码，看看会得到怎样的结果。\n\n第一组输入：\n\n```\n身高(cm)：175\n体重(kg)：68\nbmi = 22.2\n你的身材很棒！\n```\n\n第二组输入：\n\n```\n身高(cm)：175\n体重(kg)：95\nbmi = 31.0\n你已中度肥胖！\n```\n\n第三组输入：\n\n```\n身高(cm)：175\n体重(kg)：50\nbmi = 16.3\n你的体重过轻！\n```\n\n### 使用match和case构造分支结构\n\nPython 3.10 中增加了一种新的构造分支结构的方式，通过使用`match`和`case` 关键字，我们可以轻松的构造出多分支结构。Python 的官方文档在介绍这个新语法时，举了一个 HTTP 响应状态码识别的例子（根据 HTTP 响应状态输出对应的描述），非常有意思。如果不知道什么是 HTTP 响应状态吗，可以看看 MDN 上面的[文档](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status)。下面我们对官方文档上的示例稍作修改，为大家讲解这个语法，先看看下面用`if-else`结构实现的代码。\n\n```python\nstatus_code = int(input('响应状态码: '))\nif status_code == 400:\n    description = 'Bad Request'\nelif status_code == 401:\n    description = 'Unauthorized'\nelif status_code == 403:\n    description = 'Forbidden'\nelif status_code == 404:\n    description = 'Not Found'\nelif status_code == 405:\n    description = 'Method Not Allowed'\nelif status_code == 418:\n    description = 'I am a teapot'\nelif status_code == 429:\n    description = 'Too many requests'\nelse:\n    description = 'Unknown status Code'\nprint('状态码描述:', description)\n```\n\n运行结果：\n\n```\n响应状态码: 403\n状态码描述: Forbidden\n```\n\n下面是使用`match-case`语法实现的代码，虽然作用完全相同，但是代码显得更加简单优雅。\n\n```python\nstatus_code = int(input('响应状态码: '))\nmatch status_code:\n    case 400: description = 'Bad Request'\n    case 401: description = 'Unauthorized'\n    case 403: description = 'Forbidden'\n    case 404: description = 'Not Found'\n    case 405: description = 'Method Not Allowed'\n    case 418: description = 'I am a teapot'\n    case 429: description = 'Too many requests'\n    case _: description = 'Unknown Status Code'\nprint('状态码描述:', description)\n```\n\n> **说明**：带有`_`的`case`语句在代码中起到通配符的作用，如果前面的分支都没有匹配上，代码就会来到`case _`。`case _`的是可选的，并非每种分支结构都要给出通配符选项。如果分支中出现了`case _`，它只能放在分支结构的最后面，如果它的后面还有其他的分支，那么这些分支将是不可达的。\n\n当然，`match-case`语法还有很多高级玩法，其中有一个合并模式可以先教给大家。例如，我们要将响应状态码`401`、`403`和`404`归入一个分支，`400`和`405`归入到一个分支，其他保持不变，代码还可以这么写。\n\n```python\nstatus_code = int(input('响应状态码: '))\nmatch status_code:\n    case 400 | 405: description = 'Invalid Request'\n    case 401 | 403 | 404: description = 'Not Allowed'\n    case 418: description = 'I am a teapot'\n    case 429: description = 'Too many requests'\n    case _: description = 'Unknown Status Code'\nprint('状态码描述:', description)\n```\n\n运行结果：\n\n```\n响应状态码: 403\n状态码描述: Not Allowed\n```\n\n### 分支结构的应用\n\n#### 例子1：分段函数求值\n\n有如下所示的分段函数，要求输入`x`，计算出`y`。\n\n$$\ny = \\begin{cases} 3x - 5, & (x \\gt 1) \\\\\\\\ x + 2, & (-1 \\le x \\le 1) \\\\\\\\ 5x + 3, & (x \\lt -1) \\end{cases}\n$$\n\n```python\n\"\"\"\n分段函数求值\n\nVersion: 1.0\nAuthor: 小明\n\"\"\"\nx = float(input('x = '))\nif x > 1:\n    y = 3 * x - 5\nelif x >= -1:\n    y = x + 2\nelse:\n    y = 5 * x + 3\nprint(f'{y = }')\n```\n\n根据实际开发的需要，分支结构是可以嵌套的，也就是说在分支结构的`if`、`elif`或`else`代码块中还可以再次引入分支结构。例如`if`条件成立表示玩家过关，但过关以后还要根据你获得宝物或者道具的数量对你的表现给出评价（比如点亮一颗、两颗或三颗星星），那么我们就需要在`if`的内部再构造一个新的分支结构。同理，我们在`elif`和`else`中也可以构造新的分支，我们称之为嵌套的分支结构。按照这样的思路，上面的分段函数求值也可以用下面的代码来实现。\n\n```python\n\"\"\"\n分段函数求值\n\nVersion: 1.1\nAuthor: 小明\n\"\"\"\nx = float(input('x = '))\nif x > 1:\n    y = 3 * x - 5\nelse:\n    if x >= -1:\n        y = x + 2\n    else:\n        y = 5 * x + 3\nprint(f'{y = }')\n```\n\n> **说明**：大家可以自己感受和评判一下上面两种写法哪一种更好。在“[**Python 之禅**](https://zhuanlan.zhihu.com/p/111843067)”中有这么一句话：“**Flat is better than nested**”。之所以认为“扁平化”的代码更好，是因为代码嵌套的层次如果很多，会严重的影响代码的可读性。所以，我个人更推荐大家使用第一种写法。\n\n#### 例子2：百分制成绩转换成等级\n\n要求：如果输入的成绩在90分以上（含90分），则输出`A`；输入的成绩在80分到90分之间（不含90分），则输出`B`；输入的成绩在70分到80分之间（不含80分），则输出`C`；输入的成绩在60分到70分之间（不含70分），则输出`D`；输入的成绩在60分以下，则输出`E`。\n\n```python\n\"\"\"\n百分制成绩转换为等级制成绩\n\nVersion: 1.0\nAuthor: 小明\n\"\"\"\nscore = float(input('请输入成绩: '))\nif score >= 90:\n    grade = 'A'\nelif score >= 80:\n    grade = 'B'\nelif score >= 70:\n    grade = 'C'\nelif score >= 60:\n    grade = 'D'\nelse:\n    grade = 'E'\nprint(f'{grade = }')\n```\n#### 例子3：计算三角形的周长和面积。\n\n要求：输入三条边的长度，如果能构成三角形就计算周长和面积；否则给出“不能构成三角形”的提示。\n\n```python\n\"\"\"\n计算三角形的周长和面积\n\nVersion: 1.0\nAuthor: 小明\n\"\"\"\na = float(input('a = '))\nb = float(input('b = '))\nc = float(input('c = '))\nif a + b > c and a + c > b and b + c > a:\n    perimeter = a + b + c\n    print(f'周长: {perimeter}')\n    s = perimeter / 2\n    area = (s * (s - a) * (s - b) * (s - c)) ** 0.5\n    print(f'面积: {area}')\nelse:\n    print('不能构成三角形')\n```\n> **说明：** 上面的`if` 条件表示任意两边之和大于第三边，这是构成三角形的必要条件。当这个条件成立时，我们要计算并输出周长和面积，所以`if`下方有五条语句都保持了相同的缩进，它们是一个整体，只要`if`条件成立，它们都会被执行，这就是我们之前提到的代码块的概念。另外，上面计算三角形面积的公式叫做海伦公式，假设有一个三角形，边长分别为 $\\small{a}$ 、 $\\small{b}$ 、 $\\small{c}$ ，那么三角的面积 $\\small{A}$ 可以由公式 $\\small{A = \\sqrt{s(s-a)(s-b)(s-c)}}$ 得到，其中， $s=\\frac{a + b + c}{2}$ 表示半周长。\n\n### 总结\n\n学会了 Python 中的分支结构和循环结构，我们就可以解决很多实际的问题了。这一节课相信已经帮助大家掌握了构造分支结构的方法，下一节课我们为大家介绍循环结构，学完这两次课你一定会发现，你能写出很多很有意思的代码，继续加油吧！\n", "循环结构": "## 循环结构\n\n我们在写程序的时候，极有可能遇到需要重复执行某条或某些指令的场景，例如我们需要每隔1秒钟在屏幕上输出一次“hello, world”并持续输出一个小时。如下所示的代码可以完成一次这样的操作，如果要持续输出一个小时，我们就需要把这段代码写3600遍，你愿意这么做吗？\n\n```python\nimport time\n\nprint('hello, world')\ntime.sleep(1)\n```\n\n> **说明**：Python 内置`time`模块的`sleep`函数可以实现程序的休眠，参数`1`表示休眠的秒数，可以使用`int`或`float`类型，例如`0.05`表示`50`毫秒。关于函数和模块的知识，我们在后续的课程中会为大家讲解。\n\n为了应对上述场景中的问题，我们可以在 Python 程序中使用循环结构。所谓循环结构，就是程序中控制某条或某些指令重复执行的结构。有了这样的结构，刚才的代码就不需要写 3600 遍，而是写一遍然后放到循环结构中重复 3600 次。在 Python 语言中构造循环结构有两种做法，一种是`for-in`循环，另一种是`while`循环。\n\n### for-in循环\n\n如果明确知道循环执行的次数，我们推荐使用`for-in`循环，例如上面说的那个重复3600次的场景，我们可以用下面的代码来实现。 注意，被`for-in`循环控制的代码块也是通过缩进的方式来构造，这一点跟分支结构中构造代码块的做法是一样的。我们被`for-in`循环控制的代码块称为循环体，通常循环体中的语句会根据循环的设定被重复执行。\n\n```python\n\"\"\"\n每隔1秒输出一次“hello, world”，持续1小时\n\nAuthor: 小明\nVersion: 1.0\n\"\"\"\nimport time\n\nfor i in range(3600):\n    print('hello, world')\n    time.sleep(1)\n```\n\n需要说明的是，上面代码中的`range(3600)`可以构造出一个从`0`到`3599`的范围，当我们把这样一个范围放到`for-in`循环中，就可以通过前面的循环变量`i`依次取出从`0`到`3599`的整数，这就会让`for-in`代码块中的语句重复 3600 次。当然，`range`的用法非常灵活，下面的清单给出了使用`range`函数的例子：\n\n- `range(101)`：可以用来产生`0`到`100`范围的整数，需要注意的是取不到`101`。\n- `range(1, 101)`：可以用来产生`1`到`100`范围的整数，相当于是左闭右开的设定，即`[1, 101)`。\n- `range(1, 101, 2)`：可以用来产生`1`到`100`的奇数，其中`2`是步长（跨度），即每次递增的值，`101`取不到。\n- `range(100, 0, -2)`：可以用来产生`100`到`1`的偶数，其中`-2`是步长（跨度），即每次递减的值，`0`取不到。\n\n大家可能已经注意到了，上面代码的输出操作和休眠操作都没有用到循环变量`i`，对于不需要用到循环变量的`for-in`循环结构，按照 Python 的编程惯例，我们通常把循环变量命名为`_`，修改后的代码如下所示。虽然结果没什么变化，但是这样写显得你更加专业，逼格瞬间拉满。\n\n```python\n\"\"\"\n每隔1秒输出一次“hello, world”，持续1小时\n\nAuthor: 小明\nVersion: 1.1\n\"\"\"\nimport time\n\nfor _ in range(3600):\n    print('hello, world')\n    time.sleep(1)\n```\n\n上面的代码要执行一个小时，如果想提前结束程序，在 PyCharm 中可以点击运行窗口上的停止按钮，如下图所示。如果在命令提示符或终端中运行代码，可以使用组合键`ctrl+c`来终止程序。\n\n<img class=\"lazy\" data-src=\"/res/day06/terminate_program.png\" style=\"zoom:40%;\">\n\n下面，我们用`for-in`循环实现从 1 到 100 的整数求和，即 $\\small{\\sum_{n=1}^{100}{n}}$ 。\n\n```python\n\"\"\"\n从1到100的整数求和\n\nVersion: 1.0\nAuthor: 小明\n\"\"\"\ntotal = 0\nfor i in range(1, 101):\n    total += i\nprint(total)\n```\n\n上面的代码中，变量`total`的作用是保存累加的结果。在循环的过程中，循环变量`i`的值会从 1 一直取到 100。对于变量`i`的每个取值，我们都执行了`total += i`，它相当于`total = total + i`，这条语句实现了累加操作。所以，当循环结束，我们输出变量`total` 的值，它的值就是从 1 累加到 100 的结果 5050。注意，`print(total)`这条语句前是没有缩进的，它不受`for-in`循环的控制，不会重复执行。\n\n我们再来写一个从1到100偶数求和的代码，如下所示。\n\n```python\n\"\"\"\n从1到100的偶数求和\n\nVersion: 1.0\nAuthor: 小明\n\"\"\"\ntotal = 0\nfor i in range(1, 101):\n    if i % 2 == 0:\n        total += i\nprint(total)\n```\n\n> **说明**：上面的`for-in`循环中我们使用了分支结构来判断循环变量`i`是不是偶数。\n\n我们也可以修改`range`函数的参数，将起始值和跨度修改为`2`，用更为简单的代码实现从 1 到 100 的偶数求和。\n\n```python\n\"\"\"\n从1到100的偶数求和\n\nVersion: 1.1\nAuthor: 小明\n\"\"\"\ntotal = 0\nfor i in range(2, 101, 2):\n    total += i\nprint(total)\n```\n\n当然， 更为简单的办法是使用 Python 内置的`sum`函数求和，这样我们连循环结构都省掉了。\n\n```python\n\"\"\"\n从1到100的偶数求和\n\nVersion: 1.2\nAuthor: 小明\n\"\"\"\nprint(sum(range(2, 101, 2)))\n```\n\n### while循环\n\n如果要构造循环结构但是又不能确定循环重复的次数，我们推荐使用`while`循环。`while`循环通过布尔值或能产生布尔值的表达式来控制循环，当布尔值或表达式的值为`True`时，循环体（`while`语句下方保持相同缩进的代码块）中的语句就会被重复执行，当表达式的值为`False`时，结束循环。\n\n下面我们用`while`循环来实现从 1 到 100 的整数求和，代码如下所示。\n\n```python\n\"\"\"\n从1到100的整数求和\n\nVersion: 1.1\nAuthor: 小明\n\"\"\"\ntotal = 0\ni = 1\nwhile i <= 100:\n    total += i\n    i += 1\nprint(total)\n```\n\n相较于`for-in`循环，上面的代码我们在循环开始前增加了一个变量`i`，我们使用这个变量来控制循环，所以`while`后面给出了`i <= 100`的条件。在`while`的循环体中，我们除了做累加，还需要让变量`i`的值递增，所以我们添加了`i += 1`这条语句，这样`i`的值就会依次取到1、2、3、……，直到 101。当`i`变成 101 时，`while`循环的条件不再成立，代码会离开`while`循环，此时我们输出变量`total`的值，它就是从 1 到 100 求和的结果 5050。\n\n如果要实现从 1 到 100 的偶数求和，我们可以对上面的代码稍作修改。\n\n```python\n\"\"\"\n从1到100的偶数求和\n\nVersion: 1.3\nAuthor: 小明\n\"\"\"\ntotal = 0\ni = 2\nwhile i <= 100:\n    total += i\n    i += 2\nprint(total)\n```\n\n### break和continue\n\n如果把`while`循环的条件设置为`True`，即让条件恒成立会怎么样呢？我们看看下面的代码，还是使用`while`构造循环结构，计算 1 到 100 的偶数和。\n\n```python\n\"\"\"\n从1到100的偶数求和\n\nVersion: 1.4\nAuthor: 小明\n\"\"\"\ntotal = 0\ni = 2\nwhile True:\n    total += i\n    i += 2\n    if i > 100:\n        break\nprint(total) \n```\n\n上面的代码中使用`while True`构造了一个条件恒成立的循环，也就意味着如果不做特殊处理，循环是不会结束的，这就是我们常说的“死循环”。为了在`i`的值超过 100 后让循环停下来，我们使用了`break`关键字，它的作用是终止循环结构的执行。需要注意的是，`break`只能终止它所在的那个循环，这一点在使用嵌套循环结构时需要引起注意，后面我们会讲到什么是嵌套的循环结构。除了`break`之外，还有另一个在循环结构中可以使用的关键字`continue`，它可以用来放弃本次循环后续的代码直接让循环进入下一轮，代码如下所示。\n\n```python\n\"\"\"\n从1到100的偶数求和\n\nVersion: 1.5\nAuthor: 小明\n\"\"\"\ntotal = 0\nfor i in range(1, 101):\n    if i % 2 != 0:\n        continue\n    total += i\nprint(total)\n```\n\n> **说明**：上面的代码使用`continue`关键字跳过了`i`是奇数的情况，只有在`i`是偶数的前提下，才会执行到`total += i`。\n\n### 嵌套的循环结构\n\n和分支结构一样，循环结构也是可以嵌套的，也就是说在循环结构中还可以构造循环结构。下面的例子演示了如何通过嵌套的循环来输出一个乘法口诀表（九九表）。\n\n```python\n\"\"\"\n打印乘法口诀表\n\nVersion: 1.0\nAuthor: 小明\n\"\"\"\nfor i in range(1, 10):\n    for j in range(1, i + 1):\n        print(f'{i}×{j}={i * j}', end='\\t')\n    print()\n```\n\n上面的代码中，`for-in`循环的循环体中又用到了`for-in`循环，外面的循环用来控制产生`i`行的输出，而里面的循环则用来控制在一行中输出`j`列。显然，里面的`for-in`循环的输出就是乘法口诀表中的一整行。所以在里面的循环完成时，我们用了一个`print()`来实现换行的效果，让下面的输出重新另起一行，最后的输出如下所示。\n\n```\n1×1=1\t\n2×1=2\t2×2=4\t\n3×1=3\t3×2=6\t3×3=9\t\n4×1=4\t4×2=8\t4×3=12\t4×4=16\t\n5×1=5\t5×2=10\t5×3=15\t5×4=20\t5×5=25\t\n6×1=6\t6×2=12\t6×3=18\t6×4=24\t6×5=30\t6×6=36\t\n7×1=7\t7×2=14\t7×3=21\t7×4=28\t7×5=35\t7×6=42\t7×7=49\t\n8×1=8\t8×2=16\t8×3=24\t8×4=32\t8×5=40\t8×6=48\t8×7=56\t8×8=64\t\n9×1=9\t9×2=18\t9×3=27\t9×4=36\t9×5=45\t9×6=54\t9×7=63\t9×8=72\t9×9=81\n```\n\n### 循环结构的应用\n\n#### 例子1：判断素数\n\n要求：输入一个大于 1 的正整数，判断它是不是素数。\n\n> **提示**：素数指的是只能被 1 和自身整除的大于 1 的整数。例如对于正整数 $\\small{n}$，我们可以通过在 2 到 $\\small{n - 1}$ 之间寻找有没有 $\\small{n}$ 的因子，来判断它到底是不是一个素数。当然，循环不用从 2 开始到 $\\small{n - 1}$ 结束，因为对于大于 1 的正整数，因子应该都是成对出现的，所以循环到 $\\small{\\sqrt{n}}$ 就可以结束了。\n\n```python\n\"\"\"\n输入一个大于1的正整数判断它是不是素数\n\nVersion: 1.0\nAuthor: 小明\n\"\"\"\nnum = int(input('请输入一个正整数: '))\nend = int(num ** 0.5)\nis_prime = True\nfor i in range(2, end + 1):\n    if num % i == 0:\n        is_prime = False\n        break\nif is_prime:\n    print(f'{num}是素数')\nelse:\n    print(f'{num}不是素数')\n```\n\n> **说明**：上面的代码中我们用了布尔型的变量`is_prime`，我们先将它赋值为`True`，假设`num`是一个素数；接下来，我们在 2 到`num ** 0.5`的范围寻找`num`的因子，如果找到了`num`的因子，那么它一定不是素数，此时我们将`is_prime`赋值为`False`，同时使用`break`关键字终止循环结构；最后，我们根据`is_prime`的值是`True`还是`False`来给出不同的输出。\n\n#### 例子2：最大公约数\n\n要求：输入两个大于 0 的正整数，求两个数的最大公约数。\n\n> **提示**：两个数的最大公约数是两个数的公共因子中最大的那个数。\n\n```python\n\"\"\"\n输入两个正整数求它们的最大公约数\n\nVersion: 1.0\nAuthor: 小明\n\"\"\"\nx = int(input('x = '))\ny = int(input('y = '))\nfor i in range(x, 0, -1):\n    if x % i == 0 and y % i == 0:\n        print(f'最大公约数: {i}')\n        break\n```\n\n> **说明**：上面代码中`for-in`循环的循环变量值是从大到小的，这样我们找到的能够同时整除`x`和`y`的因子`i`，就是`x`和`y`的最大公约数，此时我们用`break`终止循环。如果`x`和`y`互质，那么循环会执行到`i`变成 1，因为 1 是所有正整数的因子，此时`x`和`y`的最大公约数就是 1。\n\n用上面代码的找最大公约数在执行效率是有问题的。假如`x`的值是`999999999998`，`y`的值是`999999999999`，很显然两个数是互质的，最大公约数为 1。但是我们使用上面的代码，循环会重复`999999999998`次，这通常是难以接受的。我们可以使用欧几里得算法来找最大公约数，它能帮我们更快的得到想要的结果，代码如下所示。\n\n```python\n\"\"\"\n输入两个正整数求它们的最大公约数\n\nVersion: 1.1\nAuthor: 小明\n\"\"\"\nx = int(input('x = '))\ny = int(input('y = '))\nwhile y % x != 0:\n    x, y = y % x, x\nprint(f'最大公约数: {x}')\n```\n\n> **说明**：解决问题的方法和步骤可以称之为算法，对于同一个问题，我们可以设计出不同的算法，不同的算法在存储空间的占用和执行效率上都会存在差别，而这些差别就代表了算法的优劣。大家可以对比上面的两段待会，体会一下为什么我们说欧几里得算法是更好的选择。上面的代码中`x, y = y % x, x`语句表示将`y % x`的值赋给`x`，将`x` 原来的值赋给`y`。\n\n#### 例子3：猜数字游戏\n\n要求：计算机出一个 1 到 100 之间的随机数，玩家输入自己猜的数字，计算机给出对应的提示信息“大一点”、“小一点”或“猜对了”，如果玩家猜中了数字，计算机提示用户一共猜了多少次，游戏结束，否则游戏继续。\n\n```python\n\"\"\"\n猜数字小游戏\n\nVersion: 1.0\nAuthor: 小明\n\"\"\"\nimport random\n\nanswer = random.randrange(1, 101)\ncounter = 0\nwhile True:\n    counter += 1\n    num = int(input('请输入: '))\n    if num < answer:\n        print('大一点.')\n    elif num > answer:\n        print('小一点.')\n    else:\n        print('猜对了.')\n        break\nprint(f'你一共猜了{counter}次.')\n```\n\n> **说明**：上面的代码使用`import random`导入了 Python 标准库的`random`模块，该模块的`randrange`函数帮助我们生成了 1 到 100 范围的随机数（不包括 100）。变量`counter`用来记录循环执行的次数，也就是用户一共猜了几次，每循环一次`counter`的值都会加 1。\n\n### 总结\n\n学会了 Python 中的分支结构和循环结构，我们就可以解决很多实际的问题了。通过这节课的学习，大家应该已经知道了可以用`for`和`while`关键字来构造循环结构。**如果事先知道循环结构重复的次数，我们通常使用**`for`**循环**；**如果循环结构的重复次数不能确定，可以用**`while`**循环**。此外，我们可以在循环结构中**使用**`break`**终止循环**，**也可以在循环结构中使用**`continue`**关键字让循环结构直接进入下一轮次**。\n", "分支和循环结构实战": "## 分支和循环结构实战\n\n通过前面两节课的学习，大家对 Python 中的分支结构和循环结构已经有了初步的认知。**分支结构和循环结构是构造程序逻辑的基础**，它们的重要性不言而喻，但是对于初学者来说这也是比较困难的部分。很多人对分支结构和循环结构的语法是能够理解的，但是遇到实际问题的时候又无法下手；**看懂别人的代码很容易，但是要自己写出类似的代码却又很难**。如果你也有同样的问题和困惑，千万不要沮丧，这只是因为你的编程之旅才刚刚开始，**你的练习量还没有达到让你可以随心所欲写出代码的程度**，只要加强编程练习，通过量的积累来产生质的变化，这个问题迟早都会解决的。\n\n### 例子1：100以内的素数\n\n> **说明**：素数指的是只能被 1 和自身整除的正整数（不包括 1），之前我们写过判断素数的代码，这里相当于是一个升级版本。\n\n```python\n\"\"\"\n输出100以内的素数\n\nVersion: 1.0\nAuthor: 小明\n\"\"\"\nfor num in range(2, 100):\n    is_prime = True\n    for i in range(2, int(num ** 0.5) + 1):\n        if num % i == 0:\n            is_prime = False\n            break\n    if is_prime:\n        print(num)\n```\n\n### 例子2：斐波那契数列\n\n要求：输出斐波那契数列中的前 20 个数。\n\n> **说明**：斐波那契数列（Fibonacci sequence），通常也被称作黄金分割数列，是意大利数学家莱昂纳多·斐波那契（Leonardoda Fibonacci）在《计算之书》中研究理想假设条件下兔子成长率问题而引入的数列，因此这个数列也常被戏称为“兔子数列”。斐波那契数列的特点是数列的前两个数都是 1，从第三个数开始，每个数都是它前面两个数的和。按照这个规律，斐波那契数列的前 10 个数是：`1, 1, 2, 3, 5, 8, 13, 21, 34, 55`。斐波那契数列在现代物理、准晶体结构、化学等领域都有直接的应用。\n\n```python\n\"\"\"\n输出斐波那契数列中的前20个数\n\nVersion: 1.0\nAuthor: 小明\n\"\"\"\n\na, b = 0, 1\nfor _ in range(20):\n    a, b = b, a + b\n    print(a)\n```\n\n> **说明**：上面循环中的`a, b = b, a + b`表示将变量`b`的值赋给`a`，把`a + b`的值赋给`b`。通过这个递推公式，我们可以依次获得斐波那契数列中的数。\n\n### 例子3：寻找水仙花数\n\n要求：找出 100 到 999 范围内的所有水仙花数。\n\n> **提示**：在数论中，水仙花数（narcissistic number）也被称为超完全数字不变数、自恋数、自幂数、阿姆斯特朗数，它是一个 $\\small{N}$ 位非负整数，其各位数字的 $\\small{N}$ 次方和刚好等于该数本身，例如： $\\small{153 = 1^{3} + 5^{3} + 3^{3}}$ ，所以 153 是一个水仙花数； $\\small{1634 = 1^{4} + 6^{4} + 3^{4} + 4^{4}}$ ，所以 1634 也是一个水仙花数。对于三位数，解题的关键是将它拆分为个位、十位、百位，再判断是否满足水仙花数的要求，这一点利用 Python 中的`//`和`%`运算符其实很容易做到。\n\n```python\n\"\"\"\n找出100到999范围内的水仙花数\n\nVersion: 1.0\nAuthor: 小明\n\"\"\"\nfor num in range(100, 1000):\n    low = num % 10\n    mid = num // 10 % 10\n    high = num // 100\n    if num == low ** 3 + mid ** 3 + high ** 3:\n        print(num)\n```\n\n上面利用`//`和`%`拆分一个数的小技巧在写代码的时候还是很常用的。我们要将一个不知道有多少位的正整数进行反转，例如将 12389 变成 98321，也可以利用这两个运算来实现，代码如下所示。\n\n```python\n\"\"\"\n正整数的反转\n\nVersion: 1.0\nAuthor: 小明\n\"\"\"\nnum = int(input('num = '))\nreversed_num = 0\nwhile num > 0:\n    reversed_num = reversed_num * 10 + num % 10\n    num //= 10\nprint(reversed_num)\n```\n\n### 例子4：百钱百鸡问题\n\n> **说明**：百钱百鸡是我国古代数学家张丘建在《算经》一书中提出的数学问题：鸡翁一值钱五，鸡母一值钱三，鸡雏三值钱一。百钱买百鸡，问鸡翁、鸡母、鸡雏各几何？翻译成现代文是：公鸡 5 元一只，母鸡 3 元一只，小鸡 1 元三只，用 100 块钱买一百只鸡，问公鸡、母鸡、小鸡各有多少只？\n\n```python\n\"\"\"\n百钱百鸡问题\n\nVersion: 1.0\nAuthor: 小明\n\"\"\"\nfor x in range(0, 21):\n    for y in range(0, 34):\n        for z in range(0, 100, 3):\n            if x + y + z == 100 and 5 * x + 3 * y + z // 3 == 100:\n                print(f'公鸡: {x}只, 母鸡: {y}只, 小鸡: {z}只')\n```\n\n上面使用的方法叫做**穷举法**，也称为**暴力搜索法**，这种方法通过一项一项的列举备选解决方案中所有可能的候选项，并检查每个候选项是否符合问题的描述，最终得到问题的解。上面的代码中，我们使用了嵌套的循环结构，假设公鸡有`x`只，显然`x`的取值范围是 0 到 20，假设母鸡有`y`只，它的取值范围是 0 到 33，假设小鸡有`z`只，它的取值范围是 0 到 99 且取值是 3 的倍数。这样，我们设置好 100 只鸡的条件`x + y + z == 100`，设置好 100 块钱的条件`5 * x + 3 * y + z // 3 == 100`，当两个条件同时满足时，就是问题的正确答案，我们用`print`函数输出它。这种方法看起来比较笨拙，但对于运算能力非常强大的计算机来说，通常都是一个可行的甚至是不错的选择，只要问题的解存在就能够找到它。\n\n事实上，上面的代码还有更好的写法，既然我们已经假设公鸡有`x`只，母鸡有`y`只，那么小鸡的数量就应该是`100 - x - y`，这样减少一个条件，我们就可以把上面三层嵌套的`for-in`循环改写为两层嵌套的`for-in`循环。循环次数减少了，代码的执行效率就有了显著的提升，如下所示。\n\n```python\n\"\"\"\n百钱百鸡问题\n\nVersion: 1.1\nAuthor: 小明\n\"\"\"\nfor x in range(0, 21):\n    for y in range(0, 34):\n        z = 100 - x - y\n        if z % 3 == 0 and 5 * x + 3 * y + z // 3 == 100:\n            print(f'公鸡: {x}只, 母鸡: {y}只, 小鸡: {z}只')\n```\n\n> **说明**：上面代码中的`z % 3 == 0`是为了确保小鸡的数量是 3 的倍数。\n\n### 例子5：CRAPS赌博游戏\n\n> **说明**：CRAPS又称花旗骰，是美国拉斯维加斯非常受欢迎的一种的桌上赌博游戏。该游戏使用两粒骰子，玩家通过摇两粒骰子获得点数进行游戏。简化后的规则是：玩家第一次摇骰子如果摇出了 7 点或 11 点，玩家胜；玩家第一次如果摇出 2 点、3 点或 12 点，庄家胜；玩家如果摇出其他点数则游戏继续，玩家重新摇骰子，如果玩家摇出了 7 点，庄家胜；如果玩家摇出了第一次摇的点数，玩家胜；其他点数玩家继续摇骰子，直到分出胜负。为了增加代码的趣味性，我们设定游戏开始时玩家有 1000 元的赌注，每局游戏开始之前，玩家先下注，如果玩家获胜就可以获得对应下注金额的奖励，如果庄家获胜，玩家就会输掉自己下注的金额。游戏结束的条件是玩家破产（输光所有的赌注）。\n\n```python\n\"\"\"\nCraps赌博游戏\n\nVersion: 1.0\nAuthor: 小明\n\"\"\"\nimport random\n\nmoney = 1000\nwhile money > 0:\n    print(f'你的总资产为: {money}元')\n    # 下注金额必须大于0且小于等于玩家的总资产\n    while True:\n        debt = int(input('请下注: '))\n        if 0 < debt <= money:\n            break\n    # 用两个1到6均匀分布的随机数相加模拟摇两颗色子得到的点数\n    first_point = random.randrange(1, 7) + random.randrange(1, 7)\n    print(f'\\n玩家摇出了{first_point}点')\n    if first_point == 7 or first_point == 11:\n        print('玩家胜!\\n')\n        money += debt\n    elif first_point == 2 or first_point == 3 or first_point == 12:\n        print('庄家胜!\\n')\n        money -= debt\n    else:\n        # 如果第一次摇色子没有分出胜负，玩家需要重新摇色子\n        while True:\n            current_point = random.randrange(1, 7) + random.randrange(1, 7)\n            print(f'玩家摇出了{current_point}点')\n            if current_point == 7:\n                print('庄家胜!\\n')\n                money -= debt\n                break\n            elif current_point == first_point:\n                print('玩家胜!\\n')\n                money += debt\n                break\nprint('你破产了, 游戏结束!')\n```\n\n### 总结\n\n分支结构和循环结构都非常重要，是构造程序逻辑的基础，**一定要通过大量的练习来达到融会贯通**。我们可以用上面讲的花旗骰游戏作为一个标准，如果你能够很顺利的完成这段代码，那么分支结构和循环结构的知识你就已经很好的掌握了。\n\n", "列表-1": "## 常用数据结构之列表-1\n\n在开始本节课的内容之前，我们先给大家一个编程任务，将一颗色子掷 6000 次，统计每种点数出现的次数。这个任务对大家来说应该是非常简单的，我们可以用 1 到 6 均匀分布的随机数来模拟掷色子，然后用 6 个变量分别记录每个点数出现的次数，相信通过前面的学习，大家都能比较顺利的写出下面的代码。\n\n```python\n\"\"\"\n将一颗色子掷6000次，统计每种点数出现的次数\n\nAuthor: 小明\nVersion: 1.0\n\"\"\"\nimport random\n\nf1 = 0\nf2 = 0\nf3 = 0\nf4 = 0\nf5 = 0\nf6 = 0\nfor _ in range(6000):\n    face = random.randrange(1, 7)\n    if face == 1:\n        f1 += 1\n    elif face == 2:\n        f2 += 1\n    elif face == 3:\n        f3 += 1\n    elif face == 4:\n        f4 += 1\n    elif face == 5:\n        f5 += 1\n    else:\n        f6 += 1\nprint(f'1点出现了{f1}次')\nprint(f'2点出现了{f2}次')\nprint(f'3点出现了{f3}次')\nprint(f'4点出现了{f4}次')\nprint(f'5点出现了{f5}次')\nprint(f'6点出现了{f6}次')\n```\n\n上面的代码非常有多么“丑陋”相信就不用我多说了。当然，更为可怕的是，如果我们要掷两颗或者掷更多的色子，然后统计每种点数出现的次数，那就需要定义更多的变量，写更多的分支结构，大家想想都会感到恶心。讲到这里，相信大家心中已经有一个疑问了：有没有办法用一个变量来保存多个数据，有没有办法用统一的代码对多个数据进行操作？答案是肯定的，在 Python 语言中我们可以通过容器型变量来保存和操作多个数据，我们首先为大家介绍列表（`list`）这种新的数据类型。\n\n### 创建列表\n\n在 Python 中，**列表是由一系元素按特定顺序构成的数据序列**，这就意味着如果我们定义一个列表类型的变量，**可以用它来保存多个数据**。在 Python 中，可以使用`[]`字面量语法来定义列表，列表中的多个元素用逗号进行分隔，代码如下所示。\n\n```python\nitems1 = [35, 12, 99, 68, 55, 35, 87]\nitems2 = ['Python', 'Java', 'Go', 'Kotlin']\nitems3 = [100, 12.3, 'Python', True]\nprint(items1)  # [35, 12, 99, 68, 55, 35, 87]\nprint(items2)  # ['Python', 'Java', 'Go', 'Kotlin']\nprint(items3)  # [100, 12.3, 'Python', True]\n```\n\n> **说明**：列表中可以有重复元素，例如`items1`中的`35`；列表中可以有不同类型的元素，例如`items3`中有`int`类型、`float`类型、`str`类型和`bool`类型的元素，但是我们通常并不建议将不同类型的元素放在同一个列表中，主要是操作起来极为不便。\n\n我们可以使用`type`函数来查看变量的类型，有兴趣的小伙伴可以自行查看上面的变量`items1`到底是什么类型。因为列表可以保存多个元素，它是一种容器型的数据类型，所以我们在给列表类型的变量起名字时，变量名通常用复数形式的单词。\n\n除此以外，还可以通过 Python 内置的`list`函数将其他序列变成列表。准确的说，`list`并不是一个普通的函数，它是创建列表对象的构造器，后面的课程会为大家介绍对象和构造器这些概念。\n\n```python\nitems4 = list(range(1, 10))\nitems5 = list('hello')\nprint(items4)  # [1, 2, 3, 4, 5, 6, 7, 8, 9]\nprint(items5)  # ['h', 'e', 'l', 'l', 'o']\n```\n\n> **说明**：`range(1, 10)`会产生`1`到`9`的整数序列，给到`list`构造器中，会创建出由`1`到`9`的整数构成的列表。字符串是字符构成的序列，上面的`list('hello')`用字符串`hello`的字符作为列表元素，创建了列表对象。\n\n### 列表的运算\n\n我们可以使用`+`运算符实现两个列表的拼接，拼接运算会将两个列表中的元素连接起来放到一个列表中，代码如下所示。\n\n```python\nitems5 = [35, 12, 99, 45, 66]\nitems6 = [45, 58, 29]\nitems7 = ['Python', 'Java', 'JavaScript']\nprint(items5 + items6)  # [35, 12, 99, 45, 66, 45, 58, 29]\nprint(items6 + items7)  # [45, 58, 29, 'Python', 'Java', 'JavaScript']\nitems5 += items6\nprint(items5)  # [35, 12, 99, 45, 66, 45, 58, 29]\n```\n\n我们可以使用`*`运算符实现列表的重复运算，`*`运算符会将列表元素重复指定的次数，我们在上面的代码中增加两行，如下所示。\n\n```python\nprint(items6 * 3)  # [45, 58, 29, 45, 58, 29, 45, 58, 29]\nprint(items7 * 2)  # ['Python', 'Java', 'JavaScript', 'Python', 'Java', 'JavaScript']\n```\n\n我们可以使用`in`或`not in`运算符判断一个元素在不在列表中，我们在上面的代码代码中再增加两行，如下所示。\n\n```python\nprint(29 in items6)  # True\nprint(99 in items6)  # False\nprint('C++' not in items7)     # True\nprint('Python' not in items7)  # False\n```\n\n由于列表中有多个元素，而且元素是按照特定顺序放在列表中的，所以当我们想操作列表中的某个元素时，可以使用`[]`运算符，通过在`[]`中指定元素的位置来访问该元素，这种运算称为索引运算。需要说明的是，`[]`的元素位置可以是`0`到`N - 1`的整数，也可以是`-1`到`-N`的整数，分别称为正向索引和反向索引，其中`N`代表列表元素的个数。对于正向索引，`[0]`可以访问列表中的第一个元素，`[N - 1]`可以访问最后一个元素；对于反向索引，`[-1]`可以访问列表中的最后一个元素，`[-N]`可以访问第一个元素，代码如下所示。\n\n```python\nitems8 = ['apple', 'waxberry', 'pitaya', 'peach', 'watermelon']\nprint(items8[0])   # apple\nprint(items8[2])   # pitaya\nprint(items8[4])   # watermelon\nitems8[2] = 'durian'\nprint(items8)      # ['apple', 'waxberry', 'durian', 'peach', 'watermelon']\nprint(items8[-5])  # 'apple'\nprint(items8[-4])  # 'waxberry'\nprint(items8[-1])  # watermelon\nitems8[-4] = 'strawberry'\nprint(items8)      # ['apple', 'strawberry', 'durian', 'peach', 'watermelon']\n```\n\n在使用索引运算的时候要避免出现索引越界的情况，对于上面的`items8`，如果我们访问`items8[5]`或`items8[-6]`，就会引发`IndexError`错误，导致程序崩溃，对应的错误信息是：*list index out of range*，翻译成中文就是“数组索引超出范围”。因为对于只有五个元素的列表`items8`，有效的正向索引是`0`到`4`，有效的反向索引是`-1`到`-5`。\n\n如果希望一次性访问列表中的多个元素，我们可以使用切片运算。切片运算是形如`[start:end:stride]`的运算符，其中`start`代表访问列表元素的起始位置，`end`代表访问列表元素的终止位置（终止位置的元素无法访问），而`stride`则代表了跨度，简单的说就是位置的增量，比如我们访问的第一个元素在`start`位置，那么第二个元素就在`start + stride`位置，当然`start + stride`要小于`end`。我们给上面的代码增加下面的语句，来使用切片运算符访问列表元素。\n\n```python\nprint(items8[1:3:1])     # ['strawberry', 'durian']\nprint(items8[0:3:1])     # ['apple', 'strawberry', 'durian']\nprint(items8[0:5:2])     # ['apple', 'durian', 'watermelon']\nprint(items8[-4:-2:1])   # ['strawberry', 'durian']\nprint(items8[-2:-6:-1])  # ['peach', 'durian', 'strawberry', 'apple']\n```\n\n> **提醒**：大家可以看看上面代码中的最后一行，想一想当跨度为负数时，切片运算是如何访问元素的。\n\n如果`start`值等于`0`，那么在使用切片运算符时可以将其省略；如果`end`值等于`N`，`N`代表列表元素的个数，那么在使用切片运算符时可以将其省略；如果`stride`值等于`1`，那么在使用切片运算符时也可以将其省略。所以，下面的代码跟上面的代码作用完全相同。\n\n```python\nprint(items8[1:3])     # ['strawberry', 'durian']\nprint(items8[:3:1])    # ['apple', 'strawberry', 'durian']\nprint(items8[::2])     # ['apple', 'durian', 'watermelon']\nprint(items8[-4:-2])   # ['strawberry', 'durian']\nprint(items8[-2::-1])  # ['peach', 'durian', 'strawberry', 'apple']\n```\n\n事实上，我们还可以通过切片操作修改列表中的元素，例如我们给上面的代码再加上一行，大家可以看看这里的输出。\n\n```python\nitems8[1:3] = ['x', 'o']\nprint(items8)  # ['apple', 'x', 'o', 'peach', 'watermelon']\n```\n\n两个列表还可以做关系运算，我们可以比较两个列表是否相等，也可以给两个列表比大小，代码如下所示。\n\n```python\nnums1 = [1, 2, 3, 4]\nnums2 = list(range(1, 5))\nnums3 = [3, 2, 1]\nprint(nums1 == nums2)  # True\nprint(nums1 != nums2)  # False\nprint(nums1 <= nums3)  # True\nprint(nums2 >= nums3)  # False\n```\n\n> **说明**：上面的`nums1`和`nums2`对应元素完全相同，所以`==`运算的结果是`True`。`nums2`和`nums3`的比较，由于`nums2`的第一个元素`1`小于`nums3`的第一个元素`3`，所以`nums2 >= nums3`比较的结果是`False`。两个列表的关系运算在实际工作并不那么常用，如果实在不理解就跳过吧，不用纠结。\n\n### 元素的遍历\n\n如果想逐个取出列表中的元素，可以使用`for-in`循环的，有以下两种做法。\n\n方法一：在循环结构中通过索引运算，遍历列表元素。\n\n```python\nlanguages = ['Python', 'Java', 'C++', 'Kotlin']\nfor index in range(len(languages)):\n    print(languages[index])\n```\n\n输出：\n\n```\nPython\nJava\nC++\nKotlin\n```\n\n> **说明**：上面的`len`函数可以获取列表元素的个数`N`，而`range(N)`则构成了从`0`到`N-1`的范围，刚好可以作为列表元素的索引。\n\n方法二：直接对列表做循环，循环变量就是列表元素的代表。\n\n```python\nlanguages = ['Python', 'Java', 'C++', 'Kotlin']\nfor language in languages:\n    print(language)\n```\n\n输出：\n\n```\nPython\nJava\nC++\nKotlin\n```\n\n### 总结\n\n讲到这里，我们可以用列表的知识来重构上面“掷色子统计每种点数出现次数”的代码。\n\n```python\n\"\"\"\n将一颗色子掷6000次，统计每种点数出现的次数\n\nAuthor: 小明\nVersion: 1.1\n\"\"\"\nimport random\n\ncounters = [0] * 6\n# 模拟掷色子记录每种点数出现的次数\nfor _ in range(6000):\n    face = random.randrange(1, 7)\n    counters[face - 1] += 1\n# 输出每种点数出现的次数\nfor face in range(1, 7):\n    print(f'{face}点出现了{counters[face - 1]}次')\n```\n\n上面的代码中，我们用`counters`列表中的六个元素分别表示 1 到 6 点出现的次数，最开始的时候六个元素的值都是 0。接下来，我们用 1 到 6 均匀分布的随机数模拟掷色子，如果摇出 1 点，`counters[0]`的值加 1，如果摇出 2 点，`counters[1]`的值加 1，以此类推。大家感受一下，由于使用了列表类型加上循环结构，我们对数据的处理是批量性的，这就使得修改后的代码比之前的代码要简单优雅得多。\n", "列表-2": "## 常用数据结构之列表-2\n\n### 列表的方法\n\n列表类型的变量拥有很多方法可以帮助我们操作一个列表，假设我们有名为`foos`的列表，列表有名为`bar`的方法，那么使用列表方法的语法是：`foos.bar()`，这是一种通过对象引用调用对象方法的语法。后面我们讲面向对象编程的时候，还会对这种语法进行详细的讲解，这种语法也称为给对象发消息。\n\n#### 添加和删除元素\n\n列表是一种可变容器，可变容器指的是我们可以向容器中添加元素、可以从容器移除元素，也可以修改现有容器中的元素。我们可以使用列表的`append`方法向列表中追加元素，使用`insert`方法向列表中插入元素。追加指的是将元素添加到列表的末尾，而插入则是在指定的位置添加新元素，大家可以看看下面的代码。\n\n```python\nlanguages = ['Python', 'Java', 'C++']\nlanguages.append('JavaScript')\nprint(languages)  # ['Python', 'Java', 'C++', 'JavaScript']\nlanguages.insert(1, 'SQL')\nprint(languages)  # ['Python', 'SQL', 'Java', 'C++', 'JavaScript']\n```\n\n我们可以用列表的`remove`方法从列表中删除指定元素，需要注意的是，如果要删除的元素并不在列表中，会引发`ValueError`错误导致程序崩溃，所以建议大家在删除元素时，先用之前讲过的成员运算做一个判断。我们还可以使用`pop`方法从列表中删除元素，`pop`方法默认删除列表中的最后一个元素，当然也可以给一个位置，删除指定位置的元素。在使用`pop`方法删除元素时，如果索引的值超出了范围，会引发`IndexError`异常，导致程序崩溃。除此之外，列表还有一个`clear`方法，可以清空列表中的元素，代码如下所示。\n\n```python\nlanguages = ['Python', 'SQL', 'Java', 'C++', 'JavaScript']\nif 'Java' in languages:\n    languages.remove('Java')\nif 'Swift' in languages:\n    languages.remove('Swift')\nprint(languages)  # ['Python', 'SQL', C++', 'JavaScript']\nlanguages.pop()\ntemp = languages.pop(1)\nprint(temp)       # SQL\nlanguages.append(temp)\nprint(languages)  # ['Python', C++', 'SQL']\nlanguages.clear()\nprint(languages)  # []\n```\n\n> **说明**：`pop`方法删除元素时会得到被删除的元素，上面的代码中，我们将`pop`方法删除的元素赋值给了名为`temp`的变量。当然如果你愿意，还可以把这个元素再次加入到列表中，正如上面的代码`languages.append(temp)`所做的那样。\n\n这里还有一个小问题，例如`languages`列表中有多个`'Python'`，那么我们用`languages.remove('Python')`是删除所有的`'Python'`，还是删除第一个`'Python'`，大家可以先猜一猜，然后再自己动手尝试一下。\n\n从列表中删除元素其实还有一种方式，就是使用 Python 中的`del`关键字后面跟要删除的元素，这种做法跟使用`pop`方法指定索引删除元素没有实质性的区别，但后者会返回删除的元素，前者在性能上略优，因为`del`对应的底层字节码指令是`DELETE_SUBSCR`，而`pop`对应的底层字节码指令是`CALL_METHOD`和`POP_TOP`，如果不理解就不用管它了。\n\n```python\nitems = ['Python', 'Java', 'C++']\ndel items[1]\nprint(items)  # ['Python', 'C++']\n```\n\n#### 元素位置和频次\n\n列表的`index`方法可以查找某个元素在列表中的索引位置，如果找不到指定的元素，`index`方法会引发`ValueError`错误；列表的`count`方法可以统计一个元素在列表中出现的次数，代码如下所示。\n\n```python\nitems = ['Python', 'Java', 'Java', 'C++', 'Kotlin', 'Python']\nprint(items.index('Python'))     # 0\n# 从索引位置1开始查找'Python'\nprint(items.index('Python', 1))  # 5\nprint(items.count('Python'))     # 2\nprint(items.count('Kotlin'))     # 1\nprint(items.count('Swfit'))      # 0\n# 从索引位置3开始查找'Java'\nprint(items.index('Java', 3))    # ValueError: 'Java' is not in list\n```\n\n#### 元素排序和反转\n\n列表的`sort`操作可以实现列表元素的排序，而`reverse`操作可以实现元素的反转，代码如下所示。\n\n```python\nitems = ['Python', 'Java', 'C++', 'Kotlin', 'Swift']\nitems.sort()\nprint(items)  # ['C++', 'Java', 'Kotlin', 'Python', 'Swift']\nitems.reverse()\nprint(items)  # ['Swift', 'Python', 'Kotlin', 'Java', 'C++']\n```\n\n### 列表生成式\n\n在 Python 中，列表还可以通过一种特殊的字面量语法来创建，这种语法叫做生成式。下面，我们通过例子来说明使用列表生成式创建列表到底有什么好处。\n\n场景一：创建一个取值范围在`1`到`99`且能被`3`或者`5`整除的数字构成的列表。\n\n```python\nitems = []\nfor i in range(1, 100):\n    if i % 3 == 0 or i % 5 == 0:\n        items.append(i)\nprint(items)\n```\n\n使用列表生成式做同样的事情，代码如下所示。\n\n```python\nitems = [i for i in range(1, 100) if i % 3 == 0 or i % 5 == 0]\nprint(items)\n```\n\n场景二：有一个整数列表`nums1`，创建一个新的列表`nums2`，`nums2`中的元素是`nums1`中对应元素的平方。\n\n```python\nnums1 = [35, 12, 97, 64, 55]\nnums2 = []\nfor num in nums1:\n    nums2.append(num ** 2)\nprint(nums2)\n```\n\n使用列表生成式做同样的事情，代码如下所示。\n\n```python\nnums1 = [35, 12, 97, 64, 55]\nnums2 = [num ** 2 for num in nums1]\nprint(nums2)\n```\n\n场景三： 有一个整数列表`nums1`，创建一个新的列表`nums2`，将`nums1`中大于`50`的元素放到`nums2`中。\n\n```python\nnums1 = [35, 12, 97, 64, 55]\nnums2 = []\nfor num in nums1:\n    if num > 50:\n        nums2.append(num)\nprint(nums2)\n```\n\n使用列表生成式做同样的事情，代码如下所示。\n\n```python\nnums1 = [35, 12, 97, 64, 55]\nnums2 = [num for num in nums1 if num > 50]\nprint(nums2)\n```\n\n使用列表生成式创建列表不仅代码简单优雅，而且性能上也优于使用`for-in`循环和`append`方法向空列表中追加元素的方式。为什么说生成式有更好的性能呢，那是因为 Python 解释器的字节码指令中有专门针对生成式的指令（`LIST_APPEND`指令）；而`for`循环是通过方法调用（`LOAD_METHOD`和`CALL_METHOD`指令）的方式为列表添加元素，方法调用本身就是一个相对比较耗时的操作。对这一点不理解也没有关系，记住“**强烈建议用生成式语法来创建列表**”这个结论就可以了。\n\n### 嵌套列表\n\nPython 语言没有限定列表中的元素必须是相同的数据类型，也就是说一个列表中的元素可以任意的数据类型，当然也包括列表本身。如果列表中的元素也是列表，那么我们可以称之为嵌套的列表。嵌套的列表可以用来表示表格或数学上的矩阵，例如：我们想保存5个学生3门课程的成绩，可以用如下所示的列表。\n\n```python\nscores = [[95, 83, 92], [80, 75, 82], [92, 97, 90], [80, 78, 69], [65, 66, 89]]\nprint(scores[0])\nprint(scores[0][1])\n```\n\n对于上面的嵌套列表，每个元素相当于就是一个学生3门课程的成绩，例如`[95, 83, 92]`，而这个列表中的`83`代表了这个学生某一门课的成绩，如果想访问这个值，可以使用两次索引运算`scores[0][1]`，其中`scores[0]`可以得到`[95, 83, 92]`这个列表，再次使用索引运算`[1]`就可以获得该列表中的第二个元素。\n\n如果想通过键盘输入的方式来录入5个学生3门课程的成绩并保存在列表中，可以使用如下所示的代码。\n\n```python\nscores = []\nfor _ in range(5):\n    temp = []\n    for _ in range(3):\n        score = int(input('请输入: '))\n        temp.append(score)\n    scores.append(temp)\nprint(scores)\n```\n\n如果想通过产生随机数的方式来生成5个学生3门课程的成绩并保存在列表中，我们可以使用列表生成式，代码如下所示。\n\n```python\nimport random\n\nscores = [[random.randrange(60, 101) for _ in range(3)] for _ in range(5)]\nprint(scores)\n```\n\n> **说明**：上面的代码`[random.randrange(60, 101) for _ in range(3)] `可以产生由3个随机整数构成的列表，我们把这段代码又放在了另一个列表生成式中作为列表的元素，这样的元素一共生成5个，最终得到了一个嵌套列表。\n\n### 列表的应用\n\n下面我们通过一个双色球随机选号的例子为大家讲解列表的应用。双色球是由中国福利彩票发行管理中心发售的乐透型彩票，每注投注号码由`6`个红色球和`1`个蓝色球组成。红色球号码从`1`到`33`中选择，蓝色球号码从`1`到`16`中选择。每注需要选择`6`个红色球号码和`1`个蓝色球号码，如下所示。\n\n<img class=\"lazy\" data-src=\"/res/day09/lottery.png\" style=\"zoom:85%;\">\n\n> **提示**：知乎上有一段对国内各种形式的彩票本质的论述相当精彩，这里分享给大家：“**虚构一个不劳而获的人，去忽悠一群想不劳而获的人，最终养活一批真正不劳而获的人**”。很多对概率没有概念的人，甚至认为彩票中与不中的概率都是 50%；还有很多人认为如果中奖的概率是 1%，那么买 100 次就一定可以中奖，这些都是非常荒唐的想法。所以，**珍爱生命，远离赌博，尤其是你对概率一无所知的情况下**！\n\n下面，我们通过 Python 程序来生成一组随机号码。\n\n```python\n\"\"\"\n双色球随机选号程序\n\nAuthor: 小明\nVersion: 1.0\n\"\"\"\nimport random\n\nred_balls = list(range(1, 34))\nselected_balls = []\n# 添加6个红色球到选中列表\nfor _ in range(6):\n    # 生成随机整数代表选中的红色球的索引位置\n    index = random.randrange(len(red_balls))\n    # 将选中的球从红色球列表中移除并添加到选中列表\n    selected_balls.append(red_balls.pop(index))\n# 对选中的红色球排序\nselected_balls.sort()\n# 输出选中的红色球\nfor ball in selected_balls:\n    print(f'\\033[031m{ball:0>2d}\\033[0m', end=' ')\n# 随机选择1个蓝色球\nblue_ball = random.randrange(1, 17)\n# 输出选中的蓝色球\nprint(f'\\033[034m{blue_ball:0>2d}\\033[0m')\n```\n\n> **说明**：上面代码中`print(f'\\033[0m...\\033[0m')`是为了控制输出内容的颜色，红色球输出成红色，蓝色球输出成蓝色。其中省略号代表我们要输出的内容，`\\033[0m`是一个控制码，表示关闭所有属性，也就是说之前的控制码将会失效，你也可以将其简单的理解为一个定界符，`m`前面的`0`表示控制台的显示方式为默认值，`0`可以省略，`1`表示高亮，`5`表示闪烁，`7`表示反显等。在`0`和`m`的中间，我们可以写上代表颜色的数字，比如`30`代表黑色，`31`代表红色，`32`代表绿色，`33`代表黄色，`34`代表蓝色等。\n\n我们还可以利用`random`模块提供的`sample`和`choice`函数来简化上面的代码，前者可以实现无放回随机抽样，后者可以实现随机抽取一个元素，修改后的代码如下所示。\n\n```python\n\"\"\"\n双色球随机选号程序\n\nAuthor: 小明\nVersion: 1.1\n\"\"\"\nimport random\n\nred_balls = [i for i in range(1, 34)]\nblue_balls = [i for i in range(1, 17)]\n# 从红色球列表中随机抽出6个红色球（无放回抽样）\nselected_balls = random.sample(red_balls, 6)\n# 对选中的红色球排序\nselected_balls.sort()\n# 输出选中的红色球\nfor ball in selected_balls:\n    print(f'\\033[031m{ball:0>2d}\\033[0m', end=' ')\n# 从蓝色球列表中随机抽出1个蓝色球\nblue_ball = random.choice(blue_balls)\n# 输出选中的蓝色球\nprint(f'\\033[034m{blue_ball:0>2d}\\033[0m')\n```\n\n如果要实现随机生成`N`注号码，我们只需要将上面的代码放到一个`N`次的循环中，如下所示。\n\n```python\n\"\"\"\n双色球随机选号程序\n\nAuthor: 小明\nVersion: 1.2\n\"\"\"\nimport random\n\nn = int(input('生成几注号码: '))\nred_balls = [i for i in range(1, 34)]\nblue_balls = [i for i in range(1, 17)]\nfor _ in range(n):\n    # 从红色球列表中随机抽出6个红色球（无放回抽样）\n    selected_balls = random.sample(red_balls, 6)\n    # 对选中的红色球排序\n    selected_balls.sort()\n    # 输出选中的红色球\n    for ball in selected_balls:\n        print(f'\\033[031m{ball:0>2d}\\033[0m', end=' ')\n    # 从蓝色球列表中随机抽出1个蓝色球\n    blue_ball = random.choice(blue_balls)\n    # 输出选中的蓝色球\n    print(f'\\033[034m{blue_ball:0>2d}\\033[0m')\n```\n\n我们在 PyCharm 中运行上面的代码，输入`5`，运行效果如下图所示。\n\n<img class=\"lazy\" data-src=\"/res/day09/lottery_run_result.png\" style=\"zoom:35%;\">\n\n这里顺便给大家介绍一个名为 rich 的 Python 三方库，它可以帮助我们用最简单的方式产生最漂亮的输出，你可以在终端中使用 Python 包管理工具 pip 来安装这个三方库，对于使用 PyCharm 的用户，当然要在 PyCharm 的终端窗口使用 pip 命令将 rich 安装到项目的虚拟环境中，命令如下所示。\n\n```bash\npip install rich\n```\n\n<img class=\"lazy\" data-src=\"/res/day09/run_pip_in_terminal.png\" style=\"zoom:50%;\">\n\n如上图所示，rich 安装成功后，我们可以用如下所示的代码来控制输出。\n\n```python\n\"\"\"\n双色球随机选号程序\n\nAuthor: 小明\nVersion: 1.3\n\"\"\"\nimport random\n\nfrom rich.console import Console\nfrom rich.table import Table\n\n# 创建控制台\nconsole = Console()\n\nn = int(input('生成几注号码: '))\nred_balls = [i for i in range(1, 34)]\nblue_balls = [i for i in range(1, 17)]\n\n# 创建表格并添加表头\ntable = Table(show_header=True)\nfor col_name in ('序号', '红球', '蓝球'):\n    table.add_column(col_name, justify='center')\n\nfor i in range(n):\n    selected_balls = random.sample(red_balls, 6)\n    selected_balls.sort()\n    blue_ball = random.choice(blue_balls)\n    # 向表格中添加行（序号，红色球，蓝色球）\n    table.add_row(\n        str(i + 1),\n        f'[red]{\" \".join([f\"{ball:0>2d}\" for ball in selected_balls])}[/red]',\n        f'[blue]{blue_ball:0>2d}[/blue]'\n    )\n\n# 通过控制台输出表格\nconsole.print(table)\n```\n\n> **说明**：上面代码第 31 行使用了列表生成式语法将红色球号码处理成字符串并保存在一个列表中，`\" \".join([...])`是将列表中的多个字符串用空格拼接成一个完整的字符串，如果不理解可以先放放。字符串中的`[red]...[/red]`用来设置输出颜色为红色，第 32 行的`[blue]...[/blue]`用来设置输出颜色为蓝色。更多关于 rich 库的知识，可以参考[官方文档](https://github.com/textualize/rich/blob/master/README.cn.md)。\n\n最终的输出如下图所示，看着这样的输出，是不是心情更美好了一些。\n\n<img class=\"lazy\" data-src=\"/res/day09/output_using_rich.png\" style=\"zoom:50%;\">\n\n### 总结\n\nPython 中的列表底层是一个可以动态扩容的数组，列表元素在计算机内存中是连续存储的，所以可以实现随机访问（通过一个有效的索引获取对应的元素且操作时间与列表元素个数无关）。我们可以暂时不去触碰这些底层的存储细节，也不需要大家理解列表每个方法的渐近时间复杂度（执行方法耗费的时间跟列表元素个数之间的关系），大家先学会用列表解决工作中的问题，我想这一点更为重要。", "元组": "## 常用数据结构之元组\n\n前面的两节课，我们为大家讲解了 Python 中的列表，它是一种容器型的数据类型，通过列表类型的变量，我们可以保存多个数据并通过循环实现对数据的批量操作。当然，Python 中还有其他容器型的数据类型，接下来我们就为大家讲解另一种容器型的数据类型，它的名字叫元组（tuple）。\n\n### 元组的定义和运算\n\n在 Python 语言中，元组也是多个元素按照一定顺序构成的序列。元组和列表的不同之处在于，**元组是不可变类型**，这就意味着元组类型的变量一旦定义，其中的元素不能再添加或删除，而且元素的值也不能修改。如果试图修改元组中的元素，将引发`TypeError`错误，导致程序崩溃。定义元组通常使用形如`(x, y, z)`的字面量语法，元组类型支持的运算符跟列表是一样的，我们可以看看下面的代码。\n\n```python\n# 定义一个三元组\nt1 = (35, 12, 98)\n# 定义一个四元组\nt2 = ('小明', 43, True, '四川成都')\n\n# 查看变量的类型\nprint(type(t1))  # <class 'tuple'>\nprint(type(t2))  # <class 'tuple'>\n\n# 查看元组中元素的数量\nprint(len(t1))  # 3\nprint(len(t2))  # 4\n\n# 索引运算\nprint(t1[0])    # 35\nprint(t1[2])    # 98\nprint(t2[-1])   # 四川成都\n\n# 切片运算\nprint(t2[:2])   # ('小明', 43)\nprint(t2[::3])  # ('小明', '四川成都')\n\n# 循环遍历元组中的元素\nfor elem in t1:\n    print(elem)\n\n# 成员运算\nprint(12 in t1)         # True\nprint(99 in t1)         # False\nprint('Hao' not in t2)  # False\n\n# 拼接运算\nt3 = t1 + t2\nprint(t3)  # (35, 12, 98, '小明', 43, True, '四川成都')\n\n# 比较运算\nprint(t1 == t3)            # False\nprint(t1 >= t3)            # False\nprint(t1 <= (35, 11, 99))  # False\n```\n\n一个元组中如果有两个元素，我们就称之为二元组；一个元组中如果五个元素，我们就称之为五元组。需要提醒大家注意的是，`()`表示空元组，但是如果元组中只有一个元素，需要加上一个逗号，否则`()`就不是代表元组的字面量语法，而是改变运算优先级的圆括号，所以`('hello', )`和`(100, )`才是一元组，而`('hello')`和`(100)`只是字符串和整数。我们可以通过下面的代码来加以验证。\n\n```python\na = ()\nprint(type(a))  # <class 'tuple'>\nb = ('hello')\nprint(type(b))  # <class 'str'>\nc = (100)\nprint(type(c))  # <class 'int'>\nd = ('hello', )\nprint(type(d))  # <class 'tuple'>\ne = (100, )\nprint(type(e))  # <class 'tuple'>\n```\n\n### 打包和解包操作\n\n当我们把多个用逗号分隔的值赋给一个变量时，多个值会打包成一个元组类型；当我们把一个元组赋值给多个变量时，元组会解包成多个值然后分别赋给对应的变量，如下面的代码所示。\n\n```python\n# 打包操作\na = 1, 10, 100\nprint(type(a))  # <class 'tuple'>\nprint(a)        # (1, 10, 100)\n# 解包操作\ni, j, k = a\nprint(i, j, k)  # 1 10 100\n```\n\n在解包时，如果解包出来的元素个数和变量个数不对应，会引发`ValueError`异常，错误信息为：`too many values to unpack`（解包的值太多）或`not enough values to unpack`（解包的值不足）。\n\n```python\na = 1, 10, 100, 1000\n# i, j, k = a             # ValueError: too many values to unpack (expected 3)\n# i, j, k, l, m, n = a    # ValueError: not enough values to unpack (expected 6, got 4)\n```\n\n有一种解决变量个数少于元素的个数方法，就是使用星号表达式。通过星号表达式，我们可以让一个变量接收多个值，代码如下所示。需要注意两点：首先，用星号表达式修饰的变量会变成一个列表，列表中有0个或多个元素；其次，在解包语法中，星号表达式只能出现一次。\n\n```python\na = 1, 10, 100, 1000\ni, j, *k = a\nprint(i, j, k)        # 1 10 [100, 1000]\ni, *j, k = a\nprint(i, j, k)        # 1 [10, 100] 1000\n*i, j, k = a\nprint(i, j, k)        # [1, 10] 100 1000\n*i, j = a\nprint(i, j)           # [1, 10, 100] 1000\ni, *j = a\nprint(i, j)           # 1 [10, 100, 1000]\ni, j, k, *l = a\nprint(i, j, k, l)     # 1 10 100 [1000]\ni, j, k, l, *m = a\nprint(i, j, k, l, m)  # 1 10 100 1000 []\n```\n\n需要说明一点，解包语法对所有的序列都成立，这就意味着我们之前讲的列表、`range`函数构造的范围序列甚至字符串都可以使用解包语法。大家可以尝试运行下面的代码，看看会出现怎样的结果。\n\n```python\na, b, *c = range(1, 10)\nprint(a, b, c)\na, b, c = [1, 10, 100]\nprint(a, b, c)\na, *b, c = 'hello'\nprint(a, b, c)\n```\n\n### 交换变量的值\n\n交换变量的值是写代码时经常用到的一个操作，但是在很多编程语言中，交换两个变量的值都需要借助一个中间变量才能做到，如果不用中间变量就需要使用比较晦涩的位运算来实现。在 Python 中，交换两个变量`a`和`b`的值只需要使用如下所示的代码。\n\n```python\na, b = b, a\n```\n\n同理，如果要将三个变量`a`、`b`、`c`的值互换，即`b`的值赋给`a`，`c`的值赋给`b`，`a`的值赋给`c`，也可以如法炮制。\n\n```python\na, b, c = b, c, a\n```\n\n需要说明的是，上面的操作并没有用到打包和解包语法，Python 的字节码指令中有`ROT_TWO`和`ROT_THREE`这样的指令可以直接实现这个操作，效率是非常高的。但是如果有多于三个变量的值要依次互换，这个时候是没有直接可用的字节码指令的，需要通过打包解包的方式来完成变量之间值的交换。\n\n### 元组和列表的比较\n\n这里还有一个非常值得探讨的问题，Python 中已经有了列表类型，为什么还需要元组这样的类型呢？这个问题对于初学者来说似乎有点困难，不过没有关系，我们先抛出观点，大家可以一边学习一边慢慢体会。\n\n1. 元组是不可变类型，**不可变类型更适合多线程环境**，因为它降低了并发访问变量的同步化开销。关于这一点，我们会在后面讲解并发编程的时候跟大家一起探讨。\n\n2. 元组是不可变类型，通常**不可变类型在创建时间上优于对应的可变类型**。我们可以使用`timeit`模块的`timeit`函数来看看创建保存相同元素的元组和列表各自花费的时间，`timeit`函数的`number`参数表示代码执行的次数。下面的代码中，我们分别创建了保存`1`到`9`的整数的列表和元组，每个操作执行`10000000`次，统计运行时间。\n\n   ```python\n   import timeit\n   \n   print('%.3f 秒' % timeit.timeit('[1, 2, 3, 4, 5, 6, 7, 8, 9]', number=10000000))\n   print('%.3f 秒' % timeit.timeit('(1, 2, 3, 4, 5, 6, 7, 8, 9)', number=10000000))\n   ```\n\n   输出：\n\n   ```\n   0.635 秒\n   0.078 秒\n   ```\n\n   > **说明**：上面代码的执行结果因软硬件系统而异，在我目前使用的电脑上，执行`10000000`次创建列表的操作时间是`0.635`秒，而执行`10000000`次创建元组的操作时间是`0.078`秒，显然创建元组更快且二者时间上有数量级的差别。大家可以在自己的电脑上执行这段代码，把你的执行结果放到评论区，看看谁的电脑更厉害。\n\n当然，Python 中的元组和列表类型是可以相互转换的，我们可以通过下面的代码来完成该操作。\n\n```python\ninfos = ('小明', 43, True, '四川成都')\n# 将元组转换成列表\nprint(list(infos))  # ['小明', 43, True, '四川成都']\n\nfrts = ['apple', 'banana', 'orange']\n# 将列表转换成元组\nprint(tuple(frts))  # ('apple', 'banana', 'orange')\n```\n\n### 总结\n\n**列表和元组都是容器型的数据类型**，即一个变量可以保存多个数据，而且它们都是按一定顺序组织元素的有序容器。**列表是可变数据类型**，**元组是不可变数据类型**，所以列表可以添加元素、删除元素、清空元素、排序反转，但这些操作对元组来说是不成立的。列表和元组都可以支持**拼接运算**、**成员运算**、**索引运算**、**切片运算**等操作，后面我们要讲到的字符串类型也支持这些运算，因为字符串就是字符按一定顺序构成的序列，在这一点上三者并没有什么区别。我们**推荐大家使用列表的生成式语法来创建列表**，它不仅好用而且效率很高，是 Python 语言中非常有特色的语法。\n", "字符串": "## 常用数据结构之字符串\n\n第二次世界大战促使了现代电子计算机的诞生，世界上的第一台通用电子计算机名叫 ENIAC（电子数值积分计算机），诞生于美国的宾夕法尼亚大学，占地167平米，重量约27吨，每秒钟大约能够完成约5000次浮点运算，如下图所示。ENIAC 诞生之后被应用于导弹弹道的计算，而数值计算也是现代电子计算机最为重要的一项功能。\n\n<img class=\"lazy\" data-src=\"/res/day11/eniac.jpg\" style=\"zoom:50%;\">\n\n随着时间的推移，虽然数值运算仍然是计算机日常工作中最为重要的组成部分，但是今天的计算机还要处理大量的以文本形式存在的信息。如果我们希望通过 Python 程序来操作本这些文本信息，就必须要先了解字符串这种数据类型以及与它相关的运算和方法。\n\n### 字符串的定义\n\n所谓**字符串**，就是**由零个或多个字符组成的有限序列**，一般记为：\n\n$$\ns = a_1a_2 \\cdots a_n \\,\\,\\,\\,\\, (0 \\le n \\le \\infty)\n$$\n\n在 Python 程序中，我们把单个或多个字符用单引号或者双引号包围起来，就可以表示一个字符串。字符串中的字符可以是特殊符号、英文字母、中文字符、日文的平假名或片假名、希腊字母、Emoji 字符（如：💩、🐷、🀄️）等。\n\n```python\ns1 = 'hello, world!'\ns2 = \"你好，世界！❤️\"\ns3 = '''hello,\nwonderful\nworld!'''\nprint(s1)\nprint(s2)\nprint(s3)\n```\n\n#### 转义字符\n\n我们可以在字符串中使用`\\`（反斜杠）来表示转义，也就是说`\\`后面的字符不再是它原来的意义，例如：`\\n`不是代表字符`\\`和字符`n`，而是表示换行；`\\t`也不是代表字符`\\`和字符`t`，而是表示制表符。所以如果字符串本身又包含了`'`、`\"`、`\\`这些特殊的字符，必须要通过`\\`进行转义处理。例如要输出一个带单引号或反斜杠的字符串，需要用如下所示的方法。\n\n```python\ns1 = '\\'hello, world!\\''\ns2 = '\\\\hello, world!\\\\'\nprint(s1)\nprint(s2)\n```\n\n#### 原始字符串\n\nPython 中有一种以`r`或`R`开头的字符串，这种字符串被称为原始字符串，意思是字符串中的每个字符都是它本来的含义，没有所谓的转义字符。例如，在字符串`'hello\\n'`中，`\\n`表示换行；而在`r'hello\\n'`中，`\\n`不再表示换行，就是字符`\\`和字符`n`。大家可以运行下面的代码，看看会输出什么。\n\n```python\ns1 = '\\it \\is \\time \\to \\read \\now'\ns2 = r'\\it \\is \\time \\to \\read \\now'\nprint(s1)\nprint(s2)\n```\n\n> **说明**：上面的变量`s1`中，`\\t`、`\\r`和`\\n`都是转义字符。`\\t`是制表符（table），`\\n`是换行符（new line），`\\r`是回车符（carriage return）相当于让输出回到了行首。对比一下两个`print`函数的输出，看看到底有什么区别！\n\n#### 字符的特殊表示\n\nPython 中还允许在`\\`后面还可以跟一个八进制或者十六进制数来表示字符，例如`\\141`和`\\x61`都代表小写字母`a`，前者是八进制的表示法，后者是十六进制的表示法。另外一种表示字符的方式是在`\\u`后面跟 Unicode 字符编码，例如`\\u9a86\\u660a`代表的是中文“小明”。运行下面的代码，看看输出了什么。\n\n```python\ns1 = '\\141\\142\\143\\x61\\x62\\x63'\ns2 = '\\u9a86\\u660a'\nprint(s1)\nprint(s2)\n```\n\n### 字符串的运算\n\nPython 语言为字符串类型提供了非常丰富的运算符，有很多运算符跟列表类型的运算符作用类似。例如，我们可以使用`+`运算符来实现字符串的拼接，可以使用`*`运算符来重复一个字符串的内容，可以使用`in`和`not in`来判断一个字符串是否包含另外一个字符串，我们也可以用`[]`和`[:]`运算符从字符串取出某个字符或某些字符。\n\n#### 拼接和重复\n\n下面的例子演示了使用`+`和`*`运算符来实现字符串的拼接和重复操作。\n\n```python\ns1 = 'hello' + ', ' + 'world'\nprint(s1)    # hello, world\ns2 = '!' * 3\nprint(s2)    # !!!\ns1 += s2\nprint(s1)    # hello, world!!!\ns1 *= 2\nprint(s1)    # hello, world!!!hello, world!!!\n```\n\n用`*`实现字符串的重复是非常有意思的一个运算符，在很多编程语言中，要表示一个有10个`a`的字符串，你只能写成`'aaaaaaaaaa'`，但是在 Python 中，你可以写成`'a' * 10`。你可能觉得`'aaaaaaaaaa'`这种写法也没有什么不方便的，但是请想一想，如果字符`a`要重复100次或者1000次又会如何呢？\n\n#### 比较运算\n\n对于两个字符串类型的变量，可以直接使用比较运算符来判断两个字符串的相等性或比较大小。需要说明的是，因为字符串在计算机内存中也是以二进制形式存在的，那么字符串的大小比较比的是每个字符对应的编码的大小。例如`A`的编码是`65`， 而`a`的编码是`97`，所以`'A' < 'a'`的结果相当于就是`65 < 97`的结果，这里很显然是`True`；而`'boy' < 'bad'`，因为第一个字符都是`'b'`比不出大小，所以实际比较的是第二个字符的大小，显然`'o' < 'a'`的结果是`False`，所以`'boy' < 'bad'`的结果是`False`。如果不清楚两个字符对应的编码到底是多少，可以使用`ord`函数来获得，之前我们有提到过这个函数。例如`ord('A')`的值是`65`，而`ord('昊')`的值是`26122`。下面的代码展示了字符串的比较运算，请大家仔细看看。\n\n```python\ns1 = 'a whole new world'\ns2 = 'hello world'\nprint(s1 == s2)             # False\nprint(s1 < s2)              # True\nprint(s1 == 'hello world')  # False\nprint(s2 == 'hello world')  # True\nprint(s2 != 'Hello world')  # True\ns3 = '小明'\nprint(ord('骆'))            # 39558\nprint(ord('昊'))            # 26122\ns4 = '王大锤'\nprint(ord('王'))            # 29579\nprint(ord('大'))            # 22823\nprint(ord('锤'))            # 38180\nprint(s3 >= s4)             # True\nprint(s3 != s4)             # True\n```\n\n#### 成员运算\n\nPython 中可以用`in`和`not in`判断一个字符串中是否包含另外一个字符或字符串，跟列表类型一样，`in`和`not in`称为成员运算符，会产生布尔值`True`或`False`，代码如下所示。\n\n```python\ns1 = 'hello, world'\ns2 = 'goodbye, world'\nprint('wo' in s1)      # True\nprint('wo' not in s2)  # False\nprint(s2 in s1)        # False\n```\n\n#### 获取字符串长度\n\n获取字符串长度跟获取列表元素个数一样，使用内置函数`len`，代码如下所示。\n\n```python\ns = 'hello, world'\nprint(len(s))                 # 12\nprint(len('goodbye, world'))  # 14\n```\n\n#### 索引和切片\n\n字符串的索引和切片操作跟列表、元组几乎没有区别，因为字符串也是一种有序序列，可以通过正向或反向的整数索引访问其中的元素。但是有一点需要注意，因为**字符串是不可变类型**，所以**不能通过索引运算修改字符串中的字符**。\n\n```python\ns = 'abc123456'\nn = len(s)\nprint(s[0], s[-n])    # a a\nprint(s[n-1], s[-1])  # 6 6\nprint(s[2], s[-7])    # c c\nprint(s[5], s[-4])    # 3 3\nprint(s[2:5])         # c12\nprint(s[-7:-4])       # c12\nprint(s[2:])          # c123456\nprint(s[:2])          # ab\nprint(s[::2])         # ac246\nprint(s[::-1])        # 654321cba\n```\n\n需要再次提醒大家注意的是，在进行索引运算时，如果索引越界，会引发`IndexError`异常，错误提示信息为：`string index out of range`（字符串索引超出范围）。\n\n### 字符的遍历\n\n如果希望遍历字符串中的每个字符，可以使用`for-in`循环，有如下所示的两种方式。\n\n方式一：\n\n```python\ns = 'hello'\nfor i in range(len(s)):\n    print(s[i])\n```\n\n方式二：\n\n```python\ns = 'hello'\nfor elem in s:\n    print(elem)\n```\n\n### 字符串的方法\n\n在 Python 中，我们可以通过字符串类型自带的方法对字符串进行操作和处理，假设我们有名为`foo`的字符串，字符串有名为`bar`的方法，那么使用字符串方法的语法是：`foo.bar()`，这是一种通过对象引用调用对象方法的语法，跟前面使用列表方法的语法是一样的。\n\n#### 大小写相关操作\n\n下面的代码演示了和字符串大小写变换相关的方法。\n\n```python\ns1 = 'hello, world!'\n# 字符串首字母大写\nprint(s1.capitalize())  # Hello, world!\n# 字符串每个单词首字母大写\nprint(s1.title())       # Hello, World!\n# 字符串变大写\nprint(s1.upper())       # HELLO, WORLD!\ns2 = 'GOODBYE'\n# 字符串变小写\nprint(s2.lower())       # goodbye\n# 检查s1和s2的值\nprint(s1)               # hello, world\nprint(s2)               # GOODBYE\n```\n\n> **说明**：由于字符串是不可变类型，使用字符串的方法对字符串进行操作会产生新的字符串，但是原来变量的值并没有发生变化。所以上面的代码中，当我们最后检查`s1`和`s2`两个变量的值时，`s1`和`s2` 的值并没有发生变化。\n\n#### 查找操作\n\n如果想在一个字符串中从前向后查找有没有另外一个字符串，可以使用字符串的`find`或`index`方法。在使用`find`和`index`方法时还可以通过方法的参数来指定查找的范围，也就是查找不必从索引为`0`的位置开始。\n\n```python\ns = 'hello, world!'\nprint(s.find('or'))      # 8\nprint(s.find('or', 9))   # -1\nprint(s.find('of'))      # -1\nprint(s.index('or'))     # 8\nprint(s.index('or', 9))  # ValueError: substring not found\n```\n\n>**说明**：`find`方法找不到指定的字符串会返回`-1`，`index`方法找不到指定的字符串会引发`ValueError`错误。\n\n`find`和`index`方法还有逆向查找（从后向前查找）的版本，分别是`rfind`和`rindex`，代码如下所示。\n\n```python\ns = 'hello world!'\nprint(s.find('o'))       # 4\nprint(s.rfind('o'))      # 7\nprint(s.rindex('o'))     # 7\n# print(s.rindex('o', 8))  # ValueError: substring not found\n```\n\n#### 性质判断\n\n可以通过字符串的`startswith`、`endswith`来判断字符串是否以某个字符串开头和结尾；还可以用`is`开头的方法判断字符串的特征，这些方法都返回布尔值，代码如下所示。\n\n```python\ns1 = 'hello, world!'\nprint(s1.startswith('He'))   # False\nprint(s1.startswith('hel'))  # True\nprint(s1.endswith('!'))      # True\ns2 = 'abc123456'\nprint(s2.isdigit())  # False\nprint(s2.isalpha())  # False\nprint(s2.isalnum())  # True\n```\n\n> **说明**：上面的`isdigit`用来判断字符串是不是完全由数字构成的，`isalpha`用来判断字符串是不是完全由字母构成的，这里的字母指的是 Unicode 字符但不包含 Emoji 字符，`isalnum`用来判断字符串是不是由字母和数字构成的。\n\n#### 格式化\n\n在 Python 中，字符串类型可以通过`center`、`ljust`、`rjust`方法做居中、左对齐和右对齐的处理。如果要在字符串的左侧补零，也可以使用`zfill`方法。\n\n```python\ns = 'hello, world'\nprint(s.center(20, '*'))  # ****hello, world****\nprint(s.rjust(20))        #         hello, world\nprint(s.ljust(20, '~'))   # hello, world~~~~~~~~\nprint('33'.zfill(5))      # 00033\nprint('-33'.zfill(5))     # -0033\n```\n\n我们之前讲过，在用`print`函数输出字符串时，可以用下面的方式对字符串进行格式化。\n\n```python\na = 321\nb = 123\nprint('%d * %d = %d' % (a, b, a * b))\n```\n\n当然，我们也可以用字符串的`format`方法来完成字符串的格式，代码如下所示。\n\n```python\na = 321\nb = 123\nprint('{0} * {1} = {2}'.format(a, b, a * b))\n```\n\n从 Python 3.6 开始，格式化字符串还有更为简洁的书写方式，就是在字符串前加上`f`来格式化字符串，在这种以`f`打头的字符串中，`{变量名}`是一个占位符，会被变量对应的值将其替换掉，代码如下所示。\n\n```python\na = 321\nb = 123\nprint(f'{a} * {b} = {a * b}')\n```\n\n如果需要进一步控制格式化语法中变量值的形式，可以参照下面的表格来进行字符串格式化操作。\n\n| 变量值      | 占位符     | 格式化结果    | 说明 |\n| ----------- | ---------- | ------------- | ---- |\n| `3.1415926` | `{:.2f}`   | `'3.14'`      | 保留小数点后两位 |\n| `3.1415926` | `{:+.2f}`  | `'+3.14'`       | 带符号保留小数点后两位 |\n| `-1`        | `{:+.2f}`  | `'-1.00'` | 带符号保留小数点后两位 |\n| `3.1415926` | `{:.0f}`   | `'3'` | 不带小数 |\n| `123`       | `{:0>10d}` | `'0000000123'` | 左边补`0`，补够10位 |\n| `123`       | `{:x<10d}` | `'123xxxxxxx'` | 右边补`x` ，补够10位 |\n| `123`       | `{:>10d}`  | `'       123'` | 左边补空格，补够10位 |\n| `123`       | `{:<10d}` | `'123       '` | 右边补空格，补够10位 |\n| `123456789` | `{:,}`     | `'123,456,789'` | 逗号分隔格式 |\n| `0.123`     | `{:.2%}`   | `'12.30%'`    | 百分比格式 |\n| `123456789` | `{:.2e}`   | `'1.23e+08'`  | 科学计数法格式 |\n\n#### 修剪操作\n\n字符串的`strip`方法可以帮我们获得将原字符串修剪掉左右两端指定字符之后的字符串，默认是修剪空格字符。这个方法非常有实用价值，可以用来将用户输入时不小心键入的头尾空格等去掉，`strip`方法还有`lstrip`和`rstrip`两个版本，相信从名字大家已经猜出来这两个方法是做什么用的。\n\n```python\ns1 = '   jackfrued@126.com  '\nprint(s1.strip())      # jackfrued@126.com\ns2 = '~你好，世界~'\nprint(s2.lstrip('~'))  # 你好，世界~\nprint(s2.rstrip('~'))  # ~你好，世界\n```\n\n#### 替换操作\n\n如果希望用新的内容替换字符串中指定的内容，可以使用`replace`方法，代码如下所示。`replace`方法的第一个参数是被替换的内容，第二个参数是替换后的内容，还可以通过第三个参数指定替换的次数。\n\n```python\ns = 'hello, good world'\nprint(s.replace('o', '@'))     # hell@, g@@d w@rld\nprint(s.replace('o', '@', 1))  # hell@, good world\n```\n\n#### 拆分与合并\n\n可以使用字符串的`split`方法将一个字符串拆分为多个字符串（放在一个列表中），也可以使用字符串的`join`方法将列表中的多个字符串连接成一个字符串，代码如下所示。\n\n```python\ns = 'I love you'\nwords = s.split()\nprint(words)            # ['I', 'love', 'you']\nprint('~'.join(words))  # I~love~you\n```\n\n需要说明的是，`split`方法默认使用空格进行拆分，我们也可以指定其他的字符来拆分字符串，而且还可以指定最大拆分次数来控制拆分的效果，代码如下所示。\n\n```python\ns = 'I#love#you#so#much'\nwords = s.split('#')\nprint(words)  # ['I', 'love', 'you', 'so', 'much']\nwords = s.split('#', 2)\nprint(words)  # ['I', 'love', 'you#so#much']\n```\n\n#### 编码和解码\n\nPython 中除了字符串`str`类型外，还有一种表示二进制数据的字节串类型（`bytes`）。所谓字节串，就是**由零个或多个字节组成的有限序列**。通过字符串的`encode`方法，我们可以按照某种编码方式将字符串编码为字节串，我们也可以使用字节串的`decode`方法，将字节串解码为字符串，代码如下所示。\n\n```python\na = '小明'\nb = a.encode('utf-8')\nc = a.encode('gbk')\nprint(b)                  # b'\\xe9\\xaa\\x86\\xe6\\x98\\x8a'\nprint(c)                  # b'\\xc2\\xe6\\xea\\xbb'\nprint(b.decode('utf-8'))  # 小明\nprint(c.decode('gbk'))    # 小明\n```\n\n注意，如果编码和解码的方式不一致，会导致乱码问题（无法再现原始的内容）或引发`UnicodeDecodeError`错误，导致程序崩溃。\n\n#### 其他方法\n\n对于字符串类型来说，还有一个常用的操作是对字符串进行匹配检查，即检查字符串是否满足某种特定的模式。例如，一个网站对用户注册信息中用户名和邮箱的检查，就属于模式匹配检查。实现模式匹配检查的工具叫做正则表达式，Python 语言通过标准库中的`re`模块提供了对正则表达式的支持，我们会在后续的课程中为大家讲解这个知识点。\n\n### 总结\n\n知道如何表示和操作字符串对程序员来说是非常重要的，因为我们经常需要处理文本信息，Python 中操作字符串可以用拼接、索引、切片等运算符，也可以使用字符串类型提供的非常丰富的方法。\n", "集合": "## 常用数据结构之集合\n\n在学习了列表和元组之后，我们再来学习一种容器型的数据类型，它的名字叫集合（set）。说到集合这个词大家一定不会陌生，在数学课本上就有这个概念。如果我们**把一定范围的、确定的、可以区别的事物当作一个整体来看待**，那么这个整体就是集合，集合中的各个事物称为集合的**元素**。通常，集合需要满足以下要求：\n\n1. **无序性**：一个集合中，每个元素的地位都是相同的，元素之间是无序的。\n2. **互异性**：一个集合中，任何两个元素都是不相同的，即元素在集合中只能出现一次。\n3. **确定性**：给定一个集合和一个任意元素，该元素要么属这个集合，要么不属于这个集合，二者必居其一，不允许有模棱两可的情况出现。\n\nPython 程序中的集合跟数学上的集合没有什么本质区别，需要强调的是上面所说的无序性和互异性。无序性说明集合中的元素并不像列中的元素那样存在某种次序，可以通过索引运算就能访问任意元素，**集合并不支持索引运算**。另外，集合的互异性决定了**集合中不能有重复元素**，这一点也是集合区别于列表的地方，我们无法将重复的元素添加到一个集合中。集合类型必然是支持`in`和`not in`成员运算的，这样就可以确定一个元素是否属于集合，也就是上面所说的集合的确定性。**集合的成员运算在性能上要优于列表的成员运算**，这是集合的底层存储特性决定的，此处我们暂时不做讨论，大家记住这个结论即可。\n\n> **说明**：集合底层使用了哈希存储（散列存储），对哈希存储不了解的读者可以先看看“Hello 算法”网站对[哈希表](https://www.hello-algo.com/chapter_hashing/)的讲解，感谢作者的开源精神。\n\n### 创建集合\n\n在 Python 中，创建集合可以使用`{}`字面量语法，`{}`中需要至少有一个元素，因为没有元素的`{}`并不是空集合而是一个空字典，字典类型我们会在下一节课中为大家介绍。当然，也可以使用 Python 内置函数`set`来创建一个集合，准确的说`set`并不是一个函数，而是创建集合对象的构造器，这个知识点会在后面讲解面向对象编程的地方为大家介绍。我们可以使用`set`函数创建一个空集合，也可以用它将其他序列转换成集合，例如：`set('hello')`会得到一个包含了`4`个字符的集合（重复的字符`l`只会在集合中出现一次）。除了这两种方式，还可以使用生成式语法来创建集合，就像我们之前用生成式语法创建列表那样。\n\n```python\nset1 = {1, 2, 3, 3, 3, 2}\nprint(set1)\n\nset2 = {'banana', 'pitaya', 'apple', 'apple', 'banana', 'grape'}\nprint(set2)\n\nset3 = set('hello')\nprint(set3)\n\nset4 = set([1, 2, 2, 3, 3, 3, 2, 1])\nprint(set4)\n\nset5 = {num for num in range(1, 20) if num % 3 == 0 or num % 7 == 0}\nprint(set5)\n```\n\n需要提醒大家，集合中的元素必须是`hashable`类型，所谓`hashable`类型指的是能够计算出哈希码的数据类型，通常不可变类型都是`hashable`类型，如整数（`int`）、浮点小数（`float`）、布尔值（`bool`）、字符串（`str`）、元组（`tuple`）等。可变类型都不是`hashable`类型，因为可变类型无法计算出确定的哈希码，所以它们不能放到集合中。例如：我们不能将列表作为集合中的元素；同理，由于集合本身也是可变类型，所以集合也不能作为集合中的元素。我们可以创建出嵌套列表（列表的元素也是列表），但是我们不能创建出嵌套的集合，这一点在使用集合的时候一定要引起注意。\n\n> **温馨提示**：如果不理解上面提到的哈希码、哈希存储这些概念，可以先放放，因为它并不影响你继续学习和使用 Python 语言。当然，如果是计算机专业的小伙伴，不理解哈希存储是很难被原谅的，要赶紧去补课了。\n\n### 元素的遍历\n\n我们可以通过`len`函数来获得集合中有多少个元素，但是我们不能通过索引运算来遍历集合中的元素，因为集合元素并没有特定的顺序。当然，要实现对集合元素的遍历，我们仍然可以使用`for-in`循环，代码如下所示。\n\n```python\nset1 = {'Python', 'C++', 'Java', 'Kotlin', 'Swift'}\nfor elem in set1:\n    print(elem)\n```\n\n> **提示**：大家看看上面代码的运行结果，通过单词输出的顺序体会一下集合的无序性。\n\n### 集合的运算\n\nPython 为集合类型提供了非常丰富的运算，主要包括：成员运算、交集运算、并集运算、差集运算、比较运算（相等性、子集、超集）等。\n\n#### 成员运算\n\n可以通过成员运算`in`和`not in `检查元素是否在集合中，代码如下所示。\n\n```python\nset1 = {11, 12, 13, 14, 15}\nprint(10 in set1)      # False \nprint(15 in set1)      # True\nset2 = {'Python', 'Java', 'C++', 'Swift'}\nprint('Ruby' in set2)  # False\nprint('Java' in set2)  # True\n```\n\n#### 二元运算\n\n集合的二元运算主要指集合的交集、并集、差集、对称差等运算，这些运算可以通过运算符来实现，也可以通过集合类型的方法来实现，代码如下所示。\n\n<img class=\"lazy\" data-src=\"/res/day12/set_operations.png\" style=\"zoom:50%;\">\n\n```python\nset1 = {1, 2, 3, 4, 5, 6, 7}\nset2 = {2, 4, 6, 8, 10}\n\n# 交集\nprint(set1 & set2)                      # {2, 4, 6}\nprint(set1.intersection(set2))          # {2, 4, 6}\n\n# 并集\nprint(set1 | set2)                      # {1, 2, 3, 4, 5, 6, 7, 8, 10}\nprint(set1.union(set2))                 # {1, 2, 3, 4, 5, 6, 7, 8, 10}\n\n# 差集\nprint(set1 - set2)                      # {1, 3, 5, 7}\nprint(set1.difference(set2))            # {1, 3, 5, 7}\n\n# 对称差\nprint(set1 ^ set2)                      # {1, 3, 5, 7, 8, 10}\nprint(set1.symmetric_difference(set2))  # {1, 3, 5, 7, 8, 10}\n```\n\n通过上面的代码可以看出，对两个集合求交集，`&`运算符和`intersection`方法的作用是完全相同的，使用运算符的方式显然更直观且代码也更简短。需要说明的是，集合的二元运算还可以跟赋值运算一起构成复合赋值运算，例如：`set1 |= set2`相当于`set1 = set1 | set2`，跟`|=`作用相同的方法是`update`；`set1 &= set2`相当于`set1 = set1 & set2`，跟`&=`作用相同的方法是`intersection_update`，代码如下所示。\n\n```python\nset1 = {1, 3, 5, 7}\nset2 = {2, 4, 6}\nset1 |= set2\n# set1.update(set2)\nprint(set1)  # {1, 2, 3, 4, 5, 6, 7}\nset3 = {3, 6, 9}\nset1 &= set3\n# set1.intersection_update(set3)\nprint(set1)  # {3, 6}\nset2 -= set1\n# set2.difference_update(set1)\nprint(set2)  # {2, 4}\n```\n\n#### 比较运算\n\n两个集合可以用`==`和`!=`进行相等性判断，如果两个集合中的元素完全相同，那么`==`比较的结果就是`True`，否则就是`False`。如果集合`A`的任意一个元素都是集合`B`的元素，那么集合`A`称为集合`B`的子集，即对于 $\\small{\\forall{a} \\in {A}}$ ，均有 $\\small{{a} \\in {B}}$ ，则 $\\small{{A} \\subseteq {B}}$ ，`A`是`B`的子集，反过来也可以称`B`是`A`的超集。如果`A`是`B`的子集且`A`不等于`B`，那么`A`就是`B`的真子集。Python 为集合类型提供了判断子集和超集的运算符，其实就是我们非常熟悉的`<`、`<=`、`>`、`>=`这些运算符。当然，我们也可以通过集合类型的方法`issubset`和`issuperset`来判断集合之间的关系，代码如下所示。\n\n```python\nset1 = {1, 3, 5}\nset2 = {1, 2, 3, 4, 5}\nset3 = {5, 4, 3, 2, 1}\n\nprint(set1 < set2)   # True\nprint(set1 <= set2)  # True\nprint(set2 < set3)   # False\nprint(set2 <= set3)  # True\nprint(set2 > set1)   # True\nprint(set2 == set3)  # True\n\nprint(set1.issubset(set2))    # True\nprint(set2.issuperset(set1))  # True\n```\n\n> **说明**：上面的代码中，`set1 < set2`判断`set1`是不是`set2`的真子集，`set1 <= set2`判断`set1`是不是`set2`的子集，`set2 > set1`判断`set2`是不是`set1`的超集。当然，我们也可以通过`set1.issubset(set2)`判断`set1`是不是`set2`的子集；通过`set2.issuperset(set1)`判断`set2`是不是`set1`的超集。\n\n### 集合的方法\n\n刚才我们说过，Python 中的集合是可变类型，我们可以通过集合的方法向集合添加元素或从集合中删除元素。\n\n```python\nset1 = {1, 10, 100}\n\n# 添加元素\nset1.add(1000)\nset1.add(10000)\nprint(set1)  # {1, 100, 1000, 10, 10000}\n\n# 删除元素\nset1.discard(10)\nif 100 in set1:\n    set1.remove(100)\nprint(set1)  # {1, 1000, 10000}\n\n# 清空元素\nset1.clear()\nprint(set1)  # set()\n```\n\n> **说明**：删除元素的`remove`方法在元素不存在时会引发`KeyError`错误，所以上面的代码中我们先通过成员运算判断元素是否在集合中。集合类型还有一个`pop`方法可以从集合中随机删除一个元素，该方法在删除元素的同时会返回（获得）被删除的元素，而`remove`和`discard`方法仅仅是删除元素，不会返回（获得）被删除的元素。\n\n集合类型还有一个名为`isdisjoint`的方法可以判断两个集合有没有相同的元素，如果没有相同元素，该方法返回`True`，否则该方法返回`False`，代码如下所示。\n\n```python\nset1 = {'Java', 'Python', 'C++', 'Kotlin'}\nset2 = {'Kotlin', 'Swift', 'Java', 'Dart'}\nset3 = {'HTML', 'CSS', 'JavaScript'}\nprint(set1.isdisjoint(set2))  # False\nprint(set1.isdisjoint(set3))  # True\n```\n\n### 不可变集合\n\nPython 中还有一种不可变类型的集合，名字叫`frozenset`。`set`跟`frozenset`的区别就如同`list`跟`tuple`的区别，`frozenset`由于是不可变类型，能够计算出哈希码，因此它可以作为`set`中的元素。除了不能添加和删除元素，`frozenset`在其他方面跟`set`是一样的，下面的代码简单的展示了`frozenset`的用法。\n\n```python\nfset1 = frozenset({1, 3, 5, 7})\nfset2 = frozenset(range(1, 6))\nprint(fset1)          # frozenset({1, 3, 5, 7})\nprint(fset2)          # frozenset({1, 2, 3, 4, 5})\nprint(fset1 & fset2)  # frozenset({1, 3, 5})\nprint(fset1 | fset2)  # frozenset({1, 2, 3, 4, 5, 7})\nprint(fset1 - fset2)  # frozenset({7})\nprint(fset1 < fset2)  # False\n```\n\n### 总结\n\nPython 中的**集合类型是一种无序容器**，**不允许有重复运算**，由于底层使用了哈希存储，集合中的元素必须是`hashable`类型。集合与列表最大的区别在于**集合中的元素没有顺序**、所以**不能够通过索引运算访问元素**、但是集合可以执行交集、并集、差集等二元运算，也可以通过关系运算符检查两个集合是否存在超集、子集等关系。\n", "字典": "## 常用数据结构之字典\n\n迄今为止，我们已经为大家介绍了 Python 中的三种容器型数据类型（列表、元组、集合），但是这些数据类型仍然不足以帮助我们解决所有的问题。例如，我们需要一个变量来保存一个人的多项信息，包括：姓名、年龄、身高、体重、家庭住址、本人手机号、紧急联系人手机号，此时你会发现，我们之前学过的列表、元组和集合类型都不够好使。\n\n```python\nperson1 = ['王大锤', 55, 168, 60, '成都市武侯区科华北路62号1栋101', '13122334455', '13800998877']\nperson2 = ('王大锤', 55, 168, 60, '成都市武侯区科华北路62号1栋101', '13122334455', '13800998877')\nperson3 = {'王大锤', 55, 168, 60, '成都市武侯区科华北路62号1栋101', '13122334455', '13800998877'}\n```\n\n集合肯定是最不合适的，因为集合中不能有重复元素，如果一个人的年龄和体重刚好相同，那么集合中就会少一项信息；同理，如果这个人的手机号和紧急联系人手机号是相同的，那么集合中又会少一项信息。另一方面，虽然列表和元组可以把一个人的所有信息都保存下来，但是当你想要获取这个人的手机号或家庭住址时，你得先知道他的手机号是列表或元组中的第几个元素。总之，在遇到上述的场景时，列表、元组、集合都不是最合适的选择，此时我们需要字典（dictionary）类型，这种数据类型最适合把相关联的信息组装到一起，可以帮助我们解决 Python 程序中为真实事物建模的问题。\n\n说到字典这个词，大家一定不陌生，读小学的时候，每个人手头基本上都有一本《新华字典》，如下图所示。\n\n<img class=\"lazy\" data-src=\"/res/day13/xinhua_dictionary.jpg\" style=\"zoom:80%;\">\n\nPython 程序中的字典跟现实生活中的字典很像，它以键值对（键和值的组合）的方式把数据组织到一起，我们可以通过键找到与之对应的值并进行操作。就像《新华字典》中，每个字（键）都有与它对应的解释（值）一样，每个字和它的解释合在一起就是字典中的一个条目，而字典中通常包含了很多个这样的条目。\n\n### 创建和使用字典\n\nPython 中创建字典可以使用`{}`字面量语法，这一点跟上一节课讲的集合是一样的。但是字典的`{}`中的元素是以键值对的形式存在的，每个元素由`:`分隔的两个值构成，`:`前面是键，`:`后面是值，代码如下所示。\n\n```python\nxinhua = {\n    '麓': '山脚下',\n    '路': '道，往来通行的地方；方面，地区：南～货，外～货；种类：他俩是一～人',\n    '蕗': '甘草的别名',\n    '潞': '潞水，水名，即今山西省的浊漳河；潞江，水名，即云南省的怒江'\n}\nprint(xinhua)\nperson = {\n    'name': '王大锤',\n    'age': 55,\n    'height': 168,\n    'weight': 60,\n    'addr': '成都市武侯区科华北路62号1栋101', \n    'tel': '13122334455',\n    'emergence contact': '13800998877'\n}\nprint(person)\n```\n\n通过上面的代码，相信大家已经看出来了，用字典来保存一个人的信息远远优于使用列表或元组，因为我们可以用`:`前面的键来表示条目的含义，而`:`后面就是这个条目所对应的值。\n\n当然，如果愿意，我们也可以使用内置函数`dict`或者是字典的生成式语法来创建字典，代码如下所示。\n\n```python\n# dict函数(构造器)中的每一组参数就是字典中的一组键值对\nperson = dict(name='王大锤', age=55, height=168, weight=60, addr='成都市武侯区科华北路62号1栋101')\nprint(person)  # {'name': '王大锤', 'age': 55, 'height': 168, 'weight': 60, 'addr': '成都市武侯区科华北路62号1栋101'}\n\n# 可以通过Python内置函数zip压缩两个序列并创建字典\nitems1 = dict(zip('ABCDE', '12345'))\nprint(items1)  # {'A': '1', 'B': '2', 'C': '3', 'D': '4', 'E': '5'}\nitems2 = dict(zip('ABCDE', range(1, 10)))\nprint(items2)  # {'A': 1, 'B': 2, 'C': 3, 'D': 4, 'E': 5}\n\n# 用字典生成式语法创建字典\nitems3 = {x: x ** 3 for x in range(1, 6)}\nprint(items3)  # {1: 1, 2: 8, 3: 27, 4: 64, 5: 125}\n```\n\n想知道字典中一共有多少组键值对，仍然是使用`len`函数；如果想对字典进行遍历，可以用`for`循环，但是需要注意，`for`循环只是对字典的键进行了遍历，不过没关系，在学习了字典的索引运算后，我们可以通过字典的键访问它对应的值。\n\n```python\nperson = {\n    'name': '王大锤',\n    'age': 55,\n    'height': 168,\n    'weight': 60,\n    'addr': '成都市武侯区科华北路62号1栋101'\n}\nprint(len(person))  # 5\nfor key in person:\n    print(key)\n```\n\n### 字典的运算\n\n对于字典类型来说，成员运算和索引运算肯定是很重要的，前者可以判定指定的键在不在字典中，后者可以通过键访问对应的值或者向字典中添加新的键值对。值得注意的是，字典的索引不同于列表的索引，列表中的元素因为有属于自己有序号，所以列表的索引是一个整数；字典中因为保存的是键值对，所以字典需要用键去索引对应的值。需要**特别提醒**大家注意的是，**字典中的键必须是不可变类型**，例如整数（`int`）、浮点数（`float`）、字符串（`str`）、元组（`tuple`）等类型，这一点跟集合类型对元素的要求是一样的；很显然，之前我们讲的列表（`list`）和集合（`set`）不能作为字典中的键，字典类型本身也不能再作为字典中的键，因为字典也是可变类型，但是列表、集合、字典都可以作为字典中的值，例如：\n\n```python\nperson = {\n    'name': '王大锤',\n    'age': 55,\n    'height': 168,\n    'weight': 60,\n    'addr': ['成都市武侯区科华北路62号1栋101', '北京市西城区百万庄大街1号'],\n    'car': {\n        'brand': 'BMW X7',\n        'maxSpeed': '250',\n        'length': 5170,\n        'width': 2000,\n        'height': 1835,\n        'displacement': 3.0\n    }\n}\nprint(person)\n```\n\n大家可以看看下面的代码，了解一下字典的成员运算和索引运算。\n\n```python\nperson = {'name': '王大锤', 'age': 55, 'height': 168, 'weight': 60, 'addr': '成都市武侯区科华北路62号1栋101'}\n\n# 成员运算\nprint('name' in person)  # True\nprint('tel' in person)   # False\n\n# 索引运算\nprint(person['name'])\nprint(person['addr'])\nperson['age'] = 25\nperson['height'] = 178\nperson['tel'] = '13122334455'\nperson['signature'] = '你的男朋友是一个盖世垃圾，他会踏着五彩祥云去迎娶你的闺蜜'\nprint(person)\n\n# 循环遍历\nfor key in person:\n    print(f'{key}:\\t{person[key]}')\n```\n\n需要注意，在通过索引运算获取字典中的值时，如指定的键没有在字典中，将会引发`KeyError`异常。\n\n### 字典的方法\n\n字典类型的方法基本上都跟字典的键值对操作相关，其中`get`方法可以通过键来获取对应的值。跟索引运算不同的是，`get`方法在字典中没有指定的键时不会产生异常，而是返回`None`或指定的默认值，代码如下所示。\n\n```python\nperson = {'name': '王大锤', 'age': 25, 'height': 178, 'addr': '成都市武侯区科华北路62号1栋101'}\nprint(person.get('name'))       # 王大锤\nprint(person.get('sex'))        # None\nprint(person.get('sex', True))  # True\n```\n\n如果需要获取字典中所有的键，可以使用`keys`方法；如果需要获取字典中所有的值，可以使用`values`方法。字典还有一个名为`items`的方法，它会将键和值组装成二元组，通过该方法来遍历字典中的元素也是非常方便的。\n\n```python\nperson = {'name': '王大锤', 'age': 25, 'height': 178}\nprint(person.keys())    # dict_keys(['name', 'age', 'height'])\nprint(person.values())  # dict_values(['王大锤', 25, 178])\nprint(person.items())   # dict_items([('name', '王大锤'), ('age', 25), ('height', 178)])\nfor key, value in person.items():\n    print(f'{key}:\\t{value}')\n```\n\n字典的`update`方法实现两个字典的合并操作。例如，有两个字典`x`和`y`，当执行`x.update(y)`操作时，`x`跟`y`相同的键对应的值会被`y`中的值更新，而`y`中有但`x`中没有的键值对会直接添加到`x`中，代码如下所示。\n\n```python\nperson1 = {'name': '王大锤', 'age': 55, 'height': 178}\nperson2 = {'age': 25, 'addr': '成都市武侯区科华北路62号1栋101'}\nperson1.update(person2)\nprint(person1)  # {'name': '王大锤', 'age': 25, 'height': 178, 'addr': '成都市武侯区科华北路62号1栋101'}\n```\n\n如果使用 Python 3.9 及以上的版本，也可以使用`|`运算符来完成同样的操作，代码如下所示。\n\n```python\nperson1 = {'name': '王大锤', 'age': 55, 'height': 178}\nperson2 = {'age': 25, 'addr': '成都市武侯区科华北路62号1栋101'}\nperson1 |= person2\nprint(person1)  # {'name': '王大锤', 'age': 25, 'height': 178, 'addr': '成都市武侯区科华北路62号1栋101'}\n```\n\n可以通过`pop`或`popitem`方法从字典中删除元素，前者会返回（获得）键对应的值，但是如果字典中不存在指定的键，会引发`KeyError`错误；后者在删除元素时，会返回（获得）键和值组成的二元组。字典的`clear`方法会清空字典中所有的键值对，代码如下所示。\n\n```python\nperson = {'name': '王大锤', 'age': 25, 'height': 178, 'addr': '成都市武侯区科华北路62号1栋101'}\nprint(person.pop('age'))  # 25\nprint(person)             # {'name': '王大锤', 'height': 178, 'addr': '成都市武侯区科华北路62号1栋101'}\nprint(person.popitem())   # ('addr', '成都市武侯区科华北路62号1栋101')\nprint(person)             # {'name': '王大锤', 'height': 178}\nperson.clear()\nprint(person)             # {}\n```\n\n跟列表一样，从字典中删除元素也可以使用`del`关键字，在删除元素的时候如果指定的键索引不到对应的值，一样会引发`KeyError`错误，具体的做法如下所示。\n\n```python\nperson = {'name': '王大锤', 'age': 25, 'height': 178, 'addr': '成都市武侯区科华北路62号1栋101'}\ndel person['age']\ndel person['addr']\nprint(person)  # {'name': '王大锤', 'height': 178}\n```\n\n### 字典的应用\n\n我们通过几个简单的例子来看看如何使用字典类型解决一些实际的问题。\n\n**例子1**：输入一段话，统计每个英文字母出现的次数，按出现次数从高到低输出。\n\n```python\nsentence = input('请输入一段话: ')\ncounter = {}\nfor ch in sentence:\n    if 'A' <= ch <= 'Z' or 'a' <= ch <= 'z':\n        counter[ch] = counter.get(ch, 0) + 1\nsorted_keys = sorted(counter, key=counter.get, reverse=True)\nfor key in sorted_keys:\n    print(f'{key} 出现了 {counter[key]} 次.')\n```\n\n输入：\n\n```\nMan is distinguished, not only by his reason, but by this singular passion from other animals, which is a lust of the mind, that by a perseverance of delight in the continued and indefatigable generation of knowledge, exceeds the short vehemence of any carnal pleasure.\n```\n\n输出：\n\n```\ne 出现了 27 次.\nn 出现了 21 次.\na 出现了 18 次.\ni 出现了 18 次.\ns 出现了 16 次.\nt 出现了 16 次.\no 出现了 14 次.\nh 出现了 13 次.\nr 出现了 10 次.\nd 出现了 9 次.\nl 出现了 9 次.\ng 出现了 6 次.\nu 出现了 6 次.\nf 出现了 6 次.\nc 出现了 6 次.\ny 出现了 5 次.\nb 出现了 5 次.\nm 出现了 4 次.\np 出现了 3 次.\nw 出现了 2 次.\nv 出现了 2 次.\nM 出现了 1 次.\nk 出现了 1 次.\nx 出现了 1 次.\n```\n\n**例子2**：在一个字典中保存了股票的代码和价格，找出股价大于100元的股票并创建一个新的字典。\n\n> **说明**：可以用字典的生成式语法来创建这个新字典。\n\n```python\nstocks = {\n    'AAPL': 191.88,\n    'GOOG': 1186.96,\n    'IBM': 149.24,\n    'ORCL': 48.44,\n    'ACN': 166.89,\n    'FB': 208.09,\n    'SYMC': 21.29\n}\nstocks2 = {key: value for key, value in stocks.items() if value > 100}\nprint(stocks2)\n```\n\n输出：\n\n```\n{'AAPL': 191.88, 'GOOG': 1186.96, 'IBM': 149.24, 'ACN': 166.89, 'FB': 208.09}\n```\n\n### 总结\n\nPython 程序中的字典跟现实生活中字典非常像，允许我们**以键值对的形式保存数据**，再**通过键访问对应的值**。字典是一种非常**有利于数据检索**的数据类型，但是需要再次提醒大家，**字典中的键必须是不可变类型**，列表、集合、字典等类型的数据都不能作为字典的键。\n", "函数和模块": "## 函数和模块\n\n在讲解本节课的内容之前，我们先来研究一道数学题，请说出下面的方程有多少组正整数解。\n\n$$\nx_{1} + x_{2} + x_{3} + x_{4} = 8\n$$\n\n你可能已经想到了，这个问题其实等同于将 8 个苹果分成四组且每组至少一个苹果有多少种方案，也等价于在分隔 8 个苹果的 7 个间隙之间放入三个隔断将苹果分成四组有多少种方案，所以答案是 $\\small{C_{7}^{3} = 35}$ ，其中 $\\small{C_{7}^{3}}$ 代表 7 选 3 的组合数，其计算公式如下所示。\n\n$$\nC_m^n = \\frac {m!} {n!(m-n)!}\n$$\n\n根据之前学习的知识，我们可以用循环做累乘的方式分别计算出 $\\small{m!}$ 、 $\\small{n!}$ 和 $\\small{(m-n)!}$ ，然后再通过除法运算得到组合数 $\\small{C_{m}^{n}}$ ，代码如下所示。\n\n```python\n\"\"\"\n输入m和n，计算组合数C(m,n)的值\n\nVersion: 1.0\nAuthor: 小明\n\"\"\"\n\nm = int(input('m = '))\nn = int(input('n = '))\n# 计算m的阶乘\nfm = 1\nfor num in range(1, m + 1):\n    fm *= num\n# 计算n的阶乘\nfn = 1\nfor num in range(1, n + 1):\n    fn *= num\n# 计算m-n的阶乘\nfk = 1\nfor num in range(1, m - n + 1):\n    fk *= num\n# 计算C(M,N)的值\nprint(fm // fn // fk)\n```\n\n输入：\n\n```\nm = 7\nn = 3\n```\n\n输出：\n\n```\n35\n```\n\n不知大家是否注意到，上面的代码中我们做了三次求阶乘的操作，虽然 $\\small{m}$ 、 $\\small{n}$ 、 $\\small{m - n}$ 的值各不相同，但是三段代码并没有实质性的区别，属于重复代码。世界级的编程大师*Martin Fowler*曾经说过：“**代码有很多种坏味道，重复是最坏的一种！**”。要写出高质量的代码，首先就要解决重复代码的问题。对于上面的代码来说，我们可以将求阶乘的功能封装到一个称为“函数”的代码块中，在需要计算阶乘的地方，我们只需“调用函数”即可实现对求阶乘功能的复用。\n\n### 定义函数\n\n数学上的函数通常形如 $\\small{y = f(x)}$ 或者 $\\small{z = g(x, y)}$ 这样的形式，在 $\\small{y = f(x)}$ 中， $\\small{f}$ 是函数的名字， $\\small{x}$ 是函数的自变量， $\\small{y}$ 是函数的因变量；而在 $\\small{z = g(x, y)}$ 中， $\\small{g}$ 是函数名， $\\small{x}$ 和 $\\small{y}$ 是函数的自变量， $\\small{z}$ 是函数的因变量。Python 中的函数跟这个结构是一致的，每个函数都有自己的名字、自变量和因变量。我们通常把 Python 函数的自变量称为函数的参数，而因变量称为函数的返回值。\n\nPython 中可以使用`def`关键字来定义函数，和变量一样每个函数也应该有一个漂亮的名字，命名规则跟变量的命名规则是一样的（大家赶紧想想我们之前讲过的变量的命名规则）。在函数名后面的圆括号中可以设置函数的参数，也就是我们刚才说的函数的自变量，而函数执行完成后，我们会通过`return`关键字来返回函数的执行结果，这就是我们刚才说的函数的因变量。如果函数中没有`return`语句，那么函数会返回代表空值的`None`。另外，函数也可以没有自变量（参数），但是函数名后面的圆括号是必须有的。一个函数要做的事情（要执行的代码），是通过代码缩进的方式放到函数定义行之后，跟之前分支和循环结构的代码块类似，如下图所示。\n\n<img class=\"lazy\" data-src=\"/res/day14/function_definition.png\" style=\"zoom:45%;\">\n\n下面，我们将之前代码中求阶乘的操作放到一个函数中，通过这种方式来重构上面的代码。**所谓重构，是在不影响代码执行结果的前提下对代码的结构进行调整**，重构之后的代码如下所示。\n\n```python\n\"\"\"\n输入m和n，计算组合数C(m,n)的值\n\nVersion: 1.1\nAuthor: 小明\n\"\"\"\n\n\n# 通过关键字def定义求阶乘的函数\n# 自变量（参数）num是一个非负整数\n# 因变量（返回值）是num的阶乘\ndef fac(num):\n    result = 1\n    for n in range(2, num + 1):\n        result *= n\n    return result\n\n\nm = int(input('m = '))\nn = int(input('n = '))\n# 计算阶乘的时候不需要写重复的代码而是直接调用函数\n# 调用函数的语法是在函数名后面跟上圆括号并传入参数\nprint(fac(m) // fac(n) // fac(m - n))\n```\n\n大家可以感受下，上面的代码是不是比之前的版本更加简单优雅。更为重要的是，我们定义的求阶乘函数`fac`还可以在其他需要求阶乘的代码中重复使用。所以，**使用函数可以帮助我们将功能上相对独立且会被重复使用的代码封装起来**，当我们需要这些的代码，不是把重复的代码再编写一遍，而是**通过调用函数实现对既有代码的复用**。事实上，Python 标准库的`math`模块中，已经有一个名为`factorial`的函数实现了求阶乘的功能，我们可以直接用`import math`导入`math`模块，然后使用`math.factorial`来调用求阶乘的函数；我们也可以通过`from math import factorial`直接导入`factorial`函数来使用它，代码如下所示。\n\n```python\n\"\"\"\n输入m和n，计算组合数C(m,n)的值\n\nVersion: 1.2\nAuthor: 小明\n\"\"\"\nfrom math import factorial\n\nm = int(input('m = '))\nn = int(input('n = '))\nprint(factorial(m) // factorial(n) // factorial(m - n))\n```\n\n将来我们使用的函数，要么是自定义的函数，要么是 Python 标准库或者三方库中提供的函数，如果已经有现成的可用的函数，我们就没有必要自己去定义，“**重复发明轮子**”是一件非常糟糕的事情。对于上面的代码，如果你觉得`factorial`这个名字太长，书写代码的时候不是特别方便，我们在导入函数的时候还可以通过`as`关键字为其别名。在调用函数的时候，我们可以用函数的别名，而不再使用它之前的名字，代码如下所示。\n\n```python\n\"\"\"\n输入m和n，计算组合数C(m,n)的值\n\nVersion: 1.3\nAuthor: 小明\n\"\"\"\nfrom math import factorial as f\n\nm = int(input('m = '))\nn = int(input('n = '))\nprint(f(m) // f(n) // f(m - n))\n```\n\n### 函数的参数\n\n#### 位置参数和关键字参数\n\n我们再来写一个函数，根据给出的三条边的长度判断是否可以构成三角形，如果可以构成三角形则返回`True`，否则返回`False`，代码如下所示。\n\n```python\ndef make_judgement(a, b, c):\n    \"\"\"判断三条边的长度能否构成三角形\"\"\"\n    return a + b > c and b + c > a and a + c > b\n```\n\n上面`make_judgement`函数有三个参数，这种参数叫做位置参数，在调用函数时通常按照从左到右的顺序依次传入，而且传入参数的数量必须和定义函数时参数的数量相同，如下所示。\n\n```python\nprint(make_judgement(1, 2, 3))  # False\nprint(make_judgement(4, 5, 6))  # True\n```\n\n如果不想按照从左到右的顺序依次给出`a`、`b`、`c` 三个参数的值，也可以使用关键字参数，通过“参数名=参数值”的形式为函数传入参数，如下所示。\n\n```python\nprint(make_judgement(b=2, c=3, a=1))  # False\nprint(make_judgement(c=6, b=4, a=5))  # True\n```\n\n在定义函数时，我们可以在参数列表中用`/`设置**强制位置参数**（*positional-only arguments*），用`*`设置**命名关键字参数**。所谓强制位置参数，就是调用函数时只能按照参数位置来接收参数值的参数；而命名关键字参数只能通过“参数名=参数值”的方式来传递和接收参数，大家可以看看下面的例子。\n\n```python\n# /前面的参数是强制位置参数\ndef make_judgement(a, b, c, /):\n    \"\"\"判断三条边的长度能否构成三角形\"\"\"\n    return a + b > c and b + c > a and a + c > b\n\n\n# 下面的代码会产生TypeError错误，错误信息提示“强制位置参数是不允许给出参数名的”\n# TypeError: make_judgement() got some positional-only arguments passed as keyword arguments\n# print(make_judgement(b=2, c=3, a=1))\n```\n\n> **说明**：强制位置参数是 Python 3.8 引入的新特性，在使用低版本的 Python 解释器时需要注意。\n\n```python\n# *后面的参数是命名关键字参数\ndef make_judgement(*, a, b, c):\n    \"\"\"判断三条边的长度能否构成三角形\"\"\"\n    return a + b > c and b + c > a and a + c > b\n\n\n# 下面的代码会产生TypeError错误，错误信息提示“函数没有位置参数但却给了3个位置参数”\n# TypeError: make_judgement() takes 0 positional arguments but 3 were given\n# print(make_judgement(1, 2, 3))\n```\n\n#### 参数的默认值\n\nPython 中允许函数的参数拥有默认值，我们可以把之前讲过的一个例子“CRAPS赌博游戏”（《第07课：分支和循环结构的应用》）中摇色子获得点数的功能封装到函数中，代码如下所示。\n\n```python\nfrom random import randrange\n\n\n# 定义摇色子的函数\n# 函数的自变量（参数）n表示色子的个数，默认值为2\n# 函数的因变量（返回值）表示摇n颗色子得到的点数\ndef roll_dice(n=2):\n    total = 0\n    for _ in range(n):\n        total += randrange(1, 7)\n    return total\n\n\n# 如果没有指定参数，那么n使用默认值2，表示摇两颗色子\nprint(roll_dice())\n# 传入参数3，变量n被赋值为3，表示摇三颗色子获得点数\nprint(roll_dice(3))\n```\n\n我们再来看一个更为简单的例子。\n\n```python\ndef add(a=0, b=0, c=0):\n    \"\"\"三个数相加求和\"\"\"\n    return a + b + c\n\n\n# 调用add函数，没有传入参数，那么a、b、c都使用默认值0\nprint(add())         # 0\n# 调用add函数，传入一个参数，该参数赋值给变量a, 变量b和c使用默认值0\nprint(add(1))        # 1\n# 调用add函数，传入两个参数，分别赋值给变量a和b，变量c使用默认值0\nprint(add(1, 2))     # 3\n# 调用add函数，传入三个参数，分别赋值给a、b、c三个变量\nprint(add(1, 2, 3))  # 6\n```\n\n需要注意的是，**带默认值的参数必须放在不带默认值的参数之后**，否则将产生`SyntaxError`错误，错误消息是：`non-default argument follows default argument`，翻译成中文的意思是“没有默认值的参数放在了带默认值的参数后面”。\n\n#### 可变参数\n\nPython 语言中可以通过星号表达式语法让函数支持可变参数。所谓可变参数指的是在调用函数时，可以向函数传入`0`个或任意多个参数。将来我们以团队协作的方式开发商业项目时，很有可能要设计函数给其他人使用，但有的时候我们并不知道函数的调用者会向该函数传入多少个参数，这个时候可变参数就能派上用场。\n\n下面的代码演示了如何使用可变位置参数实现对任意多个数求和的`add`函数，调用函数时传入的参数会保存到一个元组，通过对该元组的遍历，可以获取传入函数的参数。\n\n```python\n# 用星号表达式来表示args可以接收0个或任意多个参数\n# 调用函数时传入的n个参数会组装成一个n元组赋给args\n# 如果一个参数都没有传入，那么args会是一个空元组\ndef add(*args):\n    total = 0\n    # 对保存可变参数的元组进行循环遍历\n    for val in args:\n        # 对参数进行了类型检查（数值型的才能求和）\n        if type(val) in (int, float):\n            total += val\n    return total\n\n\n# 在调用add函数时可以传入0个或任意多个参数\nprint(add())         # 0\nprint(add(1))        # 1\nprint(add(1, 2, 3))  # 6\nprint(add(1, 2, 'hello', 3.45, 6))  # 12.45\n```\n\n如果我们希望通过“参数名=参数值”的形式传入若干个参数，具体有多少个参数也是不确定的，我们还可以给函数添加可变关键字参数，把传入的关键字参数组装到一个字典中，代码如下所示。\n\n```python\n# 参数列表中的**kwargs可以接收0个或任意多个关键字参数\n# 调用函数时传入的关键字参数会组装成一个字典（参数名是字典中的键，参数值是字典中的值）\n# 如果一个关键字参数都没有传入，那么kwargs会是一个空字典\ndef foo(*args, **kwargs):\n    print(args)\n    print(kwargs)\n\n\nfoo(3, 2.1, True, name='小明', age=43, gpa=4.95)\n```\n\n输出：\n\n```\n(3, 2.1, True)\n{'name': '小明', 'age': 43, 'gpa': 4.95}\n```\n\n### 用模块管理函数\n\n不管用什么样的编程语言来写代码，给变量、函数起名字都是一个让人头疼的问题，因为我们会遇到**命名冲突**这种尴尬的情况。最简单的场景就是在同一个`.py`文件中定义了两个同名的函数，如下所示。\n\n```python\ndef foo():\n    print('hello, world!')\n\n\ndef foo():\n    print('goodbye, world!')\n\n    \nfoo()  # 大家猜猜调用foo函数会输出什么\n```\n\n当然上面的这种情况我们很容易就能避免，但是如果项目是团队协作多人开发的时候，团队中可能有多个程序员都定义了名为`foo`的函数，这种情况下怎么解决命名冲突呢？答案其实很简单，Python 中每个文件就代表了一个模块（module），我们在不同的模块中可以有同名的函数，在使用函数的时候，我们通过`import`关键字导入指定的模块再使用**完全限定名**（`模块名.函数名`）的调用方式，就可以区分到底要使用的是哪个模块中的`foo`函数，代码如下所示。\n\n`module1.py`\n\n```python\ndef foo():\n    print('hello, world!')\n```\n\n`module2.py`\n\n```python\ndef foo():\n    print('goodbye, world!')\n```\n\n`test.py`\n\n```python\nimport module1\nimport module2\n\n# 用“模块名.函数名”的方式（完全限定名）调用函数，\nmodule1.foo()  # hello, world!\nmodule2.foo()  # goodbye, world!\n```\n\n在导入模块时，还可以使用`as`关键字对模块进行别名，这样我们可以使用更为简短的完全限定名。\n\n`test.py`\n\n```python\nimport module1 as m1\nimport module2 as m2\n\nm1.foo()  # hello, world!\nm2.foo()  # goodbye, world!\n```\n\n上面两段代码，我们导入的是定义函数的模块，我们也可以使用`from...import...`语法从模块中直接导入需要使用的函数，代码如下所示。\n\n`test.py`\n\n```python\nfrom module1 import foo\n\nfoo()  # hello, world!\n\nfrom module2 import foo\n\nfoo()  # goodbye, world!\n```\n\n但是，如果我们如果从两个不同的模块中导入了同名的函数，后面导入的函数会替换掉之前的导入，就像下面的代码，调用`foo`会输出`goodbye, world!`，因为我们先导入了`module1`的`foo`，后导入了`module2`的`foo` 。如果两个`from...import...`反过来写，那就是另外一番光景了。\n\n`test.py`\n\n```python\nfrom module1 import foo\nfrom module2 import foo\n\nfoo()  # goodbye, world!\n```\n\n如果想在上面的代码中同时使用来自两个模块的`foo`函数还是有办法的，大家可能已经猜到了，还是用`as`关键字对导入的函数进行别名，代码如下所示。\n\n`test.py`\n\n```python\nfrom module1 import foo as f1\nfrom module2 import foo as f2\n\nf1()  # hello, world!\nf2()  # goodbye, world!\n```\n\n### 标准库中的模块和函数\n\nPython 标准库中提供了大量的模块和函数来简化我们的开发工作，我们之前用过的`random`模块就为我们提供了生成随机数和进行随机抽样的函数；而`time`模块则提供了和时间操作相关的函数；我们之前用到过的`math`模块中还包括了计算正弦、余弦、指数、对数等一系列的数学函数。随着我们深入学习 Python 语言，我们还会用到更多的模块和函数。\n\nPython 标准库中还有一类函数是不需要`import`就能够直接使用的，我们将其称之为**内置函数**，这些内置函数不仅有用而且还很常用，下面的表格列出了一部分的内置函数。\n\n| 函数    | 说明                                                         |\n| ------- | ------------------------------------------------------------ |\n| `abs`   | 返回一个数的绝对值，例如：`abs(-1.3)`会返回`1.3`。           |\n| `bin`   | 把一个整数转换成以`'0b'`开头的二进制字符串，例如：`bin(123)`会返回`'0b1111011'`。 |\n| `chr`   | 将Unicode编码转换成对应的字符，例如：`chr(8364)`会返回`'€'`。 |\n| `hex`   | 将一个整数转换成以`'0x'`开头的十六进制字符串，例如：`hex(123)`会返回`'0x7b'`。 |\n| `input` | 从输入中读取一行，返回读到的字符串。                         |\n| `len`   | 获取字符串、列表等的长度。                                   |\n| `max`   | 返回多个参数或一个可迭代对象中的最大值，例如：`max(12, 95, 37)`会返回`95`。 |\n| `min`   | 返回多个参数或一个可迭代对象中的最小值，例如：`min(12, 95, 37)`会返回`12`。 |\n| `oct`   | 把一个整数转换成以`'0o'`开头的八进制字符串，例如：`oct(123)`会返回`'0o173'`。 |\n| `open`  | 打开一个文件并返回文件对象。                                 |\n| `ord`   | 将字符转换成对应的Unicode编码，例如：`ord('€')`会返回`8364`。 |\n| `pow`   | 求幂运算，例如：`pow(2, 3)`会返回`8`；`pow(2, 0.5)`会返回`1.4142135623730951`。 |\n| `print` | 打印输出。                                                   |\n| `range` | 构造一个范围序列，例如：`range(100)`会产生`0`到`99`的整数序列。 |\n| `round` | 按照指定的精度对数值进行四舍五入，例如：`round(1.23456, 4)`会返回`1.2346`。 |\n| `sum`   | 对一个序列中的项从左到右进行求和运算，例如：`sum(range(1, 101))`会返回`5050`。 |\n| `type`  | 返回对象的类型，例如：`type(10)`会返回`int`；而` type('hello')`会返回`str`。 |\n\n###  总结\n\n**函数是对功能相对独立且会重复使用的代码的封装**。学会使用定义和使用函数，就能够写出更为优质的代码。当然，Python 语言的标准库中已经为我们提供了大量的模块和常用的函数，用好这些模块和函数就能够用更少的代码做更多的事情；如果这些模块和函数不能满足我们的要求，可能就需要自定义函数，然后再通过模块的概念来管理这些自定义函数。", "函数应用实战": "## 函数应用实战\n\n### 例子1：随机验证码\n\n设计一个生成随机验证码的函数，验证码由数字和英文大小写字母构成，长度可以通过参数设置。\n\n```python\nimport random\nimport string\n\nALL_CHARS = string.digits + string.ascii_letters\n\n\ndef generate_code(*, code_len=4):\n    \"\"\"\n    生成指定长度的验证码\n    :param code_len: 验证码的长度(默认4个字符)\n    :return: 由大小写英文字母和数字构成的随机验证码字符串\n    \"\"\"\n    return ''.join(random.choices(ALL_CHARS, k=code_len))\n```\n\n> **说明1**：`string`模块的`digits`代表0到9的数字构成的字符串`'0123456789'`，`string`模块的`ascii_letters`代表大小写英文字母构成的字符串`'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'`。\n>\n> **说明2**：`random`模块的`sample`和`choices`函数都可以实现随机抽样，`sample`实现无放回抽样，这意味着抽样取出的元素是不重复的；`choices`实现有放回抽样，这意味着可能会重复选中某些元素。这两个函数的第一个参数代表抽样的总体，而参数`k`代表样本容量，需要说明的是`choices`函数的参数`k`是一个命名关键字参数，在传参时必须指定参数名。\n\n可以用下面的代码生成5组随机验证码来测试上面的函数。\n\n```python\nfor _ in range(5):\n    print(generate_code()) \n```\n\n输出：\n\n```\n59tZ\nQKU5\nizq8\nIBBb\njIfX\n```\n\n或者\n\n```python\nfor _ in range(5):\n    print(generate_code(code_len=6))\n```\n\n输出：\n\n```\nFxJucw\nHS4H9G\n0yyXfz\nx7fohf\nReO22w\n```\n\n> **说明**：我们设计的`generate_code`函数的参数是命名关键字参数，由于它有默认值，可以不给它传值，使用默认值4。如果需要给函数传入参数，必须指定参数名`code_len`。\n\n### 例子2：判断素数\n\n设计一个判断给定的大于1的正整数是不是质数的函数。质数是只能被1和自身整除的正整数（大于1），如果一个大于 1 的正整数 $\\small{N}$ 是质数，那就意味着在 2 到 $\\small{N-1}$ 之间都没有它的因子。\n\n```python\ndef is_prime(num: int) -> bool:\n    \"\"\"\n    判断一个正整数是不是质数\n    :param num: 大于1的正整数\n    :return: 如果num是质数返回True，否则返回False\n    \"\"\"\n    for i in range(2, int(num ** 0.5) + 1):\n        if num % i == 0:\n            return False\n    return True\n```\n\n> **说明1**：上面`is_prime`函数的参数`num`后面的`: int`用来标注参数的类型，虽然它对代码的执行结果不产生任何影响，但是很好的增强了代码的可读性。同理，参数列表后面的`-> bool`用来标注函数返回值的类型，它也不会对代码的执行结果产生影响，但是却让我们清楚的知道，调用函数会得到一个布尔值，要么是`True`，要么是`False`。\n>\n> **说明2**：上面的循环并不需要从 2 循环到 $\\small{N-1}$ ，因为如果循环进行到 $\\small{\\sqrt{N}}$ 时，还没有找到$\\small{N}$的因子，那么 $\\small{\\sqrt{N}}$ 之后也不会出现 $\\small{N}$ 的因子，大家可以自己想一想这是为什么。\n\n### 例子3：最大公约数和最小公倍数\n\n设计计算两个正整数最大公约数和最小公倍数的函数。 $\\small{x}$ 和 $\\small{y}$ 的最大公约数是能够同时整除 $\\small{x}$ 和 $\\small{y}$ 的最大整数，如果 $\\small{x}$ 和 $\\small{y}$ 互质，那么它们的最大公约数为 1； $\\small{x}$ 和 $\\small{y}$ 的最小公倍数是能够同时被 $\\small{x}$ 和 $\\small{y}$ 整除的最小正整数，如果 $\\small{x}$ 和 $\\small{y}$ 互质，那么它们的最小公倍数为 $\\small{x \\times y}$ 。需要提醒大家注意的是，计算最大公约数和最小公倍数是两个不同的功能，应该设计成两个函数，而不是把两个功能放到同一个函数中。\n\n```python\ndef lcm(x: int, y: int) -> int:\n    \"\"\"求最小公倍数\"\"\"\n    return x * y // gcd(x, y)\n\n\ndef gcd(x: int, y: int) -> int:\n    \"\"\"求最大公约数\"\"\"\n    while y % x != 0:\n        x, y = y % x, x\n    return x\n```\n\n> **说明**：函数之间可以相互调用，上面求最小公倍数的`lcm`函数调用了求最大公约数的`gcd`函数，通过 $\\frac{x \\times y}{ gcd(x, y)}$ 来计算最小公倍数。\n\n### 例子4：数据统计\n\n假设样本数据保存一个列表中，设计计算样本数据描述性统计信息的函数。描述性统计信息通常包括：算术平均值、中位数、极差（最大值和最小值的差）、方差、标准差、变异系数等，计算公式如下所示。\n\n样本均值（sample mean）：\n\n$$\n\\bar{x} = \\frac{\\sum_{i=1}^{n}x_{i}}{n} = \\frac{x_{1}+x_{2}+\\cdots +x_{n}}{n}\n$$\n\n样本方差（sample variance）：\n\n$$\ns^2 = \\frac {\\sum_{i=1}^{n}(x_i - \\bar{x})^2} {n-1}\n$$\n\n样本标准差（sample standard deviation）：\n\n$$\ns = \\sqrt{\\frac{\\sum_{i=1}^{n}(x_i - \\bar{x})^2}{n-1}}\n$$\n\n变异系数（coefficient of sample variation）：\n\n$$\nCV = \\frac{s}{\\bar{x}}\n$$\n\n```python\ndef ptp(data):\n    \"\"\"极差（全距）\"\"\"\n    return max(data) - min(data)\n\n\ndef mean(data):\n    \"\"\"算术平均\"\"\"\n    return sum(data) / len(data)\n\n\ndef median(data):\n    \"\"\"中位数\"\"\"\n    temp, size = sorted(data), len(data)\n    if size % 2 != 0:\n        return temp[size // 2]\n    else:\n        return mean(temp[size // 2 - 1:size // 2 + 1])\n\n\ndef var(data, ddof=1):\n    \"\"\"方差\"\"\"\n    x_bar = mean(data)\n    temp = [(num - x_bar) ** 2 for num in data]\n    return sum(temp) / (len(temp) - ddof)\n\n\ndef std(data, ddof=1):\n    \"\"\"标准差\"\"\"\n    return var(data, ddof) ** 0.5\n\n\ndef cv(data, ddof=1):\n    \"\"\"变异系数\"\"\"\n    return std(data, ddof) / mean(data)\n\n\ndef describe(data):\n    \"\"\"输出描述性统计信息\"\"\"\n    print(f'均值: {mean(data)}')\n    print(f'中位数: {median(data)}')\n    print(f'极差: {ptp(data)}')\n    print(f'方差: {var(data)}')\n    print(f'标准差: {std(data)}')\n    print(f'变异系数: {cv(data)}')\n```\n\n> **说明1**：中位数是将数据按照升序或降序排列后位于中间的数，它描述了数据的中等水平。中位数的计算分两种情况：当数据体量$n$为奇数时，中位数是位于 $\\frac{n + 1}{2}$ 位置的元素；当数据体量 $\\small{n}$ 为偶数时，中位数是位于 $\\frac{n}{2}$ 和 $\\frac{n}{2} + 1$ 两个位置元素的均值。\n>\n> **说明2**：计算方差和标准差的函数中有一个名为`ddof`的参数，它代表了可以调整的自由度，默认值为 1。在计算样本方差和样本标准差时，需要进行自由度校正；如果要计算总体方差和总体标准差，可以将`ddof`参数赋值为 0，即不需要进行自由度校正。\n>\n> **说明3**：`describe`函数将上面封装好的统计函数组装到一起，用于输出数据的描述性统计信息。事实上，Python 标准库中有一个名为`statistics`的模块，它已经把获取描述性统计信息的函数封装好了，有兴趣的读者可以自行了解。\n\n### 例子5：双色球随机选号\n\n我们用函数重构之前讲过的双色球随机选号的例子（《第09课：常用数据结构之列表-2》），将生成随机号码和输出一组号码的功能分别封装到两个函数中，然后通过调用函数实现机选`N`注号码的功能。\n\n```python\n\"\"\"\n双色球随机选号程序\n\nAuthor: 小明\nVersion: 1.3\n\"\"\"\nimport random\n\nRED_BALLS = [i for i in range(1, 34)]\nBLUE_BALLS = [i for i in range(1, 17)]\n\n\ndef choose():\n    \"\"\"\n    生成一组随机号码\n    :return: 保存随机号码的列表\n    \"\"\"\n    selected_balls = random.sample(RED_BALLS, 6)\n    selected_balls.sort()\n    selected_balls.append(random.choice(BLUE_BALLS))\n    return selected_balls\n\n\ndef display(balls):\n    \"\"\"\n    格式输出一组号码\n    :param balls: 保存随机号码的列表\n    \"\"\"\n    for ball in balls[:-1]:\n        print(f'\\033[031m{ball:0>2d}\\033[0m', end=' ')\n    print(f'\\033[034m{balls[-1]:0>2d}\\033[0m')\n\n\nn = int(input('生成几注号码: '))\nfor _ in range(n):\n    display(choose())\n```\n\n> **说明**：大家看看`display(choose())`这行代码，这里我们先通过`choose`函数获得一组随机号码，然后把`choose`函数的返回值作为`display`函数的参数，通过`display`函数将选中的随机号码显示出来。重构之后的代码逻辑非常清晰，代码的可读性更强了。如果有人为你封装了这两个函数，你仅仅是函数的调用者，其实你根本不用关心`choose`函数和`display`函数的内部实现，你只需要知道调用`choose`函数可以生成一组随机号码，而调用`display`函数传入一个列表，就可以输出这组号码。将来我们使用各种各样的 Python 三方库时，我们也根本不关注它们的底层实现，我们需要知道的仅仅是调用哪个函数可以解决问题。\n\n### 总结\n\n在写代码尤其是开发商业项目的时候，一定要有意识的**将相对独立且重复使用的功能封装成函数**，这样不管是自己还是团队的其他成员都可以通过调用函数的方式来使用这些功能，减少工作中那些重复且乏味的劳动。", "函数使用进阶": "## 函数使用进阶\n\n我们继续探索定义和使用函数的相关知识。通过前面的学习，我们知道了函数有自变量（参数）和因变量（返回值），自变量可以是任意的数据类型，因变量也可以是任意的数据类型，那么这里就有一个小问题，我们能不能用函数作为函数的参数，用函数作为函数的返回值？这里我们先说结论：**Python 中的函数是“一等函数”**，所谓“一等函数”指的就是函数可以赋值给变量，函数可以作为函数的参数，函数也可以作为函数的返回值。把一个函数作为其他函数的参数或返回值的用法，我们通常称之为“高阶函数”。\n\n### 高阶函数\n\n我们回到之前讲过的一个例子，设计一个函数，传入任意多个参数，对其中`int`类型或`float`类型的元素实现求和操作。我们对之前的代码稍作调整，让整个代码更加紧凑一些，如下所示。\n\n```python\ndef calc(*args, **kwargs):\n    items = list(args) + list(kwargs.values())\n    result = 0\n    for item in items:\n        if type(item) in (int, float):\n            result += item\n    return result\n```\n\n如果我们希望上面的`calc`函数不仅仅可以做多个参数的求和，还可以实现更多的甚至是自定义的二元运算，我们该怎么做呢？上面的代码只能求和是因为函数中使用了`+=`运算符，这使得函数跟加法运算形成了耦合关系，如果能解除这种耦合关系，函数的通用性和灵活性就会更好。解除耦合的办法就是将`+`运算符变成函数调用，并将其设计为函数的参数，代码如下所示。\n\n```python\ndef calc(init_value, op_func, *args, **kwargs):\n    items = list(args) + list(kwargs.values())\n    result = init_value\n    for item in items:\n        if type(item) in (int, float):\n            result = op_func(result, item)\n    return result\n```\n\n注意，上面的函数增加了两个参数，其中`init_value`代表运算的初始值，`op_func`代表二元运算函数，为了调用修改后的函数，我们先定义做加法和乘法运算的函数，代码如下所示。\n\n```python\ndef add(x, y):\n    return x + y\n\n\ndef mul(x, y):\n    return x * y\n```\n\n如果要做求和的运算，我们可以按照下面的方式调用`calc`函数。\n\n```python\nprint(calc(0, add, 1, 2, 3, 4, 5))  # 15\n```\n\n如果要做求乘积运算，我们可以按照下面的方式调用`calc`函数。\n\n```python\nprint(calc(1, mul, 1, 2, 3, 4, 5))  # 120 \n```\n\n上面的`calc`函数通过将运算符变成函数的参数，实现了跟加法运算耦合，这是一种非常高明和实用的编程技巧，但对于最初学者来说可能会觉得难以理解，建议大家细品一下。需要注意上面的代码中，将函数作为参数传入其他函数和直接调用函数是有显著的区别的，**调用函数需要在函数名后面跟上圆括号，而把函数作为参数时只需要函数名即可**。\n\n如果我们没有提前定义好`add`和`mul`函数，也可以使用 Python 标准库中的`operator`模块提供的`add`和`mul`函数，它们分别代表了做加法和做乘法的二元运算，我们拿过来直接使用即可，代码如下所示。\n\n```python\nimport operator\n\nprint(calc(0, operator.add, 1, 2, 3, 4, 5))  # 15\nprint(calc(1, operator.mul, 1, 2, 3, 4, 5))  # 120\n```\n\nPython 内置函数中有不少高阶函数，我们前面提到过的`filter`和`map`函数就是高阶函数，前者可以实现对序列中元素的过滤，后者可以实现对序列中元素的映射，例如我们要去掉一个整数列表中的奇数，并对所有的偶数求平方得到一个新的列表，就可以直接使用这两个函数来做到，具体的做法是如下所示。\n\n```python\ndef is_even(num):\n    \"\"\"判断num是不是偶数\"\"\"\n    return num % 2 == 0\n\n\ndef square(num):\n    \"\"\"求平方\"\"\"\n    return num ** 2\n\n\nold_nums = [35, 12, 8, 99, 60, 52]\nnew_nums = list(map(square, filter(is_even, old_nums)))\nprint(new_nums)  # [144, 64, 3600, 2704]\n```\n\n当然，要完成上面代码的功能，也可以使用列表生成式，列表生成式的做法更为简单优雅。\n\n```python\nold_nums = [35, 12, 8, 99, 60, 52]\nnew_nums = [num ** 2 for num in old_nums if num % 2 == 0]\nprint(new_nums)  # [144, 64, 3600, 2704]\n```\n\n我们再来讨论一个内置函数`sorted`，它可以实现对容器型数据类型（如：列表、字典等）元素的排序。我们之前讲过`list`类型的`sort`方法，它实现了对列表元素的排序，`sorted`函数从功能上来讲跟列表的`sort`方法没有区别，但它会返回排序后的列表对象，而不是直接修改原来的列表，这一点我们称为**函数的无副作用设计**，也就是说调用函数除了产生返回值以外，不会对程序的状态或外部环境产生任何其他的影响。使用`sorted`函数排序时，可以通过高阶函数的形式自定义排序的规则，我们通过下面的例子加以说明。\n\n```python\nold_strings = ['in', 'apple', 'zoo', 'waxberry', 'pear']\nnew_strings = sorted(old_strings)\nprint(new_strings)  # ['apple', 'in', 'pear', waxberry', 'zoo']\n```\n\n上面的代码对大家来说并不陌生，但是如果希望根据字符串的长度而不是字母表顺序对列表元素排序，我们可以向`sorted`函数传入一个名为`key`的参数，将`key`参数赋值为获取字符串长度的函数`len`，这个函数我们在之前的课程中讲到过，代码如下所示。\n\n```python\nold_strings = ['in', 'apple', 'zoo', 'waxberry', 'pear']\nnew_strings = sorted(old_strings, key=len)\nprint(new_strings)  # ['in', 'zoo', 'pear', 'apple', 'waxberry']\n```\n\n> **说明**：列表类型的`sort`方法也有同样的`key`参数，有兴趣的读者可以自行尝试。\n\n### Lambda函数\n\n在使用高阶函数的时候，如果作为参数或者返回值的函数本身非常简单，一行代码就能够完成，也不需要考虑对函数的复用，那么我们可以使用 lambda 函数。Python 中的 lambda 函数是没有的名字函数，所以很多人也把它叫做**匿名函数**，lambda 函数只能有一行代码，代码中的表达式产生的运算结果就是这个匿名函数的返回值。之前的代码中，我们写的`is_even`和`square`函数都只有一行代码，我们可以考虑用 lambda 函数来替换掉它们，代码如下所示。\n\n```python\nold_nums = [35, 12, 8, 99, 60, 52]\nnew_nums = list(map(lambda x: x ** 2, filter(lambda x: x % 2 == 0, old_nums)))\nprint(new_nums)  # [144, 64, 3600, 2704]\n```\n\n通过上面的代码可以看出，定义 lambda 函数的关键字是`lambda`，后面跟函数的参数，如果有多个参数用逗号进行分隔；冒号后面的部分就是函数的执行体，通常是一个表达式，表达式的运算结果就是 lambda 函数的返回值，不需要写`return` 关键字。\n\n前面我们说过，Python 中的函数是“一等函数”，函数是可以直接赋值给变量的。在学习了 lambda 函数之后，前面我们写过的一些函数就可以用一行代码来实现它们了，大家可以看看能否理解下面的求阶乘和判断素数的函数。\n\n```python\nimport functools\nimport operator\n\n# 用一行代码实现计算阶乘的函数\nfac = lambda n: functools.reduce(operator.mul, range(2, n + 1), 1)\n\n# 用一行代码实现判断素数的函数\nis_prime = lambda x: all(map(lambda f: x % f, range(2, int(x ** 0.5) + 1)))\n\n# 调用Lambda函数\nprint(fac(6))        # 720\nprint(is_prime(37))  # True\n```\n\n> **提示1**：上面使用的`reduce`函数是 Python 标准库`functools`模块中的函数，它可以实现对一组数据的归约操作，类似于我们之前定义的`calc`函数，第一个参数是代表运算的函数，第二个参数是运算的数据，第三个参数是运算的初始值。很显然，`reduce`函数也是高阶函数，它和`filter`函数、`map`函数一起构成了处理数据中非常关键的三个动作：**过滤**、**映射**和**归约**。\n>\n> **提示2**：上面判断素数的 lambda 函数通过`range`函数构造了从 2 到 $\\small{\\sqrt{x}}$ 的范围，检查这个范围有没有`x`的因子。`all`函数也是 Python 内置函数，如果传入的序列中所有的布尔值都是`True`，`all`函数返回`True`，否则`all`函数返回`False`。\n\n### 偏函数\n\n偏函数是指固定函数的某些参数，生成一个新的函数，这样就无需在每次调用函数时都传递相同的参数。在 Python 语言中，我们可以使用`functools`模块的`partial`函数来创建偏函数。例如，`int`函数在默认情况下可以将字符串视为十进制整数进行类型转换，如果我们修修改它的`base`参数，就可以定义出三个新函数，分别用于将二进制、八进制、十六进制字符串转换为整数，代码如下所示。\n\n```python\nimport functools\n\nint2 = functools.partial(int, base=2)\nint8 = functools.partial(int, base=8)\nint16 = functools.partial(int, base=16)\n\nprint(int('1001'))    # 1001\n\nprint(int2('1001'))   # 9\nprint(int8('1001'))   # 513\nprint(int16('1001'))  # 4097\n```\n\n不知大家是否注意到，`partial`函数的第一个参数和返回值都是函数，它将传入的函数处理成一个新的函数返回。通过构造偏函数，我们可以结合实际的使用场景将原函数变成使用起来更为便捷的新函数，不知道大家有没有觉得这波操作很有意思。\n\n###  总结\n\nPython 中的函数是一等函数，可以赋值给变量，也可以作为函数的参数和返回值，这也就意味着我们可以在 Python 中使用高阶函数。高阶函数的概念对新手并不友好，但它却带来了函数设计上的灵活性。如果我们要定义的函数非常简单，只有一行代码，而且不需要函数名来复用它，我们可以使用 lambda 函数。\n\n", "函数高级应用": "## 函数高级应用\n\n在上一个章节中，我们探索了 Python 中的高阶函数，相信大家对函数的定义和应用有了更深刻的认知。本章我们继续为大家讲解函数相关的知识，一个是 Python 中的特色语法装饰器，一个是函数的递归调用。\n\n### 装饰器\n\nPython 语言中，装饰器是“**用一个函数装饰另外一个函数并为其提供额外的能力**”的语法现象。装饰器本身是一个函数，它的参数是被装饰的函数，它的返回值是一个带有装饰功能的函数。通过前面的描述，相信大家已经听出来了，装饰器是一个高阶函数，它的参数和返回值都是函数。但是，装饰器的概念对编程语言的初学者来说，还是让人头疼的，下面我们先通过一个简单的例子来说明装饰器的作用。假设有名为`downlaod`和`upload`的两个函数，分别用于文件的上传和下载，如下所示。\n\n```python\nimport random\nimport time\n\n\ndef download(filename):\n    \"\"\"下载文件\"\"\"\n    print(f'开始下载{filename}.')\n    time.sleep(random.random() * 6)\n    print(f'{filename}下载完成.')\n\n    \ndef upload(filename):\n    \"\"\"上传文件\"\"\"\n    print(f'开始上传{filename}.')\n    time.sleep(random.random() * 8)\n    print(f'{filename}上传完成.')\n\n    \ndownload('MySQL从删库到跑路.avi')\nupload('Python从入门到住院.pdf')\n```\n\n> **说明**：上面的代码用休眠一段随机时间的方式模拟了下载和上传文件需要花费一定的时间，并没有真正的联网上传下载文件。用 Python 语言实现联网上传下载文件也非常简单，后面我们会讲到相关的知识。\n\n现在有一个新的需求，我们希望知道调用`download`和`upload`函数上传下载文件到底用了多少时间，这应该如何实现呢？相信很多小伙伴已经想到了，我们可以在函数开始执行的时候记录一个时间，在函数调用结束后记录一个时间，两个时间相减就可以计算出下载或上传的时间，代码如下所示。\n\n```python\nstart = time.time()\ndownload('MySQL从删库到跑路.avi')\nend = time.time()\nprint(f'花费时间: {end - start:.2f}秒')\nstart = time.time()\nupload('Python从入门到住院.pdf')\nend = time.time()\nprint(f'花费时间: {end - start:.2f}秒')\n```\n\n通过上面的代码，我们可以在下载和上传文件时记录下耗费的时间，但不知道大家是否注意到，上面记录时间、计算和显示执行时间的代码都是重复代码。有编程经验的人都知道，**重复的代码是万恶之源**，那么有没有办法在不写重复代码的前提下，用一种简单优雅的方式记录下函数的执行时间呢？在 Python 语言中，装饰器就是解决这类问题的最佳选择。通过装饰器语法，我们可以把跟原来的业务（上传和下载）没有关系计时功能的代码封装到一个函数中，如果`upload`和`download`函数需要记录时间，我们直接把装饰器作用到这两个函数上即可。既然上面提到了，装饰器是一个高阶函数，它的参数和返回值都是函数，我们将记录时间的装饰器姑且命名为`record_time`，那么它的整体结构应该如下面的代码所示。\n\n```python\ndef record_time(func):\n    \n    def wrapper(*args, **kwargs):\n        \n        result = func(*args, **kwargs)\n        \n        return result\n    \n    return wrapper\n```\n\n相信大家注意到了，`record_time`函数的参数`func`代表了一个被装饰的函数，函数里面定义的`wrapper`函数是带有装饰功能的函数，它会执行被装饰的函数`func`，它还需要返回在最后产生函数执行的返回值。不知大家是否留意到，上面的代码我在第4行和第6行留下了两个空行，这意味着我们可以这些地方添加代码来实现额外的功能。`record_time`函数最终会返回这个带有装饰功能的函数`wrapper`并通过它替代原函数`func`，当原函数`func`被`record_time`函数装饰后，我们调用它时其实调用的是`wrapper`函数，所以才获得了额外的能力。`wrapper`函数的参数比较特殊，由于我们要用`wrapper`替代原函数`func`，但是我们又不清楚原函数`func`会接受哪些参数，所以我们就通过可变参数和关键字参数照单全收，然后在调用`func`的时候，原封不动的全部给它。这里还要强调一下，Python 语言支持函数的嵌套定义，就像上面，我们可以在`record_time`函数中定义`wrapper`函数，这个操作在很多编程语言中并不被支持。\n\n看懂这个结构后，我们就可以把记录时间的功能写到这个装饰器中，代码如下所示。\n\n```python\nimport time\n\n\ndef record_time(func):\n\n    def wrapper(*args, **kwargs):\n        # 在执行被装饰的函数之前记录开始时间\n        start = time.time()\n        # 执行被装饰的函数并获取返回值\n        result = func(*args, **kwargs)\n        # 在执行被装饰的函数之后记录结束时间\n        end = time.time()\n        # 计算和显示被装饰函数的执行时间\n        print(f'{func.__name__}执行时间: {end - start:.2f}秒')\n        # 返回被装饰函数的返回值\n        return result\n    \n    return wrapper\n```\n\n写装饰器虽然颇费周折，但是这是个一劳永逸的骚操作，将来再有记录函数执行时间的需求时，我们只需要添加上面的装饰器即可。使用上面的装饰器函数有两种方式，第一种方式就是直接调用装饰器函数，传入被装饰的函数并获得返回值，我们可以用这个返回值直接替代原来的函数，那么在调用时就已经获得了装饰器提供的额外的能力（记录执行时间），大家试试下面的代码就明白了。\n\n```python\ndownload = record_time(download)\nupload = record_time(upload)\ndownload('MySQL从删库到跑路.avi')\nupload('Python从入门到住院.pdf')\n```\n\n在 Python 中，使用装饰器很有更为便捷的**语法糖**（编程语言中添加的某种语法，这种语法对语言的功能没有影响，但是使用更加方法，代码的可读性也更强，我们将其称之为“语法糖”或“糖衣语法”），可以用`@装饰器函数`将装饰器函数直接放在被装饰的函数上，效果跟上面的代码相同。我们把完整的代码为大家罗列出来，大家可以再看看我们是如何定义和使用装饰器的。\n\n```python\nimport random\nimport time\n\n\ndef record_time(func):\n\n    def wrapper(*args, **kwargs):\n        start = time.time()\n        result = func(*args, **kwargs)\n        end = time.time()\n        print(f'{func.__name__}执行时间: {end - start:.2f}秒')\n        return result\n\n    return wrapper\n\n\n@record_time\ndef download(filename):\n    print(f'开始下载{filename}.')\n    time.sleep(random.random() * 6)\n    print(f'{filename}下载完成.')\n\n\n@record_time\ndef upload(filename):\n    print(f'开始上传{filename}.')\n    time.sleep(random.random() * 8)\n    print(f'{filename}上传完成.')\n\n\ndownload('MySQL从删库到跑路.avi')\nupload('Python从入门到住院.pdf')\n```\n\n上面的代码，我们通过装饰器语法糖为`download`和`upload`函数添加了装饰器，被装饰后的`download`和`upload`函数其实就是我们在装饰器中返回的`wrapper`函数，调用它们其实就是在调用`wrapper`函数，所以才有了记录函数执行时间的功能。\n\n如果在代码的某些地方，我们想去掉装饰器的作用执行原函数，那么在定义装饰器函数的时候，需要做一点点额外的工作。Python 标准库`functools`模块的`wraps`函数也是一个装饰器，我们将它放在`wrapper`函数上，这个装饰器可以帮我们保留被装饰之前的函数，这样在需要取消装饰器时，可以通过被装饰函数的`__wrapped__`属性获得被装饰之前的函数。\n\n```python\nimport random\nimport time\n\nfrom functools import wraps\n\n\ndef record_time(func):\n\n    @wraps(func)\n    def wrapper(*args, **kwargs):\n        start = time.time()\n        result = func(*args, **kwargs)\n        end = time.time()\n        print(f'{func.__name__}执行时间: {end - start:.2f}秒')\n        return result\n\n    return wrapper\n\n\n@record_time\ndef download(filename):\n    print(f'开始下载{filename}.')\n    time.sleep(random.random() * 6)\n    print(f'{filename}下载完成.')\n\n\n@record_time\ndef upload(filename):\n    print(f'开始上传{filename}.')\n    time.sleep(random.random() * 8)\n    print(f'{filename}上传完成.')\n\n\n# 调用装饰后的函数会记录执行时间\ndownload('MySQL从删库到跑路.avi')\nupload('Python从入门到住院.pdf')\n# 取消装饰器的作用不记录执行时间\ndownload.__wrapped__('MySQL必知必会.pdf')\nupload.__wrapped__('Python从新手到大师.pdf')\n```\n\n**装饰器函数本身也可以参数化**，简单的说就是装饰器也是可以通过调用者传入的参数来进行定制的，这个知识点我们在后面用到的时候再为大家讲解。\n\n### 递归调用\n\nPython 中允许函数嵌套定义，也允许函数之间相互调用，而且一个函数还可以直接或间接的调用自身。函数自己调用自己称为递归调用，那么递归调用有什么用处呢？现实中，有很多问题的定义本身就是一个递归定义，例如我们之前讲到的阶乘，非负整数`N`的阶乘是`N`乘以`N-1`的阶乘，即 $\\small{N! = N \\times (N-1)!}$ ，定义的左边和右边都出现了阶乘的概念，所以这是一个递归定义。既然如此，我们可以使用递归调用的方式来写一个求阶乘的函数，代码如下所示。\n\n```python\ndef fac(num):\n    if num in (0, 1):\n        return 1\n    return num * fac(num - 1)\n```\n\n上面的代码中，`fac`函数中又调用了`fac`函数，这就是所谓的递归调用。代码第2行的`if`条件叫做递归的收敛条件，简单的说就是什么时候要结束函数的递归调用，在计算阶乘时，如果计算到`0`或`1`的阶乘，就停止递归调用，直接返回`1`；代码第4行的`num * fac(num - 1)`是递归公式，也就是阶乘的递归定义。下面，我们简单的分析下，如果用`fac(5)`计算`5`的阶乘，整个过程会是怎样的。\n\n```python\n# 递归调用函数入栈\n# 5 * fac(4)\n# 5 * (4 * fac(3))\n# 5 * (4 * (3 * fac(2)))\n# 5 * (4 * (3 * (2 * fac(1))))\n# 停止递归函数出栈\n# 5 * (4 * (3 * (2 * 1)))\n# 5 * (4 * (3 * 2))\n# 5 * (4 * 6)\n# 5 * 24\n# 120\nprint(fac(5))    # 120\n```\n\n注意，函数调用会通过内存中称为“栈”（stack）的数据结构来保存当前代码的执行现场，函数调用结束后会通过这个栈结构恢复之前的执行现场。栈是一种先进后出的数据结构，这也就意味着最早入栈的函数最后才会返回，而最后入栈的函数会最先返回。例如调用一个名为`a`的函数，函数`a`的执行体中又调用了函数`b`，函数`b`的执行体中又调用了函数`c`，那么最先入栈的函数是`a`，最先出栈的函数是`c`。每进入一个函数调用，栈就会增加一层栈帧（stack frame），栈帧就是我们刚才提到的保存当前代码执行现场的结构；每当函数调用结束后，栈就会减少一层栈帧。通常，内存中的栈空间很小，因此递归调用的次数如果太多，会导致栈溢出（stack overflow），所以**递归调用一定要确保能够快速收敛**。我们可以尝试执行`fac(5000)`，看看是不是会提示`RecursionError`错误，错误消息为：`maximum recursion depth exceeded in comparison`（超出最大递归深度），其实就是发生了栈溢出。\n\n如果我们使用官方的 Python 解释器（CPython），默认将函数调用的栈结构最大深度设置为`1000`层。如果超出这个深度，就会发生上面说的`RecursionError`。当然，我们可以使用`sys`模块的`setrecursionlimit`函数来改变递归调用的最大深度，但是我们不建议这样做，因为让递归快速收敛才是我们应该做的事情，否则就应该考虑使用循环递推而不是递归。\n\n再举一个之前讲过的生成斐波那契数列的例子，因为斐波那契数列前两个数都是`1`，从第三个数开始，每个数是前两个数相加的和，可以记为`f(n) = f(n - 1) + f(n - 2)`，很显然这又是一个递归的定义，所以我们可以用下面的递归调用函数来计算第​`n`个斐波那契数。\n\n```python\ndef fib1(n):\n    if n in (1, 2):\n        return 1\n    return fib1(n - 1) + fib1(n - 2)\n\n\nfor i in range(1, 21):\n    print(fib1(i))\n```\n\n需要提醒大家，上面计算斐波那契数的代码虽然看起来非常简单明了，但执行性能是比较糟糕的。大家可以试一试，把上面代码`for`循环中`range`函数的第二个参数修改为`51`，即输出前50个斐波那契数，看看需要多长时间，也欢迎大家在评论区留下你的代码执行时间。至于为什么这么慢，大家可以自己思考一下原因。很显然，直接使用循环递推的方式获得斐波那契数列是更好的选择，代码如下所示。\n\n```python\ndef fib2(n):\n    a, b = 0, 1\n    for _ in range(n):\n        a, b = b, a + b\n    return a\n```\n\n除此以外，我们还可以使用 Python 标准库中`functools`模块的`lru_cache`函数来优化上面的递归代码。`lru_cache`函数是一个装饰器函数，我们将其置于上面的函数`fib1`之上，它可以缓存该函数的执行结果从而避免在递归调用的过程中产生大量的重复运算，这样代码的执行性能就有“飞一般”的提升。大家可以尝试输出前50个斐波那契数，看看加上装饰器以后代码需要执行多长时间，评论区见！\n\n```python\nfrom functools import lru_cache\n\n\n@lru_cache()\ndef fib1(n):\n    if n in (1, 2):\n        return 1\n    return fib1(n - 1) + fib1(n - 2)\n\n\nfor i in range(1, 51):\n    print(i, fib1(i))\n```\n\n> **提示**：`lru_cache`函数是一个带参数的装饰器，所以上面第4行代码使用装饰器语法糖时，`lru_cache`后面要跟上圆括号。`lru_cache`函数有一个非常重要的参数叫`maxsize`，它可以用来定义缓存空间的大小，默认值是128。\n\n###  总结\n\n装饰器是 Python 语言中的特色语法，**可以通过装饰器来增强现有的函数**，这是一种非常有用的编程技巧。另一方面，通过函数递归调用，可以在代码层面将一些复杂的问题简单化，但是**递归调用一定要注意收敛条件和递归公式**，找到递归公式才有机会使用递归调用，而收敛条件则确保了递归调用能停下来。函数调用通过内存中的栈空间来保存现场和恢复现场，栈空间通常都很小，所以**递归如果不能迅速收敛，很可能会引发栈溢出错误，从而导致程序的崩溃**。\n", "面向对象编程入门": "## 面向对象编程入门\n\n面向对象编程是一种非常流行的**编程范式**（programming paradigm），所谓编程范式就是**程序设计的方法论**，简单的说就是程序员对程序的认知和理解以及他们编写代码的方式。\n\n在前面的课程中，我们说过“**程序是指令的集合**”，运行程序时，程序中的语句会变成一条或多条指令，然后由CPU（中央处理器）去执行。为了简化程序的设计，我们又讲到了函数，**把相对独立且经常重复使用的代码放置到函数中**，在需要使用这些代码的时候调用函数即可。如果一个函数的功能过于复杂和臃肿，我们又可以进一步**将函数进一步拆分为多个子函数**来降低系统的复杂性。\n\n不知大家是否发现，编程其实是写程序的人按照计算机的工作方式通过代码控制机器完成任务。但是，计算机的工作方式与人类正常的思维模式是不同的，如果编程就必须抛弃人类正常的思维方式去迎合计算机，编程的乐趣就少了很多。这里，我想说的并不是我们不能按照计算机的工作方式去编写代码，但是当我们需要开发一个复杂的系统时，这种方式会让代码过于复杂，从而导致开发和维护工作都变得举步维艰。\n\n随着软件复杂性的增加，编写正确可靠的代码会变成了一项极为艰巨的任务，这也是很多人都坚信“软件开发是人类改造世界所有活动中最为复杂的活动”的原因。如何用程序描述复杂系统和解决复杂问题，就成为了所有程序员必须要思考和直面的问题。诞生于上世纪70年代的 Smalltalk 语言让软件开发者看到了希望，因为它引入了一种新的编程范式叫面向对象编程。在面向对象编程的世界里，程序中的**数据和操作数据的函数是一个逻辑上的整体**，我们称之为**对象**，**对象可以接收消息**，解决问题的方法就是**创建对象并向对象发出各种各样的消息**；通过消息传递，程序中的多个对象可以协同工作，这样就能构造出复杂的系统并解决现实中的问题。当然，面向对象编程的雏形还可以向前追溯到更早期的Simula语言，但这不是我们要讨论的重点。\n\n> **说明：** 今天我们使用的很多高级程序设计语言都支持面向对象编程，但是面向对象编程也不是解决软件开发中所有问题的“银弹”，或者说在软件开发这个行业目前还没有所谓的“银弹”。关于这个问题，大家可以参考 IBM360 系统之父弗雷德里克·布鲁克斯所发表的论文《没有银弹：软件工程的本质性与附属性工作》或软件工程的经典著作《人月神话》一书。\n\n### 类和对象\n\n如果要用一句话来概括面向对象编程，我认为下面的说法是相当精辟和准确的。\n\n> **面向对象编程**：把一组数据和处理数据的方法组成**对象**，把行为相同的对象归纳为**类**，通过**封装**隐藏对象的内部细节，通过**继承**实现类的特化和泛化，通过**多态**实现基于对象类型的动态分派。\n\n这句话对初学者来说可能不那么容易理解，但是我可以先为大家圈出几个关键词：**对象**（object）、**类**（class）、**封装**（encapsulation）、**继承**（inheritance）、**多态**（polymorphism）。\n\n我们先说说类和对象这两个词。在面向对象编程中，**类是一个抽象的概念，对象是一个具体的概念**。我们把同一类对象的共同特征抽取出来就是一个类，比如我们经常说的人类，这是一个抽象概念，而我们每个人就是人类的这个抽象概念下的实实在在的存在，也就是一个对象。简而言之，**类是对象的蓝图和模板，对象是类的实例，是可以接受消息的实体**。\n\n在面向对象编程的世界中，**一切皆为对象**，**对象都有属性和行为**，**每个对象都是独一无二的**，而且**对象一定属于某个类**。对象的属性是对象的静态特征，对象的行为是对象的动态特征。按照上面的说法，如果我们把拥有共同特征的对象的属性和行为都抽取出来，就可以定义出一个类。\n\n<img class=\"lazy\" data-src=\"/res/day18/20210731182741.png\" width=\"75%\">\n\n### 定义类\n\n在 Python 语言中，我们可以使用`class`关键字加上类名来定义类，通过缩进我们可以确定类的代码块，就如同定义函数那样。在类的代码块中，我们需要写一些函数，我们说过类是一个抽象概念，那么这些函数就是我们对一类对象共同的动态特征的提取。写在类里面的函数我们通常称之为**方法**，方法就是对象的行为，也就是对象可以接收的消息。方法的第一个参数通常都是`self`，它代表了接收这个消息的对象本身。\n\n```python\nclass Student:\n\n    def study(self, course_name):\n        print(f'学生正在学习{course_name}.')\n\n    def play(self):\n        print(f'学生正在玩游戏.')\n```\n\n### 创建和使用对象\n\n在我们定义好一个类之后，可以使用构造器语法来创建对象，代码如下所示。\n\n```python\nstu1 = Student()\nstu2 = Student()\nprint(stu1)    # <__main__.Student object at 0x10ad5ac50>\nprint(stu2)    # <__main__.Student object at 0x10ad5acd0> \nprint(hex(id(stu1)), hex(id(stu2)))    # 0x10ad5ac50 0x10ad5acd0\n```\n\n在类的名字后跟上圆括号就是所谓的构造器语法，上面的代码创建了两个学生对象，一个赋值给变量`stu1`，一个赋值给变量`stu2`。当我们用`print`函数打印`stu1`和`stu2`两个变量时，我们会看到输出了对象在内存中的地址（十六进制形式），跟我们用`id`函数查看对象标识获得的值是相同的。现在我们可以告诉大家，我们定义的变量其实保存的是一个对象在内存中的逻辑地址（位置），通过这个逻辑地址，我们就可以在内存中找到这个对象。所以`stu3 = stu2`这样的赋值语句并没有创建新的对象，只是用一个新的变量保存了已有对象的地址。\n\n接下来，我们尝试给对象发消息，即调用对象的方法。刚才的`Student`类中我们定义了`study`和`play`两个方法，两个方法的第一个参数`self`代表了接收消息的学生对象，`study`方法的第二个参数是学习的课程名称。Python中，给对象发消息有两种方式，请看下面的代码。\n\n```python\n# 通过“类.方法”调用方法\n# 第一个参数是接收消息的对象\n# 第二个参数是学习的课程名称\nStudent.study(stu1, 'Python程序设计')    # 学生正在学习Python程序设计.\n# 通过“对象.方法”调用方法\n# 点前面的对象就是接收消息的对象\n# 只需要传入第二个参数课程名称\nstu1.study('Python程序设计')             # 学生正在学习Python程序设计.\n\nStudent.play(stu2)                      # 学生正在玩游戏.\nstu2.play()                             # 学生正在玩游戏. \n```\n\n### 初始化方法\n\n大家可能已经注意到了，刚才我们创建的学生对象只有行为没有属性，如果要给学生对象定义属性，我们可以修改`Student`类，为其添加一个名为`__init__`的方法。在我们调用`Student`类的构造器创建对象时，首先会在内存中获得保存学生对象所需的内存空间，然后通过自动执行`__init__`方法，完成对内存的初始化操作，也就是把数据放到内存空间中。所以我们可以通过给`Student`类添加`__init__`方法的方式为学生对象指定属性，同时完成对属性赋初始值的操作，正因如此，`__init__`方法通常也被称为初始化方法。\n\n我们对上面的`Student`类稍作修改，给学生对象添加`name`（姓名）和`age`（年龄）两个属性。\n\n```python\nclass Student:\n    \"\"\"学生\"\"\"\n\n    def __init__(self, name, age):\n        \"\"\"初始化方法\"\"\"\n        self.name = name\n        self.age = age\n\n    def study(self, course_name):\n        \"\"\"学习\"\"\"\n        print(f'{self.name}正在学习{course_name}.')\n\n    def play(self):\n        \"\"\"玩耍\"\"\"\n        print(f'{self.name}正在玩游戏.')\n```\n\n修改刚才创建对象和给对象发消息的代码，重新执行一次，看看程序的执行结果有什么变化。\n\n```python\n# 调用Student类的构造器创建对象并传入初始化参数\nstu1 = Student('小明', 44)\nstu2 = Student('王大锤', 25)\nstu1.study('Python程序设计')    # 小明正在学习Python程序设计.\nstu2.play()                    # 王大锤正在玩游戏.\n```\n\n\n### 面向对象的支柱\n\n面向对象编程有三大支柱，就是我们之前给大家划重点的时候圈出的三个词：**封装**、**继承**和**多态**。后面两个概念在下一节课中会详细说明，这里我们先说一下什么是封装。我自己对封装的理解是：**隐藏一切可以隐藏的实现细节，只向外界暴露简单的调用接口**。我们在类中定义的对象方法其实就是一种封装，这种封装可以让我们在创建对象之后，只需要给对象发送一个消息就可以执行方法中的代码，也就是说我们在只知道方法的名字和参数（方法的外部视图），不知道方法内部实现细节（方法的内部视图）的情况下就完成了对方法的使用。\n\n举一个例子，假如要控制一个机器人帮我倒杯水，如果不使用面向对象编程，不做任何的封装，那么就需要向这个机器人发出一系列的指令，如站起来、向左转、向前走5步、拿起面前的水杯、向后转、向前走10步、弯腰、放下水杯、按下出水按钮、等待10秒、松开出水按钮、拿起水杯、向右转、向前走5步、放下水杯等，才能完成这个简单的操作，想想都觉得麻烦。按照面向对象编程的思想，我们可以将倒水的操作封装到机器人的一个方法中，当需要机器人帮我们倒水的时候，只需要向机器人对象发出倒水的消息就可以了，这样做不是更好吗？\n\n在很多场景下，面向对象编程其实就是一个三步走的问题。第一步定义类，第二步创建对象，第三步给对象发消息。当然，有的时候我们是不需要第一步的，因为我们想用的类可能已经存在了。之前我们说过，Python内置的`list`、`set`、`dict`其实都是类，如果要创建列表、集合、字典对象，我们就不用自定义类了。当然，有的类并不是 Python 标准库中直接提供的，它可能来自于第三方的代码，如何安装和使用三方代码在后续课程中会进行讨论。在某些特殊的场景中，我们会用到名为“内置对象”的对象，所谓“内置对象”就是说上面三步走的第一步和第二步都不需要了，因为类已经存在而且对象已然创建过了，直接向对象发消息就可以了，这也就是我们常说的“开箱即用”。\n\n### 面向对象案例\n\n#### 例子1：时钟\n\n> **要求**：定义一个类描述数字时钟，提供走字和显示时间的功能。\n\n```python\nimport time\n\n\n# 定义时钟类\nclass Clock:\n    \"\"\"数字时钟\"\"\"\n\n    def __init__(self, hour=0, minute=0, second=0):\n        \"\"\"初始化方法\n        :param hour: 时\n        :param minute: 分\n        :param second: 秒\n        \"\"\"\n        self.hour = hour\n        self.min = minute\n        self.sec = second\n\n    def run(self):\n        \"\"\"走字\"\"\"\n        self.sec += 1\n        if self.sec == 60:\n            self.sec = 0\n            self.min += 1\n            if self.min == 60:\n                self.min = 0\n                self.hour += 1\n                if self.hour == 24:\n                    self.hour = 0\n\n    def show(self):\n        \"\"\"显示时间\"\"\"\n        return f'{self.hour:0>2d}:{self.min:0>2d}:{self.sec:0>2d}'\n\n\n# 创建时钟对象\nclock = Clock(23, 59, 58)\nwhile True:\n    # 给时钟对象发消息读取时间\n    print(clock.show())\n    # 休眠1秒钟\n    time.sleep(1)\n    # 给时钟对象发消息使其走字\n    clock.run()\n```\n\n#### 例子2：平面上的点\n\n>  **要求**：定义一个类描述平面上的点，提供计算到另一个点距离的方法。\n\n```python\nclass Point:\n    \"\"\"平面上的点\"\"\"\n\n    def __init__(self, x=0, y=0):\n        \"\"\"初始化方法\n        :param x: 横坐标\n        :param y: 纵坐标\n        \"\"\"\n        self.x, self.y = x, y\n\n    def distance_to(self, other):\n        \"\"\"计算与另一个点的距离\n        :param other: 另一个点\n        \"\"\"\n        dx = self.x - other.x\n        dy = self.y - other.y\n        return (dx * dx + dy * dy) ** 0.5\n\n    def __str__(self):\n        return f'({self.x}, {self.y})'\n\n\np1 = Point(3, 5)\np2 = Point(6, 9)\nprint(p1)  # 调用对象的__str__魔法方法\nprint(p2)\nprint(p1.distance_to(p2))\n```\n\n### 总结\n\n面向对象编程是一种非常流行的编程范式，除此之外还有**指令式编程**、**函数式编程**等编程范式。由于现实世界是由对象构成的，而对象是可以接收消息的实体，所以**面向对象编程更符合人类正常的思维习惯**。类是抽象的，对象是具体的，有了类就能创建对象，有了对象就可以接收消息，这就是面向对象编程的基础。定义类的过程是一个抽象的过程，找到对象公共的属性属于数据抽象，找到对象公共的方法属于行为抽象。抽象的过程是一个仁者见仁智者见智的过程，对同一类对象进行抽象可能会得到不同的结果，如下图所示。\n\n<img class=\"lazy\" data-src=\"/res/day18/20210731182914.png\" width=\"75%\">\n\n> **说明：** 本节课的插图来自于 Grady Booc 等撰写的《面向对象分析与设计》一书，该书是讲解面向对象编程的经典著作，有兴趣的读者可以购买和阅读这本书来了解更多的面向对象的相关知识。\n\n", "面向对象编程进阶": "## 面向对象编程进阶\n\n前面我们讲解了 Python 面向对象编程的一些基础知识，本节我们继续讨论面向对象编程相关的内容。\n\n### 可见性和属性装饰器\n\n在很多面向对象编程语言中，对象的属性通常会被设置为私有（private）或受保护（protected）的成员，简单的说就是不允许直接访问这些属性；对象的方法通常都是公开的（public），因为公开的方法是对象能够接受的消息，也是对象暴露给外界的调用接口，这就是所谓的访问可见性。在 Python 中，可以通过给对象属性名添加前缀下划线的方式来说明属性的访问可见性，例如，可以用`__name`表示一个私有属性，`_name`表示一个受保护属性，代码如下所示。\n\n```python\nclass Student:\n\n    def __init__(self, name, age):\n        self.__name = name\n        self.__age = age\n\n    def study(self, course_name):\n        print(f'{self.__name}正在学习{course_name}.')\n\n\nstu = Student('王大锤', 20)\nstu.study('Python程序设计')\nprint(stu.__name)  # AttributeError: 'Student' object has no attribute '__name'\n```\n\n上面代码的最后一行会引发`AttributeError`（属性错误）异常，异常消息为：`'Student' object has no attribute '__name'`。由此可见，以`__`开头的属性`__name`相当于是私有的，在类的外面无法直接访问，但是类里面的`study`方法中可以通过`self.__name`访问该属性。需要说明的是，大多数使用 Python 语言的人在定义类时，通常不会选择让对象的属性私有或受保护，正如有一句名言说的：“**We are all consenting adults here**”（大家都是成年人），成年人可以为自己的行为负责，而不需要通过 Python 语言本身来限制访问可见性。事实上，大多数的程序员都认为**开放比封闭要好**，把对象的属性私有化并非必不可少的东西，所以 Python 语言并没有从语义上做出最严格的限定，也就是说上面的代码如果你愿意，用`stu._Student__name`的方式仍然可以访问到私有属性`__name`，有兴趣的读者可以自己试一试。\n\n### 动态属性\n\nPython 语言属于动态语言，维基百科对动态语言的解释是：“在运行时可以改变其结构的语言，例如新的函数、对象、甚至代码可以被引进，已有的函数可以被删除或是其他结构上的变化”。动态语言非常灵活，目前流行的 Python 和 JavaScript 都是动态语言，除此之外，诸如 PHP、Ruby 等也都属于动态语言，而 C、C++ 等语言则不属于动态语言。\n\n在 Python 中，我们可以动态为对象添加属性，这是 Python 作为动态类型语言的一项特权，代码如下所示。需要提醒大家的是，对象的方法其实本质上也是对象的属性，如果给对象发送一个无法接收的消息，引发的异常仍然是`AttributeError`。\n\n```python\nclass Student:\n\n    def __init__(self, name, age):\n        self.name = name\n        self.age = age\n\n\nstu = Student('王大锤', 20)\nstu.sex = '男'  # 给学生对象动态添加sex属性\n```\n\n如果不希望在使用对象时动态的为对象添加属性，可以使用 Python 语言中的`__slots__`魔法。对于`Student`类来说，可以在类中指定`__slots__ = ('name', 'age')`，这样`Student`类的对象只能有`name`和`age`属性，如果想动态添加其他属性将会引发异常，代码如下所示。\n\n```python\nclass Student:\n    __slots__ = ('name', 'age')\n\n    def __init__(self, name, age):\n        self.name = name\n        self.age = age\n\n\nstu = Student('王大锤', 20)\n# AttributeError: 'Student' object has no attribute 'sex'\nstu.sex = '男'\n```\n\n### 静态方法和类方法\n\n之前我们在类中定义的方法都是对象方法，换句话说这些方法都是对象可以接收的消息。除了对象方法之外，类中还可以有静态方法和类方法，这两类方法是发给类的消息，二者并没有实质性的区别。在面向对象的世界里，一切皆为对象，我们定义的每一个类其实也是一个对象，而静态方法和类方法就是发送给类对象的消息。那么，什么样的消息会直接发送给类对象呢？\n\n举一个例子，定义一个三角形类，通过传入三条边的长度来构造三角形，并提供计算周长和面积的方法。计算周长和面积肯定是三角形对象的方法，这一点毫无疑问。但是在创建三角形对象时，传入的三条边长未必能构造出三角形，为此我们可以先写一个方法来验证给定的三条边长是否可以构成三角形，这种方法很显然就不是对象方法，因为在调用这个方法时三角形对象还没有创建出来。我们可以把这类方法设计为静态方法或类方法，也就是说这类方法不是发送给三角形对象的消息，而是发送给三角形类的消息，代码如下所示。\n\n```python\nclass Triangle(object):\n    \"\"\"三角形\"\"\"\n\n    def __init__(self, a, b, c):\n        \"\"\"初始化方法\"\"\"\n        self.a = a\n        self.b = b\n        self.c = c\n\n    @staticmethod\n    def is_valid(a, b, c):\n        \"\"\"判断三条边长能否构成三角形(静态方法)\"\"\"\n        return a + b > c and b + c > a and a + c > b\n\n    # @classmethod\n    # def is_valid(cls, a, b, c):\n    #     \"\"\"判断三条边长能否构成三角形(类方法)\"\"\"\n    #     return a + b > c and b + c > a and a + c > b\n\n    def perimeter(self):\n        \"\"\"计算周长\"\"\"\n        return self.a + self.b + self.c\n\n    def area(self):\n        \"\"\"计算面积\"\"\"\n        p = self.perimeter() / 2\n        return (p * (p - self.a) * (p - self.b) * (p - self.c)) ** 0.5\n```\n\n上面的代码使用`staticmethod`装饰器声明了`is_valid`方法是`Triangle`类的静态方法，如果要声明类方法，可以使用`classmethod`装饰器（如上面的代码15~18行所示）。可以直接使用`类名.方法名`的方式来调用静态方法和类方法，二者的区别在于，类方法的第一个参数是类对象本身，而静态方法则没有这个参数。简单的总结一下，**对象方法、类方法、静态方法都可以通过“类名.方法名”的方式来调用，区别在于方法的第一个参数到底是普通对象还是类对象，还是没有接受消息的对象**。静态方法通常也可以直接写成一个独立的函数，因为它并没有跟特定的对象绑定。\n\n这里做一个补充说明，我们可以给上面计算三角形周长和面积的方法添加一个`property`装饰器（Python 内置类型），这样三角形类的`perimeter`和`area`就变成了两个属性，不再通过调用方法的方式来访问，而是用对象访问属性的方式直接获得，修改后的代码如下所示。\n\n```python\nclass Triangle(object):\n    \"\"\"三角形\"\"\"\n\n    def __init__(self, a, b, c):\n        \"\"\"初始化方法\"\"\"\n        self.a = a\n        self.b = b\n        self.c = c\n\n    @staticmethod\n    def is_valid(a, b, c):\n        \"\"\"判断三条边长能否构成三角形(静态方法)\"\"\"\n        return a + b > c and b + c > a and a + c > b\n\n    @property\n    def perimeter(self):\n        \"\"\"计算周长\"\"\"\n        return self.a + self.b + self.c\n\n    @property\n    def area(self):\n        \"\"\"计算面积\"\"\"\n        p = self.perimeter / 2\n        return (p * (p - self.a) * (p - self.b) * (p - self.c)) ** 0.5\n\n\nt = Triangle(3, 4, 5)\nprint(f'周长: {t.perimeter}')\nprint(f'面积: {t.area}')\n```\n\n### 继承和多态\n\n面向对象的编程语言支持在已有类的基础上创建新类，从而减少重复代码的编写。提供继承信息的类叫做父类（超类、基类），得到继承信息的类叫做子类（派生类、衍生类）。例如，我们定义一个学生类和一个老师类，我们会发现他们有大量的重复代码，而这些重复代码都是老师和学生作为人的公共属性和行为，所以在这种情况下，我们应该先定义人类，再通过继承，从人类派生出老师类和学生类，代码如下所示。\n\n```python\nclass Person:\n    \"\"\"人\"\"\"\n\n    def __init__(self, name, age):\n        self.name = name\n        self.age = age\n    \n    def eat(self):\n        print(f'{self.name}正在吃饭.')\n    \n    def sleep(self):\n        print(f'{self.name}正在睡觉.')\n\n\nclass Student(Person):\n    \"\"\"学生\"\"\"\n    \n    def __init__(self, name, age):\n        super().__init__(name, age)\n    \n    def study(self, course_name):\n        print(f'{self.name}正在学习{course_name}.')\n\n\nclass Teacher(Person):\n    \"\"\"老师\"\"\"\n\n    def __init__(self, name, age, title):\n        super().__init__(name, age)\n        self.title = title\n    \n    def teach(self, course_name):\n        print(f'{self.name}{self.title}正在讲授{course_name}.')\n\n\n\nstu1 = Student('白元芳', 21)\nstu2 = Student('狄仁杰', 22)\ntea1 = Teacher('武则天', 35, '副教授')\nstu1.eat()\nstu2.sleep()\ntea1.eat()\nstu1.study('Python程序设计')\ntea1.teach('Python程序设计')\nstu2.study('数据科学导论')\n```\n\n继承的语法是在定义类的时候，在类名后的圆括号中指定当前类的父类。如果定义一个类的时候没有指定它的父类是谁，那么默认的父类是`object`类。`object`类是 Python 中的顶级类，这也就意味着所有的类都是它的子类，要么直接继承它，要么间接继承它。Python 语言允许多重继承，也就是说一个类可以有一个或多个父类，关于多重继承的问题我们在后面会有更为详细的讨论。在子类的初始化方法中，我们可以通过`super().__init__()`来调用父类初始化方法，`super`函数是 Python 内置函数中专门为获取当前对象的父类对象而设计的。从上面的代码可以看出，子类除了可以通过继承得到父类提供的属性和方法外，还可以定义自己特有的属性和方法，所以子类比父类拥有的更多的能力。在实际开发中，我们经常会用子类对象去替换掉一个父类对象，这是面向对象编程中一个常见的行为，也叫做“里氏替换原则”（Liskov Substitution Principle）。\n\n子类继承父类的方法后，还可以对方法进行重写（重新实现该方法），不同的子类可以对父类的同一个方法给出不同的实现版本，这样的方法在程序运行时就会表现出多态行为（调用相同的方法，做了不同的事情）。多态是面向对象编程中最精髓的部分，当然也是对初学者来说最难以理解和灵活运用的部分，我们会在下一个章节用专门的例子来讲解这个知识点。\n\n### 总结\n\nPython 是动态类型语言，Python 中的对象可以动态的添加属性，对象的方法其实也是属性，只不过和该属性对应的是一个可以调用的函数。在面向对象的世界中，**一切皆为对象**，我们定义的类也是对象，所以**类也可以接收消息**，对应的方法是类方法或静态方法。通过继承，我们**可以从已有的类创建新类**，实现对已有类代码的复用。\n", "面向对象编程应用": "## 面向对象编程应用\n\n面向对象编程对初学者来说不难理解但很难应用，虽然我们为大家总结过面向对象的三步走方法（定义类、创建对象、给对象发消息），但是说起来容易做起来难。**大量的编程练习**和**阅读优质的代码**可能是这个阶段最能够帮助到大家的两件事情。接下来我们还是通过经典的案例来剖析面向对象编程的知识，同时也通过这些案例把我们之前学过的 Python 知识都串联起来。\n\n### 例子1：扑克游戏。\n\n> **说明**：简单起见，我们的扑克只有52张牌（没有大小王），游戏需要将 52 张牌发到 4 个玩家的手上，每个玩家手上有 13 张牌，按照黑桃、红心、草花、方块的顺序和点数从小到大排列，暂时不实现其他的功能。\n\n使用面向对象编程方法，首先需要从问题的需求中找到对象并抽象出对应的类，此外还要找到对象的属性和行为。当然，这件事情并不是特别困难，我们可以从需求的描述中找出名词和动词，名词通常就是对象或者是对象的属性，而动词通常是对象的行为。扑克游戏中至少应该有三类对象，分别是牌、扑克和玩家，牌、扑克、玩家三个类也并不是孤立的。类和类之间的关系可以粗略的分为 **is-a关系（继承）**、**has-a关系（关联）**和 **use-a关系（依赖）**。很显然扑克和牌是 has-a 关系，因为一副扑克有（has-a）52 张牌；玩家和牌之间不仅有关联关系还有依赖关系，因为玩家手上有（has-a）牌而且玩家使用了（use-a）牌。\n\n牌的属性显而易见，有花色和点数。我们可以用 0 到 3 的四个数字来代表四种不同的花色，但是这样的代码可读性会非常糟糕，因为我们并不知道黑桃、红心、草花、方块跟 0 到 3 的数字的对应关系。如果一个变量的取值只有有限多个选项，我们可以使用枚举。与 C、Java 等语言不同的是，Python 中没有声明枚举类型的关键字，但是可以通过继承`enum`模块的`Enum`类来创建枚举类型，代码如下所示。\n\n```python\nfrom enum import Enum\n\n\nclass Suite(Enum):\n    \"\"\"花色(枚举)\"\"\"\n    SPADE, HEART, CLUB, DIAMOND = range(4)\n```\n\n通过上面的代码可以看出，定义枚举类型其实就是定义符号常量，如`SPADE`、`HEART`等。每个符号常量都有与之对应的值，这样表示黑桃就可以不用数字 0，而是用`Suite.SPADE`；同理，表示方块可以不用数字 3， 而是用`Suite.DIAMOND`。注意，使用符号常量肯定是优于使用字面常量的，因为能够读懂英文就能理解符号常量的含义，代码的可读性会提升很多。Python 中的枚举类型是可迭代类型，简单的说就是可以将枚举类型放到`for-in`循环中，依次取出每一个符号常量及其对应的值，如下所示。\n\n```python\nfor suite in Suite:\n    print(f'{suite}: {suite.value}')\n```\n\n接下来我们可以定义牌类。\n\n```python\nclass Card:\n    \"\"\"牌\"\"\"\n\n    def __init__(self, suite, face):\n        self.suite = suite\n        self.face = face\n\n    def __repr__(self):\n        suites = '♠♥♣♦'\n        faces = ['', 'A', '2', '3', '4', '5', '6', '7', '8', '9', '10', 'J', 'Q', 'K']\n        return f'{suites[self.suite.value]}{faces[self.face]}'  # 返回牌的花色和点数\n```\n\n可以通过下面的代码来测试下`Card`类。\n\n```python\ncard1 = Card(Suite.SPADE, 5)\ncard2 = Card(Suite.HEART, 13)\nprint(card1)  # ♠5 \nprint(card2)  # ♥K\n```\n\n接下来我们定义扑克类。\n\n```python\nimport random\n\n\nclass Poker:\n    \"\"\"扑克\"\"\"\n\n    def __init__(self):\n        self.cards = [Card(suite, face) \n                      for suite in Suite\n                      for face in range(1, 14)]  # 52张牌构成的列表\n        self.current = 0  # 记录发牌位置的属性\n\n    def shuffle(self):\n        \"\"\"洗牌\"\"\"\n        self.current = 0\n        random.shuffle(self.cards)  # 通过random模块的shuffle函数实现随机乱序\n\n    def deal(self):\n        \"\"\"发牌\"\"\"\n        card = self.cards[self.current]\n        self.current += 1\n        return card\n\n    @property\n    def has_next(self):\n        \"\"\"还有没有牌可以发\"\"\"\n        return self.current < len(self.cards)\n```\n\n可以通过下面的代码来测试下`Poker`类。\n\n```python\npoker = Poker()\nprint(poker.cards)  # 洗牌前的牌\npoker.shuffle()\nprint(poker.cards)  # 洗牌后的牌\n```\n\n定义玩家类。\n\n```python\nclass Player:\n    \"\"\"玩家\"\"\"\n\n    def __init__(self, name):\n        self.name = name\n        self.cards = []  # 玩家手上的牌\n\n    def get_one(self, card):\n        \"\"\"摸牌\"\"\"\n        self.cards.append(card)\n\n    def arrange(self):\n        \"\"\"整理手上的牌\"\"\"\n        self.cards.sort()\n```\n\n创建四个玩家并将牌发到玩家的手上。\n\n```python\npoker = Poker()\npoker.shuffle()\nplayers = [Player('东邪'), Player('西毒'), Player('南帝'), Player('北丐')]\n# 将牌轮流发到每个玩家手上每人13张牌\nfor _ in range(13):\n    for player in players:\n        player.get_one(poker.deal())\n# 玩家整理手上的牌输出名字和手牌\nfor player in players:\n    player.arrange()\n    print(f'{player.name}: ', end='')\n    print(player.cards)\n```\n\n执行上面的代码会在`player.arrange()`那里出现异常，因为`Player`的`arrange`方法使用了列表的`sort`对玩家手上的牌进行排序，排序需要比较两个`Card`对象的大小，而`<`运算符又不能直接作用于`Card`类型，所以就出现了`TypeError`异常，异常消息为：`'<' not supported between instances of 'Card' and 'Card'`。\n\n为了解决这个问题，我们可以对`Card`类的代码稍作修改，使得两个`Card`对象可以直接用`<`进行大小的比较。这里用到技术叫**运算符重载**，Python 中要实现对`<`运算符的重载，需要在类中添加一个名为`__lt__`的魔术方法。很显然，魔术方法`__lt__`中的`lt`是英文单词“less than”的缩写，以此类推，魔术方法`__gt__`对应`>`运算符，魔术方法`__le__`对应`<=`运算符，`__ge__`对应`>=`运算符，`__eq__`对应`==`运算符，`__ne__`对应`!=`运算符。\n\n修改后的`Card`类代码如下所示。\n\n```python\nclass Card:\n    \"\"\"牌\"\"\"\n\n    def __init__(self, suite, face):\n        self.suite = suite\n        self.face = face\n\n    def __repr__(self):\n        suites = '♠♥♣♦'\n        faces = ['', 'A', '2', '3', '4', '5', '6', '7', '8', '9', '10', 'J', 'Q', 'K']\n        return f'{suites[self.suite.value]}{faces[self.face]}'\n    \n    def __lt__(self, other):\n        if self.suite == other.suite:\n            return self.face < other.face   # 花色相同比较点数的大小\n        return self.suite.value < other.suite.value   # 花色不同比较花色对应的值\n```\n\n>**说明：** 大家可以尝试在上面代码的基础上写一个简单的扑克游戏，如 21 点游戏（Black Jack），游戏的规则可以自己在网上找一找。\n\n### 例子2：工资结算系统。\n\n> **要求**：某公司有三种类型的员工，分别是部门经理、程序员和销售员。需要设计一个工资结算系统，根据提供的员工信息来计算员工的月薪。其中，部门经理的月薪是固定 15000 元；程序员按工作时间（以小时为单位）支付月薪，每小时 200 元；销售员的月薪由 1800 元底薪加上销售额 5% 的提成两部分构成。\n\n通过对上述需求的分析，可以看出部门经理、程序员、销售员都是员工，有相同的属性和行为，那么我们可以先设计一个名为`Employee`的父类，再通过继承的方式从这个父类派生出部门经理、程序员和销售员三个子类。很显然，后续的代码不会创建`Employee` 类的对象，因为我们需要的是具体的员工对象，所以这个类可以设计成专门用于继承的抽象类。Python 语言中没有定义抽象类的关键字，但是可以通过`abc`模块中名为`ABCMeta` 的元类来定义抽象类。关于元类的概念此处不展开讲解，当然大家不用纠结，照做即可。\n\n```python\nfrom abc import ABCMeta, abstractmethod\n\n\nclass Employee(metaclass=ABCMeta):\n    \"\"\"员工\"\"\"\n\n    def __init__(self, name):\n        self.name = name\n\n    @abstractmethod\n    def get_salary(self):\n        \"\"\"结算月薪\"\"\"\n        pass\n```\n\n在上面的员工类中，有一个名为`get_salary`的方法用于结算月薪，但是由于还没有确定是哪一类员工，所以结算月薪虽然是员工的公共行为但这里却没有办法实现。对于暂时无法实现的方法，我们可以使用`abstractmethod`装饰器将其声明为抽象方法，所谓**抽象方法就是只有声明没有实现的方法**，**声明这个方法是为了让子类去重写这个方法**。接下来的代码展示了如何从员工类派生出部门经理、程序员、销售员这三个子类以及子类如何重写父类的抽象方法。\n\n```python\nclass Manager(Employee):\n    \"\"\"部门经理\"\"\"\n\n    def get_salary(self):\n        return 15000.0\n\n\nclass Programmer(Employee):\n    \"\"\"程序员\"\"\"\n\n    def __init__(self, name, working_hour=0):\n        super().__init__(name)\n        self.working_hour = working_hour\n\n    def get_salary(self):\n        return 200 * self.working_hour\n\n\nclass Salesman(Employee):\n    \"\"\"销售员\"\"\"\n\n    def __init__(self, name, sales=0):\n        super().__init__(name)\n        self.sales = sales\n\n    def get_salary(self):\n        return 1800 + self.sales * 0.05\n```\n\n上面的`Manager`、`Programmer`、`Salesman`三个类都继承自`Employee`，三个类都分别重写了`get_salary`方法。**重写就是子类对父类已有的方法重新做出实现**。相信大家已经注意到了，三个子类中的`get_salary`各不相同，所以这个方法在程序运行时会产生**多态行为**，多态简单的说就是**调用相同的方法**，**不同的子类对象做不同的事情**。\n\n我们通过下面的代码来完成这个工资结算系统，由于程序员和销售员需要分别录入本月的工作时间和销售额，所以在下面的代码中我们使用了 Python 内置的`isinstance`函数来判断员工对象的类型。我们之前讲过的`type`函数也能识别对象的类型，但是`isinstance`函数更加强大，因为它可以判断出一个对象是不是某个继承结构下的子类型，你可以简单的理解为`type`函数是对对象类型的精准匹配，而`isinstance`函数是对对象类型的模糊匹配。\n\n```python\nemps = [Manager('刘备'), Programmer('诸葛亮'), Manager('曹操'), Programmer('荀彧'), Salesman('张辽')]\nfor emp in emps:\n    if isinstance(emp, Programmer):\n        emp.working_hour = int(input(f'请输入{emp.name}本月工作时间: '))\n    elif isinstance(emp, Salesman):\n        emp.sales = float(input(f'请输入{emp.name}本月销售额: '))\n    print(f'{emp.name}本月工资为: ￥{emp.get_salary():.2f}元')\n```\n\n### 总结\n\n面向对象的编程思想非常的好，也符合人类的正常思维习惯，但是要想灵活运用面向对象编程中的抽象、封装、继承、多态需要长时间的积累和沉淀，这件事情无法一蹴而就，因为知识的积累本就是涓滴成河的过程。\n", "文件读写和异常处理": "## 文件读写和异常处理\n\n实际开发中常常会遇到对数据进行持久化的场景，所谓持久化是指将数据从无法长久保存数据的存储介质（通常是内存）转移到可以长久保存数据的存储介质（通常是硬盘）中。实现数据持久化最直接简单的方式就是通过**文件系统**将数据保存到**文件**中。\n\n计算机的**文件系统**是一种存储和组织计算机数据的方法，它使得对数据的访问和查找变得容易，文件系统使用**文件**和**树形目录**的抽象逻辑概念代替了硬盘、光盘、闪存等物理设备的数据块概念，用户使用文件系统来保存数据时，不必关心数据实际保存在硬盘的哪个数据块上，只需要记住这个文件的路径和文件名。在写入新数据之前，用户不必关心硬盘上的哪个数据块没有被使用，硬盘上的存储空间管理（分配和释放）功能由文件系统自动完成，用户只需要记住数据被写入到了哪个文件中。\n\n### 打开和关闭文件\n\n有了文件系统，我们可以非常方便的通过文件来读写数据；在Python中要实现文件操作是非常简单的。我们可以使用Python内置的`open`函数来打开文件，在使用`open`函数时，我们可以通过函数的参数指定**文件名**、**操作模式**和**字符编码**等信息，接下来就可以对文件进行读写操作了。这里所说的操作模式是指要打开什么样的文件（字符文件或二进制文件）以及做什么样的操作（读、写或追加），具体如下表所示。\n\n| 操作模式 | 具体含义                         |\n| -------- | -------------------------------- |\n| `'r'`    | 读取 （默认）                    |\n| `'w'`    | 写入（会先截断之前的内容）       |\n| `'x'`    | 写入，如果文件已经存在会产生异常 |\n| `'a'`    | 追加，将内容写入到已有文件的末尾 |\n| `'b'`    | 二进制模式                       |\n| `'t'`    | 文本模式（默认）                 |\n| `'+'`    | 更新（既可以读又可以写）         |\n\n下图展示了如何根据程序的需要来设置`open`函数的操作模式。\n\n<img class=\"lazy\" data-src=\"/res/20210803201644.png\" width=\"75%\">\n\n在使用`open`函数时，如果打开的文件是字符文件（文本文件），可以通过`encoding`参数来指定读写文件使用的字符编码。如果对字符编码和字符集这些概念不了解，可以看看[《字符集和字符编码》](https://www.cnblogs.com/skynet/archive/2011/05/03/2035105.html)一文，此处不再进行赘述。\n\n使用`open`函数打开文件成功后会返回一个文件对象，通过这个对象，我们就可以实现对文件的读写操作；如果打开文件失败，`open`函数会引发异常，稍后会对此加以说明。如果要关闭打开的文件，可以使用文件对象的`close`方法，这样可以在结束文件操作时释放掉这个文件。\n\n### 读写文本文件\n\n用`open`函数打开文本文件时，需要指定文件名并将文件的操作模式设置为`'r'`，如果不指定，默认值也是`'r'`；如果需要指定字符编码，可以传入`encoding`参数，如果不指定，默认值是None，那么在读取文件时使用的是操作系统默认的编码。需要提醒大家，如果不能保证保存文件时使用的编码方式与`encoding`参数指定的编码方式是一致的，那么就可能因无法解码字符而导致读取文件失败。\n\n下面的例子演示了如何读取一个纯文本文件（一般指只有字符原生编码构成的文件，与富文本相比，纯文本不包含字符样式的控制元素，能够被最简单的文本编辑器直接读取）。\n\n```python\nfile = open('致橡树.txt', 'r', encoding='utf-8')\nprint(file.read())\nfile.close()\n```\n\n> **说明**：[《致橡树》](http://www.china.org.cn/learning_english/2011-02/21/content_21967654.htm)是舒婷老师在1977年3月创建的爱情诗，也是我最喜欢的现代诗之一。\n\n除了使用文件对象的`read`方法读取文件之外，还可以使用`for-in`循环逐行读取或者用`readlines`方法将文件按行读取到一个列表容器中，代码如下所示。\n\n```python\nfile = open('致橡树.txt', 'r', encoding='utf-8')\nfor line in file:\n    print(line, end='')\nfile.close()\n\nfile = open('致橡树.txt', 'r', encoding='utf-8')\nlines = file.readlines()\nfor line in lines:\n    print(line, end='')\nfile.close()\n```\n\n如果要向文件中写入内容，可以在打开文件时使用`w`或者`a`作为操作模式，前者会截断之前的文本内容写入新的内容，后者是在原来内容的尾部追加新的内容。\n\n```python\nfile = open('致橡树.txt', 'a', encoding='utf-8')\nfile.write('\\n标题：《致橡树》')\nfile.write('\\n作者：舒婷')\nfile.write('\\n时间：1977年3月')\nfile.close()\n```\n\n### 异常处理机制\n\n请注意上面的代码，如果`open`函数指定的文件并不存在或者无法打开，那么将引发异常状况导致程序崩溃。为了让代码具有健壮性和容错性，我们可以**使用Python的异常机制对可能在运行时发生状况的代码进行适当的处理**。Python中和异常相关的关键字有五个，分别是`try`、`except`、`else`、`finally`和`raise`，我们先看看下面的代码，再来为大家介绍这些关键字的用法。\n\n```python\nfile = None\ntry:\n    file = open('致橡树.txt', 'r', encoding='utf-8')\n    print(file.read())\nexcept FileNotFoundError:\n    print('无法打开指定的文件!')\nexcept LookupError:\n    print('指定了未知的编码!')\nexcept UnicodeDecodeError:\n    print('读取文件时解码错误!')\nfinally:\n    if file:\n        file.close()\n```\n\n在Python中，我们可以将运行时会出现状况的代码放在`try`代码块中，在`try`后面可以跟上一个或多个`except`块来捕获异常并进行相应的处理。例如，在上面的代码中，文件找不到会引发`FileNotFoundError`，指定了未知的编码会引发`LookupError`，而如果读取文件时无法按指定编码方式解码文件会引发`UnicodeDecodeError`，所以我们在`try`后面跟上了三个`except`分别处理这三种不同的异常状况。在`except`后面，我们还可以加上`else`代码块，这是`try` 中的代码没有出现异常时会执行的代码，而且`else`中的代码不会再进行异常捕获，也就是说如果遇到异常状况，程序会因异常而终止并报告异常信息。最后我们使用`finally`代码块来关闭打开的文件，释放掉程序中获取的外部资源。由于`finally`块的代码不论程序正常还是异常都会执行，甚至是调用了`sys`模块的`exit`函数终止Python程序，`finally`块中的代码仍然会被执行（因为`exit`函数的本质是引发了`SystemExit`异常），因此我们把`finally`代码块称为“总是执行代码块”，它最适合用来做释放外部资源的操作。\n\nPython中内置了大量的异常类型，除了上面代码中用到的异常类型以及之前的课程中遇到过的异常类型外，还有许多的异常类型，其继承结构如下所示。\n\n```\nBaseException\n +-- SystemExit\n +-- KeyboardInterrupt\n +-- GeneratorExit\n +-- Exception\n      +-- StopIteration\n      +-- StopAsyncIteration\n      +-- ArithmeticError\n      |    +-- FloatingPointError\n      |    +-- OverflowError\n      |    +-- ZeroDivisionError\n      +-- AssertionError\n      +-- AttributeError\n      +-- BufferError\n      +-- EOFError\n      +-- ImportError\n      |    +-- ModuleNotFoundError\n      +-- LookupError\n      |    +-- IndexError\n      |    +-- KeyError\n      +-- MemoryError\n      +-- NameError\n      |    +-- UnboundLocalError\n      +-- OSError\n      |    +-- BlockingIOError\n      |    +-- ChildProcessError\n      |    +-- ConnectionError\n      |    |    +-- BrokenPipeError\n      |    |    +-- ConnectionAbortedError\n      |    |    +-- ConnectionRefusedError\n      |    |    +-- ConnectionResetError\n      |    +-- FileExistsError\n      |    +-- FileNotFoundError\n      |    +-- InterruptedError\n      |    +-- IsADirectoryError\n      |    +-- NotADirectoryError\n      |    +-- PermissionError\n      |    +-- ProcessLookupError\n      |    +-- TimeoutError\n      +-- ReferenceError\n      +-- RuntimeError\n      |    +-- NotImplementedError\n      |    +-- RecursionError\n      +-- SyntaxError\n      |    +-- IndentationError\n      |         +-- TabError\n      +-- SystemError\n      +-- TypeError\n      +-- ValueError\n      |    +-- UnicodeError\n      |         +-- UnicodeDecodeError\n      |         +-- UnicodeEncodeError\n      |         +-- UnicodeTranslateError\n      +-- Warning\n           +-- DeprecationWarning\n           +-- PendingDeprecationWarning\n           +-- RuntimeWarning\n           +-- SyntaxWarning\n           +-- UserWarning\n           +-- FutureWarning\n           +-- ImportWarning\n           +-- UnicodeWarning\n           +-- BytesWarning\n           +-- ResourceWarning\n```\n\n从上面的继承结构可以看出，Python中所有的异常都是`BaseException`的子类型，它有四个直接的子类，分别是：`SystemExit`、`KeyboardInterrupt`、`GeneratorExit`和`Exception`。其中，`SystemExit`表示解释器请求退出，`KeyboardInterrupt`是用户中断程序执行（按下`Ctrl+c`），`GeneratorExit`表示生成器发生异常通知退出，不理解这些异常没有关系，继续学习就好了。值得一提的是`Exception`类，它是常规异常类型的父类型，很多的异常都是直接或间接的继承自`Exception`类。如果Python内置的异常类型不能满足应用程序的需要，我们可以自定义异常类型，而自定义的异常类型也应该直接或间接继承自`Exception`类，当然还可以根据需要重写或添加方法。\n\n在Python中，可以使用`raise`关键字来引发异常（抛出异常对象），而调用者可以通过`try...except...`结构来捕获并处理异常。例如在函数中，当函数的执行条件不满足时，可以使用抛出异常的方式来告知调用者问题的所在，而调用者可以通过捕获处理异常来使得代码从异常中恢复，定义异常和抛出异常的代码如下所示。\n\n```python\nclass InputError(ValueError):\n    \"\"\"自定义异常类型\"\"\"\n    pass\n\n\ndef fac(num):\n    \"\"\"求阶乘\"\"\"\n    if num < 0:\n        raise InputError('只能计算非负整数的阶乘')\n    if num in (0, 1):\n        return 1\n    return num * fac(num - 1)\n```\n\n调用求阶乘的函数`fac`，通过`try...except...`结构捕获输入错误的异常并打印异常对象（显示异常信息），如果输入正确就计算阶乘并结束程序。\n\n```python\nflag = True\nwhile flag:\n    num = int(input('n = '))\n    try:\n        print(f'{num}! = {fac(num)}')\n        flag = False\n    except InputError as err:\n        print(err)\n```\n\n### 上下文管理器语法\n\n对于`open`函数返回的文件对象，还可以使用`with`上下文管理器语法在文件操作完成后自动执行文件对象的`close`方法，这样可以让代码变得更加简单优雅，因为不需要再写`finally`代码块来执行关闭文件释放资源的操作。需要提醒大家的是，并不是所有的对象都可以放在`with`上下文语法中，只有符合**上下文管理器协议**（有`__enter__`和`__exit__`魔术方法）的对象才能使用这种语法，Python标准库中的`contextlib`模块也提供了对`with`上下文语法的支持，后面再为大家进行讲解。\n\n用`with`上下文语法改写后的代码如下所示。\n\n```python\ntry:\n    with open('致橡树.txt', 'r', encoding='utf-8') as file:\n        print(file.read())\nexcept FileNotFoundError:\n    print('无法打开指定的文件!')\nexcept LookupError:\n    print('指定了未知的编码!')\nexcept UnicodeDecodeError:\n    print('读取文件时解码错误!')\n```\n\n### 读写二进制文件\n\n读写二进制文件跟读写文本文件的操作类似，但是需要注意，在使用`open`函数打开文件时，如果要进行读操作，操作模式是`'rb'`，如果要进行写操作，操作模式是`'wb'`。还有一点，读写文本文件时，`read`方法的返回值以及`write`方法的参数是`str`对象（字符串），而读写二进制文件时，`read`方法的返回值以及`write`方法的参数是`bytes-like`对象（字节串）。下面的代码实现了将当前路径下名为`guido.jpg`的图片文件复制到`吉多.jpg`文件中的操作。\n\n```python\ntry:\n    with open('guido.jpg', 'rb') as file1:\n        data = file1.read()\n    with open('吉多.jpg', 'wb') as file2:\n        file2.write(data)\nexcept FileNotFoundError:\n    print('指定的文件无法打开.')\nexcept IOError:\n    print('读写文件时出现错误.')\nprint('程序执行结束.')\n```\n\n如果要复制的图片文件很大，一次将文件内容直接读入内存中可能会造成非常大的内存开销，为了减少对内存的占用，可以为`read`方法传入`size`参数来指定每次读取的字节数，通过循环读取和写入的方式来完成上面的操作，代码如下所示。\n\n```python\ntry:\n    with open('guido.jpg', 'rb') as file1, open('吉多.jpg', 'wb') as file2:\n        data = file1.read(512)\n        while data:\n            file2.write(data)\n            data = file1.read()\nexcept FileNotFoundError:\n    print('指定的文件无法打开.')\nexcept IOError:\n    print('读写文件时出现错误.')\nprint('程序执行结束.')\n```\n\n###  总结\n\n通过读写文件的操作，我们可以实现数据持久化。在Python中可以通过`open`函数来获得文件对象，可以通过文件对象的`read`和`write`方法实现文件读写操作。程序在运行时可能遭遇无法预料的异常状况，可以使用Python的异常机制来处理这些状况。Python的异常机制主要包括`try`、`except`、`else`、`finally`和`raise`这五个核心关键字。`try`后面的`except`语句不是必须的，`finally`语句也不是必须的，但是二者必须要有一个；`except`语句可以有一个或多个，多个`except`会按照书写的顺序依次匹配指定的异常，如果异常已经处理就不会再进入后续的`except`语句；`except`语句中还可以通过元组同时指定多个异常类型进行捕获；`except`语句后面如果不指定异常类型，则默认捕获所有异常；捕获异常后可以使用`raise`要再次抛出，但是不建议捕获并抛出同一个异常；不建议在不清楚逻辑的情况下捕获所有异常，这可能会掩盖程序中严重的问题。最后强调一点，**不要使用异常机制来处理正常业务逻辑或控制程序流程**，简单的说就是不要滥用异常机制，这是初学者常犯的错误。\n", "对象的序列化和反序列化": "## 对象的序列化和反序列化\n\n###JSON概述\n\n通过上面的讲解，我们已经知道如何将文本数据和二进制数据保存到文件中，那么这里还有一个问题，如果希望把一个列表或者一个字典中的数据保存到文件中又该怎么做呢？在Python中，我们可以将程序中的数据以JSON格式进行保存。JSON是“JavaScript Object Notation”的缩写，它本来是JavaScript语言中创建对象的一种字面量语法，现在已经被广泛的应用于跨语言跨平台的数据交换。使用JSON的原因非常简单，因为它结构紧凑而且是纯文本，任何操作系统和编程语言都能处理纯文本，这就是**实现跨语言跨平台数据交换**的前提条件。目前JSON基本上已经取代了XML（可扩展标记语言）作为**异构系统间交换数据的事实标准**。可以在[JSON的官方网站](https://www.json.org/json-zh.html)找到更多关于JSON的知识，这个网站还提供了每种语言处理JSON数据格式可以使用的工具或三方库。\n\n```JavaScript\n{\n    name: \"小明\",\n    age: 40,\n    friends: [\"王大锤\", \"白元芳\"],\n    cars: [\n        {\"brand\": \"BMW\", \"max_speed\": 240},\n        {\"brand\": \"Benz\", \"max_speed\": 280},\n        {\"brand\": \"Audi\", \"max_speed\": 280}\n    ]\n}\n```\n\n上面是JSON的一个简单例子，大家可能已经注意到了，它跟Python中的字典非常类似而且支持嵌套结构，就好比Python字典中的值可以是另一个字典。我们可以尝试把下面的代码输入浏览器的控制台（对于Chrome浏览器，可以通过“更多工具”菜单找到“开发者工具”子菜单，就可以打开浏览器的控制台），浏览器的控制台提供了一个运行JavaScript代码的交互式环境（类似于Python的交互式环境），下面的代码会帮我们创建出一个JavaScript的对象，我们将其赋值给名为`obj`的变量。\n\n```JavaScript\nlet obj = {\n    name: \"小明\",\n    age: 40,\n    friends: [\"王大锤\", \"白元芳\"],\n    cars: [\n        {\"brand\": \"BMW\", \"max_speed\": 240},\n        {\"brand\": \"Benz\", \"max_speed\": 280},\n        {\"brand\": \"Audi\", \"max_speed\": 280}\n    ]\n}\n```\n\n<img src=\"https://github.com/jackfrued/mypic/raw/master/20210820143803.png\" alt=\"image-20210820143756353\" width=\"80%\">\n\n上面的`obj`就是JavaScript中的一个对象，我们可以通过`obj.name`或`obj[\"name\"]`两种方式获取到`name`对应的值，如下图所示。可以注意到，`obj[\"name\"]`这种获取数据的方式跟Python字典通过键获取值的索引操作是完全一致的，而Python中也通过名为`json`的模块提供了字典与JSON双向转换的支持。\n\n<img src=\"https://github.com/jackfrued/mypic/raw/master/20210820144411.png\" width=\"85%\">\n\n我们在JSON中使用的数据类型（JavaScript数据类型）和Python中的数据类型也是很容易找到对应关系的，大家可以看看下面的两张表。\n\n表1：JavaScript数据类型（值）对应的Python数据类型（值）\n\n| JSON         | Python       |\n| ------------ | ------------ |\n| `object`      |`dict`|\n| `array`      |`list`|\n| `string`     | `str`        |\n| `number ` |`int` / `float`|\n| `number` (real)   |`float`|\n| `boolean` (`true` / `false`) | `bool` (`True` / `False`) |\n| `null`       | `None`       |\n\n表2：Python数据类型（值）对应的JavaScript数据类型（值）\n\n| Python                      | JSON                         |\n| --------------------------- | ---------------------------- |\n| `dict`                      | `object`                     |\n| `list` / `tuple`            | `array`                      |\n| `str`                       | `string`                     |\n| `int` / `float`             | `number`                     |\n| `bool` （`True` / `False`） | `boolean` (`true` / `false`) |\n| `None`                      | `null`                       |\n\n### 读写JSON格式的数据\n\n在Python中，如果要将字典处理成JSON格式（以字符串形式存在），可以使用`json`模块的`dumps`函数，代码如下所示。\n\n```python\nimport json\n\nmy_dict = {\n    'name': '小明',\n    'age': 40,\n    'friends': ['王大锤', '白元芳'],\n    'cars': [\n        {'brand': 'BMW', 'max_speed': 240},\n        {'brand': 'Audi', 'max_speed': 280},\n        {'brand': 'Benz', 'max_speed': 280}\n    ]\n}\nprint(json.dumps(my_dict))\n```\n\n运行上面的代码，输出如下所示，可以注意到中文字符都是用Unicode编码显示的。\n\n```JSON\n{\"name\": \"\\u9a86\\u660a\", \"age\": 40, \"friends\": [\"\\u738b\\u5927\\u9524\", \"\\u767d\\u5143\\u82b3\"], \"cars\": [{\"brand\": \"BMW\", \"max_speed\": 240}, {\"brand\": \"Audi\", \"max_speed\": 280}, {\"brand\": \"Benz\", \"max_speed\": 280}]}\n```\n\n如果要将字典处理成JSON格式并写入文本文件，只需要将`dumps`函数换成`dump`函数并传入文件对象即可，代码如下所示。\n\n```python\nimport json\n\nmy_dict = {\n    'name': '小明',\n    'age': 40,\n    'friends': ['王大锤', '白元芳'],\n    'cars': [\n        {'brand': 'BMW', 'max_speed': 240},\n        {'brand': 'Audi', 'max_speed': 280},\n        {'brand': 'Benz', 'max_speed': 280}\n    ]\n}\nwith open('data.json', 'w') as file:\n    json.dump(my_dict, file)\n```\n\n执行上面的代码，会创建`data.json`文件，文件的内容跟上面代码的输出是一样的。\n\n`json`模块有四个比较重要的函数，分别是：\n\n- `dump` - 将Python对象按照JSON格式序列化到文件中\n- `dumps` - 将Python对象处理成JSON格式的字符串\n- `load` - 将文件中的JSON数据反序列化成对象\n- `loads` - 将字符串的内容反序列化成Python对象\n\n这里出现了两个概念，一个叫序列化，一个叫反序列化，[维基百科](https://zh.wikipedia.org/)上的解释是：“序列化（serialization）在计算机科学的数据处理中，是指将数据结构或对象状态转换为可以存储或传输的形式，这样在需要的时候能够恢复到原先的状态，而且通过序列化的数据重新获取字节时，可以利用这些字节来产生原始对象的副本（拷贝）。与这个过程相反的动作，即从一系列字节中提取数据结构的操作，就是反序列化（deserialization）”。\n\n我们可以通过下面的代码，读取上面创建的`data.json`文件，将JSON格式的数据还原成Python中的字典。\n\n```python\nimport json\n\nwith open('data.json', 'r') as file:\n    my_dict = json.load(file)\n    print(type(my_dict))\n    print(my_dict)\n```\n\n### 包管理工具pip\n\nPython标准库中的`json`模块在数据序列化和反序列化时性能并不是非常理想，为了解决这个问题，可以使用三方库`ujson`来替换`json`。所谓三方库，是指非公司内部开发和使用的，也不是来自于官方标准库的Python模块，这些模块通常由其他公司、组织或个人开发，所以被称为三方库。虽然Python语言的标准库虽然已经提供了诸多模块来方便我们的开发，但是对于一个强大的语言来说，它的生态圈一定也是非常繁荣的。\n\n之前安装Python解释器时，默认情况下已经勾选了安装pip，大家可以在命令提示符或终端中通过`pip --version`来确定是否已经拥有了pip。pip是Python的包管理工具，通过pip可以查找、安装、卸载、更新Python的三方库或工具，macOS和Linux系统应该使用pip3。例如要安装替代`json`模块的`ujson`，可以使用下面的命令。\n\n```Bash\npip install ujson\n```\n\n在默认情况下，pip会访问`https://pypi.org/simple/`来获得三方库相关的数据，但是国内访问这个网站的速度并不是十分理想，因此国内用户可以使用豆瓣网提供的镜像来替代这个默认的下载源，操作如下所示。\n\n```Bash\npip install ujson\n```\n\n可以通过`pip search`命令根据名字查找需要的三方库，可以通过`pip list`命令来查看已经安装过的三方库。如果想更新某个三方库，可以使用`pip install -U`或`pip install --upgrade`；如果要删除某个三方库，可以使用`pip uninstall`命令。\n\n搜索`ujson`三方库。\n\n```Bash\npip search ujson\n\nmicropython-cpython-ujson (0.2)  - MicroPython module ujson ported to CPython\npycopy-cpython-ujson (0.2)       - Pycopy module ujson ported to CPython\nujson (3.0.0)                    - Ultra fast JSON encoder and decoder for Python\nujson-bedframe (1.33.0)          - Ultra fast JSON encoder and decoder for Python\nujson-segfault (2.1.57)          - Ultra fast JSON encoder and decoder for Python. Continuing \n                                   development.\nujson-ia (2.1.1)                 - Ultra fast JSON encoder and decoder for Python (Internet \n                                   Archive fork)\nujson-x (1.37)                   - Ultra fast JSON encoder and decoder for Python\nujson-x-legacy (1.35.1)          - Ultra fast JSON encoder and decoder for Python\ndrf_ujson (1.2)                  - Django Rest Framework UJSON Renderer\ndrf-ujson2 (1.6.1)               - Django Rest Framework UJSON Renderer\nujsonDB (0.1.0)                  - A lightweight and simple database using ujson.\nfast-json (0.3.2)                - Combines best parts of json and ujson for fast serialization\ndecimal-monkeypatch (0.4.3)      - Python 2 performance patches: decimal to cdecimal, json to \n                                   ujson for psycopg2\n```\n\n查看已经安装的三方库。\n\n```Bash\npip list\n\nPackage                       Version\n----------------------------- ----------\naiohttp                       3.5.4\nalipay                        0.7.4\naltgraph                      0.16.1\namqp                          2.4.2\n...\t\t\t\t\t\t\t  ...\n```\n\n更新`ujson`三方库。\n\n```Bash\npip install -U ujson\n```\n\n删除`ujson`三方库。\n\n```Bash\npip uninstall -y ujson\n```\n\n> **提示**：如果要更新`pip`自身，对于macOS系统来说，可以使用命令`pip install -U pip`。在Windows系统上，可以将命令替换为`python -m pip install -U --user pip`。\n\n### 使用网络API获取数据\n\n如果想在我们自己的程序中显示天气、路况、航班等信息，这些信息我们自己没有能力提供，所以必须使用网络数据服务。目前绝大多数的网络数据服务（或称之为网络API）都是基于[HTTP](https://zh.wikipedia.org/wiki/%E8%B6%85%E6%96%87%E6%9C%AC%E4%BC%A0%E8%BE%93%E5%8D%8F%E8%AE%AE)或HTTPS提供JSON格式的数据，我们可以通过Python程序发送HTTP请求给指定的URL（统一资源定位符），这个URL就是所谓的网络API，如果请求成功，它会返回HTTP响应，而HTTP响应的消息体中就有我们需要的JSON格式的数据。关于HTTP的相关知识，可以看看阮一峰的[《HTTP协议入门》](http://www.ruanyifeng.com/blog/2016/08/http.html)一文。\n\n国内有很多提供网络API接口的网站，例如[聚合数据](https://www.juhe.cn/)、[阿凡达数据](http://www.avatardata.cn/)等，这些网站上有免费的和付费的数据接口，国外的[{API}Search](http://apis.io/)网站也提供了类似的功能，有兴趣的可以自行研究。下面的例子演示了如何使用[`requests`](http://docs.python-requests.org/zh_CN/latest/)库（基于HTTP进行网络资源访问的三方库）访问网络API获取国内新闻并显示新闻标题和链接。在这个例子中，我们使用了名为[天行数据](https://www.tianapi.com/)的网站提供的国内新闻数据接口，其中的APIKey需要自己到网站上注册申请。在天行数据网站注册账号后会自动分配APIKey，但是要访问接口获取数据，需要绑定验证邮箱或手机，然后还要申请需要使用的接口，如下图所示。\n\n<img class=\"lazy\" data-src=\"/res/20210820151134.png\" alt=\"image-20210820151134034\" width=\"100%\">\n\nPython通过URL接入网络，我们推荐大家使用`requests`三方库，它简单且强大，但需要自行安装。\n\n```Bash\npip install requests\n```\n\n获取国内新闻并显示新闻标题和链接。\n\n```python\nimport requests\n\nresp = requests.get('http://api.tianapi.com/guonei/?key=APIKey&num=10')\nif resp.status_code == 200:\n    data_model = resp.json()\n    for news in data_model['newslist']:\n        print(news['title'])\n        print(news['url'])\n        print('-' * 60)\n```\n\n上面的代码通过`requests`模块的`get`函数向天行数据的国内新闻接口发起了一次请求，如果请求过程没有出现问题，`get`函数会返回一个`Response`对象，通过该对象的`status_code`属性表示HTTP响应状态码，如果不理解没关系，你只需要关注它的值，如果值等于`200`或者其他`2`字头的值，那么我们的请求是成功的。通过`Response`对象的`json()`方法可以将返回的JSON格式的数据直接处理成Python字典，非常方便。天行数据国内新闻接口返回的JSON格式的数据（部分）如下图所示。\n\n<img src=\"https://github.com/jackfrued/mypic/raw/master/20210820154455.png\" width=\"100%\">\n\n> **提示**：上面代码中的APIKey需要换成自己在天行数据网站申请的APIKey。天行数据网站上还有提供了很多非常有意思的API接口，例如：垃圾分类、周公解梦等，大家可以仿照上面的代码来调用这些接口。每个接口都有对应的接口文档，文档中有关于如何使用接口的详细说明。\n\n###  总结\n\nPython中实现序列化和反序列化除了使用`json`模块之外，还可以使用`pickle`和`shelve`模块，但是这两个模块是使用特有的序列化协议来序列化数据，因此序列化后的数据只能被Python识别，关于这两个模块的相关知识，有兴趣的读者可以自己查找网络上的资料。处理JSON格式的数据很显然是程序员必须掌握的一项技能，因为不管是访问网络API接口还是提供网络API接口给他人使用，都需要具备处理JSON格式数据的相关知识。\n\n", "读写CSV文件": "## Python读写CSV文件\n\n### CSV文件介绍\n\nCSV（Comma Separated Values）全称逗号分隔值文件是一种简单、通用的文件格式，被广泛的应用于应用程序（数据库、电子表格等）数据的导入和导出以及异构系统之间的数据交换。因为CSV是纯文本文件，不管是什么操作系统和编程语言都是可以处理纯文本的，而且很多编程语言中都提供了对读写CSV文件的支持，因此CSV格式在数据处理和数据科学中被广泛应用。\n\nCSV文件有以下特点：\n\n1. 纯文本，使用某种字符集（如[ASCII](https://zh.wikipedia.org/wiki/ASCII)、[Unicode](https://zh.wikipedia.org/wiki/Unicode)、[GB2312](https://zh.wikipedia.org/wiki/GB2312)）等）；\n2. 由一条条的记录组成（典型的是每行一条记录）；\n3. 每条记录被分隔符（如逗号、分号、制表符等）分隔为字段（列）；\n4. 每条记录都有同样的字段序列。\n\nCSV文件可以使用文本编辑器或类似于Excel电子表格这类工具打开和编辑，当使用Excel这类电子表格打开CSV文件时，你甚至感觉不到CSV和Excel文件的区别。很多数据库系统都支持将数据导出到CSV文件中，当然也支持从CSV文件中读入数据保存到数据库中，这些内容并不是现在要讨论的重点。\n\n### 将数据写入CSV文件\n\n现有五个学生三门课程的考试成绩需要保存到一个CSV文件中，要达成这个目标，可以使用Python标准库中的`csv`模块，该模块的`writer`函数会返回一个`csvwriter`对象，通过该对象的`writerow`或`writerows`方法就可以将数据写入到CSV文件中，具体的代码如下所示。\n\n```python\nimport csv\nimport random\n\nwith open('scores.csv', 'w') as file:\n    writer = csv.writer(file)\n    writer.writerow(['姓名', '语文', '数学', '英语'])\n    names = ['关羽', '张飞', '赵云', '马超', '黄忠']\n    for name in names:\n        scores = [random.randrange(50, 101) for _ in range(3)]\n        scores.insert(0, name)\n        writer.writerow(scores)\n```\n\n生成的CSV文件的内容。\n\n```\n姓名,语文,数学,英语\n关羽,98,86,61\n张飞,86,58,80\n赵云,95,73,70\n马超,83,97,55\n黄忠,61,54,87\n```\n\n需要说明的是上面的`writer`函数，除了传入要写入数据的文件对象外，还可以`dialect`参数，它表示CSV文件的方言，默认值是`excel`。除此之外，还可以通过`delimiter`、`quotechar`、`quoting`参数来指定分隔符（默认是逗号）、包围值的字符（默认是双引号）以及包围的方式。其中，包围值的字符主要用于当字段中有特殊符号时，通过添加包围值的字符可以避免二义性。大家可以尝试将上面第5行代码修改为下面的代码，然后查看生成的CSV文件。\n\n```python\nwriter = csv.writer(file, delimiter='|', quoting=csv.QUOTE_ALL)\n```\n\n生成的CSV文件的内容。\n\n```\n\"姓名\"|\"语文\"|\"数学\"|\"英语\"\n\"关羽\"|\"88\"|\"64\"|\"65\"\n\"张飞\"|\"76\"|\"93\"|\"79\"\n\"赵云\"|\"78\"|\"55\"|\"76\"\n\"马超\"|\"72\"|\"77\"|\"68\"\n\"黄忠\"|\"70\"|\"72\"|\"51\"\n```\n\n### 从CSV文件读取数据\n\n如果要读取刚才创建的CSV文件，可以使用下面的代码，通过`csv`模块的`reader`函数可以创建出`csvreader`对象，该对象是一个迭代器，可以通过`next`函数或`for-in`循环读取到文件中的数据。\n\n```python\nimport csv\n\nwith open('scores.csv', 'r') as file:\n    reader = csv.reader(file, delimiter='|')\n    for data_list in reader:\n        print(reader.line_num, end='\\t')\n        for elem in data_list:\n            print(elem, end='\\t')\n        print()\n```\n\n> **注意**：上面的代码对`csvreader`对象做`for`循环时，每次会取出一个列表对象，该列表对象包含了一行中所有的字段。\n\n###  总结\n\n将来如果大家使用Python做数据分析，很有可能会用到名为`pandas`的三方库，它是Python数据分析的神器之一。`pandas`中封装了名为`read_csv`和`to_csv`的函数用来读写CSV文件，其中`read_CSV`会将读取到的数据变成一个`DataFrame`对象，而`DataFrame`就是`pandas`库中最重要的类型，它封装了一系列用于数据处理的方法（清洗、转换、聚合等）；而`to_csv`会将`DataFrame`对象中的数据写入CSV文件，完成数据的持久化。`read_csv`函数和`to_csv`函数远远比原生的`csvreader`和`csvwriter`强大。\n", "读写Excel文件-1": "## Python读写Excel文件-1\n\n### Excel简介\n\nExcel 是 Microsoft（微软）为使用 Windows 和 macOS 操作系统开发的一款电子表格软件。Excel 凭借其直观的界面、出色的计算功能和图表工具，再加上成功的市场营销，一直以来都是最为流行的个人计算机数据处理软件。当然，Excel 也有很多竞品，例如 Google Sheets、LibreOffice Calc、Numbers 等，这些竞品基本上也能够兼容 Excel，至少能够读写较新版本的 Excel 文件，当然这些不是我们讨论的重点。掌握用 Python 程序操作 Excel 文件，可以让日常办公自动化的工作更加轻松愉快，而且在很多商业项目中，导入导出 Excel 文件都是特别常见的功能。\n\nPython 操作 Excel 需要三方库的支持，如果要兼容 Excel 2007 以前的版本，也就是`xls`格式的 Excel 文件，可以使用三方库`xlrd`和`xlwt`，前者用于读 Excel 文件，后者用于写 Excel 文件。如果使用较新版本的 Excel，即`xlsx`格式的 Excel 文件，可以使用`openpyxl`库，当然这个库不仅仅可以操作Excel，还可以操作其他基于 Office Open XML 的电子表格文件。\n\n本章我们先讲解基于`xlwt`和`xlrd`操作 Excel 文件，大家可以先使用下面的命令安装这两个三方库以及配合使用的工具模块`xlutils`。\n\n```Bash\npip install xlwt xlrd xlutils\n```\n\n### 读Excel文件\n\n例如在当前文件夹下有一个名为“阿里巴巴2020年股票数据.xls”的 Excel 文件，如果想读取并显示该文件的内容，可以通过如下所示的代码来完成。\n\n```python\nimport xlrd\n\n# 使用xlrd模块的open_workbook函数打开指定Excel文件并获得Book对象（工作簿）\nwb = xlrd.open_workbook('阿里巴巴2020年股票数据.xls')\n# 通过Book对象的sheet_names方法可以获取所有表单名称\nsheetnames = wb.sheet_names()\nprint(sheetnames)\n# 通过指定的表单名称获取Sheet对象（工作表）\nsheet = wb.sheet_by_name(sheetnames[0])\n# 通过Sheet对象的nrows和ncols属性获取表单的行数和列数\nprint(sheet.nrows, sheet.ncols)\nfor row in range(sheet.nrows):\n    for col in range(sheet.ncols):\n        # 通过Sheet对象的cell方法获取指定Cell对象（单元格）\n        # 通过Cell对象的value属性获取单元格中的值\n        value = sheet.cell(row, col).value\n        # 对除首行外的其他行进行数据格式化处理\n        if row > 0:\n            # 第1列的xldate类型先转成元组再格式化为“年月日”的格式\n            if col == 0:\n                # xldate_as_tuple函数的第二个参数只有0和1两个取值\n                # 其中0代表以1900-01-01为基准的日期，1代表以1904-01-01为基准的日期\n                value = xlrd.xldate_as_tuple(value, 0)\n                value = f'{value[0]}年{value[1]:>02d}月{value[2]:>02d}日'\n            # 其他列的number类型处理成小数点后保留两位有效数字的浮点数\n            else:\n                value = f'{value:.2f}'\n        print(value, end='\\t')\n    print()\n# 获取最后一个单元格的数据类型\n# 0 - 空值，1 - 字符串，2 - 数字，3 - 日期，4 - 布尔，5 - 错误\nlast_cell_type = sheet.cell_type(sheet.nrows - 1, sheet.ncols - 1)\nprint(last_cell_type)\n# 获取第一行的值（列表）\nprint(sheet.row_values(0))\n# 获取指定行指定列范围的数据（列表）\n# 第一个参数代表行索引，第二个和第三个参数代表列的开始（含）和结束（不含）索引\nprint(sheet.row_slice(3, 0, 5))\n```\n\n> **提示**：上面代码中使用的Excel文件“阿里巴巴2020年股票数据.xls”可以通过后面的百度云盘地址进行获取。链接:https://pan.baidu.com/s/1rQujl5RQn9R7PadB2Z5g_g 提取码:e7b4。\n\n相信通过上面的代码，大家已经了解到了如何读取一个 Excel 文件，如果想知道更多关于`xlrd`模块的知识，可以阅读它的[官方文档](https://xlrd.readthedocs.io/en/latest/)。\n\n### 写Excel文件\n\n写入 Excel 文件可以通过`xlwt` 模块的`Workbook`类创建工作簿对象，通过工作簿对象的`add_sheet`方法可以添加工作表，通过工作表对象的`write`方法可以向指定单元格中写入数据，最后通过工作簿对象的`save`方法将工作簿写入到指定的文件或内存中。下面的代码实现了将5 个学生 3 门课程的考试成绩写入 Excel 文件的操作。\n\n```python\nimport random\n\nimport xlwt\n\nstudent_names = ['关羽', '张飞', '赵云', '马超', '黄忠']\nscores = [[random.randrange(50, 101) for _ in range(3)] for _ in range(5)]\n# 创建工作簿对象（Workbook）\nwb = xlwt.Workbook()\n# 创建工作表对象（Worksheet）\nsheet = wb.add_sheet('一年级二班')\n# 添加表头数据\ntitles = ('姓名', '语文', '数学', '英语')\nfor index, title in enumerate(titles):\n    sheet.write(0, index, title)\n# 将学生姓名和考试成绩写入单元格\nfor row in range(len(scores)):\n    sheet.write(row + 1, 0, student_names[row])\n    for col in range(len(scores[row])):\n        sheet.write(row + 1, col + 1, scores[row][col])\n# 保存Excel工作簿\nwb.save('考试成绩表.xls')\n```\n\n### 调整单元格样式\n\n在写Excel文件时，我们还可以为单元格设置样式，主要包括字体（Font）、对齐方式（Alignment）、边框（Border）和背景（Background）的设置，`xlwt`对这几项设置都封装了对应的类来支持。要设置单元格样式需要首先创建一个`XFStyle`对象，再通过该对象的属性对字体、对齐方式、边框等进行设定，例如在上面的例子中，如果希望将表头单元格的背景色修改为黄色，可以按照如下的方式进行操作。\n\n```python\nheader_style = xlwt.XFStyle()\npattern = xlwt.Pattern()\npattern.pattern = xlwt.Pattern.SOLID_PATTERN\n# 0 - 黑色、1 - 白色、2 - 红色、3 - 绿色、4 - 蓝色、5 - 黄色、6 - 粉色、7 - 青色\npattern.pattern_fore_colour = 5\nheader_style.pattern = pattern\ntitles = ('姓名', '语文', '数学', '英语')\nfor index, title in enumerate(titles):\n    sheet.write(0, index, title, header_style)\n```\n\n如果希望为表头设置指定的字体，可以使用`Font`类并添加如下所示的代码。\n\n```python\nfont = xlwt.Font()\n# 字体名称\nfont.name = '华文楷体'\n# 字体大小（20是基准单位，18表示18px）\nfont.height = 20 * 18\n# 是否使用粗体\nfont.bold = True\n# 是否使用斜体\nfont.italic = False\n# 字体颜色\nfont.colour_index = 1\nheader_style.font = font\n```\n\n> **注意**：上面代码中指定的字体名（`font.name`）应当是本地系统有的字体，例如在我的电脑上有名为“华文楷体”的字体。\n\n如果希望表头垂直居中对齐，可以使用下面的代码进行设置。\n\n```python\nalign = xlwt.Alignment()\n# 垂直方向的对齐方式\nalign.vert = xlwt.Alignment.VERT_CENTER\n# 水平方向的对齐方式\nalign.horz = xlwt.Alignment.HORZ_CENTER\nheader_style.alignment = align\n```\n\n如果希望给表头加上黄色的虚线边框，可以使用下面的代码来设置。\n\n```python\nborders = xlwt.Borders()\nprops = (\n    ('top', 'top_colour'), ('right', 'right_colour'),\n    ('bottom', 'bottom_colour'), ('left', 'left_colour')\n)\n# 通过循环对四个方向的边框样式及颜色进行设定\nfor position, color in props:\n    # 使用setattr内置函数动态给对象指定的属性赋值\n    setattr(borders, position, xlwt.Borders.DASHED)\n    setattr(borders, color, 5)\nheader_style.borders = borders\n```\n\n如果要调整单元格的宽度（列宽）和表头的高度（行高），可以按照下面的代码进行操作。\n\n```python\n# 设置行高为40px\nsheet.row(0).set_style(xlwt.easyxf(f'font:height {20 * 40}'))\ntitles = ('姓名', '语文', '数学', '英语')\nfor index, title in enumerate(titles):\n    # 设置列宽为200px\n    sheet.col(index).width = 20 * 200\n    # 设置单元格的数据和样式\n    sheet.write(0, index, title, header_style)\n```\n\n### 公式计算\n\n对于前面打开的“阿里巴巴2020年股票数据.xls”文件，如果要统计全年收盘价（Close字段）的平均值以及全年交易量（Volume字段）的总和，可以使用Excel的公式计算即可。我们可以先使用`xlrd`读取Excel文件夹，然后通过`xlutils`三方库提供的`copy`函数将读取到的Excel文件转成`Workbook`对象进行写操作，在调用`write`方法时，可以将一个`Formula`对象写入单元格。\n\n实现公式计算的代码如下所示。\n\n```python\nimport xlrd\nimport xlwt\nfrom xlutils.copy import copy\n\nwb_for_read = xlrd.open_workbook('阿里巴巴2020年股票数据.xls')\nsheet1 = wb_for_read.sheet_by_index(0)\nnrows, ncols = sheet1.nrows, sheet1.ncols\nwb_for_write = copy(wb_for_read)\nsheet2 = wb_for_write.get_sheet(0)\nsheet2.write(nrows, 4, xlwt.Formula(f'average(E2:E{nrows})'))\nsheet2.write(nrows, 6, xlwt.Formula(f'sum(G2:G{nrows})'))\nwb_for_write.save('阿里巴巴2020年股票数据汇总.xls')\n```\n\n> **说明**：上面的代码有一些小瑕疵，有兴趣的读者可以自行探索并思考如何解决。\n\n###  总结\n\n掌握了 Python 程序操作 Excel 的方法，可以解决日常办公中很多繁琐的处理 Excel 电子表格工作，最常见就是将多个数据格式相同的 Excel 文件合并到一个文件以及从多个 Excel 文件或表单中提取指定的数据。当然，如果要对表格数据进行处理，使用 Python 数据分析神器之一的 pandas 库可能更为方便。\n", "读写Excel文件-2": "## Python读写Excel文件-2\n\n### Excel简介\n\nExcel 是 Microsoft（微软）为使用 Windows 和 macOS 操作系统开发的一款电子表格软件。Excel 凭借其直观的界面、出色的计算功能和图表工具，再加上成功的市场营销，一直以来都是最为流行的个人计算机数据处理软件。当然，Excel 也有很多竞品，例如 Google Sheets、LibreOffice Calc、Numbers 等，这些竞品基本上也能够兼容 Excel，至少能够读写较新版本的 Excel 文件，当然这些不是我们讨论的重点。掌握用 Python 程序操作 Excel 文件，可以让日常办公自动化的工作更加轻松愉快，而且在很多商业项目中，导入导出 Excel 文件都是特别常见的功能。\n\n本章我们继续讲解基于另一个三方库`openpyxl`如何进行 Excel 文件操作，首先需要先安装它。\n\n```Bash\npip install openpyxl\n```\n\n`openpyxl`的优点在于，当我们打开一个 Excel 文件后，既可以对它进行读操作，又可以对它进行写操作，而且在操作的便捷性上是优于`xlwt`和`xlrd`的。此外，如果要进行样式编辑和公式计算，使用`openpyxl`也远比上一个章节我们讲解的方式更为简单，而且`openpyxl`还支持数据透视和插入图表等操作，功能非常强大。有一点需要再次强调，`openpyxl`并不支持操作 Office 2007 以前版本的 Excel 文件。\n\n### 读取Excel文件\n\n例如在当前文件夹下有一个名为“阿里巴巴2020年股票数据.xlsx”的 Excel 文件，如果想读取并显示该文件的内容，可以通过如下所示的代码来完成。\n\n```python\nimport datetime\n\nimport openpyxl\n\n# 加载一个工作簿 ---> Workbook\nwb = openpyxl.load_workbook('阿里巴巴2020年股票数据.xlsx')\n# 获取工作表的名字\nprint(wb.sheetnames)\n# 获取工作表 ---> Worksheet\nsheet = wb.worksheets[0]\n# 获得单元格的范围\nprint(sheet.dimensions)\n# 获得行数和列数\nprint(sheet.max_row, sheet.max_column)\n\n# 获取指定单元格的值\nprint(sheet.cell(3, 3).value)\nprint(sheet['C3'].value)\nprint(sheet['G255'].value)\n\n# 获取多个单元格（嵌套元组）\nprint(sheet['A2:C5'])\n\n# 读取所有单元格的数据\nfor row_ch in range(2, sheet.max_row + 1):\n    for col_ch in 'ABCDEFG':\n        value = sheet[f'{col_ch}{row_ch}'].value\n        if type(value) == datetime.datetime:\n            print(value.strftime('%Y年%m月%d日'), end='\\t')\n        elif type(value) == int:\n            print(f'{value:<10d}', end='\\t')\n        elif type(value) == float:\n            print(f'{value:.4f}', end='\\t')\n        else:\n            print(value, end='\\t')\n    print()\n```\n\n> **提示**：上面代码中使用的Excel文件“阿里巴巴2020年股票数据.xlsx”可以通过后面的百度云盘地址进行获取。链接:https://pan.baidu.com/s/1rQujl5RQn9R7PadB2Z5g_g 提取码:e7b4。\n\n需要提醒大家一点，`openpyxl`获取指定的单元格有两种方式，一种是通过`cell`方法，需要注意，该方法的行索引和列索引都是从`1`开始的，这是为了照顾用惯了 Excel 的人的习惯；另一种是通过索引运算，通过指定单元格的坐标，例如`C3`、`G255`，也可以取得对应的单元格，再通过单元格对象的`value`属性，就可以获取到单元格的值。通过上面的代码，相信大家还注意到了，可以通过类似`sheet['A2:C5']`或`sheet['A2':'C5']`这样的切片操作获取多个单元格，该操作将返回嵌套的元组，相当于获取到了多行多列。\n\n### 写Excel文件\n\n下面我们使用`openpyxl`来进行写 Excel 操作。\n\n```python\nimport random\n\nimport openpyxl\n\n# 第一步：创建工作簿（Workbook）\nwb = openpyxl.Workbook()\n\n# 第二步：添加工作表（Worksheet）\nsheet = wb.active\nsheet.title = '期末成绩'\n\ntitles = ('姓名', '语文', '数学', '英语')\nfor col_index, title in enumerate(titles):\n    sheet.cell(1, col_index + 1, title)\n\nnames = ('关羽', '张飞', '赵云', '马超', '黄忠')\nfor row_index, name in enumerate(names):\n    sheet.cell(row_index + 2, 1, name)\n    for col_index in range(2, 5):\n        sheet.cell(row_index + 2, col_index, random.randrange(50, 101))\n\n# 第四步：保存工作簿\nwb.save('考试成绩表.xlsx')\n```\n\n### 调整样式和公式计算\n\n在使用`openpyxl`操作 Excel 时，如果要调整单元格的样式，可以直接通过单元格对象（`Cell`对象）的属性进行操作。单元格对象的属性包括字体（`font`）、对齐（`alignment`）、边框（`border`）等，具体的可以参考`openpyxl`的[官方文档](https://openpyxl.readthedocs.io/en/stable/index.html)。在使用`openpyxl`时，如果需要做公式计算，可以完全按照 Excel 中的操作方式来进行，具体的代码如下所示。\n\n```python\nimport openpyxl\nfrom openpyxl.styles import Font, Alignment, Border, Side\n\n# 对齐方式\nalignment = Alignment(horizontal='center', vertical='center')\n# 边框线条\nside = Side(color='ff7f50', style='mediumDashed')\n\nwb = openpyxl.load_workbook('考试成绩表.xlsx')\nsheet = wb.worksheets[0]\n\n# 调整行高和列宽\nsheet.row_dimensions[1].height = 30\nsheet.column_dimensions['E'].width = 120\n\nsheet['E1'] = '平均分'\n# 设置字体\nsheet.cell(1, 5).font = Font(size=18, bold=True, color='ff1493', name='华文楷体')\n# 设置对齐方式\nsheet.cell(1, 5).alignment = alignment\n# 设置单元格边框\nsheet.cell(1, 5).border = Border(left=side, top=side, right=side, bottom=side)\nfor i in range(2, 7):\n    # 公式计算每个学生的平均分\n    sheet[f'E{i}'] = f'=average(B{i}:D{i})'\n    sheet.cell(i, 5).font = Font(size=12, color='4169e1', italic=True)\n    sheet.cell(i, 5).alignment = alignment\n\nwb.save('考试成绩表.xlsx')\n```\n\n### 生成统计图表\n\n通过`openpyxl`库，可以直接向 Excel 中插入统计图表，具体的做法跟在 Excel 中插入图表大体一致。我们可以创建指定类型的图表对象，然后通过该对象的属性对图表进行设置。当然，最为重要的是为图表绑定数据，即横轴代表什么，纵轴代表什么，具体的数值是多少。最后，可以将图表对象添加到表单中，具体的代码如下所示。\n\n```python\nfrom openpyxl import Workbook\nfrom openpyxl.chart import BarChart, Reference\n\nwb = Workbook(write_only=True)\nsheet = wb.create_sheet()\n\nrows = [\n    ('类别', '销售A组', '销售B组'),\n    ('手机', 40, 30),\n    ('平板', 50, 60),\n    ('笔记本', 80, 70),\n    ('外围设备', 20, 10),\n]\n\n# 向表单中添加行\nfor row in rows:\n    sheet.append(row)\n\n# 创建图表对象\nchart = BarChart()\nchart.type = 'col'\nchart.style = 10\n# 设置图表的标题\nchart.title = '销售统计图'\n# 设置图表纵轴的标题\nchart.y_axis.title = '销量'\n# 设置图表横轴的标题\nchart.x_axis.title = '商品类别'\n# 设置数据的范围\ndata = Reference(sheet, min_col=2, min_row=1, max_row=5, max_col=3)\n# 设置分类的范围\ncats = Reference(sheet, min_col=1, min_row=2, max_row=5)\n# 给图表添加数据\nchart.add_data(data, titles_from_data=True)\n# 给图表设置分类\nchart.set_categories(cats)\nchart.shape = 4\n# 将图表添加到表单指定的单元格中\nsheet.add_chart(chart, 'A10')\n\nwb.save('demo.xlsx')\n```\n\n运行上面的代码，打开生成的 Excel 文件，效果如下图所示。\n\n<img class=\"lazy\" data-src=\"/res/20210819235009.png\"  width=\"75%\">\n\n###  总结\n\n掌握了 Python 程序操作 Excel 的方法，可以解决日常办公中很多繁琐的处理 Excel 电子表格工作，最常见就是将多个数据格式相同的Excel 文件合并到一个文件以及从多个 Excel 文件或表单中提取指定的数据。如果数据体量较大或者处理数据的方式比较复杂，我们还是推荐大家使用 Python 数据分析神器之一的 pandas 库。\n", "操作Word和PowerPoint文件": "## Python操作Word和PowerPoint文件\n\n在日常工作中，有很多简单重复的劳动其实完全可以交给 Python 程序，比如根据样板文件（模板文件）批量的生成很多个 Word 文件或 PowerPoint 文件。Word 是微软公司开发的文字处理程序，相信大家都不陌生，日常办公中很多正式的文档都是用 Word 进行撰写和编辑的，目前使用的 Word 文件后缀名一般为`.docx`。PowerPoint 是微软公司开发的演示文稿程序，是微软的 Office 系列软件中的一员，被商业人士、教师、学生等群体广泛使用，通常也将其称之为“幻灯片”。在 Python 中，可以使用名为`python-docx` 的三方库来操作 Word，可以使用名为`python-pptx`的三方库来生成 PowerPoint。\n\n### 操作Word文档\n\n我们可以先通过下面的命令来安装`python-docx`三方库。\n\n```bash\npip install python-docx\n```\n\n按照[官方文档](https://python-docx.readthedocs.io/en/latest/)的介绍，我们可以使用如下所示的代码来生成一个简单的 Word 文档。\n\n```python\nfrom docx import Document\nfrom docx.shared import Cm, Pt\n\nfrom docx.document import Document as Doc\n\n# 创建代表Word文档的Doc对象\ndocument = Document()  # type: Doc\n# 添加大标题\ndocument.add_heading('快快乐乐学Python', 0)\n# 添加段落\np = document.add_paragraph('Python是一门非常流行的编程语言，它')\nrun = p.add_run('简单')\nrun.bold = True\nrun.font.size = Pt(18)\np.add_run('而且')\nrun = p.add_run('优雅')\nrun.font.size = Pt(18)\nrun.underline = True\np.add_run('。')\n\n# 添加一级标题\ndocument.add_heading('Heading, level 1', level=1)\n# 添加带样式的段落\ndocument.add_paragraph('Intense quote', style='Intense Quote')\n# 添加无序列表\ndocument.add_paragraph(\n    'first item in unordered list', style='List Bullet'\n)\ndocument.add_paragraph(\n    'second item in ordered list', style='List Bullet'\n)\n# 添加有序列表\ndocument.add_paragraph(\n    'first item in ordered list', style='List Number'\n)\ndocument.add_paragraph(\n    'second item in ordered list', style='List Number'\n)\n\n# 添加图片（注意路径和图片必须要存在）\ndocument.add_picture('resources/guido.jpg', width=Cm(5.2))\n\n# 添加分节符\ndocument.add_section()\n\nrecords = (\n    ('小明', '男', '1995-5-5'),\n    ('孙美丽', '女', '1992-2-2')\n)\n# 添加表格\ntable = document.add_table(rows=1, cols=3)\ntable.style = 'Dark List'\nhdr_cells = table.rows[0].cells\nhdr_cells[0].text = '姓名'\nhdr_cells[1].text = '性别'\nhdr_cells[2].text = '出生日期'\n# 为表格添加行\nfor name, sex, birthday in records:\n    row_cells = table.add_row().cells\n    row_cells[0].text = name\n    row_cells[1].text = sex\n    row_cells[2].text = birthday\n\n# 添加分页符\ndocument.add_page_break()\n\n# 保存文档\ndocument.save('demo.docx')\n```\n\n> **提示**：上面代码第7行中的注释`# type: Doc`是为了在PyCharm中获得代码补全提示，因为如果不清楚对象具体的数据类型，PyCharm 无法在后续代码中给出`Doc`对象的代码补全提示。\n\n执行上面的代码，打开生成的 Word 文档，效果如下图所示。\n\n<img class=\"lazy\" data-src=\"/res/20210820002742.png\" width=\"40%\">&nbsp;&nbsp;<img class=\"lazy\" data-src=\"/res/20210820002843.png\" width=\"40%\">\n\n对于一个已经存在的 Word 文件，我们可以通过下面的代码去遍历它所有的段落并获取对应的内容。\n\n```python\nfrom docx import Document\nfrom docx.document import Document as Doc\n\ndoc = Document('resources/离职证明.docx')  # type: Doc\nfor no, p in enumerate(doc.paragraphs):\n    print(no, p.text)\n```\n\n> **提示**：如果需要上面代码中的 Word 文件，可以通过下面的百度云盘地址进行获取。链接:https://pan.baidu.com/s/1rQujl5RQn9R7PadB2Z5g_g 提取码:e7b4。\n\n读取到的内容如下所示。\n\n```\n0 \n1 离 职 证 明\n2 \n3 兹证明 王大锤 ，身份证号码： 100200199512120001 ，于 2018 年 8 月 7 日至 2020 年 6 月 28 日在我单位  开发部 部门担任 Java开发工程师 职务，在职期间无不良表现。因 个人 原因，于 2020 年 6 月 28 日起终止解除劳动合同。现已结清财务相关费用，办理完解除劳动关系相关手续，双方不存在任何劳动争议。\n4 \n5 特此证明！\n6 \n7 \n8 公司名称（盖章）:成都风车车科技有限公司\n9    \t\t\t2020 年 6 月 28 日\n```\n\n讲到这里，相信很多读者已经想到了，我们可以把上面的离职证明制作成一个模板文件，把姓名、身份证号、入职和离职日期等信息用占位符代替，这样通过对占位符的替换，就可以根据实际需要写入对应的信息，这样就可以批量的生成 Word 文档。\n\n按照上面的思路，我们首先编辑一个离职证明的模板文件，如下图所示。\n\n<img class=\"lazy\" data-src=\"/res/20210820004223.png\" width=\"75%\" style=\"border:1px solid black\"/>\n\n接下来我们读取该文件，将占位符替换为真实信息，就可以生成一个新的 Word 文档，如下所示。\n\n```python\nfrom docx import Document\nfrom docx.document import Document as Doc\n\n# 将真实信息用字典的方式保存在列表中\nemployees = [\n    {\n        'name': '小明',\n        'id': '100200198011280001',\n        'sdate': '2008年3月1日',\n        'edate': '2012年2月29日',\n        'department': '产品研发',\n        'position': '架构师',\n        'company': '成都华为技术有限公司'\n    },\n    {\n        'name': '王大锤',\n        'id': '510210199012125566',\n        'sdate': '2019年1月1日',\n        'edate': '2021年4月30日',\n        'department': '产品研发',\n        'position': 'Python开发工程师',\n        'company': '成都谷道科技有限公司'\n    },\n    {\n        'name': '李元芳',\n        'id': '2102101995103221599',\n        'sdate': '2020年5月10日',\n        'edate': '2021年3月5日',\n        'department': '产品研发',\n        'position': 'Java开发工程师',\n        'company': '同城企业管理集团有限公司'\n    },\n]\n# 对列表进行循环遍历，批量生成Word文档 \nfor emp_dict in employees:\n    # 读取离职证明模板文件\n    doc = Document('resources/离职证明模板.docx')  # type: Doc\n    # 循环遍历所有段落寻找占位符\n    for p in doc.paragraphs:\n        if '{' not in p.text:\n            continue\n        # 不能直接修改段落内容，否则会丢失样式\n        # 所以需要对段落中的元素进行遍历并进行查找替换\n        for run in p.runs:\n            if '{' not in run.text:\n                continue\n            # 将占位符换成实际内容\n            start, end = run.text.find('{'), run.text.find('}')\n            key, place_holder = run.text[start + 1:end], run.text[start:end + 1]\n            run.text = run.text.replace(place_holder, emp_dict[key])\n    # 每个人对应保存一个Word文档\n    doc.save(f'{emp_dict[\"name\"]}离职证明.docx')\n```\n\n执行上面的代码，会在当前路径下生成三个 Word 文档，如下图所示。\n\n<img class=\"lazy\" data-src=\"/res/20210820004825.png\" width=\"50%\">\n\n### 生成PowerPoint\n\n首先我们需要安装名为`python-pptx`的三方库，命令如下所示。\n\n```Bash\npip install python-pptx\n```\n\n用 Python 操作 PowerPoint 的内容，因为实际应用场景不算很多，我不打算在这里进行赘述，有兴趣的读者可以自行阅读`python-pptx`的[官方文档](https://python-pptx.readthedocs.io/en/latest/)，下面仅展示一段来自于官方文档的代码。\n\n```python\nfrom pptx import Presentation\n\n# 创建幻灯片对象\npres = Presentation()\n\n# 选择母版添加一页\ntitle_slide_layout = pres.slide_layouts[0]\nslide = pres.slides.add_slide(title_slide_layout)\n# 获取标题栏和副标题栏\ntitle = slide.shapes.title\nsubtitle = slide.placeholders[1]\n# 编辑标题和副标题\ntitle.text = \"Welcome to Python\"\nsubtitle.text = \"Life is short, I use Python\"\n\n# 选择母版添加一页\nbullet_slide_layout = pres.slide_layouts[1]\nslide = pres.slides.add_slide(bullet_slide_layout)\n# 获取页面上所有形状\nshapes = slide.shapes\n# 获取标题和主体\ntitle_shape = shapes.title\nbody_shape = shapes.placeholders[1]\n# 编辑标题\ntitle_shape.text = 'Introduction'\n# 编辑主体内容\ntf = body_shape.text_frame\ntf.text = 'History of Python'\n# 添加一个一级段落\np = tf.add_paragraph()\np.text = 'X\\'max 1989'\np.level = 1\n# 添加一个二级段落\np = tf.add_paragraph()\np.text = 'Guido began to write interpreter for Python.'\np.level = 2\n\n# 保存幻灯片\npres.save('test.pptx')\n```\n\n运行上面的代码，生成的 PowerPoint 文件如下图所示。\n\n<img class=\"lazy\" data-src=\"/res/20210820010306.png\" width=\"75%\" />\n\n### 总结\n\n用 Python 程序解决办公自动化的问题真的非常酷，它可以将我们从繁琐乏味的劳动中解放出来。写这类代码就是去做一件一劳永逸的事情，写代码的过程即便不怎么愉快，使用这些代码的时候应该是非常开心的。\n", "操作PDF文件": "## Python操作PDF文件\n\nPDF 是 Portable Document Format 的缩写，这类文件通常使用`.pdf`作为其扩展名。在日常开发工作中，最容易遇到的就是从 PDF 中读取文本内容以及用已有的内容生成PDF文档这两个任务。\n\n### 从PDF中提取文本\n\n在 Python 中，可以使用名为`PyPDF2`的三方库来读取 PDF 文件，可以使用下面的命令来安装它。\n\n```Bash\npip install PyPDF2\n```\n\n`PyPDF2`没有办法从 PDF 文档中提取图像、图表或其他媒体，但它可以提取文本，并将其返回为 Python 字符串。\n\n```python\nimport PyPDF2\n\nreader = PyPDF2.PdfReader('test.pdf')\nfor page in reader.pages:\n    print(page.extract_text())\n```\n\n> **提示**：本章代码使用到的 PDF 文件都可以通过下面的百度云盘地址进行获取，链接：https://pan.baidu.com/s/1rQujl5RQn9R7PadB2Z5g_g，提取码：e7b4。\n\n当然，`PyPDF2`并不是什么样的 PDF 文档都能提取出文字来，这个问题就我所知并没有什么特别好的解决方法，尤其是在提取中文的时候。网上也有很多讲解从 PDF 中提取文字的文章，推荐大家自行阅读[《三大神器助力Python提取pdf文档信息》](https://cloud.tencent.com/developer/article/1395339)一文进行了解。\n\n要从 PDF 文件中提取文本也可以直接使用三方的命令行工具，具体的做法如下所示。\n\n```Bash\npip install pdfminer.six\npdf2text.py test.pdf\n```\n\n### 旋转和叠加页面\n\n上面的代码中通过创建`PdfFileReader`对象的方式来读取 PDF 文档，该对象的`getPage`方法可以获得PDF文档的指定页并得到一个`PageObject`对象，通过`PageObject`对象的`rotateClockwise`和`rotateCounterClockwise`方法可以实现页面的顺时针和逆时针方向旋转，通过`PageObject`对象的`addBlankPage`方法可以添加一个新的空白页，代码如下所示。\n\n```python\nreader = PyPDF2.PdfReader('XGBoost.pdf')\nwriter = PyPDF2.PdfWriter()\n\nfor no, page in enumerate(reader.pages):\n    if no % 2 == 0:\n        new_page = page.rotate(-90)\n    else:\n        new_page = page.rotate(90)\n    writer.add_page(new_page)\n\nwith open('temp.pdf', 'wb') as file_obj:\n    writer.write(file_obj)\n```\n\n### 加密PDF文件\n\n使用`PyPDF2`中的`PdfFileWrite`对象可以为PDF文档加密，如果需要给一系列的PDF文档设置统一的访问口令，使用Python程序来处理就会非常的方便。\n\n```python\nimport PyPDF2\n\nreader = PyPDF2.PdfReader('XGBoost.pdf')\nwriter = PyPDF2.PdfWriter()\n\nfor page in reader.pages:\n    writer.add_page(page)\n    \nwriter.encrypt('foobared')\n\nwith open('temp.pdf', 'wb') as file_obj:\n    writer.write(file_obj)\n```\n\n### 批量添加水印\n\n上面提到的`PageObject`对象还有一个名为`mergePage`的方法，可以两个 PDF 页面进行叠加，通过这个操作，我们很容易实现给PDF文件添加水印的功能。例如要给上面的“XGBoost.pdf”文件添加一个水印，我们可以先准备好一个提供水印页面的 PDF 文件，然后将包含水印的`PageObject`读取出来，然后再循环遍历“XGBoost.pdf”文件的每个页，获取到`PageObject`对象，然后通过`mergePage`方法实现水印页和原始页的合并，代码如下所示。\n\n```python\nreader1 = PyPDF2.PdfReader('XGBoost.pdf')\nreader2 = PyPDF2.PdfReader('watermark.pdf')\nwriter = PyPDF2.PdfWriter()\nwatermark_page = reader2.pages[0]\n\nfor page in reader1.pages:\n    page.merge_page(watermark_page)\n    writer.add_page(page)\n\nwith open('temp.pdf', 'wb') as file_obj:\n    writer.write(file_obj)\n```\n\n如果愿意，还可以让奇数页和偶数页使用不同的水印，大家可以自己思考下应该怎么做。\n\n### 创建PDF文件\n\n创建 PDF 文档需要三方库`reportlab`的支持，安装的方法如下所示。\n\n```Bash\npip install reportlab\n```\n\n下面通过一个例子为大家展示`reportlab`的用法。\n\n```python\nfrom reportlab.lib.pagesizes import A4\nfrom reportlab.pdfbase import pdfmetrics\nfrom reportlab.pdfbase.ttfonts import TTFont\nfrom reportlab.pdfgen import canvas\n\npdf_canvas = canvas.Canvas('resources/demo.pdf', pagesize=A4)\nwidth, height = A4\n\n# 绘图\nimage = canvas.ImageReader('resources/guido.jpg')\npdf_canvas.drawImage(image, 20, height - 395, 250, 375)\n\n# 显示当前页\npdf_canvas.showPage()\n\n# 注册字体文件\npdfmetrics.registerFont(TTFont('Font1', 'resources/fonts/Vera.ttf'))\npdfmetrics.registerFont(TTFont('Font2', 'resources/fonts/青呱石头体.ttf'))\n\n# 写字\npdf_canvas.setFont('Font2', 40)\npdf_canvas.setFillColorRGB(0.9, 0.5, 0.3, 1)\npdf_canvas.drawString(width // 2 - 120, height // 2, '你好，世界！')\npdf_canvas.setFont('Font1', 40)\npdf_canvas.setFillColorRGB(0, 1, 0, 0.5)\npdf_canvas.rotate(18)\npdf_canvas.drawString(250, 250, 'hello, world!')\n\n# 保存\npdf_canvas.save()\n```\n\n上面的代码如果不太理解也没有关系，等真正需要用 Python 创建 PDF 文档的时候，再好好研读一下`reportlab`的[官方文档](https://www.reportlab.com/docs/reportlab-userguide.pdf)就可以了。\n\n> **提示**：上面代码中用到的图片和字体可以通过下面的百度云盘链接获取，链接：https://pan.baidu.com/s/1rQujl5RQn9R7PadB2Z5g_g，提取码：e7b4。\n\n###  总结\n\n在学习完上面的内容之后，相信大家已经知道像合并多个 PDF 文件这样的工作应该如何用 Python 代码来处理了，赶紧自己动手试一试吧。\n", "处理图像": "## Python处理图像\n\n### 入门知识\n\n1. 颜色。如果你有使用颜料画画的经历，那么一定知道混合红、黄、蓝三种颜料可以得到其他的颜色，事实上这三种颜色就是美术中的三原色，它们是不能再分解的基本颜色。在计算机中，我们可以将红、绿、蓝三种色光以不同的比例叠加来组合成其他的颜色，因此这三种颜色就是色光三原色。在计算机系统中，我们通常会将一个颜色表示为一个 RGB 值或 RGBA 值（其中的 A 表示 Alpha 通道，它决定了透过这个图像的像素，也就是透明度）。\n\n   |    名称     |      RGB值      |     名称     |     RGB值     |\n   | :---------: | :-------------: | :----------: | :-----------: |\n   | White（白） | (255, 255, 255) |  Red（红）   |  (255, 0, 0)  |\n   | Green（绿） |   (0, 255, 0)   |  Blue（蓝）  |  (0, 0, 255)  |\n   | Gray（灰）  | (128, 128, 128) | Yellow（黄） | (255, 255, 0) |\n   | Black（黑） |    (0, 0, 0)    | Purple（紫） | (128, 0, 128) |\n\n2. 像素。对于一个由数字序列表示的图像来说，最小的单位就是图像上单一颜色的小方格，这些小方块都有一个明确的位置和被分配的色彩数值，而这些一小方格的颜色和位置决定了该图像最终呈现出来的样子，它们是不可分割的单位，我们通常称之为像素（pixel）。每一个图像都包含了一定量的像素，这些像素决定图像在屏幕上所呈现的大小，大家如果爱好拍照或者自拍，对像素这个词就不会陌生。\n\n### 用Pillow处理图像\n\nPillow 是由从著名的 Python 图像处理库 PIL 发展出来的一个分支，通过 Pillow 可以实现图像压缩和图像处理等各种操作。可以使用下面的命令来安装 Pillow。\n\n```Shell\npip install pillow\n```\n\nPillow 中最为重要的是`Image`类，可以通过`Image`模块的`open`函数来读取图像并获得`Image`类型的对象。\n\n1. 读取和显示图像\n\n   ```python\n   from PIL import Image\n   \n   # 读取图像获得Image对象\n   image = Image.open('guido.jpg')\n   # 通过Image对象的format属性获得图像的格式\n   print(image.format) # JPEG\n   # 通过Image对象的size属性获得图像的尺寸\n   print(image.size)   # (500, 750)\n   # 通过Image对象的mode属性获取图像的模式\n   print(image.mode)   # RGB\n   # 通过Image对象的show方法显示图像\n   image.show()\n   ```\n\n   <img class=\"lazy\" data-src=\"/res/20210803202628.png\" width=\"80%\">\n\n2. 剪裁图像\n\n   ```python\n   # 通过Image对象的crop方法指定剪裁区域剪裁图像\n   image.crop((80, 20, 310, 360)).show()\n   ```\n\n   <img class=\"lazy\" data-src=\"/res/20210803202701.png\" width=\"80%\">\n\n3. 生成缩略图\n\n   ```python\n   # 通过Image对象的thumbnail方法生成指定尺寸的缩略图\n   image.thumbnail((128, 128))\n   image.show()\n   ```\n\n   <img class=\"lazy\" data-src=\"/res/20210803202722.png\" width=\"100%\">\n\n4. 缩放和黏贴图像\n\n   ```python\n   # 读取小明的照片获得Image对象\n   luohao_image = Image.open('luohao.png')\n   # 读取吉多的照片获得Image对象\n   guido_image = Image.open('guido.jpg')\n   # 从吉多的照片上剪裁出吉多的头\n   guido_head = guido_image.crop((80, 20, 310, 360))\n   width, height = guido_head.size\n   # 使用Image对象的resize方法修改图像的尺寸\n   # 使用Image对象的paste方法将吉多的头粘贴到小明的照片上\n   luohao_image.paste(guido_head.resize((int(width / 1.5), int(height / 1.5))), (172, 40))\n   luohao_image.show()\n   ```\n\n   <img class=\"lazy\" data-src=\"/res/20210803202749.png\" width=\"80%\">\n\n5. 旋转和翻转\n\n   ```python\n   image = Image.open('guido.jpg')\n   # 使用Image对象的rotate方法实现图像的旋转\n   image.rotate(45).show()\n   # 使用Image对象的transpose方法实现图像翻转\n   # Image.FLIP_LEFT_RIGHT - 水平翻转\n   # Image.FLIP_TOP_BOTTOM - 垂直翻转\n   image.transpose(Image.FLIP_TOP_BOTTOM).show()\n   ```\n\n   <img class=\"lazy\" data-src=\"/res/20210803202829.png\" width=\"80%\">\n\n6. 操作像素\n\n   ```python\n   for x in range(80, 310):\n       for y in range(20, 360):\n           # 通过Image对象的putpixel方法修改图像指定像素点\n           image.putpixel((x, y), (128, 128, 128))\n   image.show()\n   ```\n\n   <img class=\"lazy\" data-src=\"/res/20210803202932.png\" width=\"80%\">\n\n7. 滤镜效果\n\n   ```python\n   from PIL import ImageFilter\n   \n   # 使用Image对象的filter方法对图像进行滤镜处理\n   # ImageFilter模块包含了诸多预设的滤镜也可以自定义滤镜\n   image.filter(ImageFilter.CONTOUR).show()\n   ```\n\n   <img class=\"lazy\" data-src=\"/res/20210803202953.png\" width=\"80%\">\n\n### 使用Pillow绘图\n\nPillow 中有一个名为`ImageDraw`的模块，该模块的`Draw`函数会返回一个`ImageDraw`对象，通过`ImageDraw`对象的`arc`、`line`、`rectangle`、`ellipse`、`polygon`等方法，可以在图像上绘制出圆弧、线条、矩形、椭圆、多边形等形状，也可以通过该对象的`text`方法在图像上添加文字。\n\n<img class=\"lazy\" data-src=\"/res/20210803203016.png\" width=\"80%\">\n\n要绘制如上图所示的图像，完整的代码如下所示。\n\n```python\nimport random\n\nfrom PIL import Image, ImageDraw, ImageFont\n\n\ndef random_color():\n    \"\"\"生成随机颜色\"\"\"\n    red = random.randint(0, 255)\n    green = random.randint(0, 255)\n    blue = random.randint(0, 255)\n    return red, green, blue\n\n\nwidth, height = 800, 600\n# 创建一个800*600的图像，背景色为白色\nimage = Image.new(mode='RGB', size=(width, height), color=(255, 255, 255))\n# 创建一个ImageDraw对象\ndrawer = ImageDraw.Draw(image)\n# 通过指定字体和大小获得ImageFont对象\nfont = ImageFont.truetype('Kongxin.ttf', 32)\n# 通过ImageDraw对象的text方法绘制文字\ndrawer.text((300, 50), 'Hello, world!', fill=(255, 0, 0), font=font)\n# 通过ImageDraw对象的line方法绘制两条对角直线\ndrawer.line((0, 0, width, height), fill=(0, 0, 255), width=2)\ndrawer.line((width, 0, 0, height), fill=(0, 0, 255), width=2)\nxy = width // 2 - 60, height // 2 - 60, width // 2 + 60, height // 2 + 60\n# 通过ImageDraw对象的rectangle方法绘制矩形\ndrawer.rectangle(xy, outline=(255, 0, 0), width=2)\n# 通过ImageDraw对象的ellipse方法绘制椭圆\nfor i in range(4):\n    left, top, right, bottom = 150 + i * 120, 220, 310 + i * 120, 380\n    drawer.ellipse((left, top, right, bottom), outline=random_color(), width=8)\n# 显示图像\nimage.show()\n# 保存图像\nimage.save('result.png')\n```\n\n> **注意**：上面代码中使用的字体文件需要根据自己准备，可以选择自己喜欢的字体文件并放置在代码目录下。\n\n###  总结\n\n使用 Python 语言做开发，除了可以用 Pillow 来处理图像外，还可以使用更为强大的 OpenCV 库来完成图形图像的处理，OpenCV（**Open** Source **C**omputer **V**ision Library）是一个跨平台的计算机视觉库，可以用来开发实时图像处理、计算机视觉和模式识别程序。在我们的日常工作中，有很多繁琐乏味的任务其实都可以通过 Python 程序来处理，编程的目的就是让计算机帮助我们解决问题，减少重复乏味的劳动。通过本章节的学习，相信大家已经感受到了使用 Python 程序绘图改图的乐趣，其实 Python 能做的事情还远不止这些，继续你的学习吧。\n", "发送邮件和短信": "## Python发送邮件和短信\n\n在前面的课程中，我们已经教会大家如何用 Python 程序自动的生成 Excel、Word、PDF 文档，接下来我们还可以更进一步，就是通过邮件将生成好的文档发送给指定的收件人，然后用短信告知对方我们发出了邮件。这些事情利用 Python 程序也可以轻松愉快的解决。\n\n### 发送电子邮件\n\n在即时通信软件如此发达的今天，电子邮件仍然是互联网上使用最为广泛的应用之一，公司向应聘者发出录用通知、网站向用户发送一个激活账号的链接、银行向客户推广它们的理财产品等几乎都是通过电子邮件来完成的，而这些任务应该都是由程序自动完成的。\n\n我们可以用HTTP（超文本传输协议）来访问网站资源，HTTP 是一个应用级协议，它建立在 TCP（传输控制协议）之上，TCP 为很多应用级协议提供了可靠的数据传输服务。如果要发送电子邮件，需要使用 SMTP（简单邮件传输协议），它也是建立在 TCP 之上的应用级协议，规定了邮件的发送者如何跟邮件服务器进行通信的细节。Python 通过名为`smtplib`的模块将这些操作简化成了`SMTP_SSL`对象，通过该对象的`login`和`send_mail`方法，就能够完成发送邮件的操作。\n\n我们先尝试一下发送一封极为简单的邮件，该邮件不包含附件、图片以及其他超文本内容。发送邮件首先需要接入邮件服务器，我们可以自己架设邮件服务器，这件事情对新手并不友好，但是我们可以选择使用第三方提供的邮件服务。例如，我在<www.126.com>已经注册了账号，登录成功之后，就可以在设置中开启 SMTP 服务，这样就相当于获得了邮件服务器，具体的操作如下所示。\n\n<img class=\"lazy\" data-src=\"/res/20210820190307.png\" alt=\"image-20210820190306861\" width=\"85%\">\n\n<img class=\"lazy\" data-src=\"/res/20210820190816.png\" style=\"zoom:55%;\">\n\n用手机扫码上面的二维码可以通过发送短信的方式来获取授权码，短信发送成功后，点击“我已发送”就可以获得授权码。授权码需要妥善保管，因为一旦泄露就会被其他人冒用你的身份来发送邮件。接下来，我们就可以编写发送邮件的代码了，如下所示。\n\n```python\nimport smtplib\nfrom email.header import Header\nfrom email.mime.multipart import MIMEMultipart\nfrom email.mime.text import MIMEText\n\n# 创建邮件主体对象\nemail = MIMEMultipart()\n# 设置发件人、收件人和主题\nemail['From'] = 'xxxxxxxxx@126.com'\nemail['To'] = 'yyyyyy@qq.com;zzzzzz@1000phone.com'\nemail['Subject'] = Header('上半年工作情况汇报', 'utf-8')\n# 添加邮件正文内容\ncontent = \"\"\"据德国媒体报道，当地时间9日，德国火车司机工会成员进行了投票，\n定于当地时间10日起进行全国性罢工，货运交通方面的罢工已于当地时间10日19时开始。\n此后，从11日凌晨2时到13日凌晨2时，德国全国范围内的客运和铁路基础设施将进行48小时的罢工。\"\"\"\nemail.attach(MIMEText(content, 'plain', 'utf-8'))\n\n# 创建SMTP_SSL对象（连接邮件服务器）\nsmtp_obj = smtplib.SMTP_SSL('smtp.126.com', 465)\n# 通过用户名和授权码进行登录\nsmtp_obj.login('xxxxxxxxx@126.com', '邮件服务器的授权码')\n# 发送邮件（发件人、收件人、邮件内容（字符串））\nsmtp_obj.sendmail(\n    'xxxxxxxxx@126.com',\n    ['yyyyyy@qq.com', 'zzzzzz@1000phone.com'],\n    email.as_string()\n)\n```\n\n如果要发送带有附件的邮件，只需要将附件的内容处理成 BASE64 编码，那么它就和普通的文本内容几乎没有什么区别。BASE64 是一种基于 64 个可打印字符来表示二进制数据的表示方法，常用于某些需要表示、传输、存储二进制数据的场合，电子邮件就是其中之一。对这种编码方式不理解的同学，推荐阅读[《Base64笔记》](http://www.ruanyifeng.com/blog/2008/06/base64.html)一文。在之前的内容中，我们也提到过，Python 标准库的`base64`模块提供了对 BASE64 编解码的支持。\n\n下面的代码演示了如何发送带附件的邮件。\n\n```python\nimport smtplib\nfrom email.header import Header\nfrom email.mime.multipart import MIMEMultipart\nfrom email.mime.text import MIMEText\nfrom urllib.parse import quote\n\n# 创建邮件主体对象\nemail = MIMEMultipart()\n# 设置发件人、收件人和主题\nemail['From'] = 'xxxxxxxxx@126.com'\nemail['To'] = 'zzzzzzzz@1000phone.com'\nemail['Subject'] = Header('请查收离职证明文件', 'utf-8')\n# 添加邮件正文内容（带HTML标签排版的内容）\ncontent = \"\"\"<p>亲爱的前同事：</p>\n<p>你需要的离职证明在附件中，请查收！</p>\n<br>\n<p>祝，好！</p>\n<hr>\n<p>孙美丽 即日</p>\"\"\"\nemail.attach(MIMEText(content, 'html', 'utf-8'))\n# 读取作为附件的文件\nwith open(f'resources/王大锤离职证明.docx', 'rb') as file:\n    attachment = MIMEText(file.read(), 'base64', 'utf-8')\n    # 指定内容类型\n    attachment['content-type'] = 'application/octet-stream'\n    # 将中文文件名处理成百分号编码\n    filename = quote('王大锤离职证明.docx')\n    # 指定如何处置内容\n    attachment['content-disposition'] = f'attachment; filename=\"{filename}\"'\n\n# 创建SMTP_SSL对象（连接邮件服务器）\nsmtp_obj = smtplib.SMTP_SSL('smtp.126.com', 465)\n# 通过用户名和授权码进行登录\nsmtp_obj.login('xxxxxxxxx@126.com', '邮件服务器的授权码')\n# 发送邮件（发件人、收件人、邮件内容（字符串））\nsmtp_obj.sendmail(\n    'xxxxxxxxx@126.com',\n    'zzzzzzzz@1000phone.com',\n    email.as_string()\n)\n```\n\n为了方便大家用 Python 实现邮件发送，我将上面的代码封装成了函数，使用的时候大家只需要调整邮件服务器域名、端口、用户名和授权码就可以了。\n\n```python\nimport smtplib\nfrom email.header import Header\nfrom email.mime.multipart import MIMEMultipart\nfrom email.mime.text import MIMEText\nfrom urllib.parse import quote\n\n# 邮件服务器域名（自行修改）\nEMAIL_HOST = 'smtp.126.com'\n# 邮件服务端口（通常是465）\nEMAIL_PORT = 465\n# 登录邮件服务器的账号（自行修改）\nEMAIL_USER = 'xxxxxxxxx@126.com'\n# 开通SMTP服务的授权码（自行修改）\nEMAIL_AUTH = '邮件服务器的授权码'\n\n\ndef send_email(*, from_user, to_users, subject='', content='', filenames=[]):\n    \"\"\"发送邮件\n    \n    :param from_user: 发件人\n    :param to_users: 收件人，多个收件人用英文分号进行分隔\n    :param subject: 邮件的主题\n    :param content: 邮件正文内容\n    :param filenames: 附件要发送的文件路径\n    \"\"\"\n    email = MIMEMultipart()\n    email['From'] = from_user\n    email['To'] = to_users\n    email['Subject'] = subject\n\n    message = MIMEText(content, 'plain', 'utf-8')\n    email.attach(message)\n    for filename in filenames:\n        with open(filename, 'rb') as file:\n            pos = filename.rfind('/')\n            display_filename = filename[pos + 1:] if pos >= 0 else filename\n            display_filename = quote(display_filename)\n            attachment = MIMEText(file.read(), 'base64', 'utf-8')\n            attachment['content-type'] = 'application/octet-stream'\n            attachment['content-disposition'] = f'attachment; filename=\"{display_filename}\"'\n            email.attach(attachment)\n\n    smtp = smtplib.SMTP_SSL(EMAIL_HOST, EMAIL_PORT)\n    smtp.login(EMAIL_USER, EMAIL_AUTH)\n    smtp.sendmail(from_user, to_users.split(';'), email.as_string())\n```\n\n### 发送短信\n\n发送短信也是项目中常见的功能，网站的注册码、验证码、营销信息基本上都是通过短信来发送给用户的。发送短信需要三方平台的支持，下面我们以[螺丝帽平台](https://luosimao.com/)为例，为大家介绍如何用 Python 程序发送短信。注册账号和购买短信服务的细节我们不在这里进行赘述，大家可以咨询平台的客服。\n\n<img class=\"lazy\" data-src=\"/res/20210820194421.png\" style=\"zoom:35%;\">\n\n接下来，我们可以通过`requests`库向平台提供的短信网关发起一个 HTTP 请求，通过将接收短信的手机号和短信内容作为参数，就可以发送短信，代码如下所示。\n\n```python\nimport random\n\nimport requests\n\n\ndef send_message_by_luosimao(tel, message):\n    \"\"\"发送短信（调用螺丝帽短信网关）\"\"\"\n    resp = requests.post(\n        url='http://sms-api.luosimao.com/v1/send.json',\n        auth=('api', 'key-注册成功后平台分配的KEY'),\n        data={\n            'mobile': tel,\n            'message': message\n        },\n        timeout=10,\n        verify=False\n    )\n    return resp.json()\n\n\ndef gen_mobile_code(length=6):\n    \"\"\"生成指定长度的手机验证码\"\"\"\n    return ''.join(random.choices('0123456789', k=length))\n\n\ndef main():\n    code = gen_mobile_code()\n    message = f'您的短信验证码是{code}，打死也不能告诉别人哟！【Python小课】'\n    print(send_message_by_luosimao('13500112233', message))\n\n\nif __name__ == '__main__':\n    main()\n```\n\n上面请求螺丝帽的短信网关`http://sms-api.luosimao.com/v1/send.json`会返回JSON格式的数据，如果返回`{'error': 0, 'msg': 'OK'}`就说明短信已经发送成功了，如果`error`的值不是`0`，可以通过查看官方的[开发文档](https://luosimao.com/docs/api/)了解到底哪个环节出了问题。螺丝帽平台常见的错误类型如下图所示。\n\n<img class=\"lazy\" data-src=\"/res/20210820195505.png\" style=\"zoom:50%;\">\n\n目前，大多数短信平台都会要求短信内容必须附上签名，下图是我在螺丝帽平台配置的短信签名“【Python小课】”。有些涉及到敏感内容的短信，还需要提前配置短信模板，有兴趣的读者可以自行研究。一般情况下，平台为了防范短信被盗用，还会要求设置“IP 白名单”，不清楚如何配置的可以咨询平台客服。\n\n<img class=\"lazy\" data-src=\"/res/20210820194653.png\" style=\"zoom:35%;\">\n\n当然国内的短信平台很多，读者可以根据自己的需要进行选择（通常会考虑费用预算、短信达到率、使用的难易程度等指标），如果需要在商业项目中使用短信服务建议购买短信平台提供的套餐服务。\n\n### 总结\n\n其实，发送邮件和发送短信一样，也可以通过调用三方服务来完成，在实际的商业项目中，建议自己架设邮件服务器或购买三方服务来发送邮件，这个才是比较靠谱的选择。\n", "正则表达式的应用": "## 正则表达式的应用\n\n### 正则表达式相关知识\n\n在编写处理字符串的程时，经常会遇到在一段文本中查找符合某些规则的字符串的需求，正则表达式就是用于描述这些规则的工具，换句话说，我们可以使用正则表达式来定义字符串的匹配模式，即如何检查一个字符串是否有跟某种模式匹配的部分或者从一个字符串中将与模式匹配的部分提取出来或者替换掉。\n\n举一个简单的例子，如果你在 Windows 操作系统中使用过文件查找并且在指定文件名时使用过通配符（`*`和`?`），那么正则表达式也是与之类似的用 来进行文本匹配的工具，只不过比起通配符正则表达式更强大，它能更精确地描述你的需求，当然你付出的代价是书写一个正则表达式比使用通配符要复杂得多，因为任何给你带来好处的东西都需要你付出对应的代价。\n\n再举一个例子，我们从某个地方（可能是一个文本文件，也可能是网络上的一则新闻）获得了一个字符串，希望在字符串中找出手机号和座机号。当然我们可以设定手机号是 11 位的数字（注意并不是随机的 11 位数字，因为你没有见过“25012345678”这样的手机号），而座机号则是类似于“区号-号码”这样的模式，如果不使用正则表达式要完成这个任务就会比较麻烦。最初计算机是为了做数学运算而诞生的，处理的信息基本上都是数值，而今天我们在日常工作中处理的信息很多都是文本数据，我们希望计算机能够识别和处理符合某些模式的文本，正则表达式就显得非常重要了。今天几乎所有的编程语言都提供了对正则表达式操作的支持，Python 通过标准库中的`re`模块来支持正则表达式操作。\n\n关于正则表达式的相关知识，大家可以阅读一篇非常有名的博文叫[《正则表达式30分钟入门教程》](https://deerchao.net/tutorials/regex/regex.htm)，读完这篇文章后你就可以看懂下面的表格，这是我们对正则表达式中的一些基本符号进行的扼要总结。\n\n| 符号           | 解释                             | 示例               | 说明                                                         |\n| -------------- | -------------------------------- | ------------------ | ------------------------------------------------------------ |\n| `.`            | 匹配任意字符                     | `b.t`              | 可以匹配bat / but / b#t / b1t等                              |\n| `\\w`           | 匹配字母/数字/下划线             | `b\\wt`             | 可以匹配bat / b1t / b_t等<br>但不能匹配b#t                   |\n| `\\s`           | 匹配空白字符（包括\\r、\\n、\\t等） | `love\\syou`        | 可以匹配love you                                             |\n| `\\d`           | 匹配数字                         | `\\d\\d`             | 可以匹配01 / 23 / 99等                                       |\n| `\\b`           | 匹配单词的边界                   | `\\bThe\\b`          |                                                              |\n| `^`            | 匹配字符串的开始                 | `^The`             | 可以匹配The开头的字符串                                      |\n| `$`            | 匹配字符串的结束                 | `.exe$`            | 可以匹配.exe结尾的字符串                                     |\n| `\\W`           | 匹配非字母/数字/下划线           | `b\\Wt`             | 可以匹配b#t / b@t等<br>但不能匹配but / b1t / b_t等           |\n| `\\S`           | 匹配非空白字符                   | `love\\Syou`        | 可以匹配love#you等<br>但不能匹配love you                     |\n| `\\D`           | 匹配非数字                       | `\\d\\D`             | 可以匹配9a / 3# / 0F等                                       |\n| `\\B`           | 匹配非单词边界                   | `\\Bio\\B`           |                                                              |\n| `[]`           | 匹配来自字符集的任意单一字符     | `[aeiou]`          | 可以匹配任一元音字母字符                                     |\n| `[^]`          | 匹配不在字符集中的任意单一字符   | `[^aeiou]`         | 可以匹配任一非元音字母字符                                   |\n| `*`            | 匹配0次或多次                    | `\\w*`              |                                                              |\n| `+`            | 匹配1次或多次                    | `\\w+`              |                                                              |\n| `?`            | 匹配0次或1次                     | `\\w?`              |                                                              |\n| `{N}`          | 匹配N次                          | `\\w{3}`            |                                                              |\n| `{M,}`         | 匹配至少M次                      | `\\w{3,}`           |                                                              |\n| `{M,N}`        | 匹配至少M次至多N次               | `\\w{3,6}`          |                                                              |\n| `\\|`            | 分支                             | `foo\\|bar`          | 可以匹配foo或者bar                                           |\n| `(?#)`         | 注释                             |                    |                                                              |\n| `(exp)`        | 匹配exp并捕获到自动命名的组中    |                    |                                                              |\n| `(?<name>exp)` | 匹配exp并捕获到名为name的组中    |                    |                                                              |\n| `(?:exp)`      | 匹配exp但是不捕获匹配的文本      |                    |                                                              |\n| `(?=exp)`      | 匹配exp前面的位置                | `\\b\\w+(?=ing)`     | 可以匹配I'm dancing中的danc                                  |\n| `(?<=exp)`     | 匹配exp后面的位置                | `(?<=\\bdanc)\\w+\\b` | 可以匹配I love dancing and reading中的第一个ing              |\n| `(?!exp)`      | 匹配后面不是exp的位置            |                    |                                                              |\n| `(?<!exp)`     | 匹配前面不是exp的位置            |                    |                                                              |\n| `*?`           | 重复任意次，但尽可能少重复       | `a.*b`<br>`a.*?b`  | 将正则表达式应用于aabab，前者会匹配整个字符串aabab，后者会匹配aab和ab两个字符串 |\n| `+?`           | 重复1次或多次，但尽可能少重复    |                    |                                                              |\n| `??`           | 重复0次或1次，但尽可能少重复     |                    |                                                              |\n| `{M,N}?`       | 重复M到N次，但尽可能少重复       |                    |                                                              |\n| `{M,}?`        | 重复M次以上，但尽可能少重复      |                    |                                                              |\n\n> **说明：** 如果需要匹配的字符是正则表达式中的特殊字符，那么可以使用`\\`进行转义处理，例如想匹配小数点可以写成`\\.`就可以了，因为直接写`.`会匹配任意字符；同理，想匹配圆括号必须写成`\\(`和`\\)`，否则圆括号被视为正则表达式中的分组。\n\n### Python对正则表达式的支持\n\nPython 提供了`re`模块来支持正则表达式相关操作，下面是`re`模块中的核心函数。\n\n| 函数                                           | 说明                                                         |\n| ---------------------------------------------- | ------------------------------------------------------------ |\n| `compile(pattern, flags=0)`                    | 编译正则表达式返回正则表达式对象                             |\n| `match(pattern, string, flags=0)`              | 用正则表达式匹配字符串 成功返回匹配对象 否则返回`None`       |\n| `search(pattern, string, flags=0)`             | 搜索字符串中第一次出现正则表达式的模式 成功返回匹配对象 否则返回`None` |\n| `split(pattern, string, maxsplit=0, flags=0)`  | 用正则表达式指定的模式分隔符拆分字符串 返回列表              |\n| `sub(pattern, repl, string, count=0, flags=0)` | 用指定的字符串替换原字符串中与正则表达式匹配的模式 可以用`count`指定替换的次数 |\n| `fullmatch(pattern, string, flags=0)`          | `match`函数的完全匹配（从字符串开头到结尾）版本              |\n| `findall(pattern, string, flags=0)`            | 查找字符串所有与正则表达式匹配的模式 返回字符串的列表        |\n| `finditer(pattern, string, flags=0)`           | 查找字符串所有与正则表达式匹配的模式 返回一个迭代器          |\n| `purge()`                                      | 清除隐式编译的正则表达式的缓存                               |\n| `re.I` / `re.IGNORECASE`                       | 忽略大小写匹配标记                                           |\n| `re.M` / `re.MULTILINE`                        | 多行匹配标记                                                 |\n\n> **说明：** 上面提到的`re`模块中的这些函数，实际开发中也可以用正则表达式对象（`Pattern`对象）的方法替代对这些函数的使用，如果一个正则表达式需要重复的使用，那么先通过`compile`函数编译正则表达式并创建出正则表达式对象无疑是更为明智的选择。\n\n下面我们通过一系列的例子来告诉大家在Python中如何使用正则表达式。\n\n#### 例子1：验证输入用户名和QQ号是否有效并给出对应的提示信息。\n\n```python\n\"\"\"\n要求：用户名必须由字母、数字或下划线构成且长度在6~20个字符之间，QQ号是5~12的数字且首位不能为0\n\"\"\"\nimport re\n\nusername = input('请输入用户名: ')\nqq = input('请输入QQ号: ')\n# match函数的第一个参数是正则表达式字符串或正则表达式对象\n# match函数的第二个参数是要跟正则表达式做匹配的字符串对象\nm1 = re.match(r'^[0-9a-zA-Z_]{6,20}$', username)\nif not m1:\n    print('请输入有效的用户名.')\n# fullmatch函数要求字符串和正则表达式完全匹配\n# 所以正则表达式没有写起始符和结束符\nm2 = re.fullmatch(r'[1-9]\\d{4,11}', qq)\nif not m2:\n    print('请输入有效的QQ号.')\nif m1 and m2:\n    print('你输入的信息是有效的!')\n```\n\n> **提示：** 上面在书写正则表达式时使用了“原始字符串”的写法（在字符串前面加上了`r`），所谓“原始字符串”就是字符串中的每个字符都是它原始的意义，说得更直接一点就是字符串中没有所谓的转义字符啦。因为正则表达式中有很多元字符和需要进行转义的地方，如果不使用原始字符串就需要将反斜杠写作`\\\\`，例如表示数字的`\\d`得书写成`\\\\d`，这样不仅写起来不方便，阅读的时候也会很吃力。\n\n#### 例子2：从一段文字中提取出国内手机号码。\n\n下面这张图是截止到 2017 年底，国内三家运营商推出的手机号段。\n\n<img class=\"lazy\" data-src=\"/res/20210803203134.png\" style=\"zoom:100%;\">\n\n```python\nimport re\n\n# 创建正则表达式对象，使用了前瞻和回顾来保证手机号前后不应该再出现数字\npattern = re.compile(r'(?<=\\D)1[34578]\\d{9}(?=\\D)')\nsentence = '''重要的事情说8130123456789遍，我的手机号是13512346789这个靓号，\n不是15600998765，也不是110或119，王大锤的手机号才是15600998765。'''\n# 方法一：查找所有匹配并保存到一个列表中\ntels_list = re.findall(pattern, sentence)\nfor tel in tels_list:\n    print(tel)\nprint('--------华丽的分隔线--------')\n\n# 方法二：通过迭代器取出匹配对象并获得匹配的内容\nfor temp in pattern.finditer(sentence):\n    print(temp.group())\nprint('--------华丽的分隔线--------')\n\n# 方法三：通过search函数指定搜索位置找出所有匹配\nm = pattern.search(sentence)\nwhile m:\n    print(m.group())\n    m = pattern.search(sentence, m.end())\n```\n\n> **说明：** 上面匹配国内手机号的正则表达式并不够好，因为像 14 开头的号码只有 145 或 147，而上面的正则表达式并没有考虑这种情况，要匹配国内手机号，更好的正则表达式的写法是：`(?<=\\D)(1[38]\\d{9}|14[57]\\d{8}|15[0-35-9]\\d{8}|17[678]\\d{8})(?=\\D)`，国内好像已经有 19 和 16 开头的手机号了，但是这个暂时不在我们考虑之列。\n\n#### 例子3：替换字符串中的不良内容\n\n```python\nimport re\n\nsentence = 'Oh, shit! 你是傻逼吗? Fuck you.'\npurified = re.sub('fuck|shit|[傻煞沙][比笔逼叉缺吊碉雕]',\n                  '*', sentence, flags=re.IGNORECASE)\nprint(purified)  # Oh, *! 你是*吗? * you.\n```\n\n> **说明：**` re`模块的正则表达式相关函数中都有一个`flags`参数，它代表了正则表达式的匹配标记，可以通过该标记来指定匹配时是否忽略大小写、是否进行多行匹配、是否显示调试信息等。如果需要为`flags`参数指定多个值，可以使用[按位或运算符](http://www.runoob.com/python/python-operators.html#ysf5)进行叠加，如`flags=re.I | re.M`。\n\n#### 例子4：拆分长字符串\n\n```python\nimport re\n\npoem = '窗前明月光，疑是地上霜。举头望明月，低头思故乡。'\nsentences_list = re.split(r'[，。]', poem)\nsentences_list = [sentence for sentence in sentences_list if sentence]\nfor sentence in sentences_list:\n    print(sentence)\n```\n\n###  总结\n\n正则表达式在字符串的处理和匹配上真的非常强大，通过上面的例子相信大家已经感受到了正则表达式的魅力，当然写一个正则表达式对新手来说并不是那么容易，但是很多事情都是熟能生巧，大胆的去尝试就行了，有一个在线的[正则表达式测试工具](https://c.runoob.com/front-end/854)相信能够在一定程度上帮到大家。\n", "语言进阶": "## Python语言进阶\n\n### 重要知识点\n\n- 生成式（推导式）的用法\n\n  ```Python\n  prices = {\n      'AAPL': 191.88,\n      'GOOG': 1186.96,\n      'IBM': 149.24,\n      'ORCL': 48.44,\n      'ACN': 166.89,\n      'FB': 208.09,\n      'SYMC': 21.29\n  }\n  # 用股票价格大于100元的股票构造一个新的字典\n  prices2 = {key: value for key, value in prices.items() if value > 100}\n  print(prices2)\n  ```\n\n  > 说明：生成式（推导式）可以用来生成列表、集合和字典。\n\n- 嵌套的列表的坑\n\n  ```Python\n  names = ['关羽', '张飞', '赵云', '马超', '黄忠']\n  courses = ['语文', '数学', '英语']\n  # 录入五个学生三门课程的成绩\n  # 错误 - 参考http://pythontutor.com/visualize.html#mode=edit\n  # scores = [[None] * len(courses)] * len(names)\n  scores = [[None] * len(courses) for _ in range(len(names))]\n  for row, name in enumerate(names):\n      for col, course in enumerate(courses):\n          scores[row][col] = float(input(f'请输入{name}的{course}成绩: '))\n          print(scores)\n  ```\n\n  [Python Tutor](http://pythontutor.com/) - VISUALIZE CODE AND GET LIVE HELP\n\n- `heapq`模块（堆排序）\n\n  ```Python\n  \"\"\"\n  从列表中找出最大的或最小的N个元素\n  堆结构(大根堆/小根堆)\n  \"\"\"\n  import heapq\n  \n  list1 = [34, 25, 12, 99, 87, 63, 58, 78, 88, 92]\n  list2 = [\n      {'name': 'IBM', 'shares': 100, 'price': 91.1},\n      {'name': 'AAPL', 'shares': 50, 'price': 543.22},\n      {'name': 'FB', 'shares': 200, 'price': 21.09},\n      {'name': 'HPQ', 'shares': 35, 'price': 31.75},\n      {'name': 'YHOO', 'shares': 45, 'price': 16.35},\n      {'name': 'ACME', 'shares': 75, 'price': 115.65}\n  ]\n  print(heapq.nlargest(3, list1))\n  print(heapq.nsmallest(3, list1))\n  print(heapq.nlargest(2, list2, key=lambda x: x['price']))\n  print(heapq.nlargest(2, list2, key=lambda x: x['shares']))\n  ```\n\n- `itertools`模块\n\n  ```Python\n  \"\"\"\n  迭代工具模块\n  \"\"\"\n  import itertools\n  \n  # 产生ABCD的全排列\n  itertools.permutations('ABCD')\n  # 产生ABCDE的五选三组合\n  itertools.combinations('ABCDE', 3)\n  # 产生ABCD和123的笛卡尔积\n  itertools.product('ABCD', '123')\n  # 产生ABC的无限循环序列\n  itertools.cycle(('A', 'B', 'C'))\n  ```\n\n- `collections`模块\n\n  常用的工具类：\n\n  - `namedtuple`：命令元组，它是一个类工厂，接受类型的名称和属性列表来创建一个类。\n  - `deque`：双端队列，是列表的替代实现。Python中的列表底层是基于数组来实现的，而deque底层是双向链表，因此当你需要在头尾添加和删除元素时，deque会表现出更好的性能，渐近时间复杂度为$O(1)$。\n  - `Counter`：`dict`的子类，键是元素，值是元素的计数，它的`most_common()`方法可以帮助我们获取出现频率最高的元素。`Counter`和`dict`的继承关系我认为是值得商榷的，按照CARP原则，`Counter`跟`dict`的关系应该设计为关联关系更为合理。\n  - `OrderedDict`：`dict`的子类，它记录了键值对插入的顺序，看起来既有字典的行为，也有链表的行为。\n  - `defaultdict`：类似于字典类型，但是可以通过默认的工厂函数来获得键对应的默认值，相比字典中的`setdefault()`方法，这种做法更加高效。\n\n  ```Python\n  \"\"\"\n  找出序列中出现次数最多的元素\n  \"\"\"\n  from collections import Counter\n  \n  words = [\n      'look', 'into', 'my', 'eyes', 'look', 'into', 'my', 'eyes',\n      'the', 'eyes', 'the', 'eyes', 'the', 'eyes', 'not', 'around',\n      'the', 'eyes', \"don't\", 'look', 'around', 'the', 'eyes',\n      'look', 'into', 'my', 'eyes', \"you're\", 'under'\n  ]\n  counter = Counter(words)\n  print(counter.most_common(3))\n  ```\n\n### 数据结构和算法\n\n- 算法：解决问题的方法和步骤\n\n- 评价算法的好坏：渐近时间复杂度和渐近空间复杂度。\n\n- 渐近时间复杂度的大O标记：\n  - <img src=\"http://latex.codecogs.com/gif.latex?O(c)\" /> - 常量时间复杂度 - 布隆过滤器 / 哈希存储\n  - <img src=\"http://latex.codecogs.com/gif.latex?O(log_2n)\" /> - 对数时间复杂度 - 折半查找（二分查找）\n  - <img src=\"http://latex.codecogs.com/gif.latex?O(n)\" /> - 线性时间复杂度 - 顺序查找 / 计数排序\n  - <img src=\"http://latex.codecogs.com/gif.latex?O(n*log_2n)\" /> - 对数线性时间复杂度 - 高级排序算法（归并排序、快速排序）\n  - <img src=\"http://latex.codecogs.com/gif.latex?O(n^2)\" /> - 平方时间复杂度 - 简单排序算法（选择排序、插入排序、冒泡排序）\n  - <img src=\"http://latex.codecogs.com/gif.latex?O(n^3)\" /> - 立方时间复杂度 - Floyd算法 / 矩阵乘法运算\n  - <img src=\"http://latex.codecogs.com/gif.latex?O(2^n)\" /> - 几何级数时间复杂度 - 汉诺塔\n  - <img src=\"http://latex.codecogs.com/gif.latex?O(n!)\" /> - 阶乘时间复杂度 - 旅行经销商问题 - NPC\n\n  ![](./res/algorithm_complexity_1.png)\n\n  ![](./res/algorithm_complexity_2.png)\n\n- 排序算法（选择、冒泡和归并）和查找算法（顺序和折半）\n\n  ```Python\n  def select_sort(items, comp=lambda x, y: x < y):\n      \"\"\"简单选择排序\"\"\"\n      items = items[:]\n      for i in range(len(items) - 1):\n          min_index = i\n          for j in range(i + 1, len(items)):\n              if comp(items[j], items[min_index]):\n                  min_index = j\n          items[i], items[min_index] = items[min_index], items[i]\n      return items\n  ```\n\n  ```Python\n  def bubble_sort(items, comp=lambda x, y: x > y):\n      \"\"\"冒泡排序\"\"\"\n      items = items[:]\n      for i in range(len(items) - 1):\n          swapped = False\n          for j in range(len(items) - 1 - i):\n              if comp(items[j], items[j + 1]):\n                  items[j], items[j + 1] = items[j + 1], items[j]\n                  swapped = True\n          if not swapped:\n              break\n      return items\n  ```\n\n  ```Python\n  def bubble_sort(items, comp=lambda x, y: x > y):\n      \"\"\"搅拌排序(冒泡排序升级版)\"\"\"\n      items = items[:]\n      for i in range(len(items) - 1):\n          swapped = False\n          for j in range(len(items) - 1 - i):\n              if comp(items[j], items[j + 1]):\n                  items[j], items[j + 1] = items[j + 1], items[j]\n                  swapped = True\n          if swapped:\n              swapped = False\n              for j in range(len(items) - 2 - i, i, -1):\n                  if comp(items[j - 1], items[j]):\n                      items[j], items[j - 1] = items[j - 1], items[j]\n                      swapped = True\n          if not swapped:\n              break\n      return items\n  ```\n\n  ```Python\n  def merge(items1, items2, comp=lambda x, y: x < y):\n      \"\"\"合并(将两个有序的列表合并成一个有序的列表)\"\"\"\n      items = []\n      index1, index2 = 0, 0\n      while index1 < len(items1) and index2 < len(items2):\n          if comp(items1[index1], items2[index2]):\n              items.append(items1[index1])\n              index1 += 1\n          else:\n              items.append(items2[index2])\n              index2 += 1\n      items += items1[index1:]\n      items += items2[index2:]\n      return items\n  \n  \n  def merge_sort(items, comp=lambda x, y: x < y):\n      return _merge_sort(list(items), comp)\n  \n  \n  def _merge_sort(items, comp):\n      \"\"\"归并排序\"\"\"\n      if len(items) < 2:\n          return items\n      mid = len(items) // 2\n      left = _merge_sort(items[:mid], comp)\n      right = _merge_sort(items[mid:], comp)\n      return merge(left, right, comp)\n  ```\n\n  ```Python\n  def seq_search(items, key):\n      \"\"\"顺序查找\"\"\"\n      for index, item in enumerate(items):\n          if item == key:\n              return index\n      return -1\n  ```\n\n  ```Python\n  def bin_search(items, key):\n      \"\"\"折半查找\"\"\"\n      start, end = 0, len(items) - 1\n      while start <= end:\n          mid = (start + end) // 2\n          if key > items[mid]:\n              start = mid + 1\n          elif key < items[mid]:\n              end = mid - 1\n          else:\n              return mid\n      return -1\n  ```\n\n- 常用算法：\n\n  - 穷举法 - 又称为暴力破解法，对所有的可能性进行验证，直到找到正确答案。\n  - 贪婪法 - 在对问题求解时，总是做出在当前看来\n  - 最好的选择，不追求最优解，快速找到满意解。\n  - 分治法 - 把一个复杂的问题分成两个或更多的相同或相似的子问题，再把子问题分成更小的子问题，直到可以直接求解的程度，最后将子问题的解进行合并得到原问题的解。\n  - 回溯法 - 回溯法又称为试探法，按选优条件向前搜索，当搜索到某一步发现原先选择并不优或达不到目标时，就退回一步重新选择。\n  - 动态规划 - 基本思想也是将待求解问题分解成若干个子问题，先求解并保存这些子问题的解，避免产生大量的重复运算。\n\n  穷举法例子：百钱百鸡和五人分鱼。\n\n  ```Python\n  # 公鸡5元一只 母鸡3元一只 小鸡1元三只\n  # 用100元买100只鸡 问公鸡/母鸡/小鸡各多少只\n  for x in range(20):\n      for y in range(33):\n          z = 100 - x - y\n          if 5 * x + 3 * y + z // 3 == 100 and z % 3 == 0:\n              print(x, y, z)\n  \n  # A、B、C、D、E五人在某天夜里合伙捕鱼 最后疲惫不堪各自睡觉\n  # 第二天A第一个醒来 他将鱼分为5份 扔掉多余的1条 拿走自己的一份\n  # B第二个醒来 也将鱼分为5份 扔掉多余的1条 拿走自己的一份\n  # 然后C、D、E依次醒来也按同样的方式分鱼 问他们至少捕了多少条鱼\n  fish = 6\n  while True:\n      total = fish\n      enough = True\n      for _ in range(5):\n          if (total - 1) % 5 == 0:\n              total = (total - 1) // 5 * 4\n          else:\n              enough = False\n              break\n      if enough:\n          print(fish)\n          break\n      fish += 5\n  ```\n\n  贪婪法例子：假设小偷有一个背包，最多能装20公斤赃物，他闯入一户人家，发现如下表所示的物品。很显然，他不能把所有物品都装进背包，所以必须确定拿走哪些物品，留下哪些物品。\n\n  |  名称  | 价格（美元） | 重量（kg） |\n  | :----: | :----------: | :--------: |\n  |  电脑  |     200      |     20     |\n  | 收音机 |      20      |     4      |\n  |   钟   |     175      |     10     |\n  |  花瓶  |      50      |     2      |\n  |   书   |      10      |     1      |\n  |  油画  |      90      |     9      |\n\n  ```Python\n  \"\"\"\n  贪婪法：在对问题求解时，总是做出在当前看来是最好的选择，不追求最优解，快速找到满意解。\n  输入：\n  20 6\n  电脑 200 20\n  收音机 20 4\n  钟 175 10\n  花瓶 50 2\n  书 10 1\n  油画 90 9\n  \"\"\"\n  class Thing(object):\n      \"\"\"物品\"\"\"\n  \n      def __init__(self, name, price, weight):\n          self.name = name\n          self.price = price\n          self.weight = weight\n  \n      @property\n      def value(self):\n          \"\"\"价格重量比\"\"\"\n          return self.price / self.weight\n  \n  \n  def input_thing():\n      \"\"\"输入物品信息\"\"\"\n      name_str, price_str, weight_str = input().split()\n      return name_str, int(price_str), int(weight_str)\n  \n  \n  def main():\n      \"\"\"主函数\"\"\"\n      max_weight, num_of_things = map(int, input().split())\n      all_things = []\n      for _ in range(num_of_things):\n          all_things.append(Thing(*input_thing()))\n      all_things.sort(key=lambda x: x.value, reverse=True)\n      total_weight = 0\n      total_price = 0\n      for thing in all_things:\n          if total_weight + thing.weight <= max_weight:\n              print(f'小偷拿走了{thing.name}')\n              total_weight += thing.weight\n              total_price += thing.price\n      print(f'总价值: {total_price}美元')\n  \n  \n  if __name__ == '__main__':\n      main()\n  ```\n\n  分治法例子：[快速排序](https://zh.wikipedia.org/zh/%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F)。\n\n  ```Python\n  \"\"\"\n  快速排序 - 选择枢轴对元素进行划分，左边都比枢轴小右边都比枢轴大\n  \"\"\"\n  def quick_sort(items, comp=lambda x, y: x <= y):\n      items = list(items)[:]\n      _quick_sort(items, 0, len(items) - 1, comp)\n      return items\n  \n  \n  def _quick_sort(items, start, end, comp):\n      if start < end:\n          pos = _partition(items, start, end, comp)\n          _quick_sort(items, start, pos - 1, comp)\n          _quick_sort(items, pos + 1, end, comp)\n  \n  \n  def _partition(items, start, end, comp):\n      pivot = items[end]\n      i = start - 1\n      for j in range(start, end):\n          if comp(items[j], pivot):\n              i += 1\n              items[i], items[j] = items[j], items[i]\n      items[i + 1], items[end] = items[end], items[i + 1]\n      return i + 1\n  ```\n\n  回溯法例子：[骑士巡逻](https://zh.wikipedia.org/zh/%E9%AA%91%E5%A3%AB%E5%B7%A1%E9%80%BB)。\n\n  ```Python\n  \"\"\"\n  递归回溯法：叫称为试探法，按选优条件向前搜索，当搜索到某一步，发现原先选择并不优或达不到目标时，就退回一步重新选择，比较经典的问题包括骑士巡逻、八皇后和迷宫寻路等。\n  \"\"\"\n  import sys\n  import time\n  \n  SIZE = 5\n  total = 0\n  \n  \n  def print_board(board):\n      for row in board:\n          for col in row:\n              print(str(col).center(4), end='')\n          print()\n  \n  \n  def patrol(board, row, col, step=1):\n      if row >= 0 and row < SIZE and \\\n          col >= 0 and col < SIZE and \\\n          board[row][col] == 0:\n          board[row][col] = step\n          if step == SIZE * SIZE:\n              global total\n              total += 1\n              print(f'第{total}种走法: ')\n              print_board(board)\n          patrol(board, row - 2, col - 1, step + 1)\n          patrol(board, row - 1, col - 2, step + 1)\n          patrol(board, row + 1, col - 2, step + 1)\n          patrol(board, row + 2, col - 1, step + 1)\n          patrol(board, row + 2, col + 1, step + 1)\n          patrol(board, row + 1, col + 2, step + 1)\n          patrol(board, row - 1, col + 2, step + 1)\n          patrol(board, row - 2, col + 1, step + 1)\n          board[row][col] = 0\n  \n  \n  def main():\n      board = [[0] * SIZE for _ in range(SIZE)]\n      patrol(board, SIZE - 1, SIZE - 1)\n  \n  \n  if __name__ == '__main__':\n      main()\n  ```\n\n  动态规划例子：子列表元素之和的最大值。\n\n  > 说明：子列表指的是列表中索引（下标）连续的元素构成的列表；列表中的元素是int类型，可能包含正整数、0、负整数；程序输入列表中的元素，输出子列表元素求和的最大值，例如：\n  >\n  > 输入：1 -2 3 5 -3 2\n  >\n  > 输出：8\n  >\n  > 输入：0 -2 3 5 -1 2\n  >\n  > 输出：9\n  >\n  > 输入：-9 -2 -3 -5 -3\n  >\n  > 输出：-2\n\n  ```Python\n  def main():\n      items = list(map(int, input().split()))\n      overall = partial = items[0]\n      for i in range(1, len(items)):\n          partial = max(items[i], partial + items[i])\n          overall = max(partial, overall)\n      print(overall)\n  \n  \n  if __name__ == '__main__':\n      main()\n  ```\n\n  > **说明**：这个题目最容易想到的解法是使用二重循环，但是代码的时间性能将会变得非常的糟糕。使用动态规划的思想，仅仅是多用了两个变量，就将原来$O(N^2)$复杂度的问题变成了$O(N)$。\n\n### 函数的使用方式\n\n- 将函数视为“一等公民”\n\n  - 函数可以赋值给变量\n  - 函数可以作为函数的参数\n  - 函数可以作为函数的返回值\n\n- 高阶函数的用法（`filter`、`map`以及它们的替代品）\n\n  ```Python\n  items1 = list(map(lambda x: x ** 2, filter(lambda x: x % 2, range(1, 10))))\n  items2 = [x ** 2 for x in range(1, 10) if x % 2]\n  ```\n\n- 位置参数、可变参数、关键字参数、命名关键字参数\n\n- 参数的元信息（代码可读性问题）\n\n- 匿名函数和内联函数的用法（`lambda`函数）\n\n- 闭包和作用域问题\n\n  - Python搜索变量的LEGB顺序（Local >>> Embedded >>> Global >>> Built-in）\n\n  - `global`和`nonlocal`关键字的作用\n\n    `global`：声明或定义全局变量（要么直接使用现有的全局作用域的变量，要么定义一个变量放到全局作用域）。\n\n    `nonlocal`：声明使用嵌套作用域的变量（嵌套作用域必须存在该变量，否则报错）。\n\n- 装饰器函数（使用装饰器和取消装饰器）\n\n  例子：输出函数执行时间的装饰器。\n\n  ```Python\n  def record_time(func):\n      \"\"\"自定义装饰函数的装饰器\"\"\"\n      \n      @wraps(func)\n      def wrapper(*args, **kwargs):\n          start = time()\n          result = func(*args, **kwargs)\n          print(f'{func.__name__}: {time() - start}秒')\n          return result\n          \n      return wrapper\n  ```\n\n  如果装饰器不希望跟`print`函数耦合，可以编写可以参数化的装饰器。\n\n  ```Python\n  from functools import wraps\n  from time import time\n  \n  \n  def record(output):\n      \"\"\"可以参数化的装饰器\"\"\"\n  \t\n  \tdef decorate(func):\n  \t\t\n  \t\t@wraps(func)\n  \t\tdef wrapper(*args, **kwargs):\n  \t\t\tstart = time()\n  \t\t\tresult = func(*args, **kwargs)\n  \t\t\toutput(func.__name__, time() - start)\n  \t\t\treturn result\n              \n  \t\treturn wrapper\n  \t\n  \treturn decorate\n  ```\n\n  ```Python\n  from functools import wraps\n  from time import time\n  \n  \n  class Record():\n      \"\"\"通过定义类的方式定义装饰器\"\"\"\n  \n      def __init__(self, output):\n          self.output = output\n  \n      def __call__(self, func):\n  \n          @wraps(func)\n          def wrapper(*args, **kwargs):\n              start = time()\n              result = func(*args, **kwargs)\n              self.output(func.__name__, time() - start)\n              return result\n  \n          return wrapper\n  ```\n\n  > **说明**：由于对带装饰功能的函数添加了@wraps装饰器，可以通过`func.__wrapped__`方式获得被装饰之前的函数或类来取消装饰器的作用。\n\n  例子：用装饰器来实现单例模式。\n\n  ```Python\n  from functools import wraps\n  \n  \n  def singleton(cls):\n      \"\"\"装饰类的装饰器\"\"\"\n      instances = {}\n  \n      @wraps(cls)\n      def wrapper(*args, **kwargs):\n          if cls not in instances:\n              instances[cls] = cls(*args, **kwargs)\n          return instances[cls]\n  \n      return wrapper\n  \n  \n  @singleton\n  class President:\n      \"\"\"总统(单例类)\"\"\"\n      pass\n  ```\n\n  > **提示**：上面的代码中用到了闭包（closure），不知道你是否已经意识到了。还没有一个小问题就是，上面的代码并没有实现线程安全的单例，如果要实现线程安全的单例应该怎么做呢？\n\n  线程安全的单例装饰器。\n\n  ```Python\n  from functools import wraps\n  from threading import RLock\n  \n  \n  def singleton(cls):\n      \"\"\"线程安全的单例装饰器\"\"\"\n      instances = {}\n      locker = RLock()\n  \n      @wraps(cls)\n      def wrapper(*args, **kwargs):\n          if cls not in instances:\n              with locker:\n                  if cls not in instances:\n                      instances[cls] = cls(*args, **kwargs)\n          return instances[cls]\n  \n      return wrapper\n  ```\n\n  > **提示**：上面的代码用到了`with`上下文语法来进行锁操作，因为锁对象本身就是上下文管理器对象（支持`__enter__`和`__exit__`魔术方法）。在`wrapper`函数中，我们先做了一次不带锁的检查，然后再做带锁的检查，这样做比直接加锁检查性能要更好，如果对象已经创建就没有必须再去加锁而是直接返回该对象就可以了。\n\n### 面向对象相关知识\n\n- 三大支柱：封装、继承、多态\n\n  例子：工资结算系统。\n\n  ```Python\n  \"\"\"\n  月薪结算系统 - 部门经理每月15000 程序员每小时200 销售员1800底薪加销售额5%提成\n  \"\"\"\n  from abc import ABCMeta, abstractmethod\n  \n  \n  class Employee(metaclass=ABCMeta):\n      \"\"\"员工(抽象类)\"\"\"\n  \n      def __init__(self, name):\n          self.name = name\n  \n      @abstractmethod\n      def get_salary(self):\n          \"\"\"结算月薪(抽象方法)\"\"\"\n          pass\n  \n  \n  class Manager(Employee):\n      \"\"\"部门经理\"\"\"\n  \n      def get_salary(self):\n          return 15000.0\n  \n  \n  class Programmer(Employee):\n      \"\"\"程序员\"\"\"\n  \n      def __init__(self, name, working_hour=0):\n          self.working_hour = working_hour\n          super().__init__(name)\n  \n      def get_salary(self):\n          return 200.0 * self.working_hour\n  \n  \n  class Salesman(Employee):\n      \"\"\"销售员\"\"\"\n  \n      def __init__(self, name, sales=0.0):\n          self.sales = sales\n          super().__init__(name)\n  \n      def get_salary(self):\n          return 1800.0 + self.sales * 0.05\n  \n  \n  class EmployeeFactory:\n      \"\"\"创建员工的工厂（工厂模式 - 通过工厂实现对象使用者和对象之间的解耦合）\"\"\"\n  \n      @staticmethod\n      def create(emp_type, *args, **kwargs):\n          \"\"\"创建员工\"\"\"\n          all_emp_types = {'M': Manager, 'P': Programmer, 'S': Salesman}\n          cls = all_emp_types[emp_type.upper()]\n          return cls(*args, **kwargs) if cls else None\n  \n  \n  def main():\n      \"\"\"主函数\"\"\"\n      emps = [\n          EmployeeFactory.create('M', '曹操'), \n          EmployeeFactory.create('P', '荀彧', 120),\n          EmployeeFactory.create('P', '郭嘉', 85), \n          EmployeeFactory.create('S', '典韦', 123000),\n      ]\n      for emp in emps:\n          print(f'{emp.name}: {emp.get_salary():.2f}元')\n  \n  \n  if __name__ == '__main__':\n      main()\n  ```\n\n- 类与类之间的关系\n\n  - is-a关系：继承\n  - has-a关系：关联 / 聚合 / 合成\n  - use-a关系：依赖\n\n  例子：扑克游戏。\n\n  ```Python\n  \"\"\"\n  经验：符号常量总是优于字面常量，枚举类型是定义符号常量的最佳选择\n  \"\"\"\n  from enum import Enum, unique\n  \n  import random\n  \n  \n  @unique\n  class Suite(Enum):\n      \"\"\"花色\"\"\"\n  \n      SPADE, HEART, CLUB, DIAMOND = range(4)\n  \n      def __lt__(self, other):\n          return self.value < other.value\n  \n  \n  class Card:\n      \"\"\"牌\"\"\"\n  \n      def __init__(self, suite, face):\n          \"\"\"初始化方法\"\"\"\n          self.suite = suite\n          self.face = face\n  \n      def show(self):\n          \"\"\"显示牌面\"\"\"\n          suites = ['♠︎', '♥︎', '♣︎', '♦︎']\n          faces = ['', 'A', '2', '3', '4', '5', '6', '7', '8', '9', '10', 'J', 'Q', 'K']\n          return f'{suites[self.suite.value]}{faces[self.face]}'\n  \n      def __repr__(self):\n          return self.show()\n  \n  \n  class Poker:\n      \"\"\"扑克\"\"\"\n  \n      def __init__(self):\n          self.index = 0\n          self.cards = [Card(suite, face)\n                        for suite in Suite\n                        for face in range(1, 14)]\n  \n      def shuffle(self):\n          \"\"\"洗牌（随机乱序）\"\"\"\n          random.shuffle(self.cards)\n          self.index = 0\n  \n      def deal(self):\n          \"\"\"发牌\"\"\"\n          card = self.cards[self.index]\n          self.index += 1\n          return card\n  \n      @property\n      def has_more(self):\n          return self.index < len(self.cards)\n  \n  \n  class Player:\n      \"\"\"玩家\"\"\"\n  \n      def __init__(self, name):\n          self.name = name\n          self.cards = []\n  \n      def get_one(self, card):\n          \"\"\"摸一张牌\"\"\"\n          self.cards.append(card)\n  \n      def sort(self, comp=lambda card: (card.suite, card.face)):\n          \"\"\"整理手上的牌\"\"\"\n          self.cards.sort(key=comp)\n  \n  \n  def main():\n      \"\"\"主函数\"\"\"\n      poker = Poker()\n      poker.shuffle()\n      players = [Player('东邪'), Player('西毒'), Player('南帝'), Player('北丐')]\n      while poker.has_more:\n          for player in players:\n                  player.get_one(poker.deal())\n      for player in players:\n          player.sort()\n          print(player.name, end=': ')\n          print(player.cards)\n  \n  \n  if __name__ == '__main__':\n      main()\n  ```\n\n  > **说明**：上面的代码中使用了Emoji字符来表示扑克牌的四种花色，在某些不支持Emoji字符的系统上可能无法显示。\n\n- 对象的复制（深复制/深拷贝/深度克隆和浅复制/浅拷贝/影子克隆）\n\n- 垃圾回收、循环引用和弱引用\n\n  Python使用了自动化内存管理，这种管理机制以**引用计数**为基础，同时也引入了**标记-清除**和**分代收集**两种机制为辅的策略。\n\n  ```C\n  typedef struct _object {\n      /* 引用计数 */\n      int ob_refcnt;\n      /* 对象指针 */\n      struct _typeobject *ob_type;\n  } PyObject;\n  ```\n\n  ```C\n  /* 增加引用计数的宏定义 */\n  #define Py_INCREF(op)   ((op)->ob_refcnt++)\n  /* 减少引用计数的宏定义 */\n  #define Py_DECREF(op) \\ //减少计数\n      if (--(op)->ob_refcnt != 0) \\\n          ; \\\n      else \\\n          __Py_Dealloc((PyObject *)(op))\n  ```\n\n  导致引用计数+1的情况：\n\n  - 对象被创建，例如`a = 23`\n  - 对象被引用，例如`b = a`\n  - 对象被作为参数，传入到一个函数中，例如`f(a)`\n  - 对象作为一个元素，存储在容器中，例如`list1 = [a, a]`\n\n  导致引用计数-1的情况：\n\n  - 对象的别名被显式销毁，例如`del a`\n  - 对象的别名被赋予新的对象，例如`a = 24`\n  - 一个对象离开它的作用域，例如f函数执行完毕时，f函数中的局部变量（全局变量不会）\n  - 对象所在的容器被销毁，或从容器中删除对象\n\n  引用计数可能会导致循环引用问题，而循环引用会导致内存泄露，如下面的代码所示。为了解决这个问题，Python中引入了“标记-清除”和“分代收集”。在创建一个对象的时候，对象被放在第一代中，如果在第一代的垃圾检查中对象存活了下来，该对象就会被放到第二代中，同理在第二代的垃圾检查中对象存活下来，该对象就会被放到第三代中。\n\n  ```Python\n  # 循环引用会导致内存泄露 - Python除了引用技术还引入了标记清理和分代回收\n  # 在Python 3.6以前如果重写__del__魔术方法会导致循环引用处理失效\n  # 如果不想造成循环引用可以使用弱引用\n  list1 = []\n  list2 = [] \n  list1.append(list2)\n  list2.append(list1)\n  ```\n\n  以下情况会导致垃圾回收：\n\n  - 调用`gc.collect()`\n  - `gc`模块的计数器达到阀值\n  - 程序退出\n\n  如果循环引用中两个对象都定义了`__del__`方法，`gc`模块不会销毁这些不可达对象，因为gc模块不知道应该先调用哪个对象的`__del__`方法，这个问题在Python 3.6中得到了解决。\n\n  也可以通过`weakref`模块构造弱引用的方式来解决循环引用的问题。\n\n- 魔法属性和方法（请参考《Python魔法方法指南》）\n\n  有几个小问题请大家思考：\n\n  - 自定义的对象能不能使用运算符做运算？\n  - 自定义的对象能不能放到`set`中？能去重吗？\n  - 自定义的对象能不能作为`dict`的键？\n  - 自定义的对象能不能使用上下文语法？\n\n- 混入（Mixin）\n\n  例子：自定义字典限制只有在指定的key不存在时才能在字典中设置键值对。\n\n  ```Python\n  class SetOnceMappingMixin:\n      \"\"\"自定义混入类\"\"\"\n      __slots__ = ()\n  \n      def __setitem__(self, key, value):\n          if key in self:\n              raise KeyError(str(key) + ' already set')\n          return super().__setitem__(key, value)\n  \n  \n  class SetOnceDict(SetOnceMappingMixin, dict):\n      \"\"\"自定义字典\"\"\"\n      pass\n  \n  \n  my_dict= SetOnceDict()\n  try:\n      my_dict['username'] = 'jackfrued'\n      my_dict['username'] = 'hellokitty'\n  except KeyError:\n      pass\n  print(my_dict)\n  ```\n\n- 元编程和元类\n\n  对象是通过类创建的，类是通过元类创建的，元类提供了创建类的元信息。所有的类都直接或间接的继承自`object`，所有的元类都直接或间接的继承自`type`。\n\n  例子：用元类实现单例模式。\n\n  ```Python\n  import threading\n  \n  \n  class SingletonMeta(type):\n      \"\"\"自定义元类\"\"\"\n  \n      def __init__(cls, *args, **kwargs):\n          cls.__instance = None\n          cls.__lock = threading.RLock()\n          super().__init__(*args, **kwargs)\n  \n      def __call__(cls, *args, **kwargs):\n          if cls.__instance is None:\n              with cls.__lock:\n                  if cls.__instance is None:\n                      cls.__instance = super().__call__(*args, **kwargs)\n          return cls.__instance\n  \n  \n  class President(metaclass=SingletonMeta):\n      \"\"\"总统(单例类)\"\"\"\n      \n      pass\n  ```\n\n- 面向对象设计原则\n\n  - 单一职责原则 （**S**RP）- 一个类只做该做的事情（类的设计要高内聚）\n  - 开闭原则 （**O**CP）- 软件实体应该对扩展开发对修改关闭\n  - 依赖倒转原则（DIP）- 面向抽象编程（在弱类型语言中已经被弱化）\n  - 里氏替换原则（**L**SP） - 任何时候可以用子类对象替换掉父类对象\n  - 接口隔离原则（**I**SP）- 接口要小而专不要大而全（Python中没有接口的概念）\n  - 合成聚合复用原则（CARP） - 优先使用强关联关系而不是继承关系复用代码\n  - 最少知识原则（迪米特法则，Lo**D**）- 不要给没有必然联系的对象发消息\n\n  > **说明**：上面加粗的字母放在一起称为面向对象的**SOLID**原则。\n\n- GoF设计模式\n\n  - 创建型模式：单例、工厂、建造者、原型\n  - 结构型模式：适配器、门面（外观）、代理\n  - 行为型模式：迭代器、观察者、状态、策略\n\n  例子：可插拔的哈希算法（策略模式）。\n\n  ```Python\n  class StreamHasher:\n      \"\"\"哈希摘要生成器\"\"\"\n  \n      def __init__(self, alg='md5', size=4096):\n          self.size = size\n          alg = alg.lower()\n          self.hasher = getattr(__import__('hashlib'), alg.lower())()\n  \n      def __call__(self, stream):\n          return self.to_digest(stream)\n  \n      def to_digest(self, stream):\n          \"\"\"生成十六进制形式的摘要\"\"\"\n          for buf in iter(lambda: stream.read(self.size), b''):\n              self.hasher.update(buf)\n          return self.hasher.hexdigest()\n  \n  def main():\n      \"\"\"主函数\"\"\"\n      hasher1 = StreamHasher()\n      with open('Python-3.7.6.tgz', 'rb') as stream:\n          print(hasher1.to_digest(stream))\n      hasher2 = StreamHasher('sha1')\n      with open('Python-3.7.6.tgz', 'rb') as stream:\n          print(hasher2(stream))\n  \n  \n  if __name__ == '__main__':\n      main()\n  ```\n\n### 迭代器和生成器\n\n- 迭代器是实现了迭代器协议的对象。\n\n  - Python中没有像`protocol`或`interface`这样的定义协议的关键字。\n  - Python中用魔术方法表示协议。\n  - `__iter__`和`__next__`魔术方法就是迭代器协议。\n\n  ```Python\n  class Fib(object):\n      \"\"\"迭代器\"\"\"\n      \n      def __init__(self, num):\n          self.num = num\n          self.a, self.b = 0, 1\n          self.idx = 0\n     \n      def __iter__(self):\n          return self\n  \n      def __next__(self):\n          if self.idx < self.num:\n              self.a, self.b = self.b, self.a + self.b\n              self.idx += 1\n              return self.a\n          raise StopIteration()\n  ```\n\n- 生成器是语法简化版的迭代器。\n\n  ```Python\n  def fib(num):\n      \"\"\"生成器\"\"\"\n      a, b = 0, 1\n      for _ in range(num):\n          a, b = b, a + b\n          yield a\n  ```\n\n- 生成器进化为协程。\n\n  生成器对象可以使用`send()`方法发送数据，发送的数据会成为生成器函数中通过`yield`表达式获得的值。这样，生成器就可以作为协程使用，协程简单的说就是可以相互协作的子程序。\n\n  ```Python\n  def calc_avg():\n      \"\"\"流式计算平均值\"\"\"\n      total, counter = 0, 0\n      avg_value = None\n      while True:\n          value = yield avg_value\n          total, counter = total + value, counter + 1\n          avg_value = total / counter\n  \n  \n  gen = calc_avg()\n  next(gen)\n  print(gen.send(10))\n  print(gen.send(20))\n  print(gen.send(30))\n  ```\n\n### 并发编程\n\nPython中实现并发编程的三种方案：多线程、多进程和异步I/O。并发编程的好处在于可以提升程序的执行效率以及改善用户体验；坏处在于并发的程序不容易开发和调试，同时对其他程序来说它并不友好。\n\n- 多线程：Python中提供了`Thread`类并辅以`Lock`、`Condition`、`Event`、`Semaphore`和`Barrier`。Python中有GIL来防止多个线程同时执行本地字节码，这个锁对于CPython是必须的，因为CPython的内存管理并不是线程安全的，因为GIL的存在多线程并不能发挥CPU的多核特性。\n\n  ```Python\n  \"\"\"\n  面试题：进程和线程的区别和联系？\n  进程 - 操作系统分配内存的基本单位 - 一个进程可以包含一个或多个线程\n  线程 - 操作系统分配CPU的基本单位\n  并发编程（concurrent programming）\n  1. 提升执行性能 - 让程序中没有因果关系的部分可以并发的执行\n  2. 改善用户体验 - 让耗时间的操作不会造成程序的假死\n  \"\"\"\n  import glob\n  import os\n  import threading\n  \n  from PIL import Image\n  \n  PREFIX = 'thumbnails'\n  \n  \n  def generate_thumbnail(infile, size, format='PNG'):\n      \"\"\"生成指定图片文件的缩略图\"\"\"\n  \tfile, ext = os.path.splitext(infile)\n  \tfile = file[file.rfind('/') + 1:]\n  \toutfile = f'{PREFIX}/{file}_{size[0]}_{size[1]}.{ext}'\n  \timg = Image.open(infile)\n  \timg.thumbnail(size, Image.ANTIALIAS)\n  \timg.save(outfile, format)\n  \n  \n  def main():\n      \"\"\"主函数\"\"\"\n  \tif not os.path.exists(PREFIX):\n  \t\tos.mkdir(PREFIX)\n  \tfor infile in glob.glob('images/*.png'):\n  \t\tfor size in (32, 64, 128):\n              # 创建并启动线程\n  \t\t\tthreading.Thread(\n  \t\t\t\ttarget=generate_thumbnail, \n  \t\t\t\targs=(infile, (size, size))\n  \t\t\t).start()\n  \t\t\t\n  \n  if __name__ == '__main__':\n  \tmain()\n  ```\n\n  多个线程竞争资源的情况。\n\n  ```Python\n  \"\"\"\n  多线程程序如果没有竞争资源处理起来通常也比较简单\n  当多个线程竞争临界资源的时候如果缺乏必要的保护措施就会导致数据错乱\n  说明：临界资源就是被多个线程竞争的资源\n  \"\"\"\n  import time\n  import threading\n  \n  from concurrent.futures import ThreadPoolExecutor\n  \n  \n  class Account(object):\n      \"\"\"银行账户\"\"\"\n  \n      def __init__(self):\n          self.balance = 0.0\n          self.lock = threading.Lock()\n  \n      def deposit(self, money):\n          # 通过锁保护临界资源\n          with self.lock:\n              new_balance = self.balance + money\n              time.sleep(0.001)\n              self.balance = new_balance\n  \n  \n  def main():\n      \"\"\"主函数\"\"\"\n      account = Account()\n      # 创建线程池\n      pool = ThreadPoolExecutor(max_workers=10)\n      futures = []\n      for _ in range(100):\n          future = pool.submit(account.deposit, 1)\n          futures.append(future)\n      # 关闭线程池\n      pool.shutdown()\n      for future in futures:\n          future.result()\n      print(account.balance)\n  \n  \n  if __name__ == '__main__':\n      main()\n  ```\n  \n  修改上面的程序，启动5个线程向账户中存钱，5个线程从账户中取钱，取钱时如果余额不足就暂停线程进行等待。为了达到上述目标，需要对存钱和取钱的线程进行调度，在余额不足时取钱的线程暂停并释放锁，而存钱的线程将钱存入后要通知取钱的线程，使其从暂停状态被唤醒。可以使用`threading`模块的`Condition`来实现线程调度，该对象也是基于锁来创建的，代码如下所示：\n  \n  ```Python\n  \"\"\"\n  多个线程竞争一个资源 - 保护临界资源 - 锁（Lock/RLock）\n  多个线程竞争多个资源（线程数>资源数） - 信号量（Semaphore）\n  多个线程的调度 - 暂停线程执行/唤醒等待中的线程 - Condition\n  \"\"\"\n  from concurrent.futures import ThreadPoolExecutor\n  from random import randint\n  from time import sleep\n  \n  import threading\n  \n  \n  class Account:\n      \"\"\"银行账户\"\"\"\n  \n      def __init__(self, balance=0):\n          self.balance = balance\n          lock = threading.RLock()\n          self.condition = threading.Condition(lock)\n  \n      def withdraw(self, money):\n          \"\"\"取钱\"\"\"\n          with self.condition:\n              while money > self.balance:\n                  self.condition.wait()\n              new_balance = self.balance - money\n              sleep(0.001)\n              self.balance = new_balance\n  \n      def deposit(self, money):\n          \"\"\"存钱\"\"\"\n          with self.condition:\n              new_balance = self.balance + money\n              sleep(0.001)\n              self.balance = new_balance\n              self.condition.notify_all()\n  \n  \n  def add_money(account):\n      while True:\n          money = randint(5, 10)\n          account.deposit(money)\n          print(threading.current_thread().name, \n                ':', money, '====>', account.balance)\n          sleep(0.5)\n  \n  \n  def sub_money(account):\n      while True:\n          money = randint(10, 30)\n          account.withdraw(money)\n          print(threading.current_thread().name, \n                ':', money, '<====', account.balance)\n          sleep(1)\n  \n  \n  def main():\n      account = Account()\n      with ThreadPoolExecutor(max_workers=15) as pool:\n          for _ in range(5):\n              pool.submit(add_money, account)\n          for _ in range(10):\n              pool.submit(sub_money, account)\n  \n  \n  if __name__ == '__main__':\n      main()\n  ```\n  \n- 多进程：多进程可以有效的解决GIL的问题，实现多进程主要的类是`Process`，其他辅助的类跟`threading`模块中的类似，进程间共享数据可以使用管道、套接字等，在`multiprocessing`模块中有一个`Queue`类，它基于管道和锁机制提供了多个进程共享的队列。下面是官方文档上关于多进程和进程池的一个示例。\n\n  ```Python\n  \"\"\"\n  多进程和进程池的使用\n  多线程因为GIL的存在不能够发挥CPU的多核特性\n  对于计算密集型任务应该考虑使用多进程\n  time python3 example22.py\n  real    0m11.512s\n  user    0m39.319s\n  sys     0m0.169s\n  使用多进程后实际执行时间为11.512秒，而用户时间39.319秒约为实际执行时间的4倍\n  这就证明我们的程序通过多进程使用了CPU的多核特性，而且这台计算机配置了4核的CPU\n  \"\"\"\n  import concurrent.futures\n  import math\n  \n  PRIMES = [\n      1116281,\n      1297337,\n      104395303,\n      472882027,\n      533000389,\n      817504243,\n      982451653,\n      112272535095293,\n      112582705942171,\n      112272535095293,\n      115280095190773,\n      115797848077099,\n      1099726899285419\n  ] * 5\n  \n  \n  def is_prime(n):\n      \"\"\"判断素数\"\"\"\n      if n % 2 == 0:\n          return False\n  \n      sqrt_n = int(math.floor(math.sqrt(n)))\n      for i in range(3, sqrt_n + 1, 2):\n          if n % i == 0:\n              return False\n      return True\n  \n  \n  def main():\n      \"\"\"主函数\"\"\"\n      with concurrent.futures.ProcessPoolExecutor() as executor:\n          for number, prime in zip(PRIMES, executor.map(is_prime, PRIMES)):\n              print('%d is prime: %s' % (number, prime))\n  \n  \n  if __name__ == '__main__':\n      main()\n  ```\n\n  > **重点**：**多线程和多进程的比较**。\n  >\n  > 以下情况需要使用多线程：\n  >\n  > 1. 程序需要维护许多共享的状态（尤其是可变状态），Python中的列表、字典、集合都是线程安全的，所以使用线程而不是进程维护共享状态的代价相对较小。\n  > 2. 程序会花费大量时间在I/O操作上，没有太多并行计算的需求且不需占用太多的内存。\n  >\n  > 以下情况需要使用多进程：\n  >\n  > 1. 程序执行计算密集型任务（如：字节码操作、数据处理、科学计算）。\n  > 2. 程序的输入可以并行的分成块，并且可以将运算结果合并。\n  > 3. 程序在内存使用方面没有任何限制且不强依赖于I/O操作（如：读写文件、套接字等）。\n\n- 异步处理：从调度程序的任务队列中挑选任务，该调度程序以交叉的形式执行这些任务，我们并不能保证任务将以某种顺序去执行，因为执行顺序取决于队列中的一项任务是否愿意将CPU处理时间让位给另一项任务。异步任务通常通过多任务协作处理的方式来实现，由于执行时间和顺序的不确定，因此需要通过回调式编程或者`future`对象来获取任务执行的结果。Python 3通过`asyncio`模块和`await`和`async`关键字（在Python 3.7中正式被列为关键字）来支持异步处理。\n\n  ```Python\n  \"\"\"\n  异步I/O - async / await\n  \"\"\"\n  import asyncio\n  \n  \n  def num_generator(m, n):\n      \"\"\"指定范围的数字生成器\"\"\"\n      yield from range(m, n + 1)\n  \n  \n  async def prime_filter(m, n):\n      \"\"\"素数过滤器\"\"\"\n      primes = []\n      for i in num_generator(m, n):\n          flag = True\n          for j in range(2, int(i ** 0.5 + 1)):\n              if i % j == 0:\n                  flag = False\n                  break\n          if flag:\n              print('Prime =>', i)\n              primes.append(i)\n  \n          await asyncio.sleep(0.001)\n      return tuple(primes)\n  \n  \n  async def square_mapper(m, n):\n      \"\"\"平方映射器\"\"\"\n      squares = []\n      for i in num_generator(m, n):\n          print('Square =>', i * i)\n          squares.append(i * i)\n  \n          await asyncio.sleep(0.001)\n      return squares\n  \n  \n  def main():\n      \"\"\"主函数\"\"\"\n      loop = asyncio.get_event_loop()\n      future = asyncio.gather(prime_filter(2, 100), square_mapper(1, 100))\n      future.add_done_callback(lambda x: print(x.result()))\n      loop.run_until_complete(future)\n      loop.close()\n  \n  \n  if __name__ == '__main__':\n      main()\n  ```\n\n  > **说明**：上面的代码使用`get_event_loop`函数获得系统默认的事件循环，通过`gather`函数可以获得一个`future`对象，`future`对象的`add_done_callback`可以添加执行完成时的回调函数，`loop`对象的`run_until_complete`方法可以等待通过`future`对象获得协程执行结果。\n\n  Python中有一个名为`aiohttp`的三方库，它提供了异步的HTTP客户端和服务器，这个三方库可以跟`asyncio`模块一起工作，并提供了对`Future`对象的支持。Python 3.6中引入了`async`和`await`来定义异步执行的函数以及创建异步上下文，在Python 3.7中它们正式成为了关键字。下面的代码异步的从5个URL中获取页面并通过正则表达式的命名捕获组提取了网站的标题。\n\n  ```Python\n  import asyncio\n  import re\n  \n  import aiohttp\n  \n  PATTERN = re.compile(r'\\<title\\>(?P<title>.*)\\<\\/title\\>')\n  \n  \n  async def fetch_page(session, url):\n      async with session.get(url, ssl=False) as resp:\n          return await resp.text()\n  \n  \n  async def show_title(url):\n      async with aiohttp.ClientSession() as session:\n          html = await fetch_page(session, url)\n          print(PATTERN.search(html).group('title'))\n  \n  \n  def main():\n      urls = ('https://www.python.org/',\n              'https://git-scm.com/',\n              'https://www.jd.com/',\n              'https://www.taobao.com/',\n              'https://www.douban.com/')\n      loop = asyncio.get_event_loop()\n      cos = [show_title(url) for url in urls]\n      loop.run_until_complete(asyncio.wait(cos))\n      loop.close()\n  \n  \n  if __name__ == '__main__':\n      main()\n  ```\n\n  > **重点**：**异步I/O与多进程的比较**。\n  >\n  > 当程序不需要真正的并发性或并行性，而是更多的依赖于异步处理和回调时，`asyncio`就是一种很好的选择。如果程序中有大量的等待与休眠时，也应该考虑`asyncio`，它很适合编写没有实时数据处理需求的Web应用服务器。\n\n  Python还有很多用于处理并行任务的三方库，例如：`joblib`、`PyMP`等。实际开发中，要提升系统的可扩展性和并发性通常有垂直扩展（增加单个节点的处理能力）和水平扩展（将单个节点变成多个节点）两种做法。可以通过消息队列来实现应用程序的解耦合，消息队列相当于是多线程同步队列的扩展版本，不同机器上的应用程序相当于就是线程，而共享的分布式消息队列就是原来程序中的Queue。消息队列（面向消息的中间件）的最流行和最标准化的实现是AMQP（高级消息队列协议），AMQP源于金融行业，提供了排队、路由、可靠传输、安全等功能，最著名的实现包括：Apache的ActiveMQ、RabbitMQ等。\n\n  要实现任务的异步化，可以使用名为`Celery`的三方库。`Celery`是Python编写的分布式任务队列，它使用分布式消息进行工作，可以基于RabbitMQ或Redis来作为后端的消息代理。", "Web前端入门": "## Web前端概述\n\n> **说明**：本文使用的部分插图来自 *Jon Duckett* 的*[HTML and CSS: Design and Build Websites](https://www.amazon.cn/dp/1118008189/ref=sr_1_5?__mk_zh_CN=%E4%BA%9A%E9%A9%AC%E9%80%8A%E7%BD%91%E7%AB%99&keywords=html+%26+css&qid=1554609325&s=gateway&sr=8-5)*一书，这是一本非常棒的前端入门书，有兴趣的读者可以在亚马逊或者其他网站上找到该书的购买链接。\n\nHTML 是用来描述网页的一种语言，全称是 Hyper-Text Markup Language，即超文本标记语言。我们浏览网页时看到的文字、按钮、图片、视频等元素，它们都是通过 HTML 书写并通过浏览器来呈现的。\n\n### HTML简史\n\n1. 1991年10月：一个非正式CERN（[欧洲核子研究中心](https://zh.wikipedia.org/wiki/%E6%AD%90%E6%B4%B2%E6%A0%B8%E5%AD%90%E7%A0%94%E7%A9%B6%E7%B5%84%E7%B9%94)）文件首次公开18个HTML标签，这个文件的作者是物理学家[蒂姆·伯纳斯-李](https://zh.wikipedia.org/wiki/%E8%92%82%E5%A7%86%C2%B7%E4%BC%AF%E7%BA%B3%E6%96%AF-%E6%9D%8E)，因此他是[万维网](https://zh.wikipedia.org/wiki/%E4%B8%87%E7%BB%B4%E7%BD%91)的发明者，也是[万维网联盟](https://zh.wikipedia.org/wiki/%E4%B8%87%E7%BB%B4%E7%BD%91%E8%81%94%E7%9B%9F)的主席。\n2. 1995年11月：HTML 2.0标准发布（RFC 1866）。\n3. 1997年1月：HTML 3.2作为[W3C](https://zh.wikipedia.org/wiki/W3C)推荐标准发布。\n4. 1997年12月：HTML 4.0作为W3C推荐标准发布。\n5.  1999年12月：HTML4.01作为W3C推荐标准发布。\n6. 2008年1月：HTML5由W3C作为工作草案发布。\n7. 2011年5月：W3C将HTML5推进至“最终征求”（Last Call）阶段。\n8. 2012年12月：W3C指定HTML5作为“候选推荐”阶段。\n9. 2014年10月：HTML5作为稳定W3C推荐标准发布，这意味着HTML5的标准化已经完成。\n\n#### HTML5新特性\n\n1. 引入原生多媒体支持（audio和video标签）\n2. 引入可编程内容（canvas标签）\n3. 引入语义Web（article、aside、details、figure、footer、header、nav、section、summary等标签）\n4. 引入新的表单控件（日历、邮箱、搜索、滑条等）\n5. 引入对离线存储更好的支持（localStorage和sessionStorage）\n6. 引入对定位、拖放、WebSocket、后台任务等的支持\n\n### 使用标签承载内容\n\n<img src=\"https://gitee.com/jackfrued/mypic/raw/master/20211107163448.png\" style=\"zoom:35%\">\n\n<img src=\"https://gitee.com/jackfrued/mypic/raw/master/20211107163741.png\" style=\"zoom:75%\">\n\n####  结构\n\n- html\n  - head\n    - title\n    - meta\n  - body\n\n#### 文本\n\n- 标题（heading）和段落（paragraph）\n  - h1 ~ h6\n  - p\n- 上标（superscript）和下标（subscript）\n  - sup\n  - sub\n- 空白（白色空间折叠）\n- 折行（break）和水平标尺（horizontal ruler）\n  - br\n  - hr\n- 语义化标签\n  - 加粗和强调 - strong\n  - 引用 - blockquote\n  - 缩写词和首字母缩写词 - abbr / acronym\n  - 引文 - cite\n  - 所有者联系信息 - address\n  - 内容的修改 - ins / del\n\n#### 列表（list）\n\n - 有序列表（ordered list）- ol / li\n - 无序列表（unordered list）- ul / li\n - 定义列表（definition list）- dl / dt / dd\n\n#### 链接（anchor）\n\n- 页面链接\n- 锚链接\n- 功能链接\n\n#### 图像（image）\n\n- 图像存储位置\n\n  ![](./res/相对路径.png)\n\n- 图像及其宽高\n\n- 选择正确的图像格式\n  - JPEG\n  - GIF\n  - PNG\n\n- 矢量图\n\n- 语义化标签 - figure / figcaption\n\n#### 表格（table）\n\n- 基本的表格结构 - table / tr / td / th\n- 表格的标题 - caption\n- 跨行和跨列 - rowspan属性 / colspan属性\n- 长表格 - thead / tbody / tfoot\n\n#### 表单（form）\n\n- 重要属性 - action / method / enctype\n- 表单控件（input）- type属性\n  - 文本框 - `text` / 密码框 - `password` / 数字框 - `number`\n  - 邮箱 - `email` / 电话 - `tel` / 日期 - `date` / 滑条 - `range` / URL - `url` / 搜索 - `search`\n  - 单选按钮 - `radio` / 复选按钮 - `checkbox`\n  - 文件上传 - `file` / 隐藏域 - `hidden`\n  - 提交按钮 - `submit` / 图像按钮 - `image`  / 重置按钮 - `reset`\n- 下拉列表 - select / option\n- 文本域（多行文本）- textarea\n- 组合表单元素 - fieldset / legend\n\n#### 音视频（audio / video）\n\n- 视频格式和播放器\n- 视频托管服务\n- 添加视频的准备工作\n- video标签和属性 - autoplay / controls / loop / muted / preload / src\n- audio标签和属性 - autoplay / controls / loop / muted / preload / src / width / height / poster\n\n#### 窗口（frame）\n\n- 框架集（过时，不建议使用） - frameset / frame\n\n- 内嵌窗口 - iframe\n\n#### 其他\n\n- 文档类型\n\n  ```HTML\n  <!doctype html>\n  ```\n\n  ```HTML\n  <!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01//EN\" \"http://www.w3.org/TR/html4/strict.dtd\">\n  ```\n\n  ```HTML\n  <!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\" \"http://www.w3.org/TR/html4/loose.dtd\">\n  ```\n\n- 注释\n\n  ```HTML\n  <!-- 这是一段注释，注释不能够嵌套 -->\n  ```\n\n- 属性\n  - id：唯一标识\n  - class：元素所属的类，用于区分不同的元素\n  - title：元素的额外信息（鼠标悬浮时会显示工具提示文本）\n  - tabindex：Tab键切换顺序\n  - contenteditable：元素是否可编辑\n  - draggable：元素是否可拖拽\n\n- 块级元素 / 行级元素\n\n- 字符实体（实体替换符）\n\n  ![](./res/字符实体.png)\n\n### 使用CSS渲染页面\n\n#### 简介\n\n- CSS的作用\n\n- CSS的工作原理\n\n- 规则、属性和值\n\n  ![](./res/选择器语法.png)\n\n- 常用选择器\n\n  ![](./res/常用选择器.png)\n\n#### 颜色（color）\n\n- 如何指定颜色\n- 颜色术语和颜色对比\n- 背景色\n\n#### 文本（text / font）\n\n- 文本的大小和字型(font-size / font-family)\n\n  ![](./res/尺寸单位.png)\n\n  ![](./res/衬线字体+非衬线字体+等宽字体.png)\n\n- 粗细、样式、拉伸和装饰(font-weight / font-style / font-stretch / text-decoration)\n\n  ![](./res/字体样式.png)\n\n- 行间距(line-height)、字母间距(letter-spacing)和单词间距(word-spacing)\n\n- 对齐(text-align)方式和缩进(text-ident)\n\n- 链接样式（:link / :visited / :active / :hover）\n\n- CSS3新属性\n  - 阴影效果 - text-shadow\n  - 首字母和首行文本(:first-letter / :first-line)\n  - 响应用户\n\n#### 盒子（box model）\n\n- 盒子大小的控制（width / height）\n\n  ![](./res/尺寸单位.png)\n\n- 盒子的边框、外边距和内边距（border /  margin / padding）\n\n  ![](./res/盒子模型.png)\n\n- 盒子的显示和隐藏（display / visibility）\n\n- CSS3新属性\n  - 边框图像（border-image）\n  - 投影（border-shadow）\n  - 圆角（border-radius）\n\n#### 列表、表格和表单\n\n- 列表的项目符号（list-style）\n- 表格的边框和背景（border-collapse）\n- 表单控件的外观\n- 表单控件的对齐\n- 浏览器的开发者工具\n\n#### 图像\n\n- 控制图像的大小（display: inline-block）\n- 对齐图像\n- 背景图像（background / background-image / background-repeat / background-position）\n\n#### 布局\n\n- 控制元素的位置（position / z-index）\n  - 普通流\n  - 相对定位\n  - 绝对定位\n  - 固定定位\n  - 浮动元素（float / clear）\n- 网站布局\n\n  - HTML5布局\n\n    ![](./res/经典布局-2.png)\n- 适配屏幕尺寸\n  - 固定宽度布局\n  - 流体布局\n  - 布局网格\n\n### 使用JavaScript控制行为\n\n#### JavaScript基本语法\n\n- 语句和注释\n- 变量和数据类型\n  - 声明和赋值\n  - 简单数据类型和复杂数据类型\n  - 变量的命名规则\n- 表达式和运算符\n  - 赋值运算符\n  - 算术运算符\n  - 比较运算符\n  - 逻辑运算符：`&&`、`||`、`!`\n- 分支结构\n  - `if...else...`\n  - `switch...cas...default...`\n- 循环结构\n  - `for`循环\n  - `while`循环\n  - `do...while`循环\n- 数组\n  - 创建数组\n  - 操作数组中的元素\n- 函数\n  - 声明函数\n  - 调用函数\n  - 参数和返回值\n  - 匿名函数\n  - 立即调用函数\n\n#### 面向对象\n\n - 对象的概念\n - 创建对象的字面量语法\n - 访问成员运算符\n - 创建对象的构造函数语法\n    - `this`关键字\n - 添加和删除属性\n    - `delete`关键字\n - 标准对象\n    - `Number` / `String` / `Boolean` / `Symbol` / `Array` / `Function` \n    - `Date` / `Error` / `Math` / `RegExp` / `Object` / `Map` / `Set`\n    - `JSON` / `Promise` / `Generator` / `Reflect` / `Proxy`\n\n#### BOM\n\n - `window`对象的属性和方法\n - `history`对象\n    - `forward()` / `back()` / `go()`\n - `location`对象\n - `navigator`对象\n - `screen`对象\n\n#### DOM\n\n - DOM树\n - 访问元素\n    - `getElementById()` / `querySelector()`\n    - `getElementsByClassName()` / `getElementsByTagName()` / `querySelectorAll()`\n    - `parentNode` / `previousSibling` / `nextSibling` / `children` / `firstChild` / `lastChild`\n- 操作元素\n  - `nodeValue`\n  - `innerHTML` / `textContent` / `createElement()` / `createTextNode()` / `appendChild()` / `insertBefore()` / `removeChild()`\n  - `className` / `id` / `hasAttribute()` / `getAttribute()` / `setAttribute()` / `removeAttribute()`\n- 事件处理\n  - 事件类型\n    - UI事件：`load` / `unload` / `error` / `resize` / `scroll`\n    - 键盘事件：`keydown` / `keyup` / `keypress`\n    - 鼠标事件：`click` / `dbclick` / `mousedown` / `mouseup` / `mousemove` / `mouseover` / `mouseout`\n    - 焦点事件：`focus` / `blur`\n    - 表单事件：`input` / `change` / `submit` / `reset` / `cut` / `copy` / `paste` / `select`\n  - 事件绑定\n    - HTML事件处理程序（不推荐使用，因为要做到标签与代码分离）\n    - 传统的DOM事件处理程序（只能附加一个回调函数）\n    - 事件监听器（旧的浏览器中不被支持）\n  - 事件流：事件捕获 / 事件冒泡\n  - 事件对象（低版本IE中的window.event）\n    - `target`（有些浏览器使用srcElement）\n    - `type`\n    - `cancelable`\n    - `preventDefault()`\n    - `stopPropagation()`（低版本IE中的cancelBubble）\n  - 鼠标事件 - 事件发生的位置\n    - 屏幕位置：`screenX`和`screenY`\n    - 页面位置：`pageX`和`pageY`\n    - 客户端位置：`clientX`和`clientY`\n  - 键盘事件 - 哪个键被按下了\n    - `keyCode`属性（有些浏览器使用`which`）\n    - `String.fromCharCode(event.keyCode)`\n  - HTML5事件\n    - `DOMContentLoaded`\n    - `hashchange`\n    - `beforeunload`\n\n#### JavaScript API\n\n- 客户端存储 - `localStorage`和`sessionStorage`\n\n  ```JavaScript\n  localStorage.colorSetting = '#a4509b';\n  localStorage['colorSetting'] = '#a4509b';\n  localStorage.setItem('colorSetting', '#a4509b');\n  ```\n\n- 获取位置信息 - `geolocation`\n\n  ```JavaScript\n  navigator.geolocation.getCurrentPosition(function(pos) { \t\t  \n      console.log(pos.coords.latitude)\n      console.log(pos.coords.longitude)\n  })\n  ```\n\n- 从服务器获取数据 - Fetch API\n- 绘制图形 - `<canvas>`的API\n- 音视频 - `<audio>`和`<video>`的API\n\n### 前端框架\n\n#### 渐进式框架 - [Vue.js](<https://cn.vuejs.org/>)\n\n前后端分离开发（前端渲染）必选框架。\n\n##### 快速上手\n\n1. 引入Vue的JavaScript文件，我们仍然推荐从CDN服务器加载它。\n\n   ```HTML\n   <script src=\"https://cdn.jsdelivr.net/npm/vue\"></script>\n   ```\n\n2. 数据绑定（声明式渲染 ）。\n\n   ```HTML\n   <div id=\"app\">\n   \t<h1>{{ product }}库存信息</h1>\n   </div>\n   \n   <script src=\"https://cdn.jsdelivr.net/npm/vue\"></script>\n   <script>\n   \tconst app = new Vue({\n   \t\tel: '#app',\n   \t\tdata: {\n   \t\t\tproduct: 'iPhone X'\n   \t\t}\n   \t});\n   </script>\n   ```\n\n3. 条件与循环。\n\n   ```HTML\n   <div id=\"app\">\n   \t<h1>库存信息</h1>\n       <hr>\n   \t<ul>\n   \t\t<li v-for=\"product in products\">\n   \t\t\t{{ product.name }} - {{ product.quantity }}\n   \t\t\t<span v-if=\"product.quantity === 0\">\n   \t\t\t\t已经售罄\n   \t\t\t</span>\n   \t\t</li>\n   \t</ul>\n   </div>\n   \n   <script src=\"https://cdn.jsdelivr.net/npm/vue\"></script>\n   <script>\n   \tconst app = new Vue({\n   \t\tel: '#app',\n   \t\tdata: {\n   \t\t\tproducts: [\n   \t\t\t\t{\"id\": 1, \"name\": \"iPhone X\", \"quantity\": 20},\n   \t\t\t\t{\"id\": 2, \"name\": \"华为 Mate20\", \"quantity\": 0},\n   \t\t\t\t{\"id\": 3, \"name\": \"小米 Mix3\", \"quantity\": 50}\n   \t\t\t]\n   \t\t}\n   \t});\n   </script>\n   ```\n\n4. 计算属性。\n\n   ```HTML\n   <div id=\"app\">\n   \t<h1>库存信息</h1>\n   \t<hr>\n   \t<ul>\n   \t\t<li v-for=\"product in products\">\n   \t\t\t{{ product.name }} - {{ product.quantity }}\n   \t\t\t<span v-if=\"product.quantity === 0\">\n   \t\t\t\t已经售罄\n   \t\t\t</span>\n   \t\t</li>\n   \t</ul>\n   \t<h2>库存总量：{{ totalQuantity }}台</h2>\n   </div>\n   \n   <script src=\"https://cdn.jsdelivr.net/npm/vue\"></script>\n   <script>\n   \tconst app = new Vue({\n   \t\tel: '#app',\n   \t\tdata: {\n   \t\t\tproducts: [\n   \t\t\t\t{\"id\": 1, \"name\": \"iPhone X\", \"quantity\": 20},\n   \t\t\t\t{\"id\": 2, \"name\": \"华为 Mate20\", \"quantity\": 0},\n   \t\t\t\t{\"id\": 3, \"name\": \"小米 Mix3\", \"quantity\": 50}\n   \t\t\t]\n   \t\t},\n   \t\tcomputed: {\n   \t\t\ttotalQuantity() {\n   \t\t\t\treturn this.products.reduce((sum, product) => {\n   \t\t\t\t\treturn sum + product.quantity\n   \t\t\t\t}, 0);\n   \t\t\t}\n   \t\t}\n   \t});\n   </script>\n   ```\n\n5. 处理事件。\n\n   ```HTML\n   <div id=\"app\">\n   \t<h1>库存信息</h1>\n   \t<hr>\n   \t<ul>\n   \t\t<li v-for=\"product in products\">\n   \t\t\t{{ product.name }} - {{ product.quantity }}\n   \t\t\t<span v-if=\"product.quantity === 0\">\n   \t\t\t\t已经售罄\n   \t\t\t</span>\n   \t\t\t<button @click=\"product.quantity += 1\">\n   \t\t\t\t增加库存\n   \t\t\t</button>\n   \t\t</li>\n   \t</ul>\n   \t<h2>库存总量：{{ totalQuantity }}台</h2>\n   </div>\n   \n   <script src=\"https://cdn.jsdelivr.net/npm/vue\"></script>\n   <script>\n   \tconst app = new Vue({\n   \t\tel: '#app',\n   \t\tdata: {\n   \t\t\tproducts: [\n   \t\t\t\t{\"id\": 1, \"name\": \"iPhone X\", \"quantity\": 20},\n   \t\t\t\t{\"id\": 2, \"name\": \"华为 Mate20\", \"quantity\": 0},\n   \t\t\t\t{\"id\": 3, \"name\": \"小米 Mix3\", \"quantity\": 50}\n   \t\t\t]\n   \t\t},\n   \t\tcomputed: {\n   \t\t\ttotalQuantity() {\n   \t\t\t\treturn this.products.reduce((sum, product) => {\n   \t\t\t\t\treturn sum + product.quantity\n   \t\t\t\t}, 0);\n   \t\t\t}\n   \t\t}\n   \t});\n   </script>\n   ```\n\n6. 用户输入。\n\n   ```HTML\n   <div id=\"app\">\n   \t<h1>库存信息</h1>\n   \t<hr>\n   \t<ul>\n   \t\t<li v-for=\"product in products\">\n   \t\t\t{{ product.name }} - \n   \t\t\t<input type=\"number\" v-model.number=\"product.quantity\" min=\"0\">\n   \t\t\t<span v-if=\"product.quantity === 0\">\n   \t\t\t\t已经售罄\n   \t\t\t</span>\n   \t\t\t<button @click=\"product.quantity += 1\">\n   \t\t\t\t增加库存\n   \t\t\t</button>\n   \t\t</li>\n   \t</ul>\n   \t<h2>库存总量：{{ totalQuantity }}台</h2>\n   </div>\n   \n   <script src=\"https://cdn.jsdelivr.net/npm/vue\"></script>\n   <script>\n   \tconst app = new Vue({\n   \t\tel: '#app',\n   \t\tdata: {\n   \t\t\tproducts: [\n   \t\t\t\t{\"id\": 1, \"name\": \"iPhone X\", \"quantity\": 20},\n   \t\t\t\t{\"id\": 2, \"name\": \"华为 Mate20\", \"quantity\": 0},\n   \t\t\t\t{\"id\": 3, \"name\": \"小米 Mix3\", \"quantity\": 50}\n   \t\t\t]\n   \t\t},\n   \t\tcomputed: {\n   \t\t\ttotalQuantity() {\n   \t\t\t\treturn this.products.reduce((sum, product) => {\n   \t\t\t\t\treturn sum + product.quantity\n   \t\t\t\t}, 0);\n   \t\t\t}\n   \t\t}\n   \t});\n   </script>\n   ```\n\n7. 通过网络加载JSON数据。\n\n   ```HTML\n   <div id=\"app\">\n   \t<h2>库存信息</h2>\n   \t<ul>\n   \t\t<li v-for=\"product in products\">\n   \t\t\t{{ product.name }} - {{ product.quantity }}\n   \t\t\t<span v-if=\"product.quantity === 0\">\n   \t\t\t\t已经售罄\n   \t\t\t</span>\n   \t\t</li>\n   \t</ul>\n   </div>\n   \n   <script src=\"https://cdn.jsdelivr.net/npm/vue\"></script>\n   <script>\n   \tconst app = new Vue({\n   \t\tel: '#app',\n   \t\tdata: {\n   \t\t\tproducts: []\n   \t\t}，\n   \t\tcreated() {\n   \t\t\tfetch('https://jackfrued.top/api/products')\n   \t\t\t\t.then(response => response.json())\n   \t\t\t\t.then(json => {\n   \t\t\t\t\tthis.products = json\n   \t\t\t\t});\n   \t\t}\n   \t});\n   </script>\n   ```\n\n##### 使用脚手架 - vue-cli\n\nVue为商业项目开发提供了非常便捷的脚手架工具vue-cli，通过工具可以省去手工配置开发环境、测试环境和运行环境的步骤，让开发者只需要关注要解决的问题。\n\n1. 安装脚手架。\n2. 创建项目。\n3. 安装依赖包。\n4. 运行项目。\n\n\n#### UI框架 - [Element](<http://element-cn.eleme.io/#/zh-CN>)\n\n基于Vue 2.0的桌面端组件库，用于构造用户界面，支持响应式布局。\n\n1. 引入Element的CSS和JavaScript文件。\n\n   ```HTML\n   <!-- 引入样式 -->\n   <link rel=\"stylesheet\" href=\"https://unpkg.com/element-ui/lib/theme-chalk/index.css\">\n   <!-- 引入组件库 -->\n   <script src=\"https://unpkg.com/element-ui/lib/index.js\"></script>\n   ```\n\n2. 一个简单的例子。\n\n   ```HTML\n   <!DOCTYPE html>\n   <html>\n   \t<head>\n   \t\t<meta charset=\"UTF-8\">\n   \t\t<link rel=\"stylesheet\" href=\"https://unpkg.com/element-ui/lib/theme-chalk/index.css\">\n   \t</head>\n   \t<body>\n   \t\t<div id=\"app\">\n   \t\t\t<el-button @click=\"visible = true\">点我</el-button>\n   \t\t\t<el-dialog :visible.sync=\"visible\" title=\"Hello world\">\n   \t\t\t\t<p>开始使用Element吧</p>\n   \t\t\t</el-dialog>\n               </div>\n   \t</body>\n   \t<script src=\"https://unpkg.com/vue/dist/vue.js\"></script>\n   \t<script src=\"https://unpkg.com/element-ui/lib/index.js\"></script>\n   \t<script>\n   \t\tnew Vue({\n   \t\t\tel: '#app',\n   \t\t\tdata: {\n   \t\t\t\tvisible: false,\n   \t\t\t}\n   \t\t})\n   \t</script>\n   </html>\n   ```\n\n3. 使用组件。\n\n   ```HTML\n   <!DOCTYPE html>\n   <html>\n   \t<head>\n   \t\t<meta charset=\"UTF-8\">\n   \t\t<link rel=\"stylesheet\" href=\"https://unpkg.com/element-ui/lib/theme-chalk/index.css\">\n   \t</head>\n   \t<body>\n   \t\t<div id=\"app\">\n   \t\t\t<el-table :data=\"tableData\" stripe style=\"width: 100%\">\n   \t\t\t\t<el-table-column prop=\"date\" label=\"日期\" width=\"180\">\n   \t\t\t\t</el-table-column>\n   \t\t\t\t<el-table-column prop=\"name\" label=\"姓名\" width=\"180\">\n   \t\t\t\t</el-table-column>\n   \t\t\t\t<el-table-column prop=\"address\" label=\"地址\">\n   \t\t\t\t</el-table-column>\n   \t\t\t</el-table>\n   \t\t</div>\n   \t</body>\n   \t<script src=\"https://unpkg.com/vue/dist/vue.js\"></script>\n   \t<script src=\"https://unpkg.com/element-ui/lib/index.js\"></script>\n   \t<script>\n   \t\tnew Vue({\n   \t\t\tel: '#app',\n   \t\t\tdata: {\n   \t\t\t\ttableData:  [\n   \t\t\t\t\t{\n   \t\t\t\t\t\tdate: '2016-05-02',\n   \t\t\t\t\t\tname: '王一霸',\n   \t\t\t\t\t\taddress: '上海市普陀区金沙江路 1518 弄'\n   \t\t\t\t\t}, \n   \t\t\t\t\t{\n   \t\t\t\t\t\tdate: '2016-05-04',\n   \t\t\t\t\t\tname: '刘二狗',\n   \t\t\t\t\t\taddress: '上海市普陀区金沙江路 1517 弄'\n   \t\t\t\t\t}, \n   \t\t\t\t\t{\n   \t\t\t\t\t\tdate: '2016-05-01',\n   \t\t\t\t\t\tname: '杨三萌',\n   \t\t\t\t\t\taddress: '上海市普陀区金沙江路 1519 弄'\n   \t\t\t\t\t}, \n   \t\t\t\t\t{\n   \t\t\t\t\t\tdate: '2016-05-03',\n   \t\t\t\t\t\tname: '陈四吹',\n   \t\t\t\t\t\taddress: '上海市普陀区金沙江路 1516 弄'\n   \t\t\t\t\t}\n   \t\t\t\t]\n   \t\t\t}\n   \t\t})\n   \t</script>\n   </html>\n   ```\n\n\n#### 报表框架 - [ECharts](<https://echarts.baidu.com>)\n\n百度出品的开源可视化库，常用于生成各种类型的报表。\n\n![](./res/baidu_echarts.png)\n\n#### 基于弹性盒子的CSS框架 - [Bulma](<https://bulma.io/>)\n\nBulma是一个基于Flexbox的现代化的CSS框架，其初衷就是移动优先（Mobile First），模块化设计，可以轻松用来实现各种简单或者复杂的内容布局，即使不懂CSS的开发者也能够使用它定制出漂亮的页面。\n\n```HTML\n<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n\t<meta charset=\"UTF-8\">\n\t<title>Bulma</title>\n\t<link href=\"https://cdn.bootcss.com/bulma/0.7.4/css/bulma.min.css\" rel=\"stylesheet\">\n\t<style type=\"text/css\">\n\t\tdiv { margin-top: 10px; }\n\t\t.column { color: #fff; background-color: #063; margin: 10px 10px; text-align: center; }\n\t</style>\n</head>\n<body>\n\t<div class=\"columns\">\n\t\t<div class=\"column\">1</div>\n\t\t<div class=\"column\">2</div>\n\t\t<div class=\"column\">3</div>\n\t\t<div class=\"column\">4</div>\n\t</div>\n\t<div>\n\t\t<a class=\"button is-primary\">Primary</a>\n\t\t<a class=\"button is-link\">Link</a>\n\t\t<a class=\"button is-info\">Info</a>\n\t\t<a class=\"button is-success\">Success</a>\n\t\t<a class=\"button is-warning\">Warning</a>\n\t\t<a class=\"button is-danger\">Danger</a>\n\t</div>\n\t<div>\n\t\t<progress class=\"progress is-danger is-medium\" max=\"100\">60%</progress>\n\t</div>\n\t<div>\n\t\t<table class=\"table is-hoverable\">\n\t\t\t<tr>\n\t\t\t\t<th>One</th>\n\t\t\t\t<th>Two</th>\n\t\t\t</tr>\n\t\t\t<tr>\n\t\t\t\t<td>Three</td>\n\t\t\t\t<td>Four</td>\n\t\t\t</tr>\n\t\t\t<tr>\n\t\t\t\t<td>Five</td>\n\t\t\t\t<td>Six</td>\n\t\t\t</tr>\n\t\t\t<tr>\n\t\t\t\t<td>Seven</td>\n\t\t\t\t<td>Eight</td>\n\t\t\t</tr>\n\t\t\t<tr>\n\t\t\t\t<td>Nine</td>\n\t\t\t\t<td>Ten</td>\n\t\t\t</tr>\n\t\t\t<tr>\n\t\t\t\t<td>Eleven</td>\n\t\t\t\t<td>Twelve</td>\n\t\t\t</tr>\n\t\t</table>\n\t</div>\n</body>\n</html>\n```\n\n#### 响应式布局框架 - [Bootstrap](<http://www.bootcss.com/>)\n\n用于快速开发Web应用程序的前端框架，支持响应式布局。\n\n1. 特点\n   - 支持主流的浏览器和移动设备\n   - 容易上手\n   - 响应式设计\n\n2. 内容\n   - 网格系统\n   - 封装的CSS\n   - 现成的组件\n   - JavaScript插件\n\n3. 可视化\n\n   ![](./res/bootstrap-layoutit.png)    ", "玩转Linux操作系统": "玩转Linux操作系统\n\n> **说明**：本文中对Linux命令的讲解都是基于名为CentOS的Linux发行版本，我自己使用的是阿里云服务器，系统版本为CentOS Linux release 7.6.1810。不同的Linux发行版本在Shell命令和工具程序上会有一些差别，但是这些差别是很小的。\n\n### 操作系统发展史\n\n只有硬件没有软件的计算机系统被称之为“裸机”，我们很难用“裸机”来完成计算机日常的工作（如存储和运算），所以必须用特定的软件来控制硬件的工作。最靠近计算机硬件的软件是系统软件，其中最为重要的就是“操作系统”。“操作系统”是控制和管理整个计算机硬件和软件资源、实现资源分配和任务调配、为系统用户以及其他软件提供接口和环境的程序的集合。\n\n#### 没有操作系统（手工操作）\n\n在计算机诞生之初没有操作系统的年代，人们先把程序纸带（或卡片）装上计算机，然后启动输入机把程序送入计算机，接着通过控制台开关启动程序运行。当程序执行完毕，打印机输出计算的结果，用户卸下并取走纸带（或卡片）。第二个用户上机，重复同样的步骤。在整个过程中用户独占机器，CPU等待手工操作，资源利用率极低。\n\n#### 批处理系统\n\n首先启动计算机上的一个监督程序，在监督程序的控制下，计算机能够自动的、成批的处理一个或多个用户的作业。完成一批作业后，监督程度又从输入机读取作业存入磁带机。按照上面的步骤重复处理任务。监督程序不停的处理各个作业，实现了作业的自动转接，减少了作业的建立时间和手工操作时间，提高了计算机资源的利用率。 批处理系统又可以分为单道批处理系统、多道批处理系统、联机批处理系统、脱机批处理系统。\n\n#### 分时系统和实时系统\n\n分时系统是把处理器的运行时间分成很短的时间片，按时间片轮流把处理机分配给各联机作业使用。 若某个作业在分配给它的时间片内不能完成其计算，则该作业暂时中断，把处理机让给另一作业使用，等待下一轮调度时再继续其运行。由于计算机速度很快，作业运行轮转得很快，给每个用户的感觉是他独占了一台计算机。而每个用户可以通过自己的终端向系统发出各种操作控制命令，在充分的人机交互情况下，完成作业的运行。为了解决分时系统不能及时响应用户指令的情况，又出现了能够在在严格的时间范围内完成事件处理，及时响应随机外部事件的实时系统。\n\n#### 通用操作系统\n\n1. 1960s：IBM的System/360系列的机器有了统一的操作系统OS/360。\n\n2. 1965年：AT&T的贝尔实验室加入GE和MIT的合作计划开始开发MULTICS。\n\n3. 1969年：MULTICS项目失败，Ken Tompson赋闲在家，为了玩“Space Travel”游戏用汇编语言在当时已经被淘汰的PDP-7上开发了Unics。\n\n   > 注：很难想象，Unix这么伟大的操作系统，居然是一个赋闲在家的程序员（关键是老婆回娘家还带上了孩子）在一台被淘汰的设备上为了玩游戏开发出来的。\n\n4. 1970年~1971年：Ken Thompson和Dennis Ritchie用B语言在PDP-11上重写了Unics，并在Brian Kernighan的建议下将其更名为Unix。\n\n   <img class=\"lazy\" data-src=\"/res/ken-and-dennis-pdp-11.png\" style=\"zoom:62%;\" />\n\n5. 1972年~1973年：Dennis Ritchie发明了C语言来取代可移植性较差的B语言，并开启了用C语言重写Unix的工作。\n\n6. 1974年：Unix推出了里程碑意义的第5版，几乎完全用C语言来实现。\n\n7. 1979年：从Unix第7版开始，AT&T发布新的使用条款，将Unix私有化。\n\n8. 1987年：Andrew S. Tanenbaum教授为了能在课堂上为学生讲解操作系统运作的细节，决定在不使用任何AT&T的源代码前提下，自行开发与Unix兼容的操作系统以避免版权上的争议，该系统被命名为Minix。\n\n   <img class=\"lazy\" data-src=\"/res/andrew.jpg\" style=\"zoom:50%;\" />\n\n9. 1991年：Linus Torvalds就读于芬兰赫尔辛基大学期间，尝试在Minix上做一些开发工作，但因为Minix只是作为教学用途的操作系统，功能并不强大，为了方便在学校的新闻组和邮件系统中读写和下载文件，Linus编写了磁盘驱动程序和文件系统，这些东西形成了Linux系统内核的雏形。\n\n   ![](./res/linus.png)\n\n下图是Unix操作系统家族的图谱。\n\n![](./res/history-of-unix.png)\n\n### Linux概述\n\nLinux是一个通用操作系统。一个操作系统要负责任务调度、内存分配、处理外围设备I/O等操作。操作系统通常由内核（运行其他程序，管理像磁盘、打印机等硬件设备的核心程序）和系统程序（设备驱动、底层库、shell、服务程序等）两部分组成。\n\nLinux内核是芬兰人Linus Torvalds开发的，于1991年9月发布。而Linux操作系统作为Internet时代的产物，它是由全世界许多开发者共同合作开发的，是一个自由的操作系统（注意自由和免费并不是同一个概念，想了解二者的差别可以[点击这里](https://www.debian.org/intro/free)）。\n\n### Linux系统优点\n\n1. 通用操作系统，不跟特定的硬件绑定。\n2. 用C语言编写，可移植性强，有内核编程接口。\n3. 支持多用户和多任务，支持安全的分层文件系统。\n4. 大量的实用程序，完善的网络功能以及强大的支持文档。\n5. 可靠的安全性和良好的稳定性，对开发者更友好。\n\n### Linux系统发行版本\n\n1. [Redhat](https://www.redhat.com/en)\n2. [Ubuntu](https://www.ubuntu.com/)\n3. [CentOS](https://www.centos.org/)\n4. [Fedora](https://getfedora.org/)\n5. [Debian](https://www.debian.org/)\n6. [openSUSE](https://www.opensuse.org/)\n\n### 基础命令\n\nLinux系统的命令通常都是如下所示的格式：\n\n```Shell\n命令名称 [命名参数] [命令对象]\n```\n\n1. 获取登录信息 - **w** / **who** / **last**/ **lastb**。\n\n   ```Shell\n   [root ~]# w\n    23:31:16 up 12:16,  2 users,  load average: 0.00, 0.01, 0.05\n   USER     TTY      FROM             LOGIN@   IDLE   JCPU   PCPU WHAT\n   root     pts/0    182.139.66.250   23:03    4.00s  0.02s  0.00s w\n   jackfrue pts/1    182.139.66.250   23:26    3:56   0.00s  0.00s -bash\n   [root ~]# who\n   root     pts/0        2018-04-12 23:03 (182.139.66.250)\n   jackfrued pts/1        2018-04-12 23:26 (182.139.66.250)\n   [root ~]# who am i\n   root     pts/0        2018-04-12 23:03 (182.139.66.250)\n   [root ~]# who mom likes\n   root     pts/0        2018-04-12 23:03 (182.139.66.250)\n   [root ~]# last\n   root     pts/0        117.136.63.184   Sun May 26 18:57   still logged in   \n   reboot   system boot  3.10.0-957.10.1. Mon May 27 02:52 - 19:10  (-7:-42)   \n   root     pts/4        117.136.63.184   Sun May 26 18:51 - crash  (08:01)    \n   root     pts/4        117.136.63.184   Sun May 26 18:49 - 18:49  (00:00)    \n   root     pts/3        117.136.63.183   Sun May 26 18:35 - crash  (08:17)    \n   root     pts/2        117.136.63.183   Sun May 26 18:34 - crash  (08:17)    \n   root     pts/0        117.136.63.183   Sun May 26 18:10 - crash  (08:42)    \n   ```\n\n2. 查看自己使用的Shell - **ps**。\n\n   Shell也被称为“壳”或“壳程序”，它是用户与操作系统内核交流的翻译官，简单的说就是人与计算机交互的界面和接口。目前很多Linux系统默认的Shell都是bash（<u>B</u>ourne <u>A</u>gain <u>SH</u>ell），因为它可以使用tab键进行命令和路径补全、可以保存历史命令、可以方便的配置环境变量以及执行批处理操作。\n\n   ```Shell\n   [root ~]# ps\n     PID TTY          TIME CMD\n    3531 pts/0    00:00:00 bash\n    3553 pts/0    00:00:00 ps\n   ```\n\n3. 查看命令的说明和位置 - **whatis** / **which** / **whereis**。\n\n   ```Shell\n   [root ~]# whatis ps\n   ps (1)        - report a snapshot of the current processes.\n   [root ~]# whatis python\n   python (1)    - an interpreted, interactive, object-oriented programming language\n   [root ~]# whereis ps\n   ps: /usr/bin/ps /usr/share/man/man1/ps.1.gz\n   [root ~]# whereis python\n   python: /usr/bin/python /usr/bin/python2.7 /usr/lib/python2.7 /usr/lib64/python2.7 /etc/python /usr/include/python2.7 /usr/share/man/man1/python.1.gz\n   [root ~]# which ps\n   /usr/bin/ps\n   [root ~]# which python\n   /usr/bin/python\n   ```\n\n4. 清除屏幕上显示的内容 - **clear**。\n\n5. 查看帮助文档 - **man** / **info** / **--help** / **apropos**。\n   ```Shell\n   [root@izwz97tbgo9lkabnat2lo8z ~]# ps --help\n   Usage:\n    ps [options]\n    Try 'ps --help <simple|list|output|threads|misc|all>'\n     or 'ps --help <s|l|o|t|m|a>'\n    for additional help text.\n   For more details see ps(1).\n   [root@izwz97tbgo9lkabnat2lo8z ~]# man ps\n   PS(1)                                User Commands                                PS(1)\n   NAME\n          ps - report a snapshot of the current processes.\n   SYNOPSIS\n          ps [options]\n   DESCRIPTION\n   ...\n   ```\n\n6. 查看系统和主机名 - **uname** / **hostname**。\n\n   ```Shell\n   [root@izwz97tbgo9lkabnat2lo8z ~]# uname\n   Linux\n   [root@izwz97tbgo9lkabnat2lo8z ~]# hostname\n   izwz97tbgo9lkabnat2lo8z\n   [root@iZwz97tbgo9lkabnat2lo8Z ~]# cat /etc/centos-release\n   CentOS Linux release 7.6.1810 (Core)\n   ```\n\n   > 说明：`cat`是连接文件内容并打印到标准输出的命令，后面会讲到该命令；`/etc`是Linux系统上的一个非常重要的目录，它保存了很多的配置文件；`centos-release`是该目录下的一个文件，因为我自己使用的Linux发行版本是CentOS 7.6，因此这里会有一个这样的文件。\n\n7. 时间和日期 - **date** / **cal**。\n\n   ```Shell\n   [root@iZwz97tbgo9lkabnat2lo8Z ~]# date\n   Wed Jun 20 12:53:19 CST 2018\n   [root@iZwz97tbgo9lkabnat2lo8Z ~]# cal\n         June 2018\n   Su Mo Tu We Th Fr Sa\n                   1  2\n    3  4  5  6  7  8  9\n   10 11 12 13 14 15 16\n   17 18 19 20 21 22 23\n   24 25 26 27 28 29 30\n   [root@iZwz97tbgo9lkabnat2lo8Z ~]# cal 5 2017\n         May 2017\n   Su Mo Tu We Th Fr Sa\n       1  2  3  4  5  6\n    7  8  9 10 11 12 13\n   14 15 16 17 18 19 20\n   21 22 23 24 25 26 27\n   28 29 30 31\n   ```\n\n8. 重启和关机 - **reboot** / **shutdown**。\n\n   ```Shell\n   [root ~]# shutdown -h +5\n   Shutdown scheduled for Sun 2019-05-26 19:34:27 CST, use 'shutdown -c' to cancel.\n   [root ~]# \n   Broadcast message from root (Sun 2019-05-26 19:29:27 CST):\n   \n   The system is going down for power-off at Sun 2019-05-26 19:34:27 CST!\n   [root ~]# shutdown -c\n   \n   Broadcast message from root (Sun 2019-05-26 19:30:22 CST):\n   \n   The system shutdown has been cancelled at Sun 2019-05-26 19:31:22 CST!\n   [root ~]# shutdown -r 23:58\n   Shutdown scheduled for Sun 2019-05-26 23:58:00 CST, use 'shutdown -c' to cancel.\n   [root ~]# shutdown -c\n   \n   Broadcast message from root (Sun 2019-05-26 19:31:06 CST):\n   \n   The system shutdown has been cancelled at Sun 2019-05-26 19:32:06 CST!\n   ```\n\n   > 说明：在执行`shutdown`命令时会向登录系统的用户发出警告，可以在命令后面跟上警告消息来替换默认的警告消息，也可以在`-h`参数后通过`now`来表示立刻关机。\n\n9. 退出登录 -  **exit** / **logout**。\n\n10. 查看历史命令 - **history**。\n\n  ```Shell\n  [root@iZwz97tbgo9lkabnat2lo8Z ~]# history\n  ...\n  452  ls\n  453  cd Python-3.6.5/\n  454  clear\n  455  history\n  [root@iZwz97tbgo9lkabnat2lo8Z ~]# !454\n  ```\n\n  > **说明**：查看到历史命令之后，可以用`!历史命令编号`来重新执行该命令；通过`history -c`可以清除历史命令。\n\n### 实用程序\n\n#### 文件和文件夹操作\n\n1. 创建/删除空目录 - **mkdir** / **rmdir**。\n\n   ```Shell\n   [root ~]# mkdir abc\n   [root ~]# mkdir -p xyz/abc\n   [root ~]# rmdir abc\n   ```\n\n2. 创建/删除文件 - **touch** / **rm**。\n\n   ```Shell\n   [root ~]# touch readme.txt\n   [root ~]# touch error.txt\n   [root ~]# rm error.txt\n   rm: remove regular empty file ‘error.txt’? y\n   [root ~]# rm -rf xyz\n   ```\n\n   - `touch`命令用于创建空白文件或修改文件时间。在Linux系统中一个文件有三种时间：\n     - 更改内容的时间 - mtime。\n     - 更改权限的时间 - ctime。\n     - 最后访问时间 - atime。\n   - `rm`的几个重要参数：\n     - `-i`：交互式删除，每个删除项都会进行询问。\n     - `-r`：删除目录并递归的删除目录中的文件和目录。\n     - `-f`：强制删除，忽略不存在的文件，没有任何提示。\n\n3. 切换和查看当前工作目录 - **cd** / **pwd**。\n\n   > 说明：`cd`命令后面可以跟相对路径（以当前路径作为参照）或绝对路径（以`/`开头）来切换到指定的目录，也可以用`cd ..`来返回上一级目录。请大家想一想，如果要返回到上上一级目录应该给`cd`命令加上什么样的参数呢？\n\n4. 查看目录内容 - **ls**。\n\n   - `-l`：以长格式查看文件和目录。\n   - `-a`：显示以点开头的文件和目录（隐藏文件）。\n   - `-R`：遇到目录要进行递归展开（继续列出目录下面的文件和目录）。\n   - `-d`：只列出目录，不列出其他内容。\n   - `-S` / `-t`：按大小/时间排序。\n\n5. 查看文件内容 - **cat** / **tac** / **head** / **tail** / **more** / **less** / **rev** / **od**。\n\n   ```Shell\n   [root ~]# wget http://www.sohu.com/ -O sohu.html\n   --2018-06-20 18:42:34--  http://www.sohu.com/\n   Resolving www.sohu.com (www.sohu.com)... 14.18.240.6\n   Connecting to www.sohu.com (www.sohu.com)|14.18.240.6|:80... connected.\n   HTTP request sent, awaiting response... 200 OK\n   Length: 212527 (208K) [text/html]\n   Saving to: ‘sohu.html’\n   100%[==================================================>] 212,527     --.-K/s   in 0.03s\n   2018-06-20 18:42:34 (7.48 MB/s) - ‘sohu.html’ saved [212527/212527]\n   [root ~]# cat sohu.html\n   ...\n   [root ~]# head -10 sohu.html\n   <!DOCTYPE html>\n   <html>\n   <head>\n   <title>搜狐</title>\n   <meta name=\"Keywords\" content=\"搜狐,门户网站,新媒体,网络媒体,新闻,财经,体育,娱乐,时尚,汽车,房产,科技,图片,论坛,微博,博客,视频,电影,电视剧\"/>\n   <meta name=\"Description\" content=\"搜狐网为用户提供24小时不间断的最新资讯，及搜索、邮件等网络服务。内容包括全球热点事件、突发新闻、时事评论、热播影视剧、体育赛事、行业动态、生活服务信息，以及论坛、博客、微博、我的搜狐等互动空间。\" />\n   <meta name=\"shenma-site-verification\" content=\"1237e4d02a3d8d73e96cbd97b699e9c3_1504254750\">\n   <meta charset=\"utf-8\"/>\n   <meta http-equiv=\"X-UA-Compatible\" content=\"IE=Edge,chrome=1\"/>\n   [root ~]# tail -2 sohu.html\n   </body>\n   </html>\n   [root ~]# less sohu.html\n   ...\n   [root ~]# cat -n sohu.html | more\n   ...\n   ```\n\n   > **说明**：上面用到了一个名为`wget`的命令，它是一个网络下载器程序，可以从指定的URL下载资源。\n\n6. 拷贝/移动文件 - **cp** / **mv**。\n\n   ```Shell\n   [root ~]# mkdir backup\n   [root ~]# cp sohu.html backup/\n   [root ~]# cd backup\n   [root backup]# ls\n   sohu.html\n   [root backup]# mv sohu.html sohu_index.html\n   [root backup]# ls\n   sohu_index.html\n   ```\n\n7. 文件重命名 - **rename**。\n\n  ```Shell\n  [root@iZwz97tbgo9lkabnat2lo8Z ~]# rename .htm .html *.htm\n  ```\n\n8. 查找文件和查找内容 - **find** / **grep**。\n\n   ```Shell\n   [root@iZwz97tbgo9lkabnat2lo8Z ~]# find / -name \"*.html\"\n   /root/sohu.html\n   /root/backup/sohu_index.html\n   [root@izwz97tbgo9lkabnat2lo8z ~]# find . -atime 7 -type f -print\n   [root@izwz97tbgo9lkabnat2lo8z ~]# find . -type f -size +2k\n   [root@izwz97tbgo9lkabnat2lo8z ~]# find . -type f -name \"*.swp\" -delete\n   [root@iZwz97tbgo9lkabnat2lo8Z ~]# grep \"<script>\" sohu.html -n\n   20:<script>\n   [root@iZwz97tbgo9lkabnat2lo8Z ~]# grep -E \\<\\/?script.*\\> sohu.html -n\n   20:<script>\n   22:</script>\n   24:<script src=\"//statics.itc.cn/web/v3/static/js/es5-shim-08e41cfc3e.min.js\"></script>\n   25:<script src=\"//statics.itc.cn/web/v3/static/js/es5-sham-1d5fa1124b.min.js\"></script>\n   26:<script src=\"//statics.itc.cn/web/v3/static/js/html5shiv-21fc8c2ba6.js\"></script>\n   29:<script type=\"text/javascript\">\n   52:</script>\n   ...\n   ```\n   > **说明**：`grep`在搜索字符串时可以使用正则表达式，如果需要使用正则表达式可以用`grep -E`或者直接使用`egrep`。\n\n9. 创建链接和查看链接 - **ln** / **readlink**。\n\n   ```Shell\n   [root@iZwz97tbgo9lkabnat2lo8Z ~]# ls -l sohu.html\n   -rw-r--r-- 1 root root 212131 Jun 20 19:15 sohu.html\n   [root@iZwz97tbgo9lkabnat2lo8Z ~]# ln /root/sohu.html /root/backup/sohu_backup\n   [root@iZwz97tbgo9lkabnat2lo8Z ~]# ls -l sohu.html\n   -rw-r--r-- 2 root root 212131 Jun 20 19:15 sohu.html\n   [root@iZwz97tbgo9lkabnat2lo8Z ~]# ln /root/sohu.html /root/backup/sohu_backup2\n   [root@iZwz97tbgo9lkabnat2lo8Z ~]# ls -l sohu.html\n   -rw-r--r-- 3 root root 212131 Jun 20 19:15 sohu.html\n   [root@iZwz97tbgo9lkabnat2lo8Z ~]# ln -s /etc/centos-release sysinfo\n   [root@iZwz97tbgo9lkabnat2lo8Z ~]# ls -l sysinfo\n   lrwxrwxrwx 1 root root 19 Jun 20 19:21 sysinfo -> /etc/centos-release\n   [root@iZwz97tbgo9lkabnat2lo8Z ~]# cat sysinfo\n   CentOS Linux release 7.4.1708 (Core)\n   [root@iZwz97tbgo9lkabnat2lo8Z ~]# cat /etc/centos-release\n   CentOS Linux release 7.4.1708 (Core)\n   ```\n\n   > **说明**：链接可以分为硬链接和软链接（符号链接）。硬链接可以认为是一个指向文件数据的指针，就像Python中对象的引用计数，每添加一个硬链接，文件的对应链接数就增加1，只有当文件的链接数为0时，文件所对应的存储空间才有可能被其他文件覆盖。我们平常删除文件时其实并没有删除硬盘上的数据，我们删除的只是一个指针，或者说是数据的一条使用记录，所以类似于“文件粉碎机”之类的软件在“粉碎”文件时除了删除文件指针，还会在文件对应的存储区域填入数据来保证文件无法再恢复。软链接类似于Windows系统下的快捷方式，当软链接链接的文件被删除时，软链接也就失效了。\n\n10. 压缩/解压缩和归档/解归档 - **gzip** / **gunzip** / **xz**。\n\n  ```Shell\n  [root@iZwz97tbgo9lkabnat2lo8Z ~]# wget http://download.redis.io/releases/redis-4.0.10.tar.gz\n  --2018-06-20 19:29:59--  http://download.redis.io/releases/redis-4.0.10.tar.gz\n  Resolving download.redis.io (download.redis.io)... 109.74.203.151\n  Connecting to download.redis.io (download.redis.io)|109.74.203.151|:80... connected.\n  HTTP request sent, awaiting response... 200 OK\n  Length: 1738465 (1.7M) [application/x-gzip]\n  Saving to: ‘redis-4.0.10.tar.gz’\n  100%[==================================================>] 1,738,465   70.1KB/s   in 74s\n  2018-06-20 19:31:14 (22.9 KB/s) - ‘redis-4.0.10.tar.gz’ saved [1738465/1738465]\n  [root@iZwz97tbgo9lkabnat2lo8Z ~]# ls redis*\n  redis-4.0.10.tar.gz\n  [root@iZwz97tbgo9lkabnat2lo8Z ~]# gunzip redis-4.0.10.tar.gz\n  [root@iZwz97tbgo9lkabnat2lo8Z ~]# ls redis*\n  redis-4.0.10.tar\n  ```\n\n11. 归档和解归档 - **tar**。\n\n   ```Shell\n   [root@iZwz97tbgo9lkabnat2lo8Z ~]# tar -xvf redis-4.0.10.tar\n   redis-4.0.10/\n   redis-4.0.10/.gitignore\n   redis-4.0.10/00-RELEASENOTES\n   redis-4.0.10/BUGS\n   redis-4.0.10/CONTRIBUTING\n   redis-4.0.10/COPYING\n   redis-4.0.10/INSTALL\n   redis-4.0.10/MANIFESTO\n   redis-4.0.10/Makefile\n   redis-4.0.10/README.md\n   redis-4.0.10/deps/\n   redis-4.0.10/deps/Makefile\n   redis-4.0.10/deps/README.md\n   ...\n   ```\n\n   > 说明：归档（也称为创建归档）和解归档都使用`tar`命令，通常创建归档需要`-cvf`三个参数，其中`c`表示创建（create），`v`表示显示创建归档详情（verbose），`f`表示指定归档的文件（file）；解归档需要加上`-xvf`参数，其中`x`表示抽取（extract），其他两个参数跟创建归档相同。\n\n12. 将标准输入转成命令行参数 - **xargs**。\n\n   下面的命令会将查找当前路径下的html文件，然后通过`xargs`将这些文件作为参数传给`rm`命令，实现查找并删除文件的操作。\n\n   ```Shell\n   [root@iZwz97tbgo9lkabnat2lo8Z ~]# find . -type f -name \"*.html\" | xargs rm -f\n   ```\n\n   下面的命令将a.txt文件中的多行内容变成一行输出到b.txt文件中，其中`<`表示从a.txt中读取输入，`>`表示将命令的执行结果输出到b.txt中。\n\n   ```Shell\n   [root@iZwz97tbgo9lkabnat2lo8Z ~]# xargs < a.txt > b.txt\n   ```\n\n   > **说明**：这个命令就像上面演示的那样常在管道（实现进程间通信的一种方式）和重定向（重新指定输入输出的位置）操作中用到，后面的内容中会讲到管道操作和输入输出重定向操作。\n\n13. 显示文件或目录 - **basename** / **dirname**。\n\n14. 其他相关工具。 \n\n   - **sort** - 对内容排序\n   - **uniq** - 去掉相邻重复内容\n   - **tr** - 替换指定内容为新内容\n   - **cut** / **paste** - 剪切/黏贴内容\n   - **split** - 拆分文件\n   - **file** - 判断文件类型\n   - **wc** - 统计文件行数、单词数、字节数\n   - **iconv** - 编码转换\n\n   ```Shell\n   [root ~]# cat foo.txt\n   grape\n   apple\n   pitaya\n   [root ~]# cat bar.txt\n   100\n   200\n   300\n   400\n   [root ~]# paste foo.txt bar.txt\n   grape   100\n   apple   200\n   pitaya  300\n           400\n   [root ~]# paste foo.txt bar.txt > hello.txt\n   [root ~]# cut -b 4-8 hello.txt\n   pe      10\n   le      20\n   aya     3\n   0\n   [root ~]# cat hello.txt | tr '\\t' ','\n   grape,100\n   apple,200\n   pitaya,300\n   ,400\n   [root ~]# split -l 100 sohu.html hello\n   [root ~]# wget https://www.baidu.com/img/bd_logo1.png\n   [root ~]# file bd_logo1.png\n   bd_logo1.png: PNG image data, 540 x 258, 8-bit colormap, non-interlaced\n   [root ~]# wc sohu.html\n     2979   6355 212527 sohu.html\n   [root ~]# wc -l sohu.html\n   2979 sohu.html\n   [root ~]# wget http://www.qq.com -O qq.html\n   [root ~]# iconv -f gb2312 -t utf-8 qq.html\n   ```\n\n#### 管道和重定向\n\n1. 管道的使用 - **\\|**。\n\n   例子：查找当前目录下文件个数。\n\n   ```Shell\n   [root ~]# find ./ | wc -l\n   6152\n   ```\n\n   例子：列出当前路径下的文件和文件夹，给每一项加一个编号。\n\n   ```Shell\n   [root ~]# ls | cat -n\n        1  dump.rdb\n        2  mongodb-3.6.5\n        3  Python-3.6.5\n        4  redis-3.2.11\n        5  redis.conf\n   ```\n\n   例子：查找record.log中包含AAA，但不包含BBB的记录的总数\n\n   ```Shell\n   [root ~]# cat record.log | grep AAA | grep -v BBB | wc -l\n   ```\n\n2. 输出重定向和错误重定向 - **\\>** / **>>** / **2\\>**。\n\n   ```Shell\n   [root ~]# cat readme.txt\n   banana\n   apple\n   grape\n   apple\n   grape\n   watermelon\n   pear\n   pitaya\n   [root ~]# cat readme.txt | sort | uniq > result.txt\n   [root ~]# cat result.txt\n   apple\n   banana\n   grape\n   pear\n   pitaya\n   watermelon\n   ```\n\n3. 输入重定向 - **\\<**。\n\n   ```Shell\n   [root ~]# echo 'hello, world!' > hello.txt\n   [root ~]# wall < hello.txt\n   [root ~]#\n   Broadcast message from root (Wed Jun 20 19:43:05 2018):\n   hello, world!\n   [root ~]# echo 'I will show you some code.' >> hello.txt\n   [root ~]# wall < hello.txt\n   [root ~]#\n   Broadcast message from root (Wed Jun 20 19:43:55 2018):\n   hello, world!\n   I will show you some code.\n   ```\n\n4. 多重定向 - **tee**。\n\n   下面的命令除了在终端显示命令`ls`的结果之外，还会追加输出到`ls.txt`文件中。\n\n   ```Shell\n   [root ~]# ls | tee -a ls.txt\n   ```\n\n#### 别名\n\n1. **alias**\n\n   ```Shell\n   [root ~]# alias ll='ls -l'\n   [root ~]# alias frm='rm -rf'\n   [root ~]# ll\n   ...\n   drwxr-xr-x  2 root       root   4096 Jun 20 12:52 abc\n   ...\n   [root ~]# frm abc\n   ```\n\n2. **unalias**\n\n   ```Shell\n   [root ~]# unalias frm\n   [root ~]# frm sohu.html\n   -bash: frm: command not found\n   ```\n\n#### 文本处理\n\n1. 字符流编辑器 - **sed**。\n\n   sed是操作、过滤和转换文本内容的工具。假设有一个名为fruit.txt的文件，内容如下所示。\n\n   ```Shell\n   [root ~]# cat -n fruit.txt \n        1  banana\n        2  grape\n        3  apple\n        4  watermelon\n        5  orange\n   ```\n\n   接下来，我们在第2行后面添加一个pitaya。\n\n   ```Shell\n   [root ~]# sed '2a pitaya' fruit.txt \n   banana\n   grape\n   pitaya\n   apple\n   watermelon\n   orange\n   ```\n\n   > 注意：刚才的命令和之前我们讲过的很多命令一样并没有改变fruit.txt文件，而是将添加了新行的内容输出到终端中，如果想保存到fruit.txt中，可以使用输出重定向操作。\n\n   在第2行前面插入一个waxberry。\n\n   ```Shell\n   [root ~]# sed '2i waxberry' fruit.txt\n   banana\n   waxberry\n   grape\n   apple\n   watermelon\n   orange\n   ```\n\n   删除第3行。\n\n   ```Shell\n   [root ~]# sed '3d' fruit.txt\n   banana\n   grape\n   watermelon\n   orange\n   ```\n\n   删除第2行到第4行。\n\n   ```Shell\n   [root ~]# sed '2,4d' fruit.txt\n   banana\n   orange\n   ```\n\n   将文本中的字符a替换为@。\n\n   ```Shell\n   [root ~]# sed 's#a#@#' fruit.txt \n   b@nana\n   gr@pe\n   @pple\n   w@termelon\n   or@nge\n   ```\n\n   将文本中的字符a替换为@，使用全局模式。\n\n   ```Shell\n   [root ~]# sed 's#a#@#g' fruit.txt \n   b@n@n@\n   gr@pe\n   @pple\n   w@termelon\n   or@nge\n   ```\n\n2. 模式匹配和处理语言 - **awk**。\n\n   awk是一种编程语言，也是Linux系统中处理文本最为强大的工具，它的作者之一和现在的维护者就是之前提到过的Brian Kernighan（ken和dmr最亲密的伙伴）。通过该命令可以从文本中提取出指定的列、用正则表达式从文本中取出我们想要的内容、显示指定的行以及进行统计和运算，总之它非常强大。\n\n   假设有一个名为fruit2.txt的文件，内容如下所示。\n\n   ```Shell\n   [root ~]# cat fruit2.txt \n   1       banana      120\n   2       grape       500\n   3       apple       1230\n   4       watermelon  80\n   5       orange      400\n   ```\n\n   显示文件的第3行。\n\n   ```Shell\n   [root ~]# awk 'NR==3' fruit2.txt \n   3       apple       1230\n   ```\n\n   显示文件的第2列。\n\n   ```Shell\n   [root ~]# awk '{print $2}' fruit2.txt \n   banana\n   grape\n   apple\n   watermelon\n   orange\n   ```\n\n   显示文件的最后一列。\n\n   ```Shell\n   [root ~]# awk '{print $NF}' fruit2.txt \n   120\n   500\n   1230\n   80\n   400\n   ```\n\n   输出末尾数字大于等于300的行。\n\n   ```Shell\n   [root ~]# awk '{if($3 >= 300) {print $0}}' fruit2.txt \n   2       grape       500\n   3       apple       1230\n   5       orange      400\n   ```\n\n   上面展示的只是awk命令的冰山一角，更多的内容留给读者自己在实践中去探索。\n\n### 用户管理\n\n1. 创建和删除用户 - **useradd** / **userdel**。\n\n   ```Shell\n   [root home]# useradd hellokitty\n   [root home]# userdel hellokitty\n   ```\n\n   - `-d` - 创建用户时为用户指定用户主目录\n   - `-g` - 创建用户时指定用户所属的用户组\n\n2. 创建和删除用户组 - **groupadd** / **groupdel**。\n\n   > 说明：用户组主要是为了方便对一个组里面所有用户的管理。\n\n3. 修改密码 - **passwd**。\n\n   ```Shell\n   [root ~]# passwd hellokitty\n   New password: \n   Retype new password: \n   passwd: all authentication tokens updated successfully.\n   ```\n\n   > 说明：输入密码和确认密码没有回显且必须一气呵成的输入完成（不能使用退格键），密码和确认密码需要一致。如果使用`passwd`命令时没有指定命令作用的对象，则表示要修改当前用户的密码。如果想批量修改用户密码，可以使用`chpasswd`命令。\n\n   - `-l` / `-u` - 锁定/解锁用户。\n   - `-d` - 清除用户密码。\n   - `-e` - 设置密码立即过期，用户登录时会强制要求修改密码。\n   - `-i` - 设置密码过期多少天以后禁用该用户。\n\n4. 查看和修改密码有效期 - **chage**。\n\n   设置hellokitty用户100天后必须修改密码，过期前15天通知该用户，过期后7天禁用该用户。\n\n   ```Shell\n   chage -M 100 -W 15 -I 7 hellokitty\n   ```\n\n5. 切换用户 - **su**。\n\n   ```Shell\n   [root ~]# su hellokitty\n   [hellokitty root]$\n   ```\n\n6. 以管理员身份执行命令 - **sudo**。\n\n   ```Shell\n   [hellokitty ~]$ ls /root\n   ls: cannot open directory /root: Permission denied\n   [hellokitty ~]$ sudo ls /root\n   [sudo] password for hellokitty:\n   ```\n\n   > **说明**：如果希望用户能够以管理员身份执行命令，用户必须要出现在sudoers名单中，sudoers文件在 `/etc`目录下，如果希望直接编辑该文件也可以使用下面的命令。\n\n7. 编辑sudoers文件 - **visudo**。\n\n   这里使用的编辑器是vi，关于vi的知识在后面有讲解。该文件的部分内容如下所示：\n\n   ```\n   ## Allow root to run any commands anywhere \n   root    ALL=(ALL)   ALL\n   \n   ## Allows members of the 'sys' group to run networking, software, \n   ## service management apps and more.\n   # %sys ALL = NETWORKING, SOFTWARE, SERVICES, STORAGE, DELEGATING, PROCESSES, LOCATE, DRIVERS\n   ## Allows people in group wheel to run all commands\n   %wheel  ALL=(ALL)   ALL\n   \n   ## Same thing without a password\n   # %wheel    ALL=(ALL)   NOPASSWD: ALL\n   \n   ## Allows members of the users group to mount and unmount the\n   ## cdrom as root\n   # %users  ALL=/sbin/mount /mnt/cdrom, /sbin/umount /mnt/cdrom\n   \n   ## Allows members of the users group to shutdown this system\n   # %users  localhost=/sbin/shutdown -h now\n   ```\n\n8. 显示用户与用户组的信息 - **id**。\n\n9. 给其他用户发消息 -**write** / **wall**。\n\n   发送方：\n\n   ```Shell\n   [root ~]# write hellokitty\n   Dinner is on me.\n   Call me at 6pm.\n   ```\n\n   接收方：\n\n   ```Shell\n   [hellokitty ~]$ \n   Message from root on pts/0 at 17:41 ...\n   Dinner is on me.\n   Call me at 6pm.\n   EOF\n   ```\n\n10. 查看/设置是否接收其他用户发送的消息 - **mesg**。\n\n   ```Shell\n   [hellokitty ~]$ mesg\n   is y\n   [hellokitty ~]$ mesg n\n   [hellokitty ~]$ mesg\n   is n\n   ```\n\n### 文件系统\n\n#### 文件和路径\n\n1. 命名规则：文件名的最大长度与文件系统类型有关，一般情况下，文件名不应该超过255个字符，虽然绝大多数的字符都可以用于文件名，但是最好使用英文大小写字母、数字、下划线、点这样的符号。文件名中虽然可以使用空格，但应该尽可能避免使用空格，否则在输入文件名时需要用将文件名放在双引号中或者通过`\\`对空格进行转义。\n2. 扩展名：在Linux系统下文件的扩展名是可选的，但是使用扩展名有助于对文件内容的理解。有些应用程序要通过扩展名来识别文件，但是更多的应用程序并不依赖文件的扩展名，就像`file`命令在识别文件时并不是依据扩展名来判定文件的类型。\n3. 隐藏文件：以点开头的文件在Linux系统中是隐藏文件（不可见文件）。\n\n#### 目录结构\n\n1. /bin - 基本命令的二进制文件。\n2. /boot - 引导加载程序的静态文件。\n3. /dev - 设备文件。\n4. **/etc** - 配置文件。\n5. /home - 普通用户主目录的父目录。\n6. /lib - 共享库文件。\n7. /lib64 - 共享64位库文件。\n8. /lost+found - 存放未链接文件。\n9. /media - 自动识别设备的挂载目录。\n10. /mnt - 临时挂载文件系统的挂载点。\n11. /opt - 可选插件软件包安装位置。\n12. /proc -  内核和进程信息。\n13. **/root** - 超级管理员用户主目录。\n14. /run - 存放系统运行时需要的东西。\n15. /sbin - 超级用户的二进制文件。\n16. /sys - 设备的伪文件系统。\n17. /tmp - 临时文件夹。\n18. **/usr** - 用户应用目录。\n19. /var - 变量数据目录。\n\n#### 访问权限\n\n1. **chmod** - 改变文件模式比特。\n\n   ```Shell\n   [root ~]# ls -l\n   ...\n   -rw-r--r--  1 root       root 211878 Jun 19 16:06 sohu.html\n   ...\n   [root ~]# chmod g+w,o+w sohu.html\n   [root ~]# ls -l\n   ...\n   -rw-rw-rw-  1 root       root 211878 Jun 19 16:06 sohu.html\n   ...\n   [root ~]# chmod 644 sohu.html\n   [root ~]# ls -l\n   ...\n   -rw-r--r--  1 root       root 211878 Jun 19 16:06 sohu.html\n   ...\n   ```\n   > 说明：通过上面的例子可以看出，用`chmod`改变文件模式比特有两种方式：一种是字符设定法，另一种是数字设定法。除了`chmod`之外，可以通过`umask`来设定哪些权限将在新文件的默认权限中被删除。\n\n   长格式查看目录或文件时显示结果及其对应权限的数值如下表所示。\n\n   ![](./res/file-mode.png)\n\n2. **chown** - 改变文件所有者。\n\n    ```Shell\n    [root ~]# ls -l\n    ...\n    -rw-r--r--  1 root root     54 Jun 20 10:06 readme.txt\n    ...\n    [root ~]# chown hellokitty readme.txt\n    [root ~]# ls -l\n    ...\n    -rw-r--r--  1 hellokitty root     54 Jun 20 10:06 readme.txt\n    ...\n    ```\n\n3. **chgrp** - 改变用户组。\n\n#### 磁盘管理\n\n1. 列出文件系统的磁盘使用状况 - **df**。\n\n   ```Shell\n   [root ~]# df -h\n   Filesystem      Size  Used Avail Use% Mounted on\n   /dev/vda1        40G  5.0G   33G  14% /\n   devtmpfs        486M     0  486M   0% /dev\n   tmpfs           497M     0  497M   0% /dev/shm\n   tmpfs           497M  356K  496M   1% /run\n   tmpfs           497M     0  497M   0% /sys/fs/cgroup\n   tmpfs           100M     0  100M   0% /run/user/0\n   ```\n\n2. 磁盘分区表操作 - **fdisk**。\n\n   ```Shell\n   [root ~]# fdisk -l\n   Disk /dev/vda: 42.9 GB, 42949672960 bytes, 83886080 sectors\n   Units = sectors of 1 * 512 = 512 bytes\n   Sector size (logical/physical): 512 bytes / 512 bytes\n   I/O size (minimum/optimal): 512 bytes / 512 bytes\n   Disk label type: dos\n   Disk identifier: 0x000a42f4\n      Device Boot      Start         End      Blocks   Id  System\n   /dev/vda1   *        2048    83884031    41940992   83  Linux\n   Disk /dev/vdb: 21.5 GB, 21474836480 bytes, 41943040 sectors\n   Units = sectors of 1 * 512 = 512 bytes\n   Sector size (logical/physical): 512 bytes / 512 bytes\n   I/O size (minimum/optimal): 512 bytes / 512 bytes\n   ```\n\n3. 磁盘分区工具 - **parted**。\n\n4. 格式化文件系统 - **mkfs**。\n\n   ```Shell\n   [root ~]# mkfs -t ext4 -v /dev/sdb\n   ```\n\n   - `-t` - 指定文件系统的类型。\n   - `-c` - 创建文件系统时检查磁盘损坏情况。\n   - `-v` - 显示详细信息。\n\n5. 文件系统检查 - **fsck**。\n\n6. 转换或拷贝文件 - **dd**。\n\n7. 挂载/卸载 - **mount** / **umount**。\n\n8. 创建/激活/关闭交换分区 - **mkswap** / **swapon** / **swapoff**。\n\n> **说明**：执行上面这些命令会带有一定的风险，如果不清楚这些命令的用法，最好不用随意使用，在使用的过程中，最好对照参考资料进行操作，并在操作前确认是否要这么做。\n\n### 编辑器 - vim\n\n1. 启动vim。可以通过`vi`或`vim`命令来启动vim，启动时可以指定文件名来打开一个文件，如果没有指定文件名，也可以在保存的时候指定文件名。\n\n   ```Shell\n   [root ~]# vim guess.py\n   ```\n\n2. 命令模式、编辑模式和末行模式：启动vim进入的是命令模式（也称为Normal模式），在命令模式下输入英文字母`i`会进入编辑模式（Insert模式），屏幕下方出现`-- INSERT --`提示；在编辑模式下按下`Esc`会回到命令模式，此时如果输入英文`:`会进入末行模式，在末行模式下输入`q!`可以在不保存当前工作的情况下强行退出vim；在命令模式下输入`v`会进入可视模式（Visual模式），可以用光标选择一个区域再完成对应的操作。\n\n3. 保存和退出vim：在命令模式下输入`:` 进入末行模式，输入`wq`可以实现保存退出；如果想放弃编辑的内容输入`q!`强行退出，这一点刚才已经提到过了；在命令模式下也可以直接输入`ZZ`实现保存退出。如果只想保存文件不退出，那么可以在末行模式下输入`w`；可以在`w`后面输入空格再指定要保存的文件名。\n\n4. 光标操作。\n\n   - 在命令模式下可以通过`h`、`j`、`k`、`l`来控制光标向左、下、上、右的方向移动，可以在字母前输入数字来表示移动的距离，例如：`10h`表示向左移动10个字符。\n   - 在命令模式下可以通过`Ctrl+y`和`Ctrl+e`来实现向上、向下滚动一行文本的操作，可以通过`Ctrl+f`和`Ctrl+b`来实现向前和向后翻页的操作。\n   - 在命令模式下可以通过输入英文字母`G`将光标移到文件的末尾，可以通过`gg`将光标移到文件的开始，也可以通过在`G`前输入数字来将光标移动到指定的行。\n\n5. 文本操作。\n\n   - 删除：在命令模式下可以用`dd`来删除整行；可以在`dd`前加数字来指定删除的行数；可以用`d$`来实现删除从光标处删到行尾的操作，也可以通过`d0`来实现从光标处删到行首的操作；如果想删除一个单词，可以使用`dw`；如果要删除全文，可以在输入`:%d`（其中`:`用来从命令模式进入末行模式）。\n   - 复制和粘贴：在命令模式下可以用`yy`来复制整行；可以在`yy`前加数字来指定复制的行数；可以通过`p`将复制的内容粘贴到光标所在的地方。\n   - 撤销和恢复：在命令模式下输入`u`可以撤销之前的操作；通过`Ctrl+r`可以恢复被撤销的操作。\n   - 对内容进行排序：在命令模式下输入`%!sort`。\n\n6. 查找和替换。\n\n   - 查找操作需要输入`/`进入末行模式并提供正则表达式来匹配与之对应的内容，例如：`/doc.*\\.`，输入`n`来向前搜索，也可以输入`N`来向后搜索。\n   - 替换操作需要输入`:`进入末行模式并指定搜索的范围、正则表达式以及替换后的内容和匹配选项，例如：`:1,$s/doc.*/hello/gice`，其中：\n     - `g` - global：全局匹配。\n     - `i` - ignore case：忽略大小写匹配。\n     - `c` - confirm：替换时需要确认。\n     - `e` - error：忽略错误。\n\n7. 参数设定：在输入`:`进入末行模式后可以对vim进行设定。\n\n   - 设置Tab键的空格数：`set ts=4`\n\n   - 设置显示/不显示行号：`set nu` / `set nonu`\n\n   - 设置启用/关闭高亮语法：`syntax on` / `syntax off`\n\n   - 设置显示标尺（光标所在的行和列）： `set ruler`\n\n   - 设置启用/关闭搜索结果高亮：`set hls` / `set nohls`\n\n     > 说明：如果希望上面的这些设定在每次启动vim时都能自动生效，需要将这些设定写到用户主目录下的.vimrc文件中。\n\n8. 高级技巧\n\n   - 比较多个文件。\n\n     ```Shell\n     [root ~]# vim -d foo.txt bar.txt\n     ```\n     ![](./res/vim-diff.png)\n\n   - 打开多个文件。\n\n     ```Shell\n     [root ~]# vim foo.txt bar.txt hello.txt\n     ```\n\n     启动vim后只有一个窗口显示的是foo.txt，可以在末行模式中输入`ls`查看到打开的三个文件，也可以在末行模式中输入`b <num>`来显示另一个文件，例如可以用`:b 2`将bar.txt显示出来，可以用`:b 3`将hello.txt显示出来。\n\n   - 拆分和切换窗口。\n\n     可以在末行模式中输入`sp`或`vs`来实现对窗口的水平或垂直拆分，这样我们就可以同时打开多个编辑窗口，通过按两次`Ctrl+w`就可以实现编辑窗口的切换，在一个窗口中执行退出操作只会关闭对应的窗口，其他的窗口继续保留。\n\n     ![](./res/vim-multi-window.png)\n\n   - 映射快捷键：在vim下可以将一些常用操作映射为快捷键来提升工作效率。\n     - 例子1：在命令模式下输入`F4`执行从第一行开始删除10000行代码的操作。\n\n       `:map <F4> gg10000dd`。\n\n       例子2：在编辑模式下输入`__main`直接补全为`if __name__ == '__main__':`。\n\n       `:inoremap __main if __name__ == '__main__':`\n\n     > 说明：上面例子2的`inoremap`中的`i`表示映射的键在编辑模式使用， `nore`表示不要递归，这一点非常重要，否则如果键对应的内容中又出现键本身，就会引发递归（相当于进入了死循环）。如果希望映射的快捷键每次启动vim时都能生效，需要将映射写到用户主目录下的.vimrc文件中。\n\n   - 录制宏。\n\n     - 在命令模式下输入`qa`开始录制宏（其中`a`是寄存器的名字，也可以是其他英文字母或0-9的数字）。\n\n     - 执行你的操作（光标操作、编辑操作等），这些操作都会被录制下来。\n\n     - 如果录制的操作已经完成了，按`q`结束录制。\n\n     - 通过`@a`（`a`是刚才使用的寄存器的名字）播放宏，如果要多次执行宏可以在前面加数字，例如`100@a`表示将宏播放100次。\n\n     - 可以试一试下面的例子来体验录制宏的操作，该例子来源于[Harttle Land网站](https://harttle.land/tags.html#Vim)，该网站上提供了很多关于vim的使用技巧，有兴趣的可以了解一下。\n\n       ![](./res/vim-macro.png)\n\n### 软件安装和配置\n\n#### 使用包管理工具\n\n1. **yum** - Yellowdog Updater Modified。\n   - `yum search`：搜索软件包，例如`yum search nginx`。\n   - `yum list installed`：列出已经安装的软件包，例如`yum list installed | grep zlib`。\n   - `yum install`：安装软件包，例如`yum install nginx`。\n   - `yum remove`：删除软件包，例如`yum remove nginx`。\n   - `yum update`：更新软件包，例如`yum update`可以更新所有软件包，而`yum update tar`只会更新tar。\n   - `yum check-update`：检查有哪些可以更新的软件包。\n   - `yum info`：显示软件包的相关信息，例如`yum info nginx`。\n2. **rpm** - Redhat Package Manager。\n   - 安装软件包：`rpm -ivh <packagename>.rpm`。\n   - 移除软件包：`rpm -e <packagename>`。\n   - 查询软件包：`rpm -qa`，例如可以用`rpm -qa | grep mysql`来检查是否安装了MySQL相关的软件包。\n\n下面以Nginx为例，演示如何使用yum安装软件。\n\n```Shell\n[root ~]# yum -y install nginx\n...\nInstalled:\n  nginx.x86_64 1:1.12.2-2.el7\nDependency Installed:\n  nginx-all-modules.noarch 1:1.12.2-2.el7\n  nginx-mod-http-geoip.x86_64 1:1.12.2-2.el7\n  nginx-mod-http-image-filter.x86_64 1:1.12.2-2.el7\n  nginx-mod-http-perl.x86_64 1:1.12.2-2.el7\n  nginx-mod-http-xslt-filter.x86_64 1:1.12.2-2.el7\n  nginx-mod-mail.x86_64 1:1.12.2-2.el7\n  nginx-mod-stream.x86_64 1:1.12.2-2.el7\nComplete!\n[root ~]# yum info nginx\nLoaded plugins: fastestmirror\nLoading mirror speeds from cached hostfile\nInstalled Packages\nName        : nginx\nArch        : x86_64\nEpoch       : 1\nVersion     : 1.12.2\nRelease     : 2.el7\nSize        : 1.5 M\nRepo        : installed\nFrom repo   : epel\nSummary     : A high performance web server and reverse proxy server\nURL         : http://nginx.org/\nLicense     : BSD\nDescription : Nginx is a web server and a reverse proxy server for HTTP, SMTP, POP3 and\n            : IMAP protocols, with a strong focus on high concurrency, performance and low\n            : memory usage.\n[root ~]# nginx -v\nnginx version: nginx/1.12.2\n```\n\n移除Nginx。\n\n```Shell\n[root ~]# yum -y remove nginx\n```\n\n下面以MySQL为例，演示如何使用rpm安装软件。要安装MySQL需要先到[MySQL官方网站](https://www.mysql.com/)下载对应的[RPM文件](https://dev.mysql.com/downloads/mysql/)，当然要选择和你使用的Linux系统对应的版本。MySQL现在是Oracle公司旗下的产品，在MySQL被收购后，MySQL的作者重新制作了一个MySQL的分支MariaDB，可以通过yum进行安装。\n\n```Shell\n[root mysql]# ls\nmysql-community-client-5.7.22-1.el7.x86_64.rpm\nmysql-community-common-5.7.22-1.el7.x86_64.rpm\nmysql-community-libs-5.7.22-1.el7.x86_64.rpm\nmysql-community-server-5.7.22-1.el7.x86_64.rpm\n[root mysql]# yum -y remove mariadb-libs\n[root mysql]# yum -y install libaio\n[root mysql]#rpm -ivh mysql-community-common-5.7.26-1.el7.x86_64.rpm\n...\n[root mysql]#rpm -ivh mysql-community-libs-5.7.26-1.el7.x86_64.rpm\n...\n[root mysql]#rpm -ivh mysql-community-client-5.7.26-1.el7.x86_64.rpm\n...\n[root mysql]#rpm -ivh mysql-community-server-5.7.26-1.el7.x86_64.rpm\n...\n```\n\n> 说明：由于MySQL和[MariaDB](https://mariadb.org/)的底层依赖库是有冲突的，所以上面我们首先用`yum`移除了名为mariadb-libs的依赖库并安装了名为libaio支持异步I/O操作的依赖库。关于MySQL和MariaDB之间的关系，可以阅读[维基百科](https://zh.wikipedia.org/wiki/MariaDB)上关于MariaDB的介绍。\n\n移除安装的MySQL。\n\n```Shell\n[root ~]# rpm -qa | grep mysql | xargs rpm -e\n```\n\n#### 下载解压配置环境变量\n\n下面以安装MongoDB为例，演示这类软件应该如何安装。\n\n```Shell\n[root ~]# wget https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-rhel70-3.6.5.tgz\n--2018-06-21 18:32:53--  https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-rhel70-3.6.5.tgz\nResolving fastdl.mongodb.org (fastdl.mongodb.org)... 52.85.83.16, 52.85.83.228, 52.85.83.186, ...\nConnecting to fastdl.mongodb.org (fastdl.mongodb.org)|52.85.83.16|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 100564462 (96M) [application/x-gzip]\nSaving to: ‘mongodb-linux-x86_64-rhel70-3.6.5.tgz’\n100%[==================================================>] 100,564,462  630KB/s   in 2m 9s\n2018-06-21 18:35:04 (760 KB/s) - ‘mongodb-linux-x86_64-rhel70-3.6.5.tgz’ saved [100564462/100564462]\n[root ~]# gunzip mongodb-linux-x86_64-rhel70-3.6.5.tgz\n[root ~]# tar -xvf mongodb-linux-x86_64-rhel70-3.6.5.tar\nmongodb-linux-x86_64-rhel70-3.6.5/README\nmongodb-linux-x86_64-rhel70-3.6.5/THIRD-PARTY-NOTICES\nmongodb-linux-x86_64-rhel70-3.6.5/MPL-2\nmongodb-linux-x86_64-rhel70-3.6.5/GNU-AGPL-3.0\nmongodb-linux-x86_64-rhel70-3.6.5/bin/mongodump\nmongodb-linux-x86_64-rhel70-3.6.5/bin/mongorestore\nmongodb-linux-x86_64-rhel70-3.6.5/bin/mongoexport\nmongodb-linux-x86_64-rhel70-3.6.5/bin/mongoimport\nmongodb-linux-x86_64-rhel70-3.6.5/bin/mongostat\nmongodb-linux-x86_64-rhel70-3.6.5/bin/mongotop\nmongodb-linux-x86_64-rhel70-3.6.5/bin/bsondump\nmongodb-linux-x86_64-rhel70-3.6.5/bin/mongofiles\nmongodb-linux-x86_64-rhel70-3.6.5/bin/mongoreplay\nmongodb-linux-x86_64-rhel70-3.6.5/bin/mongoperf\nmongodb-linux-x86_64-rhel70-3.6.5/bin/mongod\nmongodb-linux-x86_64-rhel70-3.6.5/bin/mongos\nmongodb-linux-x86_64-rhel70-3.6.5/bin/mongo\nmongodb-linux-x86_64-rhel70-3.6.5/bin/install_compass\n[root ~]# vim .bash_profile\n...\nPATH=$PATH:$HOME/bin:$HOME/mongodb-linux-x86_64-rhel70-3.6.5/bin\nexport PATH\n...\n[root ~]# source .bash_profile\n[root ~]# mongod --version\ndb version v3.6.5\ngit version: a20ecd3e3a174162052ff99913bc2ca9a839d618\nOpenSSL version: OpenSSL 1.0.1e-fips 11 Feb 2013\nallocator: tcmalloc\nmodules: none\nbuild environment:\n    distmod: rhel70\n    distarch: x86_64\n    target_arch: x86_64\n[root ~]# mongo --version\nMongoDB shell version v3.6.5\ngit version: a20ecd3e3a174162052ff99913bc2ca9a839d618\nOpenSSL version: OpenSSL 1.0.1e-fips 11 Feb 2013\nallocator: tcmalloc\nmodules: none\nbuild environment:\n    distmod: rhel70\n    distarch: x86_64\n    target_arch: x86_64\n```\n\n> 说明：当然也可以通过yum来安装MongoDB，具体可以参照[官方网站](https://docs.mongodb.com/master/administration/install-on-linux/)上给出的说明。\n\n#### 源代码构建安装\n\n1. 安装Python 3.6。\n\n   ```Shell\n   [root ~]# yum install gcc\n   [root ~]# wget https://www.python.org/ftp/python/3.6.5/Python-3.6.5.tgz\n   [root ~]# gunzip Python-3.6.5.tgz\n   [root ~]# tar -xvf Python-3.6.5.tar\n   [root ~]# cd Python-3.6.5\n   [root ~]# ./configure --prefix=/usr/local/python36 --enable-optimizations\n   [root ~]# yum -y install zlib-devel bzip2-devel openssl-devel ncurses-devel sqlite-devel readline-devel tk-devel gdbm-devel db4-devel libpcap-devel xz-devel\n   [root ~]# make && make install\n   ...\n   [root ~]# ln -s /usr/local/python36/bin/python3.6 /usr/bin/python3\n   [root ~]# python3 --version\n   Python 3.6.5\n   [root ~]# python3 -m pip install -U pip\n   [root ~]# pip3 --version\n   ```\n\n   > 说明：上面在安装好Python之后还需要注册PATH环境变量，将Python安装路径下bin文件夹的绝对路径注册到PATH环境变量中。注册环境变量可以修改用户主目录下的.bash_profile或者/etc目录下的profile文件，二者的区别在于前者相当于是用户环境变量，而后者相当于是系统环境变量。\n\n2. 安装Redis-3.2.12。\n\n   ```Shell\n   [root ~]# wget http://download.redis.io/releases/redis-3.2.12.tar.gz\n   [root ~]# gunzip redis-3.2.12.tar.gz\n   [root ~]# tar -xvf redis-3.2.12.tar\n   [root ~]# cd redis-3.2.12\n   [root ~]# make && make install\n   [root ~]# redis-server --version\n   Redis server v=3.2.12 sha=00000000:0 malloc=jemalloc-4.0.3 bits=64 build=5bc5cd3c03d6ceb6\n   [root ~]# redis-cli --version\n   redis-cli 3.2.12\n   ```\n\n### 配置服务\n\n我们可以Linux系统下安装和配置各种服务，也就是说我们可以把Linux系统打造成数据库服务器、Web服务器、缓存服务器、文件服务器、消息队列服务器等等。Linux下的大多数服务都被设置为守护进程（驻留在系统后台运行，但不会因为服务还在运行而导致Linux无法停止运行），所以我们安装的服务通常名字后面都有一个字母`d`，它是英文单词`daemon`的缩写，例如：防火墙服务叫firewalld，我们之前安装的MySQL服务叫mysqld，Apache服务器叫httpd等。在安装好服务之后，可以使用`systemctl`命令或`service`命令来完成对服务的启动、停止等操作，具体操作如下所示。\n\n1. 启动防火墙服务。\n\n   ```Shell\n   [root ~]# systemctl start firewalld\n   ```\n\n2. 终止防火墙服务。\n\n   ```Shell\n   [root ~]# systemctl stop firewalld\n   ```\n\n3. 重启防火墙服务。\n\n   ```Shell\n   [root ~]# systemctl restart firewalld\n   ```\n\n4. 查看防火墙服务状态。\n\n    ```Shell\n    [root ~]# systemctl status firewalld\n    ```\n\n5. 设置/禁用防火墙服务开机自启。\n\n   ```Shell\n   [root ~]# systemctl enable firewalld\n   Created symlink from /etc/systemd/system/dbus-org.fedoraproject.FirewallD1.service to /usr/lib/systemd/system/firewalld.service.\n   Created symlink from /etc/systemd/system/multi-user.target.wants/firewalld.service to /usr/lib/systemd/system/firewalld.service.\n   [root ~]# systemctl disable firewalld\n   Removed symlink /etc/systemd/system/multi-user.target.wants/firewalld.service.\n   Removed symlink /etc/systemd/system/dbus-org.fedoraproject.FirewallD1.service.\n   ```\n\n### 计划任务\n\n1. 在指定的时间执行命令。\n\n   - **at** - 将任务排队，在指定的时间执行。\n   - **atq** - 查看待执行的任务队列。\n   - **atrm** - 从队列中删除待执行的任务。\n\n   指定3天以后下午5点要执行的任务。\n\n   ```Shell\n   [root ~]# at 5pm+3days\n   at> rm -f /root/*.html\n   at> <EOT>\n   job 9 at Wed Jun  5 17:00:00 2019\n   ```\n\n   查看待执行的任务队列。\n\n   ```Shell\n   [root ~]# atq\n   9       Wed Jun  5 17:00:00 2019 a root\n   ```\n\n   从队列中删除指定的任务。\n\n   ```Shell\n   [root ~]$ atrm 9\n   ```\n\n2. 计划任务表 - **crontab**。\n\n   ```Shell\n   [root ~]# crontab -e\n   * * * * * echo \"hello, world!\" >> /root/hello.txt\n   59 23 * * * rm -f /root/*.log\n   ```\n   > 说明：输入`crontab -e`命令会打开vim来编辑Cron表达式并指定触发的任务，上面我们定制了两个计划任务，一个是每分钟向/root目录下的hello.txt中追加输出`hello, world!`；另一个是每天23时59分执行删除/root目录下以log为后缀名的文件。如果不知道Cron表达式如何书写，可以参照/etc/crontab文件中的提示（下面会讲到）或者用搜索引擎找一下“Cron表达式在线生成器”来生成Cron表达式。\n\n   和crontab相关的文件在`/etc`目录下，通过修改`/etc`目录下的crontab文件也能够定制计划任务。\n\n   ```Shell\n   [root ~]# cd /etc\n   [root etc]# ls -l | grep cron\n   -rw-------.  1 root root      541 Aug  3  2017 anacrontab\n   drwxr-xr-x.  2 root root     4096 Mar 27 11:56 cron.d\n   drwxr-xr-x.  2 root root     4096 Mar 27 11:51 cron.daily\n   -rw-------.  1 root root        0 Aug  3  2017 cron.deny\n   drwxr-xr-x.  2 root root     4096 Mar 27 11:50 cron.hourly\n   drwxr-xr-x.  2 root root     4096 Jun 10  2014 cron.monthly\n   -rw-r--r--   1 root root      493 Jun 23 15:09 crontab\n   drwxr-xr-x.  2 root root     4096 Jun 10  2014 cron.weekly\n   [root etc]# vim crontab\n     1 SHELL=/bin/bash\n     2 PATH=/sbin:/bin:/usr/sbin:/usr/bin\n     3 MAILTO=root\n     4\n     5 # For details see man 4 crontabs\n     6\n     7 # Example of job definition:\n     8 # .---------------- minute (0 - 59)\n     9 # |  .------------- hour (0 - 23)\n    10 # |  |  .---------- day of month (1 - 31)\n    11 # |  |  |  .------- month (1 - 12) OR jan,feb,mar,apr ...\n    12 # |  |  |  |  .---- day of week (0 - 6) (Sunday=0 or 7) OR sun,mon,tue,wed,thu,fri,sat\n    13 # |  |  |  |  |\n    14 # *  *  *  *  * user-name  command to be executed\n   ```\n\n\n### 网络访问和管理\n\n1. 安全远程连接 - **ssh**。\n\n    ```Shell\n    [root ~]$ ssh root@120.77.222.217\n    The authenticity of host '120.77.222.217 (120.77.222.217)' can't be established.\n    ECDSA key fingerprint is SHA256:BhUhykv+FvnIL03I9cLRpWpaCxI91m9n7zBWrcXRa8w.\n    ECDSA key fingerprint is MD5:cc:85:e9:f0:d7:07:1a:26:41:92:77:6b:7f:a0:92:65.\n    Are you sure you want to continue connecting (yes/no)? yes\n    Warning: Permanently added '120.77.222.217' (ECDSA) to the list of known hosts.\n    root@120.77.222.217's password: \n    ```\n\n2. 通过网络获取资源 - **wget**。\n\n   - -b 后台下载模式\n   - -O 下载到指定的目录\n   - -r 递归下载\n\n3. 发送和接收邮件 - **mail**。\n\n4. 网络配置工具（旧） - **ifconfig**。\n\n   ```Shell\n   [root ~]# ifconfig eth0\n   eth0: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500\n           inet 172.18.61.250  netmask 255.255.240.0  broadcast 172.18.63.255\n           ether 00:16:3e:02:b6:46  txqueuelen 1000  (Ethernet)\n           RX packets 1067841  bytes 1296732947 (1.2 GiB)\n           RX errors 0  dropped 0  overruns 0  frame 0\n           TX packets 409912  bytes 43569163 (41.5 MiB)\n           TX errors 0  dropped 0 overruns 0  carrier 0  collisions \n   ```\n\n5. 网络配置工具（新） - **ip**。\n\n   ```Shell\n   [root ~]# ip address\n   1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN qlen 1\n       link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n       inet 127.0.0.1/8 scope host lo\n          valid_lft forever preferred_lft forever\n   2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP qlen 1000\n       link/ether 00:16:3e:02:b6:46 brd ff:ff:ff:ff:ff:ff\n       inet 172.18.61.250/20 brd 172.18.63.255 scope global eth0\n          valid_lft forever preferred_lft forever\n   ```\n\n6. 网络可达性检查 - **ping**。\n\n   ```Shell\n   [root ~]# ping www.baidu.com -c 3\n   PING www.a.shifen.com (220.181.111.188) 56(84) bytes of data.\n   64 bytes from 220.181.111.188 (220.181.111.188): icmp_seq=1 ttl=51 time=36.3 ms\n   64 bytes from 220.181.111.188 (220.181.111.188): icmp_seq=2 ttl=51 time=36.4 ms\n   64 bytes from 220.181.111.188 (220.181.111.188): icmp_seq=3 ttl=51 time=36.4 ms\n   --- www.a.shifen.com ping statistics ---\n   3 packets transmitted, 3 received, 0% packet loss, time 2002ms\n   rtt min/avg/max/mdev = 36.392/36.406/36.427/0.156 ms\n   ```\n\n7. 显示或管理路由表 - **route**。\n\n8. 查看网络服务和端口 - **netstat** / **ss**。\n\n   ```Shell\n   [root ~]# netstat -nap | grep nginx\n   ```\n\n9. 网络监听抓包 - **tcpdump**。\n\n10. 安全文件拷贝 - **scp**。\n\n  ```Shell\n  [root ~]# scp root@1.2.3.4:/root/guido.jpg hellokitty@4.3.2.1:/home/hellokitty/pic.jpg\n  ```\n\n11. 文件同步工具 - **rsync**。\n\n    > 说明：使用`rsync`可以实现文件的自动同步，这个对于文件服务器来说相当重要。关于这个命令的用法，我们在后面讲项目部署的时候为大家详细说明。\n\n12. 安全文件传输 - **sftp**。\n\n    ```Shell\n    [root ~]# sftp root@1.2.3.4\n    root@1.2.3.4's password:\n    Connected to 1.2.3.4.\n    sftp>\n    ```\n\n    - `help`：显示帮助信息。\n\n    - `ls`/`lls`：显示远端/本地目录列表。\n\n    - `cd`/`lcd`：切换远端/本地路径。\n\n    - `mkdir`/`lmkdir`：创建远端/本地目录。\n\n    - `pwd`/`lpwd`：显示远端/本地当前工作目录。\n\n    - `get`：下载文件。\n\n    - `put`：上传文件。\n\n    - `rm`：删除远端文件。\n\n    - `bye`/`exit`/`quit`：退出sftp。\n\n### 进程管理\n\n1. 查看进程 - **ps**。\n\n   ```Shell\n   [root ~]# ps -ef\n   UID        PID  PPID  C STIME TTY          TIME CMD\n   root         1     0  0 Jun23 ?        00:00:05 /usr/lib/systemd/systemd --switched-root --system --deserialize 21\n   root         2     0  0 Jun23 ?        00:00:00 [kthreadd]\n   ...\n   [root ~]# ps -ef | grep mysqld\n   root      4943  4581  0 22:45 pts/0    00:00:00 grep --color=auto mysqld\n   mysql    25257     1  0 Jun25 ?        00:00:39 /usr/sbin/mysqld --daemonize --pid-file=/var/run/mysqld/mysqld.pid\n   ```\n\n2. 显示进程状态树 - **pstree**。\n\n    ```Shell\n    [root ~]# pstree\n    systemd─┬─AliYunDun───18*[{AliYunDun}]\n            ├─AliYunDunUpdate───3*[{AliYunDunUpdate}]\n            ├─2*[agetty]\n            ├─aliyun-service───2*[{aliyun-service}]\n            ├─atd\n            ├─auditd───{auditd}\n            ├─dbus-daemon\n            ├─dhclient\n            ├─irqbalance\n            ├─lvmetad\n            ├─mysqld───28*[{mysqld}]\n            ├─nginx───2*[nginx]\n            ├─ntpd\n            ├─polkitd───6*[{polkitd}]\n            ├─rsyslogd───2*[{rsyslogd}]\n            ├─sshd───sshd───bash───pstree\n            ├─systemd-journal\n            ├─systemd-logind\n            ├─systemd-udevd\n            └─tuned───4*[{tuned}]\n    ```\n\n3. 查找与指定条件匹配的进程 - **pgrep**。\n\n   ```Shell\n   [root ~]$ pgrep mysqld\n   3584\n   ```\n\n4. 通过进程号终止进程 - **kill**。\n\n   ```Shell\n   [root ~]$ kill -l\n    1) SIGHUP       2) SIGINT       3) SIGQUIT      4) SIGILL       5) SIGTRAP\n    6) SIGABRT      7) SIGBUS       8) SIGFPE       9) SIGKILL     10) SIGUSR1\n   11) SIGSEGV     12) SIGUSR2     13) SIGPIPE     14) SIGALRM     15) SIGTERM\n   16) SIGSTKFLT   17) SIGCHLD     18) SIGCONT     19) SIGSTOP     20) SIGTSTP\n   21) SIGTTIN     22) SIGTTOU     23) SIGURG      24) SIGXCPU     25) SIGXFSZ\n   26) SIGVTALRM   27) SIGPROF     28) SIGWINCH    29) SIGIO       30) SIGPWR\n   31) SIGSYS      34) SIGRTMIN    35) SIGRTMIN+1  36) SIGRTMIN+2  37) SIGRTMIN+3\n   38) SIGRTMIN+4  39) SIGRTMIN+5  40) SIGRTMIN+6  41) SIGRTMIN+7  42) SIGRTMIN+8\n   43) SIGRTMIN+9  44) SIGRTMIN+10 45) SIGRTMIN+11 46) SIGRTMIN+12 47) SIGRTMIN+13\n   48) SIGRTMIN+14 49) SIGRTMIN+15 50) SIGRTMAX-14 51) SIGRTMAX-13 52) SIGRTMAX-12\n   53) SIGRTMAX-11 54) SIGRTMAX-10 55) SIGRTMAX-9  56) SIGRTMAX-8  57) SIGRTMAX-7\n   58) SIGRTMAX-6  59) SIGRTMAX-5  60) SIGRTMAX-4  61) SIGRTMAX-3  62) SIGRTMAX-2\n   63) SIGRTMAX-1  64) SIGRTMAX\n   [root ~]# kill 1234\n   [root ~]# kill -9 1234\n   ```\n\n5. 通过进程名终止进程 - **killall** / **pkill**。\n\n    结束名为mysqld的进程。\n\n    ```Shell\n    [root ~]# pkill mysqld\n    ```\n\n    结束hellokitty用户的所有进程。\n\n    ```Shell\n    [root ~]# pkill -u hellokitty\n    ```\n\n    > 说明：这样的操作会让hellokitty用户和服务器断开连接。\n\n6. 将进程置于后台运行。\n\n   - `Ctrl+Z` - 快捷键，用于停止进程并置于后台。\n   - `&` - 将进程置于后台运行。\n\n   ```Shell\n   [root ~]# mongod &\n   [root ~]# redis-server\n   ...\n   ^Z\n   [4]+  Stopped                 redis-server\n   ```\n\n7. 查询后台进程 - **jobs**。\n\n   ```Shell\n   [root ~]# jobs\n   [2]   Running                 mongod &\n   [3]-  Stopped                 cat\n   [4]+  Stopped                 redis-server\n   ```\n\n8. 让进程在后台继续运行 - **bg**。\n\n   ```Shell\n   [root ~]# bg %4\n   [4]+ redis-server &\n   [root ~]# jobs\n   [2]   Running                 mongod &\n   [3]+  Stopped                 cat\n   [4]-  Running                 redis-server &\n   ```\n\n9. 将后台进程置于前台 - **fg**。\n\n    ```Shell\n    [root ~]# fg %4\n    redis-server\n    ```\n\n    > 说明：置于前台的进程可以使用`Ctrl+C`来终止它。\n\n10. 调整程序/进程运行时优先级 - **nice** / **renice**。\n\n11. 用户登出后进程继续工作 - **nohup**。\n\n     ```Shell\n     [root ~]# nohup ping www.baidu.com > result.txt &\n     ```\n\n12. 跟踪进程系统调用情况 - **strace**。\n\n     ```Shell\n     [root ~]# pgrep mysqld\n     8803\n     [root ~]# strace -c -p 8803\n     strace: Process 8803 attached\n     ^Cstrace: Process 8803 detached\n     % time     seconds  usecs/call     calls    errors syscall\n     ------ ----------- ----------- --------- --------- ----------------\n      99.18    0.005719        5719         1           restart_syscall\n       0.49    0.000028          28         1           mprotect\n       0.24    0.000014          14         1           clone\n       0.05    0.000003           3         1           mmap\n       0.03    0.000002           2         1           accept\n     ------ ----------- ----------- --------- --------- ----------------\n     100.00    0.005766                     5           total\n     ```\n\n     > 说明：这个命令的用法和参数都比较复杂，建议大家在真正用到这个命令的时候再根据实际需要进行了解。\n\n13. 查看当前运行级别 - **runlevel**。\n\n     ```Shell\n     [root ~]# runlevel\n     N 3\n     ```\n\n14. 实时监控进程占用资源状况 - **top**。\n\n     ```Shell\n     [root ~]# top\n     top - 23:04:23 up 3 days, 14:10,  1 user,  load average: 0.00, 0.01, 0.05\n     Tasks:  65 total,   1 running,  64 sleeping,   0 stopped,   0 zombie\n     %Cpu(s):  0.3 us,  0.3 sy,  0.0 ni, 99.3 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st\n     KiB Mem :  1016168 total,   191060 free,   324700 used,   500408 buff/cache\n     KiB Swap:        0 total,        0 free,        0 used.   530944 avail Mem\n     ...\n     ```\n\n     - `-c` - 显示进程的整个路径。\n     - `-d` - 指定两次刷屏之间的间隔时间（秒为单位）。\n     - `-i` - 不显示闲置进程或僵尸进程。\n     - `-p` - 显示指定进程的信息。\n\n### 系统诊断\n\n1. 系统启动异常诊断 - **dmesg**。\n\n2. 查看系统活动信息 - **sar**。\n\n   ```Shell\n   [root ~]# sar -u -r 5 10\n   Linux 3.10.0-957.10.1.el7.x86_64 (izwz97tbgo9lkabnat2lo8z)      06/02/2019      _x86_64_        (2 CPU)\n   \n   06:48:30 PM     CPU     %user     %nice   %system   %iowait    %steal     %idle\n   06:48:35 PM     all      0.10      0.00      0.10      0.00      0.00     99.80\n   \n   06:48:30 PM kbmemfree kbmemused  %memused kbbuffers  kbcached  kbcommit   %commit  kbactive   kbinact   kbdirty\n   06:48:35 PM   1772012   2108392     54.33    102816   1634528    784940     20.23    793328   1164704         0\n   ```\n\n   - `-A` - 显示所有设备（CPU、内存、磁盘）的运行状况。\n   - `-u` - 显示所有CPU的负载情况。\n   - `-d` - 显示所有磁盘的使用情况。\n   - `-r` - 显示内存的使用情况。\n   - `-n` - 显示网络运行状态。\n\n3. 查看内存使用情况 - **free**。\n\n   ```Shell\n   [root ~]# free\n                 total        used        free      shared  buff/cache   available\n   Mem:        1016168      323924      190452         356      501792      531800\n   Swap:             0           0           0\n   ```\n\n4. 虚拟内存统计 - **vmstat**。\n\n   ```Shell\n   [root ~]# vmstat\n   procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----\n    r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st\n    2  0      0 204020  79036 667532    0    0     5    18  101   58  1  0 99  0  0\n   ```\n\n5. CPU信息统计 - **mpstat**。\n\n   ```Shell\n   [root ~]# mpstat\n   Linux 3.10.0-957.5.1.el7.x86_64 (iZ8vba0s66jjlfmo601w4xZ)       05/30/2019      _x86_64_        (1 CPU)\n   \n   01:51:54 AM  CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest  %gnice   %idle\n   01:51:54 AM  all    0.71    0.00    0.17    0.04    0.00    0.00    0.00    0.00    0.00   99.07\n   ```\n\n6. 查看进程使用内存状况 - **pmap**。\n\n   ```Shell\n   [root ~]# ps\n     PID TTY          TIME CMD\n    4581 pts/0    00:00:00 bash\n    5664 pts/0    00:00:00 ps\n   [root ~]# pmap 4581\n   4581:   -bash\n   0000000000400000    884K r-x-- bash\n   00000000006dc000      4K r---- bash\n   00000000006dd000     36K rw--- bash\n   00000000006e6000     24K rw---   [ anon ]\n   0000000001de0000    400K rw---   [ anon ]\n   00007f82fe805000     48K r-x-- libnss_files-2.17.so\n   00007f82fe811000   2044K ----- libnss_files-2.17.so\n   ...\n   ```\n\n7. 报告设备CPU和I/O统计信息 - **iostat**。\n\n   ```Shell\n   [root ~]# iostat\n   Linux 3.10.0-693.11.1.el7.x86_64 (iZwz97tbgo9lkabnat2lo8Z)      06/26/2018      _x86_64_       (1 CPU)\n   avg-cpu:  %user   %nice %system %iowait  %steal   %idle\n              0.79    0.00    0.20    0.04    0.00   98.97\n   Device:            tps    kB_read/s    kB_wrtn/s    kB_read    kB_wrtn\n   vda               0.85         6.78        21.32    2106565    6623024\n   vdb               0.00         0.01         0.00       2088          0\n   ```\n\n8. 显示所有PCI设备 - **lspci**。\n\n   ```Shell\n   [root ~]# lspci\n   00:00.0 Host bridge: Intel Corporation 440FX - 82441FX PMC [Natoma] (rev 02)\n   00:01.0 ISA bridge: Intel Corporation 82371SB PIIX3 ISA [Natoma/Triton II]\n   00:01.1 IDE interface: Intel Corporation 82371SB PIIX3 IDE [Natoma/Triton II]\n   00:01.2 USB controller: Intel Corporation 82371SB PIIX3 USB [Natoma/Triton II] (rev 01)\n   00:01.3 Bridge: Intel Corporation 82371AB/EB/MB PIIX4 ACPI (rev 03)\n   00:02.0 VGA compatible controller: Cirrus Logic GD 5446\n   00:03.0 Ethernet controller: Red Hat, Inc. Virtio network device\n   00:04.0 Communication controller: Red Hat, Inc. Virtio console\n   00:05.0 SCSI storage controller: Red Hat, Inc. Virtio block device\n   00:06.0 SCSI storage controller: Red Hat, Inc. Virtio block device\n   00:07.0 Unclassified device [00ff]: Red Hat, Inc. Virtio memory balloon\n   ```\n\n9. 显示进程间通信设施的状态 - **ipcs**。\n\n   ```Shell\n   [root ~]# ipcs\n   \n   ------ Message Queues --------\n   key        msqid      owner      perms      used-bytes   messages    \n   \n   ------ Shared Memory Segments --------\n   key        shmid      owner      perms      bytes      nattch     status      \n   \n   ------ Semaphore Arrays --------\n   key        semid      owner      perms      nsems\n   ```\n\n### Shell编程\n\n之前我们提到过，Shell是一个连接用户和操作系统的应用程序，它提供了人机交互的界面（接口），用户通过这个界面访问操作系统内核的服务。Shell脚本是一种为Shell编写的脚本程序，我们可以通过Shell脚本来进行系统管理，同时也可以通过它进行文件操作。总之，编写Shell脚本对于使用Linux系统的人来说，应该是一项标配技能。\n\n互联网上有大量关于Shell脚本的相关知识，我不打算再此对Shell脚本做一个全面系统的讲解，我们通过下面的代码来感性的认识下Shell脚本就行了。\n\n例子1：输入两个整数m和n，计算从m到n的整数求和的结果。\n\n```Shell\n#!/usr/bin/bash\nprintf 'm = '\nread m\nprintf 'n = '\nread n\na=$m\nsum=0\nwhile [ $a -le $n ]\ndo\n    sum=$[ sum + a ]\n    a=$[ a + 1 ]\ndone\necho '结果: '$sum\n```\n\n例子2：自动创建文件夹和指定数量的文件。\n\n```Shell\n#!/usr/bin/bash\nprintf '输入文件夹名: '\nread dir\nprintf '输入文件名: '\nread file\nprintf '输入文件数量(<1000): '\nread num\nif [ $num -ge 1000 ]\nthen\n    echo '文件数量不能超过1000'\nelse\n    if [ -e $dir -a -d $dir ]\n    then\n        rm -rf $dir\n    else\n        if [ -e $dir -a -f $dir ]\n        then\n            rm -f $dir\n        fi\n    fi\n    mkdir -p $dir\n    index=1\n    while [ $index -le $num ]\n    do\n        if [ $index -lt 10 ]\n        then\n            pre='00'\n        elif [ $index -lt 100 ]\n        then\n            pre='0'\n        else\n            pre=''\n        fi\n        touch $dir'/'$file'_'$pre$index\n        index=$[ index + 1 ]\n    done\nfi\n```\n\n例子3：自动安装指定版本的Redis。\n\n```Shell\n#!/usr/bin/bash\ninstall_redis() {\n    if ! which redis-server > /dev/null\n    then\n        cd /root\n        wget $1$2'.tar.gz' >> install.log\n        gunzip /root/$2'.tar.gz'\n        tar -xf /root/$2'.tar'\n        cd /root/$2\n        make >> install.log\n        make install >> install.log\n        echo '安装完成'\n    else\n        echo '已经安装过Redis'\n    fi\n}\n\ninstall_redis 'http://download.redis.io/releases/' $1\n```\n\n### 相关资源\n\n1. Linux命令行常用快捷键\n\n   | 快捷键     | 功能说明                                     |\n   | ---------- | -------------------------------------------- |\n   | tab        | 自动补全命令或路径                           |\n   | Ctrl+a     | 将光标移动到命令行行首                       |\n   | Ctrl+e     | 将光标移动到命令行行尾                       |\n   | Ctrl+f     | 将光标向右移动一个字符                       |\n   | Ctrl+b     | 将光标向左移动一个字符                       |\n   | Ctrl+k     | 剪切从光标到行尾的字符                       |\n   | Ctrl+u     | 剪切从光标到行首的字符                       |\n   | Ctrl+w     | 剪切光标前面的一个单词                       |\n   | Ctrl+y     | 复制剪切命名剪切的内容                       |\n   | Ctrl+c     | 中断正在执行的任务                           |\n   | Ctrl+h     | 删除光标前面的一个字符                       |\n   | Ctrl+d     | 退出当前命令行                               |\n   | Ctrl+r     | 搜索历史命令                                 |\n   | Ctrl+g     | 退出历史命令搜索                             |\n   | Ctrl+l     | 清除屏幕上所有内容在屏幕的最上方开启一个新行 |\n   | Ctrl+s     | 锁定终端使之暂时无法输入内容                 |\n   | Ctrl+q     | 退出终端锁定                                 |\n   | Ctrl+z     | 将正在终端执行的任务停下来放到后台           |\n   | !!         | 执行上一条命令                               |\n   | !数字      | 执行数字对应的历史命令                       |\n   | !字母      | 执行最近的以字母打头的命令                   |\n   | !$ / Esc+. | 获得上一条命令最后一个参数                   |\n   | Esc+b      | 移动到当前单词的开头                         |\n   | Esc+f      | 移动到当前单词的结尾                         |\n\n2. man查阅命令手册的内容说明\n\n   | 手册中的标题 | 功能说明                                                     |\n   | ------------ | ------------------------------------------------------------ |\n   | NAME         | 命令的说明和介绍                                             |\n   | SYNOPSIS     | 使用该命令的基本语法                                         |\n   | DESCRIPTION  | 使用该命令的详细描述，各个参数的作用，有时候这些信息会出现在OPTIONS中 |\n   | OPTIONS      | 命令相关参数选项的说明                                       |\n   | EXAMPLES     | 使用该命令的参考例子                                         |\n   | EXIT STATUS  | 命令结束的退出状态码，通常0表示成功执行                      |\n   | SEE ALSO     | 和命令相关的其他命令或信息                                   |\n   | BUGS         | 和命令相关的缺陷的描述                                       |\n   | AUTHOR       | 该命令的作者介绍                                             |\n", "关系型数据库和MySQL概述": "## 关系型数据库和MySQL概述\n\n### 关系型数据库概述\n\n1. 数据持久化 - 将数据保存到能够长久保存数据的存储介质中，在掉电的情况下数据也不会丢失。\n\n2. 数据库发展史 - 网状数据库、层次数据库、关系数据库、NoSQL 数据库、NewSQL 数据库。\n\n   > 1970年，IBM的研究员E.F.Codd在*Communication of the ACM*上发表了名为*A Relational Model of Data for Large Shared Data Banks*的论文，提出了**关系模型**的概念，奠定了关系模型的理论基础。后来Codd又陆续发表多篇文章，论述了范式理论和衡量关系系统的12条标准，用数学理论奠定了关系数据库的基础。\n\n3. 关系数据库特点。\n\n   - 理论基础：**关系代数**（集合论、一阶谓词、关系运算）。\n   - 具体表象：用**二维表**（有行和列）组织数据。\n   - 编程语言：**结构化查询语言**（SQL）。\n       - DDL：数据定义语言\n       - DML：数据操作语言\n       - DCL：数据控制语言\n       - TCL：事务控制语言\n   \n4. ER模型（实体关系模型）和概念模型图。\n\n   **ER模型**，全称为**实体关系模型**（Entity-Relationship Model），由美籍华裔计算机科学家陈品山先生提出，是概念数据模型的高层描述方式，如下图所示。\n\n   <img class=\"lazy\" data-src=\"/res/er_diagram.png\" width=\"75%\">\n\n   - 实体 - 矩形框\n   - 属性 - 椭圆框\n   - 关系 - 菱形框\n   - 重数 - 1:1（一对一） / 1:N（一对多） / M:N（多对多）\n\n   实际项目开发中，我们可以利用数据库建模工具（如：PowerDesigner）来绘制概念数据模型，然后再设置好目标数据库系统，将概念模型转换成物理模型（如下图所示），最终生成创建二维表的 SQL（很多工具都可以根据我们设计的物理模型图以及设定的目标数据库来导出 SQL 或直接生成数据表）。\n\n   <img class=\"lazy\" data-src=\"/res/conceptual_model.png\" style=\"zoom:50%;\">\n\n5. 关系数据库产品。\n   - [Oracle](https://www.oracle.com/index.html) - 目前世界上使用最为广泛的数据库管理系统，作为一个通用的数据库系统，它具有完整的数据管理功能；作为一个关系数据库，它是一个完备关系的产品；作为分布式数据库，它实现了分布式处理的功能。在 Oracle 较新的版本中，还引入了多承租方架构，使用该架构可轻松部署和管理数据库云。\n   - [DB2](https://www.ibm.com/analytics/us/en/db2/) - IBM 公司开发的、主要运行于 Unix（包括 IBM 自家的 [AIX](https://zh.wikipedia.org/wiki/AIX)）、Linux、以及 Windows 服务器版等系统的关系数据库产品。DB2 历史悠久且被认为是最早使用 SQL 的数据库产品，它拥有较为强大的商业智能功能。\n   - [SQL Server](https://www.microsoft.com/en-us/sql-server/) - 由 Microsoft 开发和推广的关系型数据库产品，最初适用于中小企业的数据管理，但是近年来它的应用范围有所扩展，部分大企业甚至是跨国公司也开始基于它来构建自己的数据管理系统。\n   - [MySQL](https://www.mysql.com/) - MySQL 是开放源代码的，任何人都可以在 GPL（General Public License）的许可下下载并根据个性化的需要对其进行修改。MySQL 因为其速度、可靠性和适应性而备受关注。\n   - [PostgreSQL]() - 在 BSD 许可证下发行的开放源代码的关系数据库产品。\n\n### MySQL 简介\n\nMySQL 最早是由瑞典的 MySQL AB 公司开发的一个开放源码的关系数据库管理系统，该公司于2008年被昇阳微系统公司（Sun Microsystems）收购。在2009年，甲骨文公司（Oracle）收购昇阳微系统公司，因此 MySQL 目前也是 Oracle 旗下产品。\n\nMySQL 在过去由于性能高、成本低、可靠性好，已经成为最流行的开源数据库，因此被广泛地应用于中小型网站开发。随着 MySQL 的不断成熟，它也逐渐被应用于更多大规模网站和应用，比如维基百科、谷歌（Google）、脸书（Facebook）、百度、淘宝、腾讯、新浪、去哪儿等都使用了 MySQL 来提供数据持久化服务。\n\n甲骨文公司收购后昇阳微系统公司，大幅调涨 MySQL 商业版的售价，且甲骨文公司不再支持另一个自由软件项目 [OpenSolaris ](https://zh.wikipedia.org/wiki/OpenSolaris) 的发展，因此导致自由软件社区对于 Oracle 是否还会持续支持 MySQL 社区版（MySQL 的各个发行版本中唯一免费的版本）有所担忧，MySQL 的创始人麦克尔·维德纽斯以 MySQL 为基础，创建了 [MariaDB](https://zh.wikipedia.org/wiki/MariaDB)（以他女儿的名字命名的数据库）分支。有许多原来使用 MySQL 数据库的公司（例如：维基百科）已经陆续完成了从 MySQL 数据库到 MariaDB 数据库的迁移。\n\n### 安装 MySQL\n\n#### Windows 环境\n\n1. 通过[官方网站](https://www.mysql.com/)提供的[下载链接](https://dev.mysql.com/downloads/windows/installer/8.0.html)下载“MySQL社区版服务器”安装程序，如下图所示，建议大家下载离线安装版的MySQL Installer。\n\n    <img class=\"lazy\" data-src=\"/res/20211105230905.png\" style=\"zoom:50%\">\n\n2. 运行 Installer，按照下面的步骤进行安装。\n\n    - 选择自定义安装。\n\n    <img class=\"lazy\" data-src=\"/res/20211105231152.jpg\" style=\"zoom:35%\">\n\n    - 选择需要安装的组件。\n\n    <img class=\"lazy\" data-src=\"/res/20211105231255.jpg\" style=\"zoom:35%\">\n\n    - 如果缺少依赖项，需要先安装依赖项。\n\n    <img class=\"lazy\" data-src=\"/res/20211105231620.png\" style=\"zoom:35%\">\n\n    - 准备开始安装。\n\n    <img class=\"lazy\" data-src=\"/res/20211105231719.jpg\" style=\"zoom:35%\">\n\n    - 安装完成。\n\n    <img class=\"lazy\" data-src=\"/res/20211105232024.jpg\" style=\"zoom:35%\">\n\n    - 准备执行配置向导。\n\n    <img class=\"lazy\" data-src=\"/res/20211105231815.jpg\" style=\"zoom:35%\">\n\n3. 执行安装后的配置向导。\n\n    - 配置服务器类型和网络。\n\n    <img class=\"lazy\" data-src=\"/res/20211105232109.jpg\" style=\"zoom:35%\">\n\n    - 配置认证方法（保护密码的方式）。\n\n        <img class=\"lazy\" data-src=\"/res/20211105232408.jpg\" style=\"zoom:35%\">\n\n    - 配置用户和角色。\n\n        <img class=\"lazy\" data-src=\"/res/20211105232521.jpg\" style=\"zoom:35%\">\n\n    - 配置Windows服务名以及是否开机自启。\n\n        <img class=\"lazy\" data-src=\"/res/20211105232608.jpg\" style=\"zoom:35%\">\n\n    - 配置日志。\n\n        <img class=\"lazy\" data-src=\"/res/20211105232641.jpg\" style=\"zoom:35%\">\n\n    - 配置高级选项。\n\n        <img class=\"lazy\" data-src=\"/res/20211105232724.jpg\" alt=\"ACAC15B8633133B65476286A49BFBD7E\" style=\"zoom:35%\">\n\n    - 应用配置。\n\n        <img class=\"lazy\" data-src=\"/res/20211105232800.jpg\" style=\"zoom:35%\">\n\n4. 可以在 Windows 系统的“服务”窗口中启动或停止 MySQL。\n\n    <img class=\"lazy\" data-src=\"/res/20211105232926.jpg\" style=\"zoom:50%\">\n\n5. 配置 PATH 环境变量，以便在命令行提示符窗口使用 MySQL 客户端工具。\n\n    - 打开 Windows 的“系统”窗口并点击“高级系统设置”。\n\n        <img class=\"lazy\" data-src=\"/res/20211105233054.jpg\" style=\"zoom:50%\">\n\n    - 在“系统属性”的“高级”窗口，点击“环境变量”按钮。\n\n        <img class=\"lazy\" data-src=\"/res/20211105233312.jpg\" style=\"zoom:50%\">\n\n    - 修改PATH环境变量，将MySQL安装路径下的`bin`文件夹的路径配置到PATH环境变量中。\n\n        <img class=\"lazy\" data-src=\"/res/20211105233359.jpg\" style=\"zoom:50%\">\n\n    - 配置完成后，可以尝试在“命令提示符”下使用 MySQL 的命令行工具。\n\n        <img class=\"lazy\" data-src=\"/res/20211105233643.jpg\" style=\"zoom:50%\">\n\n#### Linux 环境\n\n下面以 CentOS 7.x 环境为例，演示如何安装 MySQL 5.7.x，如果需要在其他 Linux 系统下安装其他版本的 MySQL，请读者自行在网络上查找对应的安装教程。\n\n1. 安装 MySQL。\n\n   可以在 [MySQL 官方网站](<https://www.mysql.com/>)下载安装文件。首先在下载页面中选择平台和版本，然后找到对应的下载链接，直接下载包含所有安装文件的归档文件，解归档之后通过包管理工具进行安装。\n\n   ```Shell\n   wget https://dev.mysql.com/get/Downloads/MySQL-5.7/mysql-5.7.26-1.el7.x86_64.rpm-bundle.tar\n   tar -xvf mysql-5.7.26-1.el7.x86_64.rpm-bundle.tar\n   ```\n\n   如果系统上有 MariaDB 相关的文件，需要先移除 MariaDB 相关的文件。\n\n   ```Shell\n   yum list installed | grep mariadb | awk '{print $1}' | xargs yum erase -y\n   ```\n\n   更新和安装可能用到的底层依赖库。\n\n   ```Bash\n   yum update\n   yum install -y libaio libaio-devel\n   ```\n\n   接下来可以按照如下所示的顺序用 RPM（Redhat Package Manager）工具安装 MySQL。\n\n   ```Shell\n   rpm -ivh mysql-community-common-5.7.26-1.el7.x86_64.rpm\n   rpm -ivh mysql-community-libs-5.7.26-1.el7.x86_64.rpm\n   rpm -ivh mysql-community-libs-compat-5.7.26-1.el7.x86_64.rpm\n   rpm -ivh mysql-community-devel-5.7.26-1.el7.x86_64.rpm\n   rpm -ivh mysql-community-client-5.7.26-1.el7.x86_64.rpm\n   rpm -ivh mysql-community-server-5.7.26-1.el7.x86_64.rpm\n   ```\n\n   可以使用下面的命令查看已经安装的 MySQL 相关的包。\n\n   ```Shell\n   rpm -qa | grep mysql\n   ```\n\n2. 配置 MySQL。\n\n   MySQL 的配置文件在`/etc`目录下，名为`my.cnf`，默认的配置文件内容如下所示。\n\n   ```Shell\n   cat /etc/my.cnf\n   ```\n\n   ```INI\n   # For advice on how to change settings please see\n   # http://dev.mysql.com/doc/refman/5.7/en/server-configuration-defaults.html\n   \n   [mysqld]\n   #\n   # Remove leading # and set to the amount of RAM for the most important data\n   # cache in MySQL. Start at 70% of total RAM for dedicated server, else 10%.\n   # innodb_buffer_pool_size = 128M\n   #\n   # Remove leading # to turn on a very important data integrity option: logging\n   # changes to the binary log between backups.\n   # log_bin\n   #\n   # Remove leading # to set options mainly useful for reporting servers.\n   # The server defaults are faster for transactions and fast SELECTs.\n   # Adjust sizes as needed, experiment to find the optimal values.\n   # join_buffer_size = 128M\n   # sort_buffer_size = 2M\n   # read_rnd_buffer_size = 2M\n   datadir=/var/lib/mysql\n   socket=/var/lib/mysql/mysql.sock\n   \n   # Disabling symbolic-links is recommended to prevent assorted security risks\n   symbolic-links=0\n   \n   log-error=/var/log/mysqld.log\n   pid-file=/var/run/mysqld/mysqld.pid\n   ```\n\n   通过配置文件，我们可以修改 MySQL 服务使用的端口、字符集、最大连接数、套接字队列大小、最大数据包大小、日志文件的位置、日志过期时间等配置。当然，我们还可以通过修改配置文件来对 MySQL 服务器进行性能调优和安全管控。\n\n3. 启动 MySQL 服务。\n\n   可以使用下面的命令来启动 MySQL。\n\n   ```Shell\n   service mysqld start\n   ```\n\n   在 CentOS 7 中，更推荐使用下面的命令来启动 MySQL。\n\n   ```Shell\n   systemctl start mysqld\n   ```\n\n   启动 MySQL 成功后，可以通过下面的命令来检查网络端口使用情况，MySQL 默认使用`3306`端口。\n\n   ```Shell\n   netstat -ntlp | grep mysql\n   ```\n\n   也可以使用下面的命令查找是否有名为`mysqld`的进程。\n\n   ```Shell\n   pgrep mysqld\n   ```\n\n4. 使用 MySQL 客户端工具连接服务器。\n\n   命令行工具：\n\n   ```Shell\n   mysql -u root -p\n   ```\n\n   > 说明：启动客户端时，`-u`参数用来指定用户名，MySQL 默认的超级管理账号为`root`；`-p`表示要输入密码（用户口令）；如果连接的是其他主机而非本机，可以用`-h`来指定连接主机的主机名或IP地址。\n\n   如果是首次安装 MySQL，可以使用下面的命令来找到默认的初始密码。\n\n   ```Shell\n   cat /var/log/mysqld.log | grep password\n   ```\n\n   上面的命令会查看 MySQL 的日志带有`password`的行，在显示的结果中`root@localhost:`后面的部分就是默认设置的初始密码。\n\n   进入客户端工具后，可以通过下面的指令来修改超级管理员（root）的访问口令为`123456`。\n\n   ```SQL\n   set global validate_password_policy=0;\n   set global validate_password_length=6;\n   alter user 'root'@'localhost' identified by '123456';\n   ```\n\n   > **说明**：MySQL 较新的版本默认不允许使用弱口令作为用户口令，所以上面的代码修改了验证用户口令的策略和口令的长度。事实上我们不应该使用弱口令，因为存在用户口令被暴力破解的风险。近年来，**攻击数据库窃取数据和劫持数据库勒索比特币**的事件屡见不鲜，要避免这些潜在的风险，最为重要的一点是**不要让数据库服务器暴露在公网上**（最好的做法是将数据库置于内网，至少要做到不向公网开放数据库服务器的访问端口），另外要保管好`root`账号的口令，应用系统需要访问数据库时，通常不使用`root`账号进行访问，而是**创建其他拥有适当权限的账号来访问**。\n\n   再次使用客户端工具连接 MySQL 服务器时，就可以使用新设置的口令了。在实际开发中，为了方便用户操作，可以选择图形化的客户端工具来连接 MySQL 服务器，包括：\n\n   - MySQL Workbench（官方工具）\n\n       <img class=\"lazy\" data-src=\"/res/20211106063939.png\" style=\"zoom:50%\">\n\n   - Navicat for MySQL（界面简单友好）\n\n       <img class=\"lazy\" data-src=\"/res/20210521152457.png\" style=\"zoom:50%;\">\n   \n\n#### macOS环境\n\nmacOS 系统安装 MySQL 是比较简单的，只需要从刚才说到的官方网站下载 DMG 安装文件并运行就可以了，下载的时候需要根据自己使用的是 Intel 的芯片还是苹果的 M1 芯片选择下载链接，如下图所示。\n\n<img class=\"lazy\" data-src=\"/res/20211121215901.png\" style=\"zoom:50%;\">\n\n安装成功后，可以在“系统偏好设置”中找到“MySQL”，在如下所示的画面中，可以启动和停止 MySQL 服务器，也可以对 MySQL 核心文件的路径进行配置。\n\n<img class=\"lazy\" data-src=\"/res/20211121215153.png\" style=\"zoom:40%;\">\n\n### MySQL 基本命令\n\n#### 查看命令\n\n1. 查看所有数据库\n\n```SQL\nshow databases;\n```\n\n2. 查看所有字符集\n\n```SQL\nshow character set;\n```\n\n3. 查看所有的排序规则\n\n```SQL\nshow collation;\n```\n\n4. 查看所有的引擎\n\n```SQL\nshow engines;\n```\n\n5. 查看所有日志文件\n\n```SQL\nshow binary logs;\n```\n\n6. 查看数据库下所有表\n\n```SQL\nshow tables;\n```\n\n#### 获取帮助\n\n在 MySQL 命令行工具中，可以使用`help`命令或`?`来获取帮助，如下所示。\n\n1. 查看`show`命令的帮助。\n\n    ```MySQL\n    ? show\n    ```\n\n2. 查看有哪些帮助内容。\n\n    ```MySQL\n    ? contents\n    ```\n\n3. 获取函数的帮助。\n\n    ```MySQL\n    ? functions\n    ```\n\n4. 获取数据类型的帮助。\n\n    ```MySQL\n    ? data types\n    ```\n\n#### 其他命令\n\n1. 新建/重建服务器连接 - `connect` / `resetconnection`。\n\n2. 清空当前输入 - `\\c`。在输入错误时，可以及时使用`\\c`清空当前输入并重新开始。\n\n3. 修改终止符（定界符）- `delimiter`。默认的终止符是`;`，可以使用该命令修改成其他的字符，例如修改为`$`符号，可以用`delimiter $`命令。\n\n4. 打开系统默认编辑器 - `edit`。编辑完成保存关闭之后，命令行会自动执行编辑的内容。\n\n5. 查看服务器状态 - `status`。\n\n6. 修改默认提示符 - `prompt`。\n\n7. 执行系统命令 - `system`。可以将系统命令跟在`system`命令的后面执行，`system`命令也可以缩写为`\\!`。\n\n8. 执行 SQL 文件 - `source`。`source`命令后面跟 SQL 文件路径。\n\n9. 重定向输出 - `tee` / `notee`。可以将命令的输出重定向到指定的文件中。\n\n10. 切换数据库 - `use`。\n\n11. 显示警告信息 - `warnings`。\n\n12. 退出命令行 - `quit`或`exit`。\n\n", "SQL详解之DDL": "## SQL详解之DDL\n\n我们通常可以将 SQL 分为四类，分别是 DDL（数据定义语言）、DML（数据操作语言）、 DCL（数据控制语言）和 TCL（事务控制语言）。DDL 主要用于创建、删除、修改数据库中的对象，比如创建、删除和修改二维表，核心的关键字包括`create`、`drop`和`alter`；DML 主要负责数据的插入、删除、更新和查询，关键词包括`insert`、`delete`、`update`和`select`；DCL 用于授予和召回权限，核心关键词是`grant`和`revoke`；TCL 通常用于事务控制。\n\n> **说明**：SQL 是不区分大小写的语言，一般情况下我们建议将关键字大写，其他部分小写。 如果公司的 SQL 编程规范有强制规定，那么就按照公司的要求来，个人的喜好不应该凌驾于公司的编程规范之上，这一点对职业人来说应该是常识。\n\n### 建库建表\n\n下面我们来实现一个非常简单的学校选课系统的数据库。我们将数据库命名为`school`，四个关键的实体分别是学院、老师、学生和课程，其中，学生跟学院是从属关系，这个关系从数量上来讲是多对一关系，因为一个学院可以有多名学生，而一个学生通常只属于一个学院；同理，老师跟学院的从属关系也是多对一关系。一名老师可以讲授多门课程，一门课程如果只有一个授课老师的话，那么课程跟老师也是多对一关系；如果允许多个老师合作讲授一门课程，那么课程和老师就是多对多关系。简单起见，我们将课程和老师设计为多对一关系。学生和课程是典型的多对多关系，因为一个学生可以选择多门课程，一门课程也可以被多个学生选择，而关系型数据库需要借助中间表才能维持维持两个实体的多对多关系。最终，我们的学校选课系统一共有五张表，分别是学院表（`tb_college`）、学生表（`tb_student`）、教师表（`tb_teacher`）、课程表（`tb_course`）和选课记录表（`tb_record`），其中选课记录表就是维持学生跟课程多对多关系的中间表。\n\n```SQL\n-- 如果存在名为school的数据库就删除它\nDROP DATABASE IF EXISTS `school`;\n\n-- 创建名为school的数据库并设置默认的字符集和排序方式\nCREATE DATABASE `school` DEFAULT CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;\n\n-- 切换到school数据库上下文环境\nUSE `school`;\n\n-- 创建学院表\nCREATE TABLE `tb_college`\n(\n`col_id`    int unsigned AUTO_INCREMENT      COMMENT '编号',\n`col_name`  varchar(50)  NOT NULL            COMMENT '名称',\n`col_intro` varchar(500) NOT NULL DEFAULT '' COMMENT '介绍',\nPRIMARY KEY (`col_id`)\n);\n\n-- 创建学生表\nCREATE TABLE `tb_student`\n(\n`stu_id`    int unsigned NOT NULL           COMMENT '学号',\n`stu_name`  varchar(20)  NOT NULL           COMMENT '姓名',\n`stu_sex`   boolean      NOT NULL DEFAULT 1 COMMENT '性别',\n`stu_birth` date         NOT NULL           COMMENT '出生日期',\n`stu_addr`  varchar(255) DEFAULT ''         COMMENT '籍贯',\n`col_id`    int unsigned NOT NULL           COMMENT '所属学院',\nPRIMARY KEY (`stu_id`),\nCONSTRAINT `fk_student_col_id` FOREIGN KEY (`col_id`) REFERENCES `tb_college` (`col_id`)\n);\n\n-- 创建教师表\nCREATE TABLE `tb_teacher`\n(\n`tea_id`    int unsigned NOT NULL                COMMENT '工号',\n`tea_name`  varchar(20)  NOT NULL                COMMENT '姓名',\n`tea_title` varchar(10)  NOT NULL DEFAULT '助教' COMMENT '职称',\n`col_id`    int unsigned NOT NULL                COMMENT '所属学院',\nPRIMARY KEY (`tea_id`),\nCONSTRAINT `fk_teacher_col_id` FOREIGN KEY (`col_id`) REFERENCES `tb_college` (`col_id`)\n);\n\n-- 创建课程表\nCREATE TABLE `tb_course`\n(\n`cou_id`     int unsigned NOT NULL COMMENT '编号',\n`cou_name`   varchar(50)  NOT NULL COMMENT '名称',\n`cou_credit` int          NOT NULL COMMENT '学分',\n`tea_id`     int unsigned NOT NULL COMMENT '授课老师',\nPRIMARY KEY (`cou_id`),\nCONSTRAINT `fk_course_tea_id` FOREIGN KEY (`tea_id`) REFERENCES `tb_teacher` (`tea_id`)\n);\n\n-- 创建选课记录表\nCREATE TABLE `tb_record`\n(\n`rec_id`   bigint unsigned AUTO_INCREMENT COMMENT '选课记录号',\n`stu_id`   int unsigned    NOT NULL       COMMENT '学号',\n`cou_id`   int unsigned    NOT NULL       COMMENT '课程编号',\n`sel_date` date            NOT NULL       COMMENT '选课日期',\n`score`    decimal(4,1)                   COMMENT '考试成绩',\nPRIMARY KEY (`rec_id`),\nCONSTRAINT `fk_record_stu_id` FOREIGN KEY (`stu_id`) REFERENCES `tb_student` (`stu_id`),\nCONSTRAINT `fk_record_cou_id` FOREIGN KEY (`cou_id`) REFERENCES `tb_course` (`cou_id`),\nCONSTRAINT `uk_record_stu_cou` UNIQUE (`stu_id`, `cou_id`)\n);\n```\n\n上面的DDL有几个地方需要强调一下：\n\n- 首先，上面 SQL 中的数据库名、表名、字段名都被反引号（`）包裹起来，反引号并不是必须的，但是却可以解决表名、字段名等跟 SQL 关键字（SQL 中有特殊含义的单词）冲突的问题。\n\n- 创建数据库时，我们通过`default character set utf8mb4`指定了数据库默认使用的字符集为`utf8mb4`（最大`4`字节的`utf-8`编码），我们推荐使用该字符集，它也是 MySQL 8.x 默认使用的字符集，因为它能够支持国际化编码，还可以存储 Emoji 字符。可以通过下面的命令查看 MySQL 支持的字符集以及默认的排序规则。\n\n  ```SQL\n  show character set;\n  ```\n\n  ```\n  +----------+---------------------------------+---------------------+--------+\n  | Charset  | Description                     | Default collation   | Maxlen |\n  +----------+---------------------------------+---------------------+--------+\n  | big5     | Big5 Traditional Chinese        | big5_chinese_ci     |      2 |\n  | dec8     | DEC West European               | dec8_swedish_ci     |      1 |\n  | cp850    | DOS West European               | cp850_general_ci    |      1 |\n  | hp8      | HP West European                | hp8_english_ci      |      1 |\n  | koi8r    | KOI8-R Relcom Russian           | koi8r_general_ci    |      1 |\n  | latin1   | cp1252 West European            | latin1_swedish_ci   |      1 |\n  | latin2   | ISO 8859-2 Central European     | latin2_general_ci   |      1 |\n  | swe7     | 7bit Swedish                    | swe7_swedish_ci     |      1 |\n  | ascii    | US ASCII                        | ascii_general_ci    |      1 |\n  | ujis     | EUC-JP Japanese                 | ujis_japanese_ci    |      3 |\n  | sjis     | Shift-JIS Japanese              | sjis_japanese_ci    |      2 |\n  | hebrew   | ISO 8859-8 Hebrew               | hebrew_general_ci   |      1 |\n  | tis620   | TIS620 Thai                     | tis620_thai_ci      |      1 |\n  | euckr    | EUC-KR Korean                   | euckr_korean_ci     |      2 |\n  | koi8u    | KOI8-U Ukrainian                | koi8u_general_ci    |      1 |\n  | gb2312   | GB2312 Simplified Chinese       | gb2312_chinese_ci   |      2 |\n  | greek    | ISO 8859-7 Greek                | greek_general_ci    |      1 |\n  | cp1250   | Windows Central European        | cp1250_general_ci   |      1 |\n  | gbk      | GBK Simplified Chinese          | gbk_chinese_ci      |      2 |\n  | latin5   | ISO 8859-9 Turkish              | latin5_turkish_ci   |      1 |\n  | armscii8 | ARMSCII-8 Armenian              | armscii8_general_ci |      1 |\n  | utf8     | UTF-8 Unicode                   | utf8_general_ci     |      3 |\n  | ucs2     | UCS-2 Unicode                   | ucs2_general_ci     |      2 |\n  | cp866    | DOS Russian                     | cp866_general_ci    |      1 |\n  | keybcs2  | DOS Kamenicky Czech-Slovak      | keybcs2_general_ci  |      1 |\n  | macce    | Mac Central European            | macce_general_ci    |      1 |\n  | macroman | Mac West European               | macroman_general_ci |      1 |\n  | cp852    | DOS Central European            | cp852_general_ci    |      1 |\n  | latin7   | ISO 8859-13 Baltic              | latin7_general_ci   |      1 |\n  | utf8mb4  | UTF-8 Unicode                   | utf8mb4_general_ci  |      4 |\n  | cp1251   | Windows Cyrillic                | cp1251_general_ci   |      1 |\n  | utf16    | UTF-16 Unicode                  | utf16_general_ci    |      4 |\n  | utf16le  | UTF-16LE Unicode                | utf16le_general_ci  |      4 |\n  | cp1256   | Windows Arabic                  | cp1256_general_ci   |      1 |\n  | cp1257   | Windows Baltic                  | cp1257_general_ci   |      1 |\n  | utf32    | UTF-32 Unicode                  | utf32_general_ci    |      4 |\n  | binary   | Binary pseudo charset           | binary              |      1 |\n  | geostd8  | GEOSTD8 Georgian                | geostd8_general_ci  |      1 |\n  | cp932    | SJIS for Windows Japanese       | cp932_japanese_ci   |      2 |\n  | eucjpms  | UJIS for Windows Japanese       | eucjpms_japanese_ci |      3 |\n  | gb18030  | China National Standard GB18030 | gb18030_chinese_ci  |      4 |\n  +----------+---------------------------------+---------------------+--------+\n  41 rows in set (0.00 sec)\n  ```\n\n  如果要设置 MySQL 服务启动时默认使用的字符集，可以修改MySQL的配置并添加以下内容。\n\n  ```INI\n  [mysqld]\n  character-set-server=utf8\n  ```\n\n  > **提示**：如果不清楚如何修改 MySQL 的配置文件就先不要管它。\n\n- 创建和删除数据库时，关键字`database`也可以替换为`schema`，二者作用相同。\n\n- 建表语句中的`not null`是非空约束，它限定了字段不能为空；`default`用于为字段指定默认值，我们称之为默认值约束；`primary key`是主键约束，它设定了能够唯一确定一条记录的列，也确保了每条记录都是独一无二的，因为主键不允许重复；`foreign key`是外键约束，它维持了两张表的参照完整性，举个例子，由于学生表中为 col_id 字段添加了外键约束，限定其必须引用（`references`）学院表中的 col_id，因此学生表中的学院编号必须来自于学院表中的学院编号，不能够随意为该字段赋值。如果需要给主键约束、外键约束等起名字，可以使用`constriant`关键字并在后面跟上约束的名字。\n\n- 建表语句中的`comment` 关键字用来给列和表添加注释，增强代码的可读性和可维护性。\n\n- 在创建表的时候，可以自行选择底层的存储引擎。MySQL 支持多种存储引擎，可以通过`show engines`命令进行查看。MySQL 5.5 以后的版本默认使用的存储引擎是 InnoDB，它是我们推荐大家使用的存储引擎（因为更适合当下互联网应用对高并发、性能以及事务支持等方面的需求），为了 SQL 语句的向下兼容性，我们可以在建表语句结束处右圆括号的后面通过`engine=innodb`来指定使用 InnoDB 存储引擎。\n\n  ```SQL\n  show engines\\G\n  ```\n\n  > **说明**：上面的 \\G 是为了换一种输出方式，在命令行客户端中，如果表的字段很多一行显示不完，就会导致输出的内容看起来非常不舒服，使用 \\G 可以将记录的每个列以独占整行的的方式输出，这种输出方式在命令行客户端中看起来会舒服很多。\n\n  ```\n  *************************** 1. row ***************************\n        Engine: InnoDB\n       Support: DEFAULT\n       Comment: Supports transactions, row-level locking, and foreign keys\n  Transactions: YES\n            XA: YES\n    Savepoints: YES\n  *************************** 2. row ***************************\n        Engine: MRG_MYISAM\n       Support: YES\n       Comment: Collection of identical MyISAM tables\n  Transactions: NO\n            XA: NO\n    Savepoints: NO\n  *************************** 3. row ***************************\n        Engine: MEMORY\n       Support: YES\n       Comment: Hash based, stored in memory, useful for temporary tables\n  Transactions: NO\n            XA: NO\n    Savepoints: NO\n  *************************** 4. row ***************************\n        Engine: BLACKHOLE\n       Support: YES\n       Comment: /dev/null storage engine (anything you write to it disappears)\n  Transactions: NO\n            XA: NO\n    Savepoints: NO\n  *************************** 5. row ***************************\n        Engine: MyISAM\n       Support: YES\n       Comment: MyISAM storage engine\n  Transactions: NO\n            XA: NO\n    Savepoints: NO\n  *************************** 6. row ***************************\n        Engine: CSV\n       Support: YES\n       Comment: CSV storage engine\n  Transactions: NO\n            XA: NO\n    Savepoints: NO\n  *************************** 7. row ***************************\n        Engine: ARCHIVE\n       Support: YES\n       Comment: Archive storage engine\n  Transactions: NO\n            XA: NO\n    Savepoints: NO\n  *************************** 8. row ***************************\n        Engine: PERFORMANCE_SCHEMA\n       Support: YES\n       Comment: Performance Schema\n  Transactions: NO\n            XA: NO\n    Savepoints: NO\n  *************************** 9. row ***************************\n        Engine: FEDERATED\n       Support: NO\n       Comment: Federated MySQL storage engine\n  Transactions: NULL\n            XA: NULL\n    Savepoints: NULL\n  9 rows in set (0.00 sec)\n  ```\n\n  下面的表格对MySQL几种常用的数据引擎进行了简单的对比。\n\n  | 特性         | InnoDB       | MRG_MYISAM | MEMORY | MyISAM |\n  | ------------ | ------------ | ---------- | ------ | ------ |\n  | 存储限制     | 有           | 没有       | 有     | 有     |\n  | 事务         | 支持         |            |        |        |\n  | 锁机制       | 行锁         | 表锁       | 表锁   | 表锁   |\n  | B树索引      | 支持         | 支持       | 支持   | 支持   |\n  | 哈希索引     |              |            | 支持   |        |\n  | 全文检索     | 支持（5.6+） |            |        | 支持   |\n  | 集群索引     | 支持         |            |        |        |\n  | 数据缓存     | 支持         |            | 支持   |        |\n  | 索引缓存     | 支持         | 支持       | 支持   | 支持   |\n  | 数据可压缩   |              |            |        | 支持   |\n  | 内存使用     | 高           | 低         | 中     | 低     |\n  | 存储空间使用 | 高           | 低         |        | 低     |\n  | 批量插入性能 | 低           | 高         | 高     | 高     |\n  | 是否支持外键 | 支持         |            |        |        |\n\n  通过上面的比较我们可以了解到，InnoDB 是唯一能够支持外键、事务以及行锁的存储引擎，所以我们之前说它更适合互联网应用，而且在较新版本的 MySQL 中，它也是默认使用的存储引擎。\n\n- 在定义表结构为每个字段选择数据类型时，如果不清楚哪个数据类型更合适，可以通过 MySQL 的帮助系统来了解每种数据类型的特性、数据的长度和精度等相关信息。\n\n  ```SQL\n  ? data types\n  ```\n\n  > **说明**：在 MySQLWorkbench 中，不能使用`?`获取帮助，要使用对应的命令`help`。\n  \n  ```\n  You asked for help about help category: \"Data Types\"\n  For more information, type 'help <item>', where <item> is one of the following\n  topics:\n     AUTO_INCREMENT\n     BIGINT\n     BINARY\n     BIT\n     BLOB\n     BLOB DATA TYPE\n     BOOLEAN\n     CHAR\n     CHAR BYTE\n     DATE\n     DATETIME\n     DEC\n     DECIMAL\n     DOUBLE\n     DOUBLE PRECISION\n     ENUM\n     FLOAT\n     INT\n     INTEGER\n     LONGBLOB\n     LONGTEXT\n     MEDIUMBLOB\n     MEDIUMINT\n     MEDIUMTEXT\n     SET DATA TYPE\n     SMALLINT\n     TEXT\n     TIME\n     TIMESTAMP\n     TINYBLOB\n     TINYINT\n     TINYTEXT\n     VARBINARY\n     VARCHAR\n     YEAR DATA TYPE\n  ```\n  \n  获取 varchar 类型的帮助：\n\n  ```SQL\n  ? varchar\n  ```\n  \n  执行结果：\n  \n  ```\n  Name: 'VARCHAR'\n  Description:\n  [NATIONAL] VARCHAR(M) [CHARACTER SET charset_name] [COLLATE\n  collation_name]\n  \n  A variable-length string. M represents the maximum column length in\n  characters. The range of M is 0 to 65,535. The effective maximum length\n  of a VARCHAR is subject to the maximum row size (65,535 bytes, which is\n  shared among all columns) and the character set used. For example, utf8\n  characters can require up to three bytes per character, so a VARCHAR\n  column that uses the utf8 character set can be declared to be a maximum\n  of 21,844 characters. See\n  http://dev.mysql.com/doc/refman/5.7/en/column-count-limit.html.\n  \n  MySQL stores VARCHAR values as a 1-byte or 2-byte length prefix plus\n  data. The length prefix indicates the number of bytes in the value. A\n  VARCHAR column uses one length byte if values require no more than 255\n  bytes, two length bytes if values may require more than 255 bytes.\n  \n  *Note*:\n  \n  MySQL follows the standard SQL specification, and does not remove\n  trailing spaces from VARCHAR values.\n  \n  VARCHAR is shorthand for CHARACTER VARYING. NATIONAL VARCHAR is the\n  standard SQL way to define that a VARCHAR column should use some\n  predefined character set. MySQL uses utf8 as this predefined character\n  set. http://dev.mysql.com/doc/refman/5.7/en/charset-national.html.\n  NVARCHAR is shorthand for NATIONAL VARCHAR.\n  \n  URL: http://dev.mysql.com/doc/refman/5.7/en/string-type-overview.html\n  ```\n  \n  在数据类型的选择上，保存字符串数据通常都使用 VARCHAR 和 CHAR 两种类型，前者通常称为变长字符串，而后者通常称为定长字符串；对于 InnoDB 存储引擎，行存储格式没有区分固定长度和可变长度列，因此 VARCHAR 类型和 CHAR 类型没有本质区别，后者不一定比前者性能更好。如果要保存的很大字符串，可以使用 TEXT 类型；如果要保存很大的字节串，可以使用 BLOB（二进制大对象）类型。在 MySQL 中，TEXT 和 BLOB又分别包括 TEXT、MEDIUMTEXT、LONGTEXT 和 BLOB、MEDIUMBLOB、LONGBLOB 三种不同的类型，它们主要的区别在于存储数据的最大大小不同。保存浮点数可以用 FLOAT 或 DOUBLE 类型，FLOAT 已经不推荐使用了，而且在 MySQL 后续的版本中可能会被移除掉。而保存定点数应该使用 DECIMAL 类型，它可以指定小数点前后有效数字的位数。如果要保存时间日期，DATETIME 类型优于 TIMESTAMP 类型，因为前者能表示的时间日期范围更大，后者底层其实就是一个整数，记录了指定的日期时间和 1970-01-01 00:00:00 相差多少个毫秒，该类型在 2038-01-19 03:14:07 之后就会溢出。\n  \n  对于自增字段 AUTO_INCREMENT，如果使用 MySQL 5.x 版本要注意自增字段的回溯问题，当然这个问题在 MySQL 8.x 中已经得到了很好的解决，当然，MySQL 8.x 还有很多其他的好处，不管是功能还是性能上都有很多的优化和调整，因此强烈推荐大家使用 MySQL 8.x 版本。对于高并发访问数据库的场景，AUTO_INCREMENT 不仅存在性能上的问题，还可能在多机结构上产生重复的 ID 值，在这种场景下，使用分布式 ID 生成算法（SnowFlake、TinyID等）才是最好的选择，有兴趣的读者可以自行研究。\n\n### 删除表和修改表\n\n下面以学生表为例，为大家说明如何删除表和修改表。删除表可以使用`drop table`，代码如下所示。\n\n```SQL\nDROP TABLE `tb_student`;\n```\n\n或\n\n```SQL\nDROP TABLE IF EXISTS `tb_student`;\n```\n\n需要注意的是，如果学生表已经录入了数据而且该数据被其他表引用了，那么就不能删除学生表，否则上面的操作会报错。在下一课中，我们会讲解如何向表中插入数据，到时候大家可以试一试，能否顺利删除学生表。\n\n如果要修改学生表，可以使用`alter table`，具体可以分为以下几种情况：\n\n修改表，添加一个新列，例如给学生表添加一个联系电话的列。\n\n```SQL\nALTER TABLE `tb_student` ADD COLUMN `stu_tel` varchar(20) NOT NULL COMMENT '联系电话';\n```\n\n> **注意**：如果新增列的时候指定了非空约束（`not null`），那么学生表不能够有数据，否则原来的数据增加了 stu_tel 列之后是没有数据的，这就违反了非空约束的要求；当然，我们在添加列的时候也可以使用默认值约束来解决这个问题。\n\n修改表，删除指定的列，例如将上面添加的联系电话列删除掉。\n\n```SQL\nALTER TABLE `tb_student` DROP COLUMN `stu_tel`;\n```\n\n修改表，修改列的数据类型，例如将学生表的 stu_sex 修改为字符。\n\n```SQL\nALTER TABLE `tb_student` MODIFY COLUMN `stu_sex` char(1) NOT NULL DEFAULT 'M' COMMENT '性别';\n```\n\n修改表，修改列的命名，例如将学生表的 stu_sex 修改为 stu_gender。\n\n```SQL\nALTER TABLE `tb_student` CHANGE COLUMN `stu_sex` `stu_gender` boolean DEFAULT 1 COMMENT '性别';\n```\n\n修改表，删除约束条件，例如删除学生表的 col_id 列的外键约束。\n\n```SQL\nALTER TABLE `tb_student` DROP FOREIGN KEY `fk_student_col_id`;\n```\n\n修改表，添加约束条件，例如给学生表的 col_id 列加上外键约束。\n\n```SQL\nALTER TABLE `tb_student` ADD FOREIGN KEY (`col_id`) REFERENCES `tb_college` (`col_id`);\n```\n\n或\n\n```SQL\nALTER TABLE `tb_student` ADD CONSTRAINT `fk_student_col_id` FOREIGN KEY (`col_id`) REFERENCES `tb_college` (`col_id`);\n```\n\n> **说明**：在添加外键约束时，还可以通过`on update`和`on delete`来指定在被引用的表发生删除和更新操作时，应该进行何种处理，二者的默认值都是`restrict`，表示如果存在外键约束，则不允许更新和删除被引用的数据。除了`restrict`之外，这里可能的取值还有`cascade`（级联操作）和`set null`（设置为空），有兴趣的读者可以自行研究。\n\n修改表的名字，例如将学生表的名字修改为 tb_stu_info。\n\n```SQL\nALTER TABLE `tb_student` RENAME TO `tb_stu_info`;\n```\n\n> **提示**：一般情况下，请不要轻易修改数据库或表的名字。", "SQL详解之DML": "## SQL详解之DML\n\n我们接着上一课中创建的学校选课系统数据库，为大家讲解 DML 的使用。DML 可以帮助将数据插入到二维表（`insert`操作）、从二维表删除数据（`delete`操作）以及更新二维表的数据（`update`操作）。在执行 DML 之前，我们先通过下面的`use`命令切换到`school`数据库。\n\n```SQL\nUSE `school`;\n```\n\n### insert操作\n\n顾名思义，`insert`是用来插入行到二维表中的，插入的方式包括：插入完整的行、插入行的一部分、插入多行、插入查询的结果。我们通过如下所示的 SQL 向学院表中添加一个学院。\n\n```SQL\nINSERT INTO `tb_college` \nVALUES\n    (DEFAULT, '计算机学院', '学习计算机科学与技术的地方');\n```\n\n其中，由于学院表的主键是一个自增字段，因此上面的 SQL 中用`default`表示该列使用默认值，我们也可以使用下面的方式完成同样的操作。\n\n```SQL\nINSERT INTO `tb_college` (`col_name`, `col_intro`) \nVALUES \n    ('计算机学院', '学习计算机科学与技术的地方');\n```\n\n我们推荐大家使用下面这种做法，指定为哪些字段赋值，这样做可以不按照建表时设定的字段顺序赋值，可以按照`values`前面的元组中给定的字段顺序为字段赋值，但是需要注意，除了允许为`null`和有默认值的字段外，其他的字段都必须要一一列出并在`values`后面的元组中为其赋值。如果希望一次性插入多条记录，我们可以在`values`后面跟上多个元组来实现批量插入，代码如下所示。\n\n```SQL\nINSERT INTO `tb_college` \n    (`col_name`, `col_intro`) \nVALUES \n    ('外国语学院', '学习歪果仁的语言的学院'),\n    ('经济管理学院', '经世济民，治理国家；管理科学，兴国之道'),\n    ('体育学院', '发展体育运动，增强人民体质');\n```\n\n在插入数据时，要注意主键是不能重复的，如果插入的数据与表中已有记录主键相同，那么`insert`操作将会产生 Duplicated Entry 的报错信息。再次提醒大家，如果`insert`操作省略了某些列，那么这些列要么有默认值，要么允许为`null`，否则也将产生错误。在业务系统中，为了让`insert`操作不影响其他操作（主要是后面要讲的`select`操作）的性能，可以在`insert`和`into`之间加一个`low_priority`来降低`insert`操作的优先级，这个做法也适用于下面要讲的`delete`和`update`操作。\n\n假如有一张名为`tb_temp`的表中有`a`和`b`两个列，分别保存了学院的名称和学院的介绍，我们也可以通过查询操作获得`tb_temp`表的数据并插入到学院表中，如下所示，其中的`select`就是我们之前提到的 DQL，在下一课中会详细讲解。\n\n```SQL\nINSERT INTO `tb_college`\n    (`col_name`, `col_intro`)\nSELECT `a`, `b` \n  FROM `tb_temp`;\n```\n\n### delete 操作\n\n如果需要从表中删除数据，可以使用`delete`操作，它可以帮助我们删除指定行或所有行，例如我们要删除编号为`1`的学院，就可以使用如下所示的 SQL。\n\n```SQL\nDELETE\n  FROM `tb_college`\n WHERE col_id=1;\n```\n\n注意，上面的`delete`操作中的`where`子句是用来指定条件的，只有满足条件的行会被删除。如果我们不小心写出了下面的 SQL，就会删除学院表中所有的记录，这是相当危险的，在实际工作中通常也不会这么做。\n\n```SQL\nDELETE\n  FROM `tb_college`;\n```\n\n需要说明的是，即便删除了所有的数据，`delete`操作不会删除表本身，也不会让 AUTO_INCREMENT 字段的值回到初始值。如果需要删除所有的数据而且让 AUTO_INCREMENT 字段回到初始值，可以使用`truncate table`执行截断表操作，`truncate`的本质是删除原来的表并重新创建一个表，它的速度其实更快，因为不需要逐行删除数据。但是请大家记住一点，用`truncate table`删除数据是非常危险的，因为它会删除所有的数据，而且由于原来的表已经被删除了，要想恢复误删除的数据也会变得极为困难。\n\n### update 操作\n\n如果要修改表中的数据，可以使用`update`操作，它可以用来删除指定的行或所有的行。例如，我们将学生表中的“杨过”修改为“杨逍”，这里我们假设“杨过”的学号为`1001`，代码如下所示。\n\n```SQL\nUPDATE `tb_student`\n   SET `stu_name`='杨逍'\n WHERE `stu_id`=1001;\n```\n\n注意上面 SQL 中的`where`子句，我们使用学号作为条件筛选出对应的学生，然后通过前面的赋值操作将其姓名修改为“杨逍”。这里为什么不直接使用姓名作为筛选条件，那是因为学生表中可能有多个名为“杨过”的学生，如果使用 stu_name 作为筛选条件，那么我们的`update`操作有可能会一次更新多条数据，这显然不是我们想要看到的。还有一个需要注意的地方是`update`操作中的`set`关键字，因为 SQL 中的`=`并不表示赋值，而是判断相等的运算符，只有出现在`set` 关键字后面的`=`，才具备赋值的能力。\n\n如果要同时修改学生的姓名和生日，我们可以对上面的`update`语句稍作修改，如下所示。\n\n```SQL\nUPDATE `tb_student`\n   SET `stu_name`='杨逍'\n     , `stu_birth`='1975-12-29'\n WHERE `stu_id`=1001;\n```\n\n`update`语句中也可以使用查询的方式获得数据并以此来更新指定的表数据，有兴趣的读者可以自行研究。在书写`update`语句时，通常都会有`where`子句，因为实际工作中几乎不太会用到更新全表的操作，这一点大家一定要注意。\n\n### 完整的数据\n\n下面我们给出完整的向 school 数据库的五张表中插入数据的 SQL。\n\n```SQL\nUSE `school`;\n\n-- 插入学院数据\nINSERT INTO `tb_college` \n    (`col_name`, `col_intro`) \nVALUES \n    ('计算机学院', '计算机学院1958年设立计算机专业，1981年建立计算机科学系，1998年设立计算机学院，2005年5月，为了进一步整合教学和科研资源，学校决定，计算机学院和软件学院行政班子合并统一运作、实行教学和学生管理独立运行的模式。 学院下设三个系：计算机科学与技术系、物联网工程系、计算金融系；两个研究所：图象图形研究所、网络空间安全研究院（2015年成立）；三个教学实验中心：计算机基础教学实验中心、IBM技术中心和计算机专业实验中心。'),\n    ('外国语学院', '外国语学院设有7个教学单位，6个文理兼收的本科专业；拥有1个一级学科博士授予点，3个二级学科博士授予点，5个一级学科硕士学位授权点，5个二级学科硕士学位授权点，5个硕士专业授权领域，同时还有2个硕士专业学位（MTI）专业；有教职员工210余人，其中教授、副教授80余人，教师中获得中国国内外名校博士学位和正在职攻读博士学位的教师比例占专任教师的60%以上。'),\n    ('经济管理学院', '经济学院前身是创办于1905年的经济科；已故经济学家彭迪先、张与九、蒋学模、胡寄窗、陶大镛、胡代光，以及当代学者刘诗白等曾先后在此任教或学习。');\n\n-- 插入学生数据\nINSERT INTO `tb_student` \n    (`stu_id`, `stu_name`, `stu_sex`, `stu_birth`, `stu_addr`, `col_id`) \nVALUES\n    (1001, '杨过', 1, '1990-3-4', '湖南长沙', 1),\n    (1002, '任我行', 1, '1992-2-2', '湖南长沙', 1),\n    (1033, '王语嫣', 0, '1989-12-3', '四川成都', 1),\n    (1572, '岳不群', 1, '1993-7-19', '陕西咸阳', 1),\n    (1378, '纪嫣然', 0, '1995-8-12', '四川绵阳', 1),\n    (1954, '林平之', 1, '1994-9-20', '福建莆田', 1),\n    (2035, '东方不败', 1, '1988-6-30', NULL, 2),\n    (3011, '林震南', 1, '1985-12-12', '福建莆田', 3),\n    (3755, '项少龙', 1, '1993-1-25', '四川成都', 3),\n    (3923, '杨不悔', 0, '1985-4-17', '四川成都', 3);\n\n-- 插入老师数据\nINSERT INTO `tb_teacher` \n    (`tea_id`, `tea_name`, `tea_title`, `col_id`) \nVALUES \n    (1122, '张三丰', '教授', 1),\n    (1133, '宋远桥', '副教授', 1),\n    (1144, '杨逍', '副教授', 1),\n    (2255, '范遥', '副教授', 2),\n    (3366, '韦一笑', DEFAULT, 3);\n\n-- 插入课程数据\nINSERT INTO `tb_course` \n    (`cou_id`, `cou_name`, `cou_credit`, `tea_id`) \nVALUES \n    (1111, 'Python程序设计', 3, 1122),\n    (2222, 'Web前端开发', 2, 1122),\n    (3333, '操作系统', 4, 1122),\n    (4444, '计算机网络', 2, 1133),\n    (5555, '编译原理', 4, 1144),\n    (6666, '算法和数据结构', 3, 1144),\n    (7777, '经贸法语', 3, 2255),\n    (8888, '成本会计', 2, 3366),\n    (9999, '审计学', 3, 3366);\n\n-- 插入选课数据\nINSERT INTO `tb_record` \n    (`stu_id`, `cou_id`, `sel_date`, `score`) \nVALUES \n    (1001, 1111, '2017-09-01', 95),\n    (1001, 2222, '2017-09-01', 87.5),\n    (1001, 3333, '2017-09-01', 100),\n    (1001, 4444, '2018-09-03', NULL),\n    (1001, 6666, '2017-09-02', 100),\n    (1002, 1111, '2017-09-03', 65),\n    (1002, 5555, '2017-09-01', 42),\n    (1033, 1111, '2017-09-03', 92.5),\n    (1033, 4444, '2017-09-01', 78),\n    (1033, 5555, '2017-09-01', 82.5),\n    (1572, 1111, '2017-09-02', 78),\n    (1378, 1111, '2017-09-05', 82),\n    (1378, 7777, '2017-09-02', 65.5),\n    (2035, 7777, '2018-09-03', 88),\n    (2035, 9999, '2019-09-02', NULL),\n    (3755, 1111, '2019-09-02', NULL),\n    (3755, 8888, '2019-09-02', NULL),\n    (3755, 9999, '2017-09-01', 92);\n```\n\n> **注意**：上面的`insert`语句使用了批处理的方式来插入数据，这种做法插入数据的效率比较高。\n\n\n\n", "SQL详解之DQL": "## SQL详解之DQL\n\n接下来，我们利用之前创建的学校选课系统数据库，为大家讲解 DML 中的查询操作。无论对于开发人员还是数据分析师，查询都是非常重要的，它关系着我们能否从关系数据库中获取我们需要的数据。建议大家把上上一节课中建库建表的 DDL 以及 上一节课中插入数据的 DML 重新执行一次，确保表和数据跟没有问题再执行下面的操作。\n\n```SQL\nUSE school;\n\n-- 查询所有学生的所有信息\nSELECT stu_id,\n       stu_name,\n       stu_sex,\n       stu_birth,\n       stu_addr,\n       col_id\n  FROM tb_student;\n\n-- 查询学生的学号、姓名和籍贯(投影和别名)\nSELECT stu_id AS 学号,\n       stu_name AS 姓名,\n       stu_addr AS 籍贯\n  FROM tb_student;\n\n-- 查询所有课程的名称及学分(投影和别名)\nSELECT cou_name AS 课程名称,\n       cou_credit AS 学分\n  FROM tb_course;\n\n-- 查询所有女学生的姓名和出生日期(数据筛选)\nSELECT stu_name,\n       stu_birth\n  FROM tb_student\n WHERE stu_sex = 0;\n\n-- 查询籍贯为“四川成都”的女学生的姓名和出生日期(数据筛选)\nSELECT stu_name,\n       stu_birth\n  FROM tb_student\n WHERE stu_sex = 0\n       AND stu_addr = '四川成都';\n\n-- 查询籍贯为“四川成都”或者性别是女的学生(数据筛选)\nSELECT stu_name,\n       stu_birth\n  FROM tb_student\n WHERE stu_sex = 0\n       OR stu_addr = '四川成都';\n\n-- 查询所有80后学生的姓名、性别和出生日期(数据筛选)\nSELECT stu_name,\n       stu_sex,\n       stu_birth\n  FROM tb_student\n WHERE '1980-1-1' <= stu_birth \n       AND stu_birth <= '1989-12-31';\n       \nSELECT stu_name,\n       stu_sex,\n       stu_birth\n  FROM tb_student\n WHERE stu_birth BETWEEN '1980-1-1' AND '1989-12-31';\n\n-- 查询学分大于2的课程的名称和学分(数据筛选)\nSELECT cou_name,\n\t   cou_credit\n  FROM tb_course\n WHERE cou_credit > 2;\n\n-- 查询学分是奇数的课程的名称和学分(数据筛选)\nSELECT cou_name,\n\t   cou_credit\n  FROM tb_course\n WHERE cou_credit MOD 2 <> 0;\n\n-- 查询选择选了1111的课程考试成绩在90分以上的学生学号(数据筛选)\nSELECT stu_id\n  FROM tb_record\n WHERE cou_id = 1111\n       AND score > 90;\n\n-- 查询名字叫“杨过”的学生的姓名和性别(数据筛选)\nSELECT stu_name AS 姓名, \n       CASE stu_sex WHEN 1 THEN '男' ELSE '女' END AS 性别\n  FROM tb_student\n WHERE stu_name = '杨过';\n \nSELECT stu_name AS 姓名, \n       IF(stu_sex, '男', '女') AS 性别\n  FROM tb_student\n WHERE stu_name = '杨过';\n    \n-- 查询姓“杨”的学生姓名和性别(模糊匹配)\n-- 通配符 % 匹配零个或任意多个字符\nSELECT stu_name AS 姓名, \n       CASE stu_sex WHEN 1 THEN '男' ELSE '女' END AS 性别\n  FROM tb_student\n WHERE stu_name LIKE '杨%';\n\n-- 查询姓“杨”名字两个字的学生姓名和性别(模糊匹配)\n-- 通过符 _ 匹配一个字符\nSELECT stu_name AS 姓名, \n       CASE stu_sex WHEN 1 THEN '男' ELSE '女' END AS 性别\n  FROM tb_student\n WHERE stu_name LIKE '杨_';\n\n-- 查询姓“杨”名字三个字的学生姓名和性别(模糊匹配)\nSELECT stu_name AS 姓名, \n       CASE stu_sex WHEN 1 THEN '男' ELSE '女' END AS 性别\n  FROM tb_student\n WHERE stu_name LIKE '杨__';\n \n-- 查询学号最后一位是3的学生的学号和姓名(模糊匹配)\nSELECT stu_id,\n       stu_name\n  FROM tb_student\n WHERE stu_id LIKE '%3';\n\n-- 查询名字中有“不”字或“嫣”字的学生的学号和姓名(模糊匹配和并集运算)\nSELECT stu_id,\n       stu_name\n  FROM tb_student\n WHERE stu_name LIKE '%不%'\n       OR stu_name LIKE '%嫣%';\n       \nSELECT stu_id,\n       stu_name\n  FROM tb_student\n WHERE stu_name LIKE '%不%'\n UNION\nSELECT stu_id,\n       stu_name\n  FROM tb_student\n WHERE stu_name LIKE '%嫣%';\n\n-- 查询姓“杨”或姓“林”名字三个字的学生的学号和姓名(正则表达式模糊匹配)\nSELECT stu_id,\n       stu_name\n  FROM tb_student\n WHERE stu_name REGEXP '[林杨][\\\\u4e00-\\\\u9fa5]{2}';\n\n-- 查询没有录入籍贯的学生姓名(空值处理)\nSELECT stu_name\n  FROM tb_student\n WHERE TRIM(stu_addr) = ''\n       OR stu_addr is null;\n \n-- 查询录入了籍贯的学生姓名(空值处理)\nSELECT stu_name\n  FROM tb_student\n WHERE TRIM(stu_addr) <> ''\n       AND stu_addr is not null;\n\n-- 查询学生选课的所有日期(去重)\nSELECT DISTINCT sel_date\n  FROM tb_record;\n\n-- 查询学生的籍贯(去重)\nSELECT DISTINCT stu_addr\n  FROM tb_student\n WHERE TRIM(stu_addr) <> ''\n       AND stu_addr is not null;\n\n-- 查询男学生的姓名和生日按年龄从大到小排列(排序)\nSELECT stu_name,\n       stu_birth\n  FROM tb_student\n WHERE stu_sex = 1\n ORDER BY stu_birth ASC;\n \n-- 补充：将上面的生日换算成年龄(日期函数、数值函数)\nSELECT stu_name AS 姓名,\n       FLOOR(DATEDIFF(CURDATE(), stu_birth) / 365) AS 年龄\n  FROM tb_student\n WHERE stu_sex = 1\n ORDER BY 年龄 DESC;\n\n-- 查询年龄最大的学生的出生日期(聚合函数)\nSELECT MIN(stu_birth)\n  FROM tb_student;\n\n-- 查询年龄最小的学生的出生日期(聚合函数)\nSELECT MAX(stu_birth)\n  FROM tb_student;\n\n-- 查询编号为1111的课程考试成绩的最高分(聚合函数)\nSELECT MAX(score)\n  FROM tb_record\n WHERE cou_id = 1111;\n\n-- 查询学号为1001的学生考试成绩的最低分、最高分、平均分、标准差、方差(聚合函数)\nSELECT MIN(score) AS 最低分,\n       MAX(score) AS 最高分,\n\t   ROUND(AVG(score), 1) AS 平均分,\n       STDDEV(score) AS 标准差,\n       VARIANCE(score) AS 方差\n  FROM tb_record\n WHERE stu_id = 1001;\n\n-- 查询学号为1001的学生考试成绩的平均分，如果有null值，null值算0分(聚合函数)\nSELECT ROUND(SUM(score) / COUNT(*), 1) AS 平均分\n  FROM tb_record\n WHERE stu_id = 1001;\n\n-- 查询男女学生的人数(分组和聚合函数)\nSELECT CASE stu_sex WHEN 1 THEN '男' ELSE '女' END AS 性别,\n       COUNT(*) AS 人数\n  FROM tb_student\n GROUP BY stu_sex;\n\n-- 查询每个学院学生人数(分组和聚合函数)\nSELECT col_id AS 学院编号,\n       COUNT(*) AS 人数\n  FROM tb_student\n GROUP BY col_id\n  WITH ROLLUP;\n\n-- 查询每个学院男女学生人数(分组和聚合函数)\nSELECT col_id AS 学院编号,\n       CASE stu_sex WHEN 1 THEN '男' ELSE '女' END AS 性别,\n       COUNT(*) AS 人数\n  FROM tb_student\n GROUP BY col_id, stu_sex;\n\n-- 查询每个学生的学号和平均成绩(分组和聚合函数)\nSELECT stu_id AS 学号,\n\t   ROUND(AVG(score), 1) AS 平均分\n  FROM tb_record\n GROUP BY stu_id;\n\n-- 查询平均成绩大于等于90分的学生的学号和平均成绩(分组后的数据筛选)\nSELECT stu_id AS 学号,\n\t   ROUND(AVG(score), 1) AS 平均分\n  FROM tb_record\n GROUP BY stu_id\nHAVING 平均分 >= 90;\n\n-- 查询1111、2222、3333三门课程平均成绩大于等于90分的学生的学号和平均成绩(分组前后的数据筛选)\nSELECT stu_id AS 学号,\n\t   ROUND(AVG(score), 1) AS 平均分\n  FROM tb_record\n WHERE cou_id in (1111, 2222, 3333)\n GROUP BY stu_id\nHAVING 平均分 >= 90\n ORDER BY 平均分 ASC;\n\n-- 查询年龄最大的学生的姓名(子查询)\nSELECT stu_name\n  FROM tb_student\n WHERE stu_birth = (SELECT MIN(stu_birth)\n                      FROM tb_student);\n\n-- 查询选了两门以上的课程的学生姓名(子查询和集合运算)\nSELECT stu_name\n  FROM tb_student\n WHERE stu_id in (SELECT stu_id\n\t\t\t\t    FROM tb_record\n\t\t\t\t   GROUP BY stu_id\n\t\t\t\t  HAVING COUNT(*) > 2);\n\n-- 查询学生的姓名、生日和所在学院名称(表连接)\nSELECT stu_name,\n       stu_birth,\n       col_name\n  FROM tb_student AS t1, tb_college AS t2\n WHERE t1.col_id = t2.col_id;\n \nSELECT stu_name,\n       stu_birth,\n\t   col_name\n  FROM tb_student INNER JOIN tb_college\n       ON tb_student.col_id = tb_college.col_id;\n\nSELECT stu_name,\n       stu_birth,\n\t   col_name\n  FROM tb_student NATURAL JOIN tb_college;\n  \nSELECT stu_name,\n       stu_birth,\n\t   col_name\n  FROM tb_student CROSS JOIN tb_college;\n\n-- 查询学生姓名、课程名称以及成绩(表连接)\nSELECT stu_name,\n       cou_name,\n\t   score\n  FROM tb_student, tb_course, tb_record\n WHERE tb_student.stu_id = tb_record.stu_id\n       AND tb_course.cou_id = tb_record.cou_id\n       AND score is not null;\n\nSELECT stu_name,\n       cou_name,\n\t   score\n  FROM tb_student \n       INNER JOIN tb_record\n\t       ON tb_student.stu_id = tb_record.stu_id\n\t   INNER JOIN tb_course\n\t       ON tb_course.cou_id = tb_record.cou_id\n WHERE score is not null;\n \nSELECT stu_name,\n       cou_name,\n       score\n  FROM tb_student \n\t   NATURAL JOIN tb_record\n       NATURAL JOIN tb_course\n WHERE score is not null;\n\n-- 补充：上面的查询结果取前5条数据(分页查询)\nSELECT stu_name,\n       cou_name,\n       score\n  FROM tb_student \n\t   NATURAL JOIN tb_record\n       NATURAL JOIN tb_course\n WHERE score is not null\n ORDER BY cou_id ASC, score DESC\n LIMIT 5;\n\n-- 补充：上面的查询结果取第6-10条数据(分页查询)\nSELECT stu_name,\n       cou_name,\n       score\n  FROM tb_student \n\t   NATURAL JOIN tb_record\n       NATURAL JOIN tb_course\n WHERE score is not null\n ORDER BY cou_id ASC, score DESC\n LIMIT 5\nOFFSET 5;\n\n-- 补充：上面的查询结果取第11-15条数据(分页查询)\nSELECT stu_name,\n       cou_name,\n       score\n  FROM tb_student \n\t   NATURAL JOIN tb_record\n       NATURAL JOIN tb_course\n WHERE score is not null\n ORDER BY cou_id ASC, score DESC\n LIMIT 10, 5;\n\n-- 查询选课学生的姓名和平均成绩(子查询和表连接)\n-- Error Code: 1248. Every derived table must have its own alias\nSELECT stu_name,\n\t   avg_score\n  FROM tb_student\n       NATURAL JOIN (SELECT stu_id,\n                            ROUND(AVG(score), 1) AS avg_score\n                       FROM tb_record\n                      GROUP BY stu_id) as tmp;\n\n-- 查询学生的姓名和选课的数量(子查询和表连接)\nSELECT stu_name,\n\t   total\n  FROM tb_student\n       NATURAL JOIN (SELECT stu_id,\n                            COUNT(*) AS total\n                       FROM tb_record\n                      GROUP BY stu_id) as tmp;\n\n-- 查询每个学生的姓名和选课数量(子查询和左外连接)\nSELECT stu_name AS 姓名,\n\t   COALESCE(total, 0) AS 选课数量\n  FROM tb_student AS t1\n\t   LEFT JOIN (SELECT stu_id,\n\t\t\t             COUNT(*) AS total\n\t\t            FROM tb_record\n\t\t\t\t   GROUP BY stu_id) AS t2\n\t       ON t1.stu_id = t2.stu_id;\n```\n\n有几个地方需要加以说明：\n\n1. MySQL目前的版本不支持全外连接，上面我们通过`union`操作，将左外连接和右外连接的结果求并集实现全外连接的效果。大家可以通过下面的图来加深对连表操作的认识。\n\n   <img src=\"http://localhost/mypic/20211121135117.png\" style=\"zoom:50%\">\n\n2. MySQL 中支持多种类型的运算符，包括：算术运算符（`+`、`-`、`*`、`/`、`%`）、比较运算符（`=`、`<>`、`<=>`、`<`、`<=`、`>`、`>=`、`BETWEEN...AND..`.、`IN`、`IS NULL`、`IS NOT NULL`、`LIKE`、`RLIKE`、`REGEXP`）、逻辑运算符（`NOT`、`AND`、`OR`、`XOR`）和位运算符（`&`、`|`、`^`、`~`、`>>`、`<<`），我们可以在 DML 中使用这些运算符处理数据。\n\n3. 在查询数据时，可以在`SELECT`语句及其子句（如`WHERE`子句、`ORDER BY`子句、`HAVING`子句等）中使用函数，这些函数包括字符串函数、数值函数、时间日期函数、流程函数等，如下面的表格所示。\n\n   常用字符串函数。\n\n   | 函数                        | 功能                                                  |\n   | --------------------------- | ----------------------------------------------------- |\n   | `CONCAT`                    | 将多个字符串连接成一个字符串                          |\n   | `FORMAT`                    | 将数值格式化成字符串并指定保留几位小数                |\n   | `FROM_BASE64` / `TO_BASE64` | BASE64解码/编码                                       |\n   | `BIN` / `OCT` / `HEX`       | 将数值转换成二进制/八进制/十六进制字符串              |\n   | `LOCATE`                    | 在字符串中查找一个子串的位置                          |\n   | `LEFT` / `RIGHT`            | 返回一个字符串左边/右边指定长度的字符                 |\n   | `LENGTH` / `CHAR_LENGTH`    | 返回字符串的长度以字节/字符为单位                     |\n   | `LOWER` / `UPPER`           | 返回字符串的小写/大写形式                             |\n   | `LPAD` / `RPAD`             | 如果字符串的长度不足，在字符串左边/右边填充指定的字符 |\n   | `LTRIM` / `RTRIM`           | 去掉字符串前面/后面的空格                             |\n   | `ORD` / `CHAR`              | 返回字符对应的编码/返回编码对应的字符                 |\n   | `STRCMP`                    | 比较字符串，返回-1、0、1分别表示小于、等于、大于      |\n   | `SUBSTRING`                 | 返回字符串指定范围的子串                              |\n\n   常用数值函数。\n\n   | 函数                                                     | 功能                               |\n   | -------------------------------------------------------- | ---------------------------------- |\n   | `ABS`                                                    | 返回一个数的绝度值                 |\n   | `CEILING` / `FLOOR`                                      | 返回一个数上取整/下取整的结果      |\n   | `CONV`                                                   | 将一个数从一种进制转换成另一种进制 |\n   | `CRC32`                                                  | 计算循环冗余校验码                 |\n   | `EXP` / `LOG` / `LOG2` / `LOG10`                         | 计算指数/对数                      |\n   | `POW`                                                    | 求幂                               |\n   | `RAND`                                                   | 返回[0,1)范围的随机数              |\n   | `ROUND`                                                  | 返回一个数四舍五入后的结果         |\n   | `SQRT`                                                   | 返回一个数的平方根                 |\n   | `TRUNCATE`                                               | 截断一个数到指定的精度             |\n   | `SIN` / `COS` / `TAN` / `COT` / `ASIN` / `ACOS` / `ATAN` | 三角函数                           |\n\n   常用时间日期函数。\n\n   | 函数                                      | 功能                                  |\n   | ----------------------------------------- | ------------------------------------- |\n   | `CURDATE` / `CURTIME` / `NOW`             | 获取当前日期/时间/日期和时间          |\n   | `ADDDATE` / `SUBDATE`                     | 将两个日期表达式相加/相减并返回结果   |\n   | `DATE` / `TIME`                           | 从字符串中获取日期/时间               |\n   | `YEAR` / `MONTH` / `DAY`                  | 从日期中获取年/月/日                  |\n   | `HOUR` / `MINUTE` / `SECOND`              | 从时间中获取时/分/秒                  |\n   | `DATEDIFF` / `TIMEDIFF` / `TIMESTAMPDIFF` | 返回两个时间日期表达式相差多少天/小时 |\n   | `MAKEDATE` / `MAKETIME`                   | 制造一个日期/时间                     |\n\n   常用流程控制函数。\n\n   | 函数     | 功能                                             |\n   | -------- | ------------------------------------------------ |\n   | `IF`     | 根据条件是否成立返回不同的值                     |\n   | `IFNULL` | 如果为NULL则返回指定的值否则就返回本身           |\n   | `NULLIF` | 两个表达式相等就返回NULL否则返回第一个表达式的值 |\n\n   其他常用函数。\n\n   | 函数                       | 功能                          |\n   | -------------------------- | ----------------------------- |\n   | `MD5` / `SHA1` / `SHA2`    | 返回字符串对应的哈希摘要      |\n   | `CHARSET` / `COLLATION`    | 返回字符集/校对规则           |\n   | `USER` / `CURRENT_USER`    | 返回当前用户                  |\n   | `DATABASE`                 | 返回当前数据库名              |\n   | `VERSION`                  | 返回当前数据库版本            |\n   | `FOUND_ROWS` / `ROW_COUNT` | 返回查询到的行数/受影响的行数 |\n   | `LAST_INSERT_ID`           | 返回最后一个自增主键的值      |\n   | `UUID` / `UUID_SHORT`      | 返回全局唯一标识符            |\n", "SQL详解之DCL": "## SQL详解之DCL\n\n数据库服务器通常包含了非常重要的数据，可以通过访问控制来确保这些数据的安全，而 DCL 就是解决这一问题的，它可以为指定的用户授予访问权限或者从指定用户处召回指定的权限。DCL 对数据库管理员来说非常重要，因为用户权限的管理关系到数据库的安全。简单的说，我们可以通过 DCL 允许受信任的用户访问数据库，阻止不受信任的用户访问数据库，同时还可以通过 DCL 将每个访问者的的权限最小化（让访问者的权限刚刚够用）。\n\n### 创建用户\n\n我们可以使用下面的 SQL 来创建一个用户并为其指定访问口令。\n\n```SQL\nCREATE USER 'wangdachui'@'%' IDENTIFIED BY 'Wang.618';\n```\n\n上面的 SQL 创建了名为 wangdachui 的用户，它的访问口令是 Wang.618，该用户可以从任意主机访问数据库服务器，因为 @ 后面使用了可以表示任意多个字符的通配符 %。如果要限制 wangdachui 这个用户只能从 192.168.0.x 这个网段的主机访问数据库服务器，可以按照下面的方式来修改 SQL 语句。\n\n```SQL\nDROP USER IF EXISTS 'wangdachui'@'%';\n\nCREATE USER 'wangdachui'@'192.168.0.%' IDENTIFIED BY 'Wang.618';\n```\n\n此时，如果我们使用 wangdachui 这个账号访问数据库服务器，我们几乎不能做任何操作，因为该账号没有任何操作权限。\n\n### 授予权限\n\n我们用下面的语句为 wangdachui 授予查询 school 数据库学院表（`tb_college`）的权限。\n\n```SQL\nGRANT SELECT ON `school`.`tb_college` TO 'wangdachui'@'192.168.0.%';\n```\n\n我们也可以让 wangdachui 对 school 数据库的所有对象都具有查询权限，代码如下所示。\n\n```SQL\nGRANT SELECT ON `school`.* TO 'wangdachui'@'192.168.0.%';\n```\n\n如果我们希望 wangdachui 还有 insert、delete 和 update 权限，可以使用下面的方式进行操作。\n\n```SQL\nGRANT INSERT, DELETE, UPDATE ON `school`.* TO 'wangdachui'@'192.168.0.%';\n```\n\n如果我们还想授予 wangdachui 执行 DDL 的权限，可以使用如下所示的 SQL。\n\n```SQL\nGRANT CREATE, DROP, ALTER ON `school`.* TO 'wangdachui'@'192.168.0.%';\n```\n\n如果我们希望 wangdachui 账号对所有数据库的所有对象都具备所有的操作权限，可以执行如下所示的操作，但是一般情况下，我们不会这样做，因为我们之前说过，权限刚刚够用就行，一个普通的账号不应该拥有这么大的权限。\n\n```SQL\nGRANT ALL PRIVILEGES ON *.* TO 'wangdachui'@'192.168.0.%';\n```\n\n### 召回权限\n\n如果要召回 wangdachui 对 school 数据库的 insert、delete 和 update 权限，可以使用下面的操作。\n\n```SQL\nREVOKE INSERT, DELETE, UPDATE ON `school`.* FROM 'wangdachui'@'192.168.0.%';\n```\n\n如果要召回所有的权限，可以按照如下所示的方式进行操作。\n\n```SQL\nREVOKE ALL PRIVILEGES ON *.* FROM 'wangdachui'@'192.168.0.%';\n```\n\n需要说明的是，由于数据库可能会缓存用户的权限，可以在授予或召回权限后执行下面的语句使新的权限即时生效。\n\n```SQL\nFLUSH PRIVILEGES;\n```\n\n", "MySQL新特性": "## MySQL新特性\n\n### JSON类型\n\n很多开发者在使用关系型数据库做数据持久化的时候，常常感到结构化的存储缺乏灵活性，因为必须事先设计好所有的列以及对应的数据类型。在业务发展和变化的过程中，如果需要修改表结构，这绝对是比较麻烦和难受的事情。从 MySQL 5.7 版本开始，MySQL引入了对 JSON 数据类型的支持（MySQL 8.0 解决了 JSON 的日志性能瓶颈问题），用好 JSON 类型，其实就是打破了关系型数据库和非关系型数据库之间的界限，为数据持久化操作带来了更多的便捷。\n\nJSON 类型主要分为 JSON 对象和 JSON数组两种，如下所示。\n\n1. JSON 对象\n\n```JSON\n{\"name\": \"小明\", \"tel\": \"13122335566\", \"QQ\": \"957658\"}\n```\n\n2. JSON 数组\n\n```JSON\n[1, 2, 3]\n```\n\n```JSON\n[{\"name\": \"小明\", \"tel\": \"13122335566\"}, {\"name\": \"王大锤\", \"QQ\": \"123456\"}]\n```\n\n哪些地方需要用到JSON类型呢？举一个简单的例子，现在很多产品的用户登录都支持多种方式，例如手机号、微信、QQ、新浪微博等，但是一般情况下我们又不会要求用户提供所有的这些信息，那么用传统的设计方式，就需要设计多个列来对应多种登录方式，可能还需要允许这些列存在空值，这显然不是很好的选择；另一方面，如果产品又增加了一种登录方式，那么就必然要修改之前的表结构，这就更让人痛苦了。但是，有了 JSON 类型，刚才的问题就迎刃而解了，我们可以做出如下所示的设计。\n\n```SQL\nCREATE TABLE `tb_test`\n(\n`user_id`    bigint unsigned,\n`login_info` json,\nPRIMARY KEY (`user_id`)\n);\n\nINSERT INTO `tb_test` \nVALUES \n    (1, '{\"tel\": \"13122335566\", \"QQ\": \"654321\", \"wechat\": \"jackfrued\"}'),\n    (2, '{\"tel\": \"13599876543\", \"weibo\": \"wangdachui123\"}');\n```\n\n如果要查询用户的手机和微信号，可以用如下所示的 SQL 语句。\n\n```SQL\nSELECT `user_id`\n     , JSON_UNQUOTE(JSON_EXTRACT(`login_info`, '$.tel')) AS 手机号\n     , JSON_UNQUOTE(JSON_EXTRACT(`login_info`, '$.wechat')) AS 微信 \nFROM `tb_test`;\n```\n\n```\n+---------+-------------+-----------+\n| user_id | 手机号      | 微信       |\n+---------+-------------+-----------+\n|       1 | 13122335566 | jackfrued |\n|       2 | 13599876543 | NULL      |\n+---------+-------------+-----------+\n```\n\n因为支持 JSON 类型，MySQL 也提供了配套的处理 JSON 数据的函数，就像上面用到的`json_extract`和`json_unquote`。当然，上面的 SQL 还有更为便捷的写法，如下所示。\n\n```SQL\nSELECT `user_id`\n     , `login_info` ->> '$.tel' AS 手机号\n     , `login_info` ->> '$.wechat' AS 微信\n  FROM `tb_test`;\n```\n\n再举个例子，如果我们的产品要实现用户画像功能（给用户打标签），然后基于用户画像给用户推荐平台的服务或消费品之类的东西，我们也可以使用 JSON 类型来保存用户画像数据，示意代码如下所示。\n\n创建画像标签表。\n\n```SQL\nCREATE TABLE `tb_tags`\n(\n`tag_id`   int unsigned NOT NULL COMMENT '标签ID',\n`tag_name` varchar(20)  NOT NULL COMMENT '标签名',\nPRIMARY KEY (`tag_id`)\n);\n\nINSERT INTO `tb_tags` (`tag_id`, `tag_name`) \nVALUES\n    (1, '70后'),\n    (2, '80后'),\n    (3, '90后'),\n    (4, '00后'),\n    (5, '爱运动'),\n    (6, '高学历'),\n    (7, '小资'),\n    (8, '有房'),\n    (9, '有车'),\n    (10, '爱看电影'),\n    (11, '爱网购'),\n    (12, '常点外卖');\n```\n\n为用户打标签。\n\n```SQL\nCREATE TABLE `tb_users_tags`\n(\n`user_id`   bigint unsigned NOT NULL COMMENT '用户ID',\n`user_tags` json            NOT NULL COMMENT '用户标签'\n);\n\nINSERT INTO `tb_users_tags`\nVALUES\n    (1, '[2, 6, 8, 10]'),\n    (2, '[3, 10, 12]'),\n    (3, '[3, 8, 9, 11]');\n```\n\n接下来，我们通过一组查询来了解 JSON 类型的巧妙之处。\n\n1. 查询爱看电影（有`10`这个标签）的用户ID。\n\n    ```SQL\n    SELECT `user_id`\n      FROM `tb_users_tags`\n     WHERE 10 MEMBER OF (`user_tags`->'$');\n    ```\n\n2. 查询爱看电影（有`10`这个标签）的80后（有`2`这个标签）用户ID。\n\n    ```SQL\n    SELECT `user_id`\n      FROM `tb_users_tags`\n     WHERE JSON_CONTAINS(`user_tags`->'$', '[2, 10]');\n    ```\n\n3. 查询爱看电影或80后或90后的用户ID。\n\n    ```SQL\n    SELECT `user_id`\n      FROM `tb_users_tags`\n     WHERE JSON_OVERLAPS(user_tags->'$', '[2, 3, 10]');\n    ```\n\n> **说明**：上面的查询用到了`member of`谓词和两个 JSON 函数，`json_contains`可以检查 JSON 数组是否包含了指定的元素，而`json_overlaps`可以检查 JSON 数组是否与指定的数组有重叠部分。\n\n### 窗口函数\n\nMySQL 从8.0开始支持窗口函数，大多数商业数据库和一些开源数据库早已提供了对窗口函数的支持，有的也将其称之为 OLAP（联机分析和处理）函数，听名字就知道跟统计和分析相关。为了帮助大家理解窗口函数，我们先说说窗口的概念。\n\n窗口可以理解为记录的集合，窗口函数也就是在满足某种条件的记录集合上执行的特殊函数，对于每条记录都要在此窗口内执行函数。窗口函数和我们上面讲到的聚合函数比较容易混淆，二者的区别主要在于聚合函数是将多条记录聚合为一条记录，窗口函数是每条记录都会执行，执行后记录条数不会变。窗口函数不仅仅是几个函数，它是一套完整的语法，函数只是该语法的一部分，基本语法如下所示：\n\n```SQL\n<窗口函数> OVER (PARTITION BY <用于分组的列名> ORDER BY <用于排序的列名>  ROWS BETWEEN ... AND ...)\n<窗口函数> OVER (PARTITION BY <用于分组的列名> ORDER BY <用于排序的列名> RANGE BETWEEN ... AND ...)\n```\n\n上面语法中，窗口函数的位置可以放以下两种函数：\n\n1. 专用窗口函数，包括：`lead`、`lag`、`first_value`、`last_value`、`rank`、`dense_rank`和`row_number`等。\n2. 聚合函数，包括：`sum`、`avg`、`max`、`min`和`count`等。\n\n下面为大家举几个使用窗口函数的简单例子，我们直接使用上一课创建的 hrs 数据库。\n\n例子1：查询按月薪从高到低排在第4到第6名的员工的姓名和月薪。\n\n```SQL\nSELECT * \n  FROM (SELECT `ename`\n             , `sal`\n             , ROW_NUMBER() over (ORDER BY `sal` DESC) AS `rk`\n\t      FROM `tb_emp`) AS `temp`\n WHERE `rk` between 4 and 6;\n```\n\n> **说明**：上面使用的函数`row_number()`可以为每条记录生成一个行号，在实际工作中可以根据需要将其替换为`rank()`或`dense_rank()`函数，三者的区别可以参考官方文档或阅读[《通俗易懂的学会：SQL窗口函数》](https://zhuanlan.zhihu.com/p/92654574)进行了解。在MySQL 8以前的版本，我们可以通过下面的方式来完成类似的操作。\n>\n> ```SQL\n> select `rank`, `ename`, `sal` from (\n>        select @a:=@a+1 as `rank`, `ename`, `sal` \n>        from `tb_emp`, (select @a:=0) as t1 order by `sal` desc\n> ) as `temp` where `rank` between 4 and 6;\n> ```\n\n例子2：查询每个部门月薪最高的两名的员工的姓名和部门名称。\n\n```SQL\nselect `ename`, `sal`, `dname` \nfrom (\n    select \n        `ename`, `sal`, `dno`,\n        rank() over (partition by `dno` order by `sal` desc) as `rank`\n    from `tb_emp`\n) as `temp` natural join `tb_dept` where `rank`<=2;\n```\n\n> 说明：在MySQL 8以前的版本，我们可以通过下面的方式来完成类似的操作。\n>\n> ```SQL\n> select `ename`, `sal`, `dname` from `tb_emp` as `t1` \nnatural join `tb_dept` \nwhere (\n        select count(*) from `tb_emp` as `t2` \n        where `t1`.`dno`=`t2`.`dno` and `t2`.`sal`>`t1`.`sal` \n)<2 order by `dno` asc, `sal` desc;\n> ```\n\n", "视图、函数和过程": "## 视图、函数和过程\n\n为了讲解视图、函数和过程，我们首先用下面的 DDL 和 DML 创建名为 hrs 的数据库并为其二维表添加如下所示的数据。\n\n```SQL\n-- 创建名为hrs的数据库并指定默认的字符集\ncreate database `hrs` default charset utf8mb4;\n\n-- 切换到hrs数据库\nuse `hrs`;\n\n-- 创建部门表\ncreate table `tb_dept`\n(\n`dno` int not null comment '编号',\n`dname` varchar(10) not null comment '名称',\n`dloc` varchar(20) not null comment '所在地',\nprimary key (`dno`)\n);\n\n-- 插入4个部门\ninsert into `tb_dept` values \n    (10, '会计部', '北京'),\n    (20, '研发部', '成都'),\n    (30, '销售部', '重庆'),\n    (40, '运维部', '深圳');\n\n-- 创建员工表\ncreate table `tb_emp`\n(\n`eno` int not null comment '员工编号',\n`ename` varchar(20) not null comment '员工姓名',\n`job` varchar(20) not null comment '员工职位',\n`mgr` int comment '主管编号',\n`sal` int not null comment '员工月薪',\n`comm` int comment '每月补贴',\n`dno` int not null comment '所在部门编号',\nprimary key (`eno`),\nconstraint `fk_emp_mgr` foreign key (`mgr`) references tb_emp (`eno`),\nconstraint `fk_emp_dno` foreign key (`dno`) references tb_dept (`dno`)\n);\n\n-- 插入14个员工\ninsert into `tb_emp` values \n    (7800, '张三丰', '总裁', null, 9000, 1200, 20),\n    (2056, '乔峰', '分析师', 7800, 5000, 1500, 20),\n    (3088, '李莫愁', '设计师', 2056, 3500, 800, 20),\n    (3211, '张无忌', '程序员', 2056, 3200, null, 20),\n    (3233, '丘处机', '程序员', 2056, 3400, null, 20),\n    (3251, '张翠山', '程序员', 2056, 4000, null, 20),\n    (5566, '宋远桥', '会计师', 7800, 4000, 1000, 10),\n    (5234, '郭靖', '出纳', 5566, 2000, null, 10),\n    (3344, '黄蓉', '销售主管', 7800, 3000, 800, 30),\n    (1359, '胡一刀', '销售员', 3344, 1800, 200, 30),\n    (4466, '苗人凤', '销售员', 3344, 2500, null, 30),\n    (3244, '欧阳锋', '程序员', 3088, 3200, null, 20),\n    (3577, '杨过', '会计', 5566, 2200, null, 10),\n    (3588, '朱九真', '会计', 5566, 2500, null, 10);\n```\n\n### 视图\n\n视图是关系型数据库中将一组查询指令构成的结果集组合成可查询的数据表的对象。简单的说，视图就是虚拟的表，但与数据表不同的是，数据表是一种实体结构，而视图是一种虚拟结构，你也可以将视图理解为保存在数据库中被赋予名字的 SQL 语句。\n\n使用视图可以获得以下好处：\n\n1. 可以将实体数据表隐藏起来，让外部程序无法得知实际的数据结构，让访问者可以使用表的组成部分而不是整个表，降低数据库被攻击的风险。\n2. 在大多数的情况下视图是只读的（更新视图的操作通常都有诸多的限制），外部程序无法直接透过视图修改数据。\n3. 重用 SQL 语句，将高度复杂的查询包装在视图表中，直接访问该视图即可取出需要的数据；也可以将视图视为数据表进行连接查询。\n4. 视图可以返回与实体数据表不同格式的数据，在创建视图的时候可以对数据进行格式化处理。\n\n创建视图。\n\n```SQL\ncreate view `vw_emp_simple`\nas\nselect  `eno`,\n        `ename`,\n        `job`,\n        `dno`\n  from  `tb_emp`;\n```\n\n> **提示**：因为视图不包含数据，所以每次使用视图时，都必须执行查询以获得数据，如果你使用了连接查询、嵌套查询创建了较为复杂的视图，你可能会发现查询性能下降得很厉害。因此，在使用复杂的视图前，应该进行测试以确保其性能能够满足应用的需求。\n\n有了上面的视图，我们就可以使用之前讲过的 DCL， 限制某些用户只能从视图中获取员工信息，这样员工表中的工资（`sal`）、补贴（`comm`）等敏感字段便不会暴露给用户。下面的代码演示了如何从视图中获取数据。\n\n```SQL\nselect * from `vw_emp_simple`;\n```\n\n查询结果：\n\n```\n+------+-----------+--------------+-----+\n| eno  | ename     | job          | dno |\n+------+-----------+--------------+-----+\n| 1359 | 胡二刀    | 销售员       |  30 |\n| 2056 | 乔峰      | 分析师       |  20 |\n| 3088 | 李莫愁    | 设计师       |  20 |\n| 3211 | 张无忌    | 程序员       |  20 |\n| 3233 | 丘处机    | 程序员       |  20 |\n| 3244 | 欧阳锋    | 程序员       |  20 |\n| 3251 | 张翠山    | 程序员       |  20 |\n| 3344 | 黄蓉      | 销售主管     |  30 |\n| 3577 | 杨过      | 会计         |  10 |\n| 3588 | 朱九真    | 会计         |  10 |\n| 4466 | 苗人凤    | 销售员       |  30 |\n| 5234 | 郭靖      | 出纳         |  10 |\n| 5566 | 宋远桥    | 会计师       |  10 |\n| 7800 | 张三丰    | 总裁         |  20 |\n+------+-----------+--------------+-----+\n```\n\n既然视图是一张虚拟的表，那么视图的中的数据可以更新吗？视图的可更新性要视具体情况而定，以下类型的视图是不能更新的：\n\n1. 使用了聚合函数（`SUM`、`MIN`、`MAX`、`AVG`、`COUNT`等）、`DISTINCT`、`GROUP BY`、`HAVING`、`UNION`或者`UNION ALL`的视图。\n2. `SELECT`中包含了子查询的视图。\n3. `FROM`子句中包含了一个不能更新的视图的视图。\n4. `WHERE`子句的子查询引用了`FROM`子句中的表的视图。\n\n删除视图。\n\n```SQL\ndrop view if exists `vw_emp_simple`;\n```\n\n> **说明**：如果希望更新视图，可以先用上面的命令删除视图，也可以通过`create or replace view`来更新视图。\n\n视图的规则和限制。\n\n1. 视图可以嵌套，可以利用从其他视图中检索的数据来构造一个新的视图。视图也可以和表一起使用。\n2. 创建视图时可以使用`order by`子句，但如果从视图中检索数据时也使用了`order by`，那么该视图中原先的`order by`会被覆盖。\n3. 视图无法使用索引，也不会激发触发器（实际开发中因为性能等各方面的考虑，通常不建议使用触发器，所以我们也不对这个概念进行介绍）的执行。\n\n### 函数\n\nMySQL 中的函数跟 Python 中的函数大同小异，因为函数都是用来封装功能上相对独立且会被重复使用的代码的。如果非要找出一些差别来，那么 MySQL 中的函数是可以执行 SQL 语句的。下面的例子，我们通过自定义函数实现了截断超长字符串的功能。\n\n```SQL\ndelimiter $$\n\ncreate function fn_truncate_string(\n    content varchar(10000),\n    max_length int unsigned\n) returns varchar(10000) no sql\nbegin\n    declare result varchar(10000) default content;\n    if char_length(content) > max_length then\n        set result = left(content, max_length);\n        set result = concat(result, '……');\n    end if;\n    return result;\nend $$\n\ndelimiter ;\n```\n\n> **说明1**：函数声明后面的`no sql`是声明函数体并没有使用 SQL 语句；如果函数体中需要通过 SQL 读取数据，需要声明为`reads sql data`。\n>\n> **说明2**：定义函数前后的`delimiter`命令是为了修改终止符（定界符），因为函数体中的语句都是用`;`表示结束，如果不重新定义定界符，那么遇到的`;`的时候代码就会被截断执行，显然这不是我们想要的效果。\n\n在查询中调用自定义函数。\n\n```SQL\nselect fn_truncate_string('和我在成都的街头走一走，直到所有的灯都熄灭了也不停留', 10) as short_string;\n```\n\n```\n+--------------------------------------+\n| short_string                         |\n+--------------------------------------+\n| 和我在成都的街头走一……                 |\n+--------------------------------------+\n```\n\n### 过程\n\n过程（又称存储过程）是事先编译好存储在数据库中的一组 SQL 的集合，调用过程可以简化应用程序开发人员的工作，减少与数据库服务器之间的通信，对于提升数据操作的性能也是有帮助的。其实迄今为止，我们使用的 SQL 语句都是针对一个或多个表的单条语句，但在实际开发中经常会遇到某个操作需要多条 SQL 语句才能完成的情况。例如，电商网站在受理用户订单时，需要做以下一系列的处理。 \n\n1. 通过查询来核对库存中是否有对应的物品以及库存是否充足。\n2. 如果库存有物品，需要锁定库存以确保这些物品不再卖给别人， 并且要减少可用的物品数量以反映正确的库存量。\n3. 如果库存不足，可能需要进一步与供应商进行交互或者至少产生一条系统提示消息。 \n4. 不管受理订单是否成功，都需要产生流水记录，而且需要给对应的用户产生一条通知信息。 \n\n我们可以通过过程将复杂的操作封装起来，这样不仅有助于保证数据的一致性，而且将来如果业务发生了变动，只需要调整和修改过程即可。对于调用过程的用户来说，过程并没有暴露数据表的细节，而且执行过程比一条条的执行一组 SQL 要快得多。\n\n下面的过程实现 hrs 数据库中员工工资的普调，具体的规则是：`10`部门的员工薪资上浮`300`， `20`部门的员工薪资上浮`800`，`30`部门的员工薪资上浮`500`。\n\n```SQL\ndelimiter $$\n\ncreate procedure sp_upgrade_salary()\nbegin\n    declare flag boolean default 1;\n    -- 定义一个异常处理器\n    declare continue handler for sqlexception set flag=0;\n\n    -- 开启事务环境\n    start transaction;\n    \n    update tb_emp set sal=sal+300 where dno=10;\n    update tb_emp set sal=sal+800 where dno=20;\n    update tb_emp set sal=sal+500 where dno=30;\n\n    -- 提交或回滚事务\n    if flag then\n        commit;\n    else\n        rollback;\n    end if;\nend $$\n\ndelimiter ;\n```\n\n> **说明**：上面的过程代码中使用了`start transaction`来开启事务环境，关于事务，在本课的最后有一个简单的介绍。为了确定代码中是否发生异常，从而提交或回滚事务，上面的过程中定义了一个名为`flag`的变量和一个异常处理器，如果发生了异常，`flag`将会被赋值为`0`，后面的分支结构会根据`flag`的值来决定是执行`commit`，还是执行`rollback`。\n\n调用过程。\n\n```SQL\ncall sp_upgrade_salary();\n```\n\n删除过程。\n\n```SQL\ndrop procedure if exists sp_upgrade_salary;\n```\n\n在过程中，我们可以定义变量、条件，可以使用分支和循环语句，可以通过游标操作查询结果，还可以使用事件调度器，这些内容我们暂时不在此处进行介绍。虽然我们说了很多过程的好处，但是在实际开发中，如果频繁的使用过程并将大量复杂的运算放到过程中，会给据库服务器造成巨大的压力，而数据库往往都是性能瓶颈所在，使用过程无疑是雪上加霜的操作。所以，对于互联网产品开发，我们一般建议让数据库只做好存储，复杂的运算和处理交给应用服务器上的程序去完成，如果应用服务器变得不堪重负了，我们可以比较容易的部署多台应用服务器来分摊这些压力。\n\n如果大家对上面讲到的视图、函数、过程包括我们没有讲到的触发器这些知识有兴趣，建议大家阅读 MySQL 的入门读物[《MySQL必知必会》](https://item.jd.com/12818982.html)进行一般性了解即可，因为这些知识点在大家将来的工作中未必用得上，学了也可能仅仅是为了应付面试而已。\n\n###  其他内容\n\n#### 范式理论\n\n范式理论是设计关系型数据库中二维表的指导思想。\n\n1. 第一范式：数据表的每个列的值域都是由原子值组成的，不能够再分割。\n2. 第二范式：数据表里的所有数据都要和该数据表的键（主键与候选键）有完全依赖关系。\n3. 第三范式：所有非键属性都只和候选键有相关性，也就是说非键属性之间应该是独立无关的。\n\n> **说明**：实际工作中，出于效率的考虑，我们在设计表时很有可能做出反范式设计，即故意降低方式级别，增加冗余数据来获得更好的操作性能。\n\n#### 数据完整性\n\n1. 实体完整性 - 每个实体都是独一无二的\n\n   - 主键（`primary key`） / 唯一约束（`unique`）\n2. 引用完整性（参照完整性）- 关系中不允许引用不存在的实体\n\n   - 外键（`foreign key`）\n3. 域（domain）完整性 - 数据是有效的\n   - 数据类型及长度\n\n   - 非空约束（`not null`）\n\n   - 默认值约束（`default`）\n\n   - 检查约束（`check`）\n\n     > **说明**：在 MySQL 8.x 以前，检查约束并不起作用。\n\n#### 数据一致性\n\n1. 事务：一系列对数据库进行读/写的操作，这些操作要么全都成功，要么全都失败。\n\n2. 事务的 ACID 特性\n   - 原子性：事务作为一个整体被执行，包含在其中的对数据库的操作要么全部被执行，要么都不执行\n   - 一致性：事务应确保数据库的状态从一个一致状态转变为另一个一致状态\n   - 隔离性：多个事务并发执行时，一个事务的执行不应影响其他事务的执行\n   - 持久性：已被提交的事务对数据库的修改应该永久保存在数据库中\n\n3. MySQL 中的事务操作\n\n   - 开启事务环境\n\n     ```SQL\n     start transaction\n     ```\n\n   - 提交事务\n\n     ```SQL\n     commit\n     ```\n\n   - 回滚事务\n\n     ```SQL\n     rollback\n     ```\n\n4. 查看事务隔离级别\n\n    ```SQL\n    show variables like 'transaction_isolation';\n    ```\n\n    ```\n    +-----------------------+-----------------+\n    | Variable_name         | Value           |\n    +-----------------------+-----------------+\n    | transaction_isolation | REPEATABLE-READ |\n    +-----------------------+-----------------+\n    ```\n\n    可以看出，MySQL 默认的事务隔离级别是`REPEATABLE-READ`。\n\n5. 修改（当前会话）事务隔离级别\n\n    ```SQL\n    set session transaction isolation level read committed;\n    ```\n\n    重新查看事务隔离级别，结果如下所示。\n\n    ```\n    +-----------------------+----------------+\n    | Variable_name         | Value          |\n    +-----------------------+----------------+\n    | transaction_isolation | READ-COMMITTED |\n    +-----------------------+----------------+\n    ```\n\n关系型数据库的事务是一个很大的话题，因为当存在多个并发事务访问数据时，就有可能出现三类读数据的问题（脏读、不可重复读、幻读）和两类更新数据的问题（第一类丢失更新、第二类丢失更新）。想了解这五类问题的，可以阅读我发布在 CSDN 网站上的[《Java面试题全集（上）》](https://blog.csdn.net/jackfrued/article/details/44921941)一文的第80题。为了避免这些问题，关系型数据库底层是有对应的锁机制的，按锁定对象不同可以分为表级锁和行级锁，按并发事务锁定关系可以分为共享锁和独占锁。然而直接使用锁是非常麻烦的，为此数据库为用户提供了自动锁机制，只要用户指定适当的事务隔离级别，数据库就会通过分析 SQL 语句，然后为事务访问的资源加上合适的锁。此外，数据库还会维护这些锁通过各种手段提高系统的性能，这些对用户来说都是透明的。想了解 MySQL 事务和锁的细节知识，推荐大家阅读进阶读物[《高性能MySQL》](https://item.jd.com/11220393.html)，这也是数据库方面的经典书籍。\n\nANSI/ISO SQL 92标准定义了4个等级的事务隔离级别，如下表所示。需要说明的是，事务隔离级别和数据访问的并发性是对立的，事务隔离级别越高并发性就越差。所以要根据具体的应用来确定到底使用哪种事务隔离级别，这个地方没有万能的原则。\n\n<img src=\"http://localhost/mypic/20211121225327.png\" style=\"zoom:50%;\">\n\n### 总结\n\n关于 MySQL 的知识肯定远远不止上面列出的这些，比如 MySQL 性能调优、MySQL 运维相关工具、MySQL 数据的备份和恢复、监控 MySQL 服务、部署高可用架构等，这一系列的问题在这里都没有办法逐一展开来讨论，那就留到有需要的时候再进行讲解吧，各位读者也可以自行探索。\n", "索引": "## 索引\n\n索引是关系型数据库中用来提升查询性能最为重要的手段。关系型数据库中的索引就像一本书的目录，我们可以想象一下，如果要从一本书中找出某个知识点，但是这本书没有目录，这将是一件多么可怕的事情！我们估计得一篇一篇的翻下去，才能确定这个知识点到底在什么位置。创建索引虽然会带来存储空间上的开销，就像一本书的目录会占用一部分篇幅一样，但是在牺牲空间后换来的查询时间的减少也是非常显著的。\n\nMySQL 数据库中所有数据类型的列都可以被索引。对于MySQL 8.0 版本的 InnoDB 存储引擎来说，它支持三种类型的索引，分别是 B+ 树索引、全文索引和 R 树索引。这里，我们只介绍使用得最为广泛的 B+ 树索引。使用 B+ 树的原因非常简单，因为它是目前在基于磁盘进行海量数据存储和排序上最有效率的数据结构。B+ 树是一棵[平衡树](https://zh.wikipedia.org/zh-cn/%E5%B9%B3%E8%A1%A1%E6%A0%91)，树的高度通常为3或4，但是却可以保存从百万级到十亿级的数据，而从这些数据里面查询一条数据，只需要3次或4次 I/O 操作。\n\nB+ 树由根节点、中间节点和叶子节点构成，其中叶子节点用来保存排序后的数据。由于记录在索引上是排序过的，因此在一个叶子节点内查找数据时可以使用二分查找，这种查找方式效率非常的高。当数据很少的时候，B+ 树只有一个根节点，数据也就保存在根节点上。随着记录越来越多，B+ 树会发生分裂，根节点不再保存数据，而是提供了访问下一层节点的指针，帮助快速确定数据在哪个叶子节点上。\n\n在创建二维表时，我们通常都会为表指定主键列，主键列上默认会创建索引，而对于 MySQL InnoDB 存储引擎来说，因为它使用的是索引组织表这种数据存储结构，所以主键上的索引就是整张表的数据，而这种索引我们也将其称之为**聚集索引**（clustered index）。很显然，一张表只能有一个聚集索引，否则表的数据岂不是要保存多次。我们自己创建的索引都是二级索引（secondary index），更常见的叫法是**非聚集索引**（non-clustered index）。通过我们自定义的非聚集索引只能定位记录的主键，在获取数据时可能需要再通过主键上的聚集索引进行查询，这种现象称为“回表”，因此通过非聚集索引检索数据通常比使用聚集索引检索数据要慢。\n\n接下来我们通过一个简单的例子来说明索引的意义，比如我们要根据学生的姓名来查找学生，这个场景在实际开发中应该经常遇到，就跟通过商品名称查找商品是一个道理。我们可以使用 MySQL 的`explain`关键字来查看 SQL 的执行计划（数据库执行 SQL 语句的具体步骤）。\n\n```SQL\nexplain select * from tb_student where stuname='林震南'\\G\n```\n\n```\n*************************** 1. row ***************************\n           id: 1\n  select_type: SIMPLE\n        table: tb_student\n   partitions: NULL\n         type: ALL\npossible_keys: NULL\n          key: NULL\n      key_len: NULL\n          ref: NULL\n         rows: 11\n     filtered: 10.00\n        Extra: Using where\n1 row in set, 1 warning (0.00 sec)\n```\n\n在上面的 SQL 执行计划中，有几项值得我们关注：\n\n1. `select_type`：查询的类型。\n    - `SIMPLE`：简单 SELECT，不需要使用 UNION 操作或子查询。\n    - `PRIMARY`：如果查询包含子查询，最外层的 SELECT 被标记为 PRIMARY。\n    - `UNION`：UNION 操作中第二个或后面的 SELECT 语句。\n    - `SUBQUERY`：子查询中的第一个 SELECT。\n    - `DERIVED`：派生表的 SELECT 子查询。\n2. `table`：查询对应的表。\n3. `type`：MySQL 在表中找到满足条件的行的方式，也称为访问类型，包括：`ALL`（全表扫描）、`index`（索引全扫描，只遍历索引树）、`range`（索引范围扫描）、`ref`（非唯一索引扫描）、`eq_ref`（唯一索引扫描）、`const` / `system`（常量级查询）、`NULL`（不需要访问表或索引）。在所有的访问类型中，很显然 ALL 是性能最差的，它代表的全表扫描是指要扫描表中的每一行才能找到匹配的行。\n4. `possible_keys`：MySQL 可以选择的索引，但是**有可能不会使用**。\n5. `key`：MySQL 真正使用的索引，如果为`NULL`就表示没有使用索引。\n6. `key_len`：使用的索引的长度，在不影响查询的情况下肯定是长度越短越好。\n7. `rows`：执行查询需要扫描的行数，这是一个**预估值**。\n8. `extra`：关于查询额外的信息。\n    - `Using filesort`：MySQL 无法利用索引完成排序操作。\n    - `Using index`：只使用索引的信息而不需要进一步查表来获取更多的信息。\n    - `Using temporary`：MySQL 需要使用临时表来存储结果集，常用于分组和排序。\n    - `Impossible where`：`where`子句会导致没有符合条件的行。\n    - `Distinct`：MySQL 发现第一个匹配行后，停止为当前的行组合搜索更多的行。\n    - `Using where`：查询的列未被索引覆盖，筛选条件并不是索引的前导列。\n\n从上面的执行计划可以看出，当我们通过学生名字查询学生时实际上是进行了全表扫描，不言而喻这个查询性能肯定是非常糟糕的，尤其是在表中的行很多的时候。如果我们需要经常通过学生姓名来查询学生，那么就应该在学生姓名对应的列上创建索引，通过索引来加速查询。\n\n```SQL\ncreate index idx_student_name on tb_student(stuname);\n```\n\n再次查看刚才的 SQL 对应的执行计划。\n\n```SQL\nexplain select * from tb_student where stuname='林震南'\\G\n```\n\n```\n*************************** 1. row ***************************\n           id: 1\n  select_type: SIMPLE\n        table: tb_student\n   partitions: NULL\n         type: ref\npossible_keys: idx_student_name\n          key: idx_student_name\n      key_len: 62\n          ref: const\n         rows: 1\n     filtered: 100.00\n        Extra: NULL\n1 row in set, 1 warning (0.00 sec)\n```\n\n可以注意到，在对学生姓名创建索引后，刚才的查询已经不是全表扫描而是基于索引的查询，而且扫描的行只有唯一的一行，这显然大大的提升了查询的性能。MySQL 中还允许创建前缀索引，即对索引字段的前N个字符创建索引，这样的话可以减少索引占用的空间（但节省了空间很有可能会浪费时间，**时间和空间是不可调和的矛盾**），如下所示。\n\n```SQL\ncreate index idx_student_name_1 on tb_student(stuname(1));\n```\n\n上面的索引相当于是根据学生姓名的第一个字来创建的索引，我们再看看 SQL 执行计划。\n\n```SQL\nexplain select * from tb_student where stuname='林震南'\\G\n```\n\n```\n*************************** 1. row ***************************\n           id: 1\n  select_type: SIMPLE\n        table: tb_student\n   partitions: NULL\n         type: ref\npossible_keys: idx_student_name\n          key: idx_student_name\n      key_len: 5\n          ref: const\n         rows: 2\n     filtered: 100.00\n        Extra: Using where\n1 row in set, 1 warning (0.00 sec)\n```\n\n不知道大家是否注意到，这一次扫描的行变成了2行，因为学生表中有两个姓“林”的学生，我们只用姓名的第一个字作为索引的话，在查询时通过索引就会找到这两行。\n\n如果要删除索引，可以使用下面的SQL。\n\n```SQL\nalter table tb_student drop index idx_student_name;\n```\n\n或者\n\n```SQL\ndrop index idx_student_name on tb_student;\n```\n\n在创建索引时，我们还可以使用复合索引、函数索引（MySQL 5.7 开始支持），用好复合索引实现**索引覆盖**可以减少不必要的排序和回表操作，这样就会让查询的性能成倍的提升，有兴趣的读者可以自行研究。\n\n我们简单的为大家总结一下索引的设计原则：\n\n1. **最适合**索引的列是出现在**WHERE子句**和连接子句中的列。\n2. 索引列的基数越大（取值多、重复值少），索引的效果就越好。\n3. 使用**前缀索引**可以减少索引占用的空间，内存中可以缓存更多的索引。\n4. **索引不是越多越好**，虽然索引加速了读操作（查询），但是写操作（增、删、改）都会变得更慢，因为数据的变化会导致索引的更新，就如同书籍章节的增删需要更新目录一样。\n5. 使用 InnoDB 存储引擎时，表的普通索引都会保存主键的值，所以**主键要尽可能选择较短的数据类型**，这样可以有效的减少索引占用的空间，提升索引的缓存效果。\n\n最后，还有一点需要说明，InnoDB 使用的 B-tree 索引，数值类型的列除了等值判断时索引会生效之外，使用`>`、`<`、`>=`、`<=`、`BETWEEN...AND... `、`<>`时，索引仍然生效；对于字符串类型的列，如果使用不以通配符开头的模糊查询，索引也是起作用的，但是其他的情况会导致索引失效，这就意味着很有可能会做全表查询。\n", "接入MySQL数据库": "## Python接入MySQL数据库\n\n在 Python3 中，我们可以使用`mysqlclient`或者`pymysql`三方库来接入 MySQL 数据库并实现数据持久化操作。二者的用法完全相同，只是导入的模块名不一样。我们推荐大家使用纯 Python 的三方库`pymysql`，因为它更容易安装成功。下面我们仍然以之前创建的名为`hrs`的数据库为例，为大家演示如何通过 Python 程序操作 MySQL 数据库实现数据持久化操作。\n\n### 接入MySQL\n\n首先，我们可以在命令行或者 PyCharm 的终端中通过下面的命令安装`pymysql`，如果需要接入 MySQL 8，还需要安装一个名为`cryptography`的三方库来支持 MySQL 8 的密码认证方式。\n\n```Shell\npip install pymysql cryptography\n```\n\n使用`pymysql`操作 MySQL 的步骤如下所示：\n\n1. 创建连接。MySQL 服务器启动后，提供了基于 TCP （传输控制协议）的网络服务。我们可以通过`pymysql`模块的`connect`函数连接 MySQL 服务器。在调用`connect`函数时，需要指定主机（`host`）、端口（`port`）、用户名（`user`）、口令（`password`）、数据库（`database`）、字符集（`charset`）等参数，该函数会返回一个`Connection`对象。\n2. 获取游标。连接 MySQL 服务器成功后，接下来要做的就是向数据库服务器发送 SQL 语句，MySQL 会执行接收到的 SQL 并将执行结果通过网络返回。要实现这项操作，需要先通过连接对象的`cursor`方法获取游标（`Cursor`）对象。\n3. 发出 SQL。通过游标对象的`execute`方法，我们可以向数据库发出 SQL 语句。\n4. 如果执行`insert`、`delete`或`update`操作，需要根据实际情况提交或回滚事务。因为创建连接时，默认开启了事务环境，在操作完成后，需要使用连接对象的`commit`或`rollback`方法，实现事务的提交或回滚，`rollback`方法通常会放在异常捕获代码块`except`中。如果执行`select`操作，需要通过游标对象抓取查询的结果，对应的方法有三个，分别是：`fetchone`、`fetchmany`和`fetchall`。其中`fetchone`方法会抓取到一条记录，并以元组或字典的方式返回；`fetchmany`和`fetchall`方法会抓取到多条记录，以嵌套元组或列表装字典的方式返回。\n5. 关闭连接。在完成持久化操作后，请不要忘记关闭连接，释放外部资源。我们通常会在`finally`代码块中使用连接对象的`close`方法来关闭连接。\n\n### 代码实操\n\n下面，我们通过代码实操的方式为大家演示上面说的五个步骤。\n\n#### 插入数据\n\n```Python\nimport pymysql\n\nno = int(input('部门编号: '))\nname = input('部门名称: ')\nlocation = input('部门所在地: ')\n\n# 1. 创建连接（Connection）\nconn = pymysql.connect(host='127.0.0.1', port=3306,\n                       user='guest', password='Guest.618',\n                       database='hrs', charset='utf8mb4')\ntry:\n    # 2. 获取游标对象（Cursor）\n    with conn.cursor() as cursor:\n        # 3. 通过游标对象向数据库服务器发出SQL语句\n        affected_rows = cursor.execute(\n            'insert into `tb_dept` values (%s, %s, %s)',\n            (no, name, location)\n        )\n        if affected_rows == 1:\n            print('新增部门成功!!!')\n    # 4. 提交事务（transaction）\n    conn.commit()\nexcept pymysql.MySQLError as err:\n    # 4. 回滚事务\n    conn.rollback()\n    print(type(err), err)\nfinally:\n    # 5. 关闭连接释放资源\n    conn.close()\n```\n\n> **说明**：上面的`127.0.0.1`称为回环地址，它代表的是本机。下面的`guest`是我提前创建好的用户，该用户拥有对`hrs`数据库的`insert`、`delete`、`update`和`select`权限。我们不建议大家在项目中直接使用`root`超级管理员账号访问数据库，这样做实在是太危险了。我们可以使用下面的命令创建名为`guest`的用户并为其授权。\n>\n> ```SQL\n> create user 'guest'@'%' identified by 'Guest.618';\n> grant insert, delete, update, select on `hrs`.* to 'guest'@'%';\n> ```\n\n如果要插入大量数据，建议使用游标对象的`executemany`方法做批处理（一个`insert`操作后面跟上多组数据），大家可以尝试向一张表插入10000条记录，然后看看不使用批处理一条条的插入和使用批处理有什么差别。游标对象的`executemany`方法第一个参数仍然是 SQL 语句，第二个参数可以是包含多组数据的列表或元组。\n\n#### 删除数据\n\n```Python\nimport pymysql\n\nno = int(input('部门编号: '))\n\n# 1. 创建连接（Connection）\nconn = pymysql.connect(host='127.0.0.1', port=3306,\n                       user='guest', password='Guest.618',\n                       database='hrs', charset='utf8mb4',\n                       autocommit=True)\ntry:\n    # 2. 获取游标对象（Cursor）\n    with conn.cursor() as cursor:\n        # 3. 通过游标对象向数据库服务器发出SQL语句\n        affected_rows = cursor.execute(\n            'delete from `tb_dept` where `dno`=%s',\n            (no, )\n        )\n        if affected_rows == 1:\n            print('删除部门成功!!!')\nfinally:\n    # 5. 关闭连接释放资源\n    conn.close()\n```\n\n> **说明**：如果不希望每次 SQL 操作之后手动提交或回滚事务，可以`connect`函数中加一个名为`autocommit`的参数并将它的值设置为`True`，表示每次执行 SQL 成功后自动提交。但是我们建议大家手动提交或回滚，这样可以根据实际业务需要来构造事务环境。如果不愿意捕获异常并进行处理，可以在`try`代码块后直接跟`finally`块，省略`except`意味着发生异常时，代码会直接崩溃并将异常栈显示在终端中。\n\n#### 更新数据\n\n```Python\nimport pymysql\n\nno = int(input('部门编号: '))\nname = input('部门名称: ')\nlocation = input('部门所在地: ')\n\n# 1. 创建连接（Connection）\nconn = pymysql.connect(host='127.0.0.1', port=3306,\n                       user='guest', password='Guest.618',\n                       database='hrs', charset='utf8mb4')\ntry:\n    # 2. 获取游标对象（Cursor）\n    with conn.cursor() as cursor:\n        # 3. 通过游标对象向数据库服务器发出SQL语句\n        affected_rows = cursor.execute(\n            'update `tb_dept` set `dname`=%s, `dloc`=%s where `dno`=%s',\n            (name, location, no)\n        )\n        if affected_rows == 1:\n            print('更新部门信息成功!!!')\n    # 4. 提交事务\n    conn.commit()\nexcept pymysql.MySQLError as err:\n    # 4. 回滚事务\n    conn.rollback()\n    print(type(err), err)\nfinally:\n    # 5. 关闭连接释放资源\n    conn.close()\n```\n\n#### 查询数据\n\n1. 查询部门表的数据。\n\n```Python\nimport pymysql\n\n# 1. 创建连接（Connection）\nconn = pymysql.connect(host='127.0.0.1', port=3306,\n                       user='guest', password='Guest.618',\n                       database='hrs', charset='utf8mb4')\ntry:\n    # 2. 获取游标对象（Cursor）\n    with conn.cursor() as cursor:\n        # 3. 通过游标对象向数据库服务器发出SQL语句\n        cursor.execute('select `dno`, `dname`, `dloc` from `tb_dept`')\n        # 4. 通过游标对象抓取数据\n        row = cursor.fetchone()\n        while row:\n            print(row)\n            row = cursor.fetchone()\nexcept pymysql.MySQLError as err:\n    print(type(err), err)\nfinally:\n    # 5. 关闭连接释放资源\n    conn.close()\n```\n>**说明**：上面的代码中，我们通过构造一个`while`循环实现了逐行抓取查询结果的操作。这种方式特别适合查询结果有非常多行的场景。因为如果使用`fetchall`一次性将所有记录抓取到一个嵌套元组中，会造成非常大的内存开销，这在很多场景下并不是一个好主意。如果不愿意使用`while`循环，还可以考虑使用`iter`函数构造一个迭代器来逐行抓取数据，有兴趣的读者可以自行研究。\n\n2. 分页查询员工表的数据。\n\n```Python\nimport pymysql\n\npage = int(input('页码: '))\nsize = int(input('大小: '))\n\n# 1. 创建连接（Connection）\ncon = pymysql.connect(host='127.0.0.1', port=3306,\n                      user='guest', password='Guest.618',\n                      database='hrs', charset='utf8')\ntry:\n    # 2. 获取游标对象（Cursor）\n    with con.cursor(pymysql.cursors.DictCursor) as cursor:\n        # 3. 通过游标对象向数据库服务器发出SQL语句\n        cursor.execute(\n            'select `eno`, `ename`, `job`, `sal` from `tb_emp` order by `sal` desc limit %s,%s',\n            ((page - 1) * size, size)\n        )\n        # 4. 通过游标对象抓取数据\n        for emp_dict in cursor.fetchall():\n            print(emp_dict)\nfinally:\n    # 5. 关闭连接释放资源\n    con.close()\n```\n\n### 案例讲解\n\n下面我们为大家讲解一个将数据库表数据导出到 Excel 文件的例子，我们需要先安装`openpyxl`三方库，命令如下所示。\n\n```Bash\npip install openpyxl\n```\n\n接下来，我们通过下面的代码实现了将数据库`hrs`中所有员工的编号、姓名、职位、月薪、补贴和部门名称导出到一个 Excel 文件中。\n\n```Python\nimport openpyxl\nimport pymysql\n\n# 创建工作簿对象\nworkbook = openpyxl.Workbook()\n# 获得默认的工作表\nsheet = workbook.active\n# 修改工作表的标题\nsheet.title = '员工基本信息'\n# 给工作表添加表头\nsheet.append(('工号', '姓名', '职位', '月薪', '补贴', '部门'))\n# 创建连接（Connection）\nconn = pymysql.connect(host='127.0.0.1', port=3306,\n                       user='guest', password='Guest.618',\n                       database='hrs', charset='utf8mb4')\ntry:\n    # 获取游标对象（Cursor）\n    with conn.cursor() as cursor:\n        # 通过游标对象执行SQL语句\n        cursor.execute(\n            'select `eno`, `ename`, `job`, `sal`, coalesce(`comm`, 0), `dname` '\n            'from `tb_emp` natural join `tb_dept`'\n        )\n        # 通过游标抓取数据\n        row = cursor.fetchone()\n        while row:\n            # 将数据逐行写入工作表中\n            sheet.append(row)\n            row = cursor.fetchone()\n    # 保存工作簿\n    workbook.save('hrs.xlsx')\nexcept pymysql.MySQLError as err:\n    print(err)\nfinally:\n    # 关闭连接释放资源\n    conn.close()\n```\n\n大家可以参考上面的例子，试一试把 Excel 文件的数据导入到指定数据库的指定表中，看看是否可以成功。", "大数据平台和HiveSQL": "## Hive简介\n\n[Hive](https://hive.apache.org/) 是 Facebook 开源的一款基于 Hadoop 的数据仓库工具，目前由 Apache 软件基金会维护，它是应用最广泛的大数据处理解决方案，它能将 SQL 查询转变为 MapReduce（Google提出的一个软件架构，用于大规模数据集的并行运算）任务，对 SQL 提供了完美的支持，能够非常方便的实现大数据统计。\n\n<img class=\"lazy\" data-src=\"/res/sql_to_mr.png\" style=\"zoom:50%;\">\n\n<img class=\"lazy\" data-src=\"/res/HADOOP-ECOSYSTEM-Edureka.png\">\n\n> **说明**：可以通过<https://www.edureka.co/blog/hadoop-ecosystem>来了解 Hadoop 生态圈。\n\n如果要简单的介绍 Hive，那么以下两点是其核心：\n\n1. 把 HDFS 中结构化的数据映射成表。\n2. 通过把 HQL 进行解析和转换，最终生成一系列基于 Hadoop 的 MapReduce 任务或 Spark 任务，通过执行这些任务完成对数据的处理。也就是说，即便不学习 Java、Scala 这样的编程语言，一样可以实现对数据的处理。\n\nHive的应用场景。\n\n<img class=\"lazy\" data-src=\"/res/what_hive_can_do.png\" style=\"zoom:50%;\">\n\n<img class=\"lazy\" data-src=\"/res/what_hive_can_not_do.png\" style=\"zoom:35%;\">\n\nHive和传统关系型数据库的对比如下图和下表所示。\n\n<img class=\"lazy\" data-src=\"/res/hive_vs_rdbms.png\" style=\"zoom:50%;\">\n\n|          | Hive              | RDBMS        |\n| -------- | ----------------- | ------------ |\n| 查询语言 | HQL               | SQL          |\n| 存储数据 | HDFS              | 本地文件系统 |\n| 执行方式 | MapReduce / Spark | Executor     |\n| 执行延迟 | 高                | 低           |\n| 数据规模 | 大                | 小           |\n\n### 准备工作\n\n1. 搭建如下图所示的大数据平台。\n\n    <img class=\"lazy\" data-src=\"/res/20220210080638.png\" style=\"zoom:60%;\">\n\n2. 通过Client节点（跳板机）访问大数据平台。\n\n    <img class=\"lazy\" data-src=\"/res/20220210080655.png\" style=\"zoom:50%;\">\n\n3. 创建文件Hadoop的文件系统。\n\n    ```Shell\n    hdfs dfs -mkdir /user/root\n    ```\n\n4. 将准备好的数据文件拷贝到Hadoop文件系统中。\n\n    ```Shell\n    hdfs dfs -put /home/ubuntu/data/* /user/root\n    ```\n\n5. 进入 hive 命令行。\n\n    ```Shell\n    hive\n    ```\n\n### 建库建表\n\n1. 创建。\n\n    ```SQL\n    create database eshop;\n    ```\n\n2. 删除。\n\n    ```SQL\n    drop database eshop cascade;\n    ```\n\n3. 切换。\n\n    ```SQL\n    use eshop;\n    ```\n\n#### 数据类型\n\nHive的数据类型如下所示。\n\n<img class=\"lazy\" data-src=\"/res/hive_data_types.png\" style=\"zoom:50%;\">\n\n基本数据类型：\n\n| 数据类型  | 占用空间 | 支持版本 |\n| --------- | -------- | -------- |\n| tinyint   | 1-Byte   |          |\n| smallint  | 2-Byte   |          |\n| int       | 4-Byte   |          |\n| bigint    | 8-Byte   |          |\n| boolean   |          |          |\n| float     | 4-Byte   |          |\n| double    | 8-Byte   |          |\n| string    |          |          |\n| binary    |          | 0.8版本  |\n| timestamp |          | 0.8版本  |\n| decimal   |          | 0.11版本 |\n| char      |          | 0.13版本 |\n| varchar   |          | 0.12版本 |\n| date      |          | 0.12版本 |\n\n复合数据类型：\n\n| 数据类型 | 描述                     | 例子                                          |\n| -------- | ------------------------ | --------------------------------------------- |\n| struct   | 和C语言中的结构体类似    | `struct<first_name:string, last_name:string>` |\n| map      | 由键值对构成的元素的集合 | `map<string,int>`                             |\n| array    | 具有相同类型的变量的容器 | `array<string>`                               |\n\n4. 创建内部表。\n\n    ```SQL\n    create table if not exists dim_user_info \n    (\n    user_id string,\n    user_name string, \n    sex string,\n    age int,\n    city string,\n    firstactivetime string,\n    level int,\n    extra1 string,\n    extra2 map<string,string>\n    )\n    row format delimited fields terminated by '\\t'\n    collection items terminated by ','\n    map keys terminated by ':'\n    lines terminated by '\\n'\n    stored as textfile;\n    ```\n\n5. 加载数据。\n\n    ```SQL\n    load data local inpath '/home/ubuntu/data/user_info/user_info.txt' overwrite into table dim_user_info;\n    ```\n\n    或\n\n    ```SQL\n    load data inpath '/user/root/user_info.txt' overwrite into table dim_user_info;\n    ```\n\n6. 创建分区表。\n\n    ```SQL\n    create table if not exists fact_user_trade \n    (\n    user_name string,\n    piece int,\n    price double,\n    pay_amount double,\n    goods_category string,\n    pay_time bigint\n    )  \n    partitioned by (dt string)\n    row format delimited fields terminated by '\\t';\n    ```\n\n7. 提供分区数据。\n\n    ```Shell\n    hdfs dfs -put /home/ubuntu/data/user_trade/* /user/hive/warehouse/eshop.db/fact_user_trade\n    ```\n\n8. 设置动态分区。\n\n    ```SQL\n    set hive.exec.dynamic.partition=true;\n    set hive.exec.dynamic.partition.mode=nonstrict;\n    set hive.exec.max.dynamic.partitions=10000;\n    set hive.exec.max.dynamic.partitions.pernode=10000;\n    ```\n\n9. 修复分区。\n\n    ```SQL\n    msck repair table fact_user_trade;\n    ```\n\n### 查询\n\n#### 基本语法\n\n```SQL\n-- 查询北京女用户的姓名取前10个\nselect user_name from dim_user_info where city='beijing' and sex='female' limit 10;\n\n-- 查询2019年3月24日购买了food类商品的用户名、购买数量和支付金额（不聚合）\nselect user_name, piece, pay_amount from fact_user_trade where dt='2019-03-24' and goods_category='food';\n\n-- 统计用户 ELLA 在2018年的总支付金额和最近最远两次消费间隔天数\nselect sum(pay_amount) as total, datediff(max(from_unixtime(pay_time, 'yyyy-MM-dd')), min(from_unixtime(pay_time, 'yyyy-MM-dd'))) from fact_user_trade where year(dt)='2018' and user_name='ELLA';\n```\n\n#### group by\n\n```SQL\n-- 查询2019年1月到4月，每个品类有多少人购买，累计金额是多少\nselect goods_category, count(distinct user_name) as total_user, sum(pay_amount) as total_pay from fact_user_trade where dt between '2019-01-01' and '2019-04-30' group by goods_category;\n```\n\n```SQL\n-- 查询2019年4月支付金额超过5万元的用户\nselect user_name, sum(pay_amount) as total from fact_user_trade where dt between '2019-04-01' and '2019-04-30' group by user_name having sum(pay_amount) > 50000;\n```\n\n```hive\n-- 查询2018年购买的商品品类在两个以上的用户数\nselect count(tmp.user_name) from (select user_name, count(distinct goods_category) as total from fact_user_trade where year(dt)='2018' group by user_name having count(distinct goods_category)>2) tmp;\n```\n\n#### order by\n\n```SQL\n-- 查询2019年4月支付金额最多的用户前5名\nselect user_name, sum(pay_amount) as total from fact_user_trade where dt between '2019-04-01' and '2019-04-30' group by user_name order by total desc limit 5;\n```\n\n#### 常用函数\n\n1. `from_unixtime`：将时间戳转换成日期\n\n    ```hive\n    select from_unixtime(pay_time, 'yyyy-MM-dd hh:mm:ss') from fact_user_trade limit 10;\n    ```\n\n2. `unix_timestamp`：将日期转换成时间戳\n\n3. `datediff`：计算两个日期的时间差\n\n    ```Hive\n    -- 用户首次激活时间与设定参照时间的间隔\n    select user_name, datediff('2019-4-1', to_date(firstactivetime)) from dim_user_info limit 10;\n    ```\n\n4. `if`：根据条件返回不同的值\n\n    ```Hive\n    -- 统计不同年龄段的用户数\n    select case when age < 20 then '20岁以下' when age < 30 then '30岁以下' when age < 40 then '40岁以下' else '40岁以上' end as age_seg, count(distinct user_id) as total from dim_user_info group by case when age < 20 then '20岁以下' when age < 30 then '30岁以下' when age < 40 then '40岁以下' else '40岁以上' end;\n    ```\n\n    ```Hive\n    -- 不同性别高级等用户数量\n    select sex, if(level > 5, '高', '低') as level_type, count(distinct user_id) as total from dim_user_info group by sex, if(level > 5, '高', '低');\n    ```\n\n5. `substr`：字符串取子串\n\n    ```Hive\n    -- 统计每个月激活的新用户数\n    select substr(firstactivetime, 1, 7) as month, count(distinct user_id) as total from dim_user_info group by substr(firstactivetime, 1, 7);\n    ```\n\n6. `get_json_object`：从JSON字符串中取出指定的`key`对应的`value`，如：`get_json_object(info, '$.first_name')`。\n\n    ```Hive\n    -- 统计不同手机品牌的用户数\n    select get_json_object(extra1, '$.phonebrand') as phone, count(distinct user_id) as total from user_info group by get_json_object(extra1, '$.phonebrand');\n    \n    select extra2['phonebrand'] as phone, count(distinct user_id) as total from user_info group by extra2['phonebrand'];\n    ```\n\n    > 说明：MySQL对应的函数名字叫`json_extract`。\n", "Django快速上手": "## Django快速上手\n\nWeb开发的早期阶段，开发者需要手动编写每个页面，例如一个新闻门户网站，每天都要修改它的HTML页面，随着网站规模和体量的增大，这种做法一定是非常糟糕的。为了解决这个问题，开发人员想到了用程序来为Web服务器生成动态内容，也就是说网页中的动态内容不再通过手动编写而是通过程序自动生成。最早的时候，这项技术被称为CGI（公共网关接口），当然随着时间的推移，CGI暴露出的问题也越来越多，例如大量重复的样板代码，总体性能较为低下等。在时代呼唤新英雄的背景下，PHP、ASP、JSP这类Web应用开发技术在上世纪90年代中后期如雨后春笋般涌现。通常我们说的Web应用是指通过浏览器来访问网络资源的应用程序，因为浏览器的普及性以及易用性，Web应用使用起来方便简单，免除了安装和更新应用程序带来的麻烦；站在开发者的角度，也不用关心用户使用什么样的操作系统，甚至不用区分是PC端还是移动端。\n\n### Web应用机制和术语\n\n下图向我们展示了Web应用的工作流程，其中涉及到的术语如下表所示。\n\n![](./res/web-application.png)\n\n> 说明：相信有经验的读者会发现，这张图中其实还少了很多东西，例如反向代理服务器、数据库服务器、防火墙等，而且图中的每个节点在实际项目部署时可能是一组节点组成的集群。当然，如果你对这些没有什么概念也不要紧，继续下去就行了，后面会给大家一一讲解的。\n\n| 术语          | 解释                                                         |\n| ------------- | ------------------------------------------------------------ |\n| **URL/URI**   | 统一资源定位符/统一资源标识符，网络资源的唯一标识            |\n| **域名**      | 与Web服务器地址对应的一个易于记忆的字符串名字                |\n| **DNS**       | 域名解析服务，可以将域名转换成对应的IP地址                   |\n| **IP地址**    | 网络上的主机的身份标识，通过IP地址可以区分不同的主机         |\n| **HTTP**      | 超文本传输协议，构建在TCP之上的应用级协议，万维网数据通信的基础 |\n| **反向代理**  | 代理客户端向服务器发出请求，然后将服务器返回的资源返回给客户端 |\n| **Web服务器** | 接受HTTP请求，然后返回HTML文件、纯文本文件、图像等资源给请求者 |\n| **Nginx**     | 高性能的Web服务器，也可以用作[反向代理](https://zh.wikipedia.org/wiki/%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86)，[负载均衡](https://zh.wikipedia.org/wiki/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1) 和 [HTTP缓存](https://zh.wikipedia.org/wiki/HTTP%E7%BC%93%E5%AD%98) |\n\n#### HTTP协议\n\n这里我们先费一些笔墨来说说HTTP这个协议。HTTP（超文本传输协议）是构建于TCP（传输控制协议）之上应用级协议，它利用了TCP提供的可靠的传输服务实现了Web应用中的数据交换。按照维基百科上的介绍，设计HTTP最初的目的是为了提供一种发布和接收[HTML](https://zh.wikipedia.org/wiki/HTML)页面的方法，也就是说这个协议是浏览器和Web服务器之间传输的数据的载体。关于这个协议的详细信息以及目前的发展状况，大家可以阅读[《HTTP 协议入门》](http://www.ruanyifeng.com/blog/2016/08/http.html)、[《互联网协议入门》](http://www.ruanyifeng.com/blog/2012/05/internet_protocol_suite_part_i.html)系列以及[《图解HTTPS协议》](http://www.ruanyifeng.com/blog/2014/09/illustration-ssl.html)这几篇文章进行了解。下图是我在四川省网络通信技术重点实验室学习和工作期间使用开源协议分析工具Ethereal（抓包工具WireShark的前身）截取的访问百度首页时的HTTP请求和响应的报文（协议数据），由于Ethereal截取的是经过网络适配器的数据，因此可以清晰的看到从物理链路层到应用层的协议数据。\n\nHTTP请求（请求行+请求头+空行+[消息体]）：\n\n![](./res/http-request.png)\n\nHTTP响应（响应行+响应头+空行+消息体）：\n\n![](./res/http-response.png)\n\n>  **说明**：这两张图是在2009年9月10日凌晨获得的，但愿这两张如同泛黄的照片般的截图能帮助你了解HTTP到底是什么样子的。当然，如果没有专业的抓包工具，也可以通过浏览器提供的“开发者工具”来查看HTTP请求和响应的数据格式。\n\n### Django概述\n\nPython的Web框架有上百个，比它的关键字还要多。所谓Web框架，就是用于开发Web服务器端应用的基础设施，说得通俗一点就是一系列封装好的模块和工具。事实上，即便没有Web框架，我们仍然可以通过socket或[CGI](https://zh.wikipedia.org/wiki/%E9%80%9A%E7%94%A8%E7%BD%91%E5%85%B3%E6%8E%A5%E5%8F%A3)来开发Web服务器端应用，但是这样做的成本和代价在商业项目中通常是不能接受的。通过Web框架，我们可以化繁为简，降低创建、更新、扩展应用程序的工作量。刚才我们说到Python有上百个Web框架，这些框架包括Django、Flask、Tornado、Sanic、Pyramid、Bottle、Web2py、web.py等。\n\n在上述Python的Web框架中，Django无疑是最有代表性的重量级选手，开发者可以基于Django快速的开发可靠的Web应用程序，因为它减少了Web开发中不必要的开销，对常用的设计和开发模式进行了封装，并对MVC架构提供了支持（Django中称之为MTV架构）。MVC是软件系统开发领域中一种放之四海而皆准的架构，它将系统中的组件分为模型（Model）、视图（View）和控制器（Controller）三个部分并借此实现模型（数据）和视图（显示）的解耦合。由于模型和视图进行了分离，所以需要一个中间人将解耦合的模型和视图联系起来，扮演这个角色的就是控制器。稍具规模的软件系统都会使用MVC架构（或者是从MVC演进出的其他架构），Django项目中我们称之为MTV，MTV中的M跟MVC中的M没有区别，就是代表数据的模型，T代表了网页模板（显示数据的视图），而V代表了视图函数，在Django框架中，视图函数和Django框架本身一起扮演了MVC中C的角色。\n\n![](./res/mvc.png)\n\nDjango框架诞生于2003年，它是一个在真正的应用中成长起来的项目，由劳伦斯出版集团旗下在线新闻网站的内容管理系统（CMS）研发团队（主要是Adrian Holovaty和Simon Willison）开发，以比利时的吉普赛爵士吉他手Django Reinhardt来命名。Django框架在2005年夏天作为开源框架发布，使用Django框架能用很短的时间构建出功能完备的网站，因为它代替程序员完成了那些重复乏味的劳动，剩下真正有意义的核心业务给程序员来开发，这一点就是对DRY（Don't Repeat Yourself）理念的最好践行。许多成功的网站和应用都是基于Python语言进行开发的，国内比较有代表性的网站包括：知乎、豆瓣网、果壳网、搜狐闪电邮箱、101围棋网、海报时尚网、背书吧、堆糖、手机搜狐网、咕咚、爱福窝、果库等，其中不乏使用了Django框架的产品。\n\n### 快速上手\n\n#### 第一个Django项目\n\n1. 检查Python环境：Django 1.11需要Python 2.7或Python 3.4以上的版本；Django 2.0需要Python 3.4以上的版本；Django 2.1和2.2需要Python 3.5以上的版本；Django 3.0需要Python 3.6以上版本。\n\n   > **说明**：Django框架不同版本所需的Python解释器环境，可以在Django官方文档的[FAQ](https://docs.djangoproject.com/zh-hans/3.0/faq/install/#faq-python-version-support)中找到。\n\n   可以在macOS的终端中输入下面的命令检查Python解释器版本，Windows系统可以在命令行提示符中输入`python --version`。\n   \n   ```Bash\npython3 --version\n   ```\n   \n   也可以在Python的交互式环境中执行下面的代码来查看Python解释器的版本。\n   \n   ```Shell\n   import sys\n   sys.version\n   sys.version_info\n   ```\n   \n2. 更新包管理工具并安装Django环境（用于创建Django项目）。\n\n   > **说明**：在更新这个文档时，Django最新的正式版本是3.0.7，Django 3.0提供了对ASGI的支持，可以实现全双工的异步通信，但是目前的使用体验一般，所以暂时不推荐大家使用Django 3.0，下面我们安装的是Django 2.2.13版本。使用`pip`安装三方库和工具时，可以通过`==`来指定安装的版本。\n   \n   ```Bash\n   pip3 install -U pip\n   pip3 install django==2.2.13\n   ```\n   \n3. 检查Django环境并使用`django-admin`命令创建Django项目（项目名称为hellodjango）。\n\n   ```Shell\n   django-admin --version\n   django-admin startproject hellodjango\n   ```\n\n4. 用PyCharm打开创建好的Djang项目，并为其添加虚拟环境。\n\n   ![](/res/pycharm-django-project.png)\n\n   如上图所示，PyCharm的项目浏览器中，最顶层的文件夹`hellodjango`是Python项目文件夹，这个文件夹的名字并不重要，Django项目也不关心这个文件夹叫什么名字。该文件夹下有一个同名的文件夹，它是Django项目文件夹，其中包含了`__init__.py`、`settings.py`、`urls.py`、`wsgi.py`四个文件，与名为`hellodjango`的Django项目文件夹同级的还有一个名为`manage.py` 的文件，这些文件的作用如下所示：\n\n   - `hellodjango/__init__.py`：空文件，告诉Python解释器这个目录应该被视为一个Python的包。\n   - `hellodjango/settings.py`：Django项目的配置文件。\n   - `hellodjango/urls.py`：Django项目的URL映射声明，就像是网站的“目录”。\n   - `hellodjango/wsgi.py`：项目运行在WSGI兼容Web服务器上的入口文件。\n   - `manage.py`： 管理Django项目的脚本程序。\n\n   > 说明：WSGI全称是Web服务器网关接口，维基百科上给出的解释是“为Python语言定义的[Web服务器](https://zh.wikipedia.org/wiki/%E7%B6%B2%E9%A0%81%E4%BC%BA%E6%9C%8D%E5%99%A8)和[Web应用程序](https://zh.wikipedia.org/wiki/%E7%BD%91%E7%BB%9C%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F)或框架之间的一种简单而通用的接口”。\n\n   创建虚拟环境的界面如下图所示。\n\n   ![pycharm-django-virtual-environment](/res/pycharm-django-virtual-environment.png)\n\n5. 安装项目依赖项。\n\n   方法一：打开PyCharm的终端，在终端中通过`pip`命令安装Django项目的依赖项。\n\n   > **说明**：由于已经基于Python 3解释器环境为项目创建了虚拟环境，所以虚拟环境中的`python`命令对应的是Python 3的解释器，而`pip`命令对应的是Python 3的包管理工具。\n\n   ```Shell\n   pip install django==2.2.13\n   ```\n\n   方法二：在PyCharm的偏好设置中，可以找到项目的解释器环境和已经安装的三方库，可以通过点击添加按钮来安装新的依赖项，需要提醒大家的是在安装Django依赖项时，需要指定版本号，否则将默认安装更新本文时最新的3.0.7版本。\n\n   ![](/res/pycharm-install-django.png)\n\n   下图展示了Django版本和Python版本的对应关系，请大家自行对号入座。\n\n   | Django版本 | Python版本                                |\n   | ---------- | ----------------------------------------- |\n   | 1.8        | 2.7、3.2、3.3、3.4、3.5                   |\n   | 1.9、1.10  | 2.7、3.4、3.5                             |\n   | 1.11       | 2.7、3.4、3.5、3.6、3.7（Django 1.11.17） |\n   | 2.0        | 3.4、3.5、3.6、3.7                        |\n   | 2.1        | 3.5、3.6、3.7                             |\n   | 2.2        | 3.5、3.6、3.7、3.8（Django 2.2.8）        |\n   | 3.0        | 3.6、3.7、3.8                             |\n\n6. 启动Django自带的服务器运行项目。\n\n   方法一：在“Run”菜单选择“Edit Configuration”，配置“Django server”运行项目（适用于专业版PyCharm）。\n\n   ![](/res/pycharm-django-server.png)\n\n   方法二：在“Run”菜单选择“Edit Configuration”，配置运行“Python”程序运行项目（适用于专业版和社区版PyCharm）。\n\n   ![](/res/pycharm-python-manage.png)\n\n   方法三：在PyCharm的终端（Terminal）中通过命令运行项目（适用于专业版和社区版PyCharm）。\n\n   ```Shell\n   python manage.py runserver\n   ```\n\n7. 查看运行效果。\n\n  在浏览器中输入`http://127.0.0.1:8000`访问我们的服务器，效果如下图所示。\n\n   ![](./res/django-index-1.png)\n\n   > **说明**：\n   >\n   > 1. 刚刚启动的Django自带的服务器只能用于开发和测试环境，因为这个服务器是纯Python编写的轻量级Web服务器，不适合在生产环境中使用。\n   > 2. 如果修改了代码，不需要为了让修改的代码生效而重新启动Django自带的服务器。但是，在添加新的项目文件时，该服务器不会自动重新加载，这个时候就得手动重启服务器。\n   > 3. 可以在终端中通过`python manage.py help`命令查看Django管理脚本程序可用的命令参数。\n   > 4. 使用`python manage.py runserver`启动服务器时，可以在后面添加参数来指定IP地址和端口号，默认情况下启动的服务器将运行在本机的`8000`端口。\n   > 5. 在终端中运行的服务器，可以通过Ctrl+C来停止它 。通过PyCharm的“运行配置”运行的服务器直接点击窗口上的关闭按钮就可以终止服务器的运行。\n   > 6. 不能在同一个端口上启动多个服务器，因为会导致地址的冲突（端口是对IP地址的扩展，也是计算机网络地址的一部分）。\n8. 修改项目的配置文件`settings.py`。\n\n   Django是一个支持国际化和本地化的框架，因此刚才我们看到的Django项目的默认首页也是支持国际化的，我们可以通过修改配置文件将默认语言修改为中文，时区设置为东八区。\n\n   找到修改前的配置（在`settings.py`文件第100行以后）。\n\n   ```Python\n   LANGUAGE_CODE = 'en-us'\n   TIME_ZONE = 'UTC'\n   ```\n\n   修改为以下内容。\n\n   ```Python\n   LANGUAGE_CODE = 'zh-hans'\n   TIME_ZONE = 'Asia/Chongqing'\n   ```\n\n   刷新刚才的页面，可以看到修改语言代码和时区之后的结果。\n\n   ![](./res/django-index-2.png)\n\n#### 创建自己的应用\n\n如果要开发自己的Web应用，需要先在Django项目中创建“应用”，一个Django项目可以包含一个或多个应用。\n\n1. 在PyCharm的终端中执行下面的命令，创建名为`first`的应用。\n\n   ```Shell\n   python manage.py startapp first\n   ```\n\n   执行上面的命令会在当前路径下创建`first`目录，其目录结构如下所示：\n\n   - `__init__.py`：一个空文件，告诉Python解释器这个目录应该被视为一个Python的包。\n   - `admin.py`：可以用来注册模型，用于在Django框架自带的管理后台中管理模型。\n   -  `apps.py`：当前应用的配置文件。\n   - `migrations`：存放与模型有关的数据库迁移信息。\n     - `__init__.py`：一个空文件，告诉Python解释器这个目录应该被视为一个Python的包。\n   - `models.py`：存放应用的数据模型（MTV中的M）。\n   - `tests.py`：包含测试应用各项功能的测试类和测试函数。\n   - `views.py`：处理用户HTTP请求并返回HTTP响应的函数或类（MTV中的V）。\n\n2. 修改应用目录下的视图文件`views.py`。\n\n   ```Python\n   from django.http import HttpResponse\n   \n\n   def show_index(request):\n       return HttpResponse('<h1>Hello, Django!</h1>')\n   ```\n   \n4. 修改Django项目目录下的`urls.py`文件，将视图函数和用户在浏览器中请求的路径对应。\n\n   ```Python\n   from django.contrib import admin\n   from django.urls import path, include\n\n   from first.views import show_index\n   \n   urlpatterns = [\n       path('admin/', admin.site.urls),\n       path('hello/', show_index),\n   ]\n   ```\n   \n5. 重新运行项目，并打开浏览器中访问`http://127.0.0.1:8000/hello/`。\n\n5. 上面我们通过代码为浏览器生成了内容，但仍然是静态内容，如果要生成动态内容，可以修改`views.py`文件并添加如下所示的代码。\n\n   ```Python\n   from random import sample\n   \n   from django.http import HttpResponse\n   \n   \n   def show_index(request):\n       fruits = [\n           'Apple', 'Orange', 'Pitaya', 'Durian', 'Waxberry', 'Blueberry',\n           'Grape', 'Peach', 'Pear', 'Banana', 'Watermelon', 'Mango'\n       ]\n       selected_fruits = sample(fruits, 3)\n       content = '<h3>今天推荐的水果是：</h3>'\n       content += '<hr>'\n       content += '<ul>'\n       for fruit in selected_fruits:\n           content += f'<li>{fruit}</li>'\n       content += '</ul>'\n       return HttpResponse(content)\n   ```\n\n6. 刷新页面查看程序的运行结果，看看每次刷新的网页的时候，是不是可以看到不一样的内容。\n\n\n#### 使用模板\n\n上面通过拼接HTML代码的方式为浏览器生成动态内容的做法在实际开发中是无能接受的，因为实际项目中的前端页面可能非常复杂，无法用这种拼接动态内容的方式来完成，这一点大家一定能够想到。为了解决这个问题，我们可以提前准备一个模板页（MTV中的T），所谓模板页就是一个带占位符和模板指令的HTML页面。\n\nDjango框架中有一个名为`render`的便捷函数可以来完成渲染模板的操作。所谓的渲染就是用数据替换掉模板页中的模板指令和占位符，当然这里的渲染称为后端渲染，即在服务器端完成页面的渲染再输出到浏览器中。后端渲染的做法在Web应用的访问量较大时，会让服务器承受较大的负担，所以越来越多的Web应用会选择前端渲染的方式，即服务器只提供页面所需的数据（通常是JSON格式），在浏览器中通过JavaScript代码获取这些数据并渲染页面上。关于前端渲染的内容，我们会在后续的课程中为大家讲解，目前我们使用的是通过模板页进行后端渲染的做法，具体步骤如下所示。\n\n使用模板页的步骤如下所示。\n\n1. 在项目目录下创建名为templates文件夹。\n\n   ![](/res/pycharm-django-template.png)\n\n2. 添加模板页`index.html`。\n\n   > **说明**：实际项目开发中，静态页由前端开发者提供，后端开发者需要将静态页修改为模板页，以便通过Python程序对其进行渲染，这种做法就是上面提到的后端渲染。\n\n   ```HTML\n   <!DOCTYPE html>\n   <html lang=\"en\">\n       <head>\n           <meta charset=\"UTF-8\">\n           <title>首页</title>\n           <style>\n               #fruits {\n                   font-size: 1.25em;\n               }\n           </style>\n       </head>\n       <body>\n           <h1>今天推荐的水果是：</h1>\n           <hr>\n           <ul id=\"fruits\">\n               {% for fruit in fruits %}\n               <li>{{ fruit }}</li>\n               {% endfor %}\n           </ul>\n       </body>\n   </html>\n   ```\n   在上面的模板页中我们使用了`{{ fruit }}`这样的模板占位符语法，也使用了`{% for %}`这样的模板指令，这些都是Django模板语言（DTL）的一部分。关于模板语法和指令，大家可以看看官方文档，相信这些内容还是很容易理解的，并不需要过多的赘述，大家也可以参考[官方文档]()了解模板指令和语法。\n\n3. 修改`views.py`文件，调用`render`函数渲染模板页。\n\n   ```Python\n   from random import sample\n   \n   from django.shortcuts import render\n   \n   \n   def show_index(request):\n       fruits = [\n           'Apple', 'Orange', 'Pitaya', 'Durian', 'Waxberry', 'Blueberry',\n           'Grape', 'Peach', 'Pear', 'Banana', 'Watermelon', 'Mango'\n       ]\n       selected_fruits = sample(fruits, 3)\n       return render(request, 'index.html', {'fruits': selected_fruits})\n   ```\n\n   `render`函数的第一个参数是请求对象request，第二个参数是我们要渲染的模板页的名字，第三个参数是要渲染到页面上的数据，我们通过一个字典将数据交给模板页，字典中的键就是模板页中使用的模板指令或占位符中的变量名。\n\n4. 到此为止，视图函数中的`render`还无法找到模板文件`index.html`，需要修改`settings.py`文件，配置模板文件所在的路径。修改`settings.py`文件，找到`TEMPLATES`配置，修改其中的`DIRS`配置。\n\n   ```Python\n   TEMPLATES = [\n       {\n           'BACKEND': 'django.template.backends.django.DjangoTemplates',\n           'DIRS': [os.path.join(BASE_DIR, 'templates'), ],\n           'APP_DIRS': True,\n           'OPTIONS': {\n               'context_processors': [\n                   'django.template.context_processors.debug',\n                   'django.template.context_processors.request',\n                   'django.contrib.auth.context_processors.auth',\n                   'django.contrib.messages.context_processors.messages',\n               ],\n           },\n       },\n   ]\n   ```\n\n5. 重新运行项目或直接刷新页面查看结果。\n\n### 总结\n\n至此，我们已经利用Django框架完成了一个非常小的Web应用，虽然它并没有任何的实际价值，但是可以通过这个项目对Django框架有一个感性的认识。学习Django最好的资料肯定是它的[官方文档](https://docs.djangoproject.com/zh-hans/2.0/)，官方文档提供了对多国语言的支持，而且有新手教程引导初学者学习使用Django框架，建议大家通过阅读Django的官方文档来学习和使用这个框架。当然图灵社区出版的[《Django基础教程》](http://www.ituring.com.cn/book/2630)也是非常适合初学者的入门级读物，有兴趣的读者可以点击链接进行购买。 \n", "深入模型": "## 深入模型\n\n在上一个章节中，我们提到了Django是基于MVC架构的Web框架，MVC架构追求的是“模型”和“视图”的解耦合。所谓“模型”说得更直白一些就是数据（的表示），所以通常也被称作“数据模型”。在实际的项目中，数据模型通常通过数据库实现持久化操作，而关系型数据库在过去和当下都是持久化的首选方案，下面我们通过完成一个投票项目来讲解和模型相关的知识点。投票项目的首页会展示某在线教育平台所有的学科；点击学科可以查看到该学科的老师及其信息；用户登录后在查看老师的页面为老师投票，可以投赞成票和反对票；未登录的用户可以通过登录页进行登录；尚未注册的用户可以通过注册页输入个人信息进行注册。在这个项目中，我们使用MySQL数据库来实现数据持久化操作。\n\n### 创建项目和应用\n\n我们首先创建Django项目`vote`并为其添加虚拟环境和依赖项。接下来，在项目下创建名为`polls`的应用和保存模板页的文件夹`tempaltes`，项目文件夹的结构如下所示。\n\n![](/res/pycharm-vote-project.png)\n\n根据上面描述的项目需求，我们准备了四个静态页面，分别是展示学科的页面`subjects.html`，显示学科老师的页面`teachers.html`，登录页面`login.html`，注册页面`register.html`，稍后我们会将静态页修改为Django项目所需的模板页。\n\n### 配置关系型数据库MySQL \n\n1. 在MySQL中创建数据库，创建用户，授权用户访问该数据库。\n\n   ```SQL\n   create database vote default charset utf8;\n   create user 'hellokitty'@'%' identified by 'Hellokitty.618';\n   grant all privileges on vote.* to 'hellokitty'@'%';\n   flush privileges;\n   ```\n\n2. 在MySQL中创建保存学科和老师信息的二维表（保存用户信息的表稍后处理）。\n\n   ```SQL\n   use vote;\n   \n   -- 创建学科表\n   create table `tb_subject`\n   (\n   \t`no` integer auto_increment comment '学科编号',\n       `name` varchar(50) not null comment '学科名称',\n       `intro` varchar(1000) not null default '' comment '学科介绍',\n       `is_hot` boolean not null default 0 comment '是不是热门学科',\n       primary key (`no`)\n   );\n   -- 创建老师表\n   create table `tb_teacher`\n   (\n       `no` integer auto_increment comment '老师编号',\n       `name` varchar(20) not null comment '老师姓名',\n       `sex` boolean not null default 1 comment '老师性别',\n       `birth` date not null comment '出生日期',\n       `intro` varchar(1000) not null default '' comment '老师介绍',\n       `photo` varchar(255) not null default '' comment '老师照片',\n       `gcount` integer not null default 0 comment '好评数',\n       `bcount` integer not null default 0 comment '差评数',\n       `sno` integer not null comment '所属学科',\n       primary key (`no`),\n       foreign key (`sno`) references `tb_subject` (`no`)\n   );\n   ```\n\n3. 在虚拟环境中安装连接MySQL数据库所需的依赖项。\n\n   ```Bash\n   pip install mysqlclient\n   ```\n\n   > **说明**：如果因为某些原因无法安装`mysqlclient`三方库，可以使用它的替代品`pymysql`，`pymysql`是用纯Python开发的连接MySQL的Python库，安装更容易成功，但是需要在Django项目文件夹的`__init__.py`中添加如下所示的代码。\n   >\n   > ```Python\n   > import pymysql\n   > \n   > pymysql.install_as_MySQLdb()\n   > ```\n   >\n   > 如果使用Django 2.2及以上版本，还会遇到PyMySQL跟Django框架的兼容性问题，兼容性问题会导致项目无法运行，需要按照GitHub上PyMySQL仓库[Issues](https://github.com/PyMySQL/PyMySQL/issues/790)中提供的方法进行处理。总体来说，使用`pymysql`会比较麻烦，强烈建议大家首选安装`mysqlclient`。\n\n4. 修改项目的settings.py文件，首先将我们创建的应用`polls`添加已安装的项目（`INSTALLED_APPS`）中，然后配置MySQL作为持久化方案。\n\n   ```Python\n   INSTALLED_APPS = [\n       'django.contrib.admin',\n       'django.contrib.auth',\n       'django.contrib.contenttypes',\n       'django.contrib.sessions',\n       'django.contrib.messages',\n       'django.contrib.staticfiles',\n       'polls',\n   ]\n   \n   DATABASES = {\n       'default': {\n           # 数据库引擎配置\n           'ENGINE': 'django.db.backends.mysql',\n           # 数据库的名字\n           'NAME': 'vote',\n           # 数据库服务器的IP地址（本机可以写localhost或127.0.0.1）\n           'HOST': 'localhost',\n           # 启动MySQL服务的端口号\n           'PORT': 3306,\n           # 数据库用户名和口令\n           'USER': 'hellokitty',\n           'PASSWORD': 'Hellokitty.618',\n           # 数据库使用的字符集\n           'CHARSET': 'utf8',\n           # 数据库时间日期的时区设定\n           'TIME_ZONE': 'Asia/Chongqing',\n       }\n   }\n   ```\n\n   在配置ENGINE属性时，常用的可选值包括：\n\n   - `'django.db.backends.sqlite3'`：SQLite嵌入式数据库。\n   - `'django.db.backends.postgresql'`：BSD许可证下发行的开源关系型数据库产品。\n   - `'django.db.backends.mysql'`：甲骨文公司经济高效的数据库产品。\n   - `'django.db.backends.oracle'`：甲骨文公司关系型数据库旗舰产品。\n\n   其他的配置可以参考官方文档中[数据库配置](https://docs.djangoproject.com/zh-hans/2.0/ref/databases/#third-party-notes)的部分。\n\n5. Django框架提供了ORM来解决数据持久化问题，ORM翻译成中文叫“对象关系映射”。因为Python是面向对象的编程语言，我们在Python程序中使用对象模型来保存数据，而关系型数据库使用关系模型，用二维表来保存数据，这两种模型并不匹配。使用ORM是为了实现对象模型到关系模型的**双向转换**，这样就不用在Python代码中书写SQL语句和游标操作，因为这些都会由ORM自动完成。利用Django的ORM，我们可以直接将刚才创建的学科表和老师表变成Django中的模型类。\n\n   ```Bash\n   python manage.py inspectdb > polls/models.py\n   ```\n\n   我们可以对自动生成的模型类稍作调整，代码如下所示。\n\n   ```Python\n   from django.db import models\n   \n   \n   class Subject(models.Model):\n       no = models.AutoField(primary_key=True, verbose_name='编号')\n       name = models.CharField(max_length=50, verbose_name='名称')\n       intro = models.CharField(max_length=1000, verbose_name='介绍')\n       is_hot = models.BooleanField(verbose_name='是否热门')\n   \n       class Meta:\n           managed = False\n           db_table = 'tb_subject'\n   \n   \n   class Teacher(models.Model):\n       no = models.AutoField(primary_key=True, verbose_name='编号')\n       name = models.CharField(max_length=20, verbose_name='姓名')\n       sex = models.BooleanField(default=True, verbose_name='性别')\n       birth = models.DateField(verbose_name='出生日期')\n       intro = models.CharField(max_length=1000, verbose_name='个人介绍')\n       photo = models.ImageField(max_length=255, verbose_name='照片')\n       good_count = models.IntegerField(default=0, db_column='gcount', verbose_name='好评数')\n       bad_count = models.IntegerField(default=0, db_column='bcount', verbose_name='差评数')\n       subject = models.ForeignKey(Subject, models.DO_NOTHING, db_column='sno')\n   \n       class Meta:\n           managed = False\n           db_table = 'tb_teacher'\n   ```\n   \n   > **说明**：模型类都直接或间接继承自`Model`类，模型类跟关系型数据库的二维表对应，模型对象跟表中的记录对应，模型对象的属性跟表中的字段对应。如果对上面模型类的属性定义不是特别理解，可以看看本文后面提供的“模型定义参考”部分的内容。\n\n### 使用ORM完成模型的CRUD操作\n\n有了Django框架的ORM，我们可以直接使用面向对象的方式来实现对数据的CRUD（增删改查）操作。我们可以在PyCharm的终端中输入下面的命令进入到Django项目的交互式环境，然后尝试对模型的操作。\n\n```Bash\npython manage.py shell\n```\n\n#### 新增\n\n```Python\nfrom polls.models import Subject\n\nsubject1 = Subject(name='Python全栈开发', intro='当下最热门的学科', is_hot=True)\nsubject1.save()\nsubject2 = Subject(name='全栈软件测试', intro='学习自动化测试的学科', is_hot=False)\nsubject2.save()\nsubject3 = Subject(name='JavaEE分布式开发', intro='基于Java语言的服务器应用开发', is_hot=True)\n```\n\n#### 删除\n\n```Python\nsubject = Subject.objects.get(no=2)\nsubject.delete()\n```\n\n#### 更新\n\n```Shell\nsubject = Subject.objects.get(no=1)\nsubject.name = 'Python全栈+人工智能'\nsubject.save()\n```\n\n#### 查询\n\n1. 查询所有对象。\n\n```Shell\nSubject.objects.all()\n```\n\n2. 过滤数据。\n\n```Shell\n# 查询名称为“Python全栈+人工智能”的学科\nSubject.objects.filter(name='Python全栈+人工智能')\n\n# 查询名称包含“全栈”的学科（模糊查询）\nSubject.objects.filter(name__contains='全栈')\nSubject.objects.filter(name__startswith='全栈')\nSubject.objects.filter(name__endswith='全栈')\n\n# 查询所有热门学科\nSubject.objects.filter(is_hot=True)\n\n# 查询编号大于3小于10的学科\nSubject.objects.filter(no__gt=3).filter(no__lt=10)\nSubject.objects.filter(no__gt=3, no__lt=10)\n\n# 查询编号在3到7之间的学科\nSubject.objects.filter(no__ge=3, no__le=7)\nSubject.objects.filter(no__range=(3, 7))\n```\n\n3. 查询单个对象。\n\n```Shell\n# 查询主键为1的学科\nSubject.objects.get(pk=1)\nSubject.objects.get(no=1)\nSubject.objects.filter(no=1).first()\nSubject.objects.filter(no=1).last()\n```\n\n4. 排序。\n\n```Shell\n# 查询所有学科按编号升序排列\nSubject.objects.order_by('no')\n# 查询所有部门按部门编号降序排列\nSubject.objects.order_by('-no')\n```\n\n5. 切片（分页查询）。\n\n```Shell\n# 按编号从小到大查询前3个学科\nSubject.objects.order_by('no')[:3]\n```\n\n6. 计数。\n\n```Python\n# 查询一共有多少个学科\nSubject.objects.count()\n```\n\n7. 高级查询。\n\n```Shell\n# 查询编号为1的学科的老师\nTeacher.objects.filter(subject__no=1)\nSubject.objects.get(pk=1).teacher_set.all() \n\n# 查询学科名称有“全栈”二字的学科的老师\nTeacher.objects.filter(subject__name__contains='全栈') \n```\n\n> **说明1**：由于老师与学科之间存在多对一外键关联，所以能通过学科反向查询到该学科的老师（从一对多关系中“一”的一方查询“多”的一方），反向查询属性默认的名字是`类名小写_set`（如上面例子中的`teacher_set`），当然也可以在创建模型时通过`ForeingKey`的`related_name`属性指定反向查询属性的名字。如果不希望执行反向查询可以将`related_name`属性设置为`'+'`或者以`'+'`开头的字符串。\n\n> **说明2**：ORM查询多个对象时会返回QuerySet对象，QuerySet使用了惰性查询，即在创建QuerySet对象的过程中不涉及任何数据库活动，等真正用到对象时（对QuerySet求值）才向数据库发送SQL语句并获取对应的结果，这一点在实际开发中需要引起注意！\n\n> **说明3**：如果希望更新多条数据，不用先逐一获取模型对象再修改对象属性，可以直接使用QuerySet对象的`update()`方法一次性更新多条数据。\n\n\n### 利用Django后台管理模型\n\n在创建好模型类之后，可以通过Django框架自带的后台管理应用（`admin`应用）实现对模型的管理。虽然实际应用中，这个后台可能并不能满足我们的需求，但是在学习Django框架时，我们可以利用`admin`应用来管理我们的模型，同时也通过它来了解一个项目的后台管理系统需要哪些功能。使用Django自带的`admin`应用步骤如下所示。\n\n1. 将`admin`应用所需的表迁移到数据库中。`admin`应用本身也需要数据库的支持，而且在`admin`应用中已经定义好了相关的数据模型类，我们只需要通过模型迁移操作就能自动在数据库中生成所需的二维表。\n\n   ```Bash\n   python manage.py migrate\n   ```\n   \n2. 创建访问`admin`应用的超级用户账号，这里需要输入用户名、邮箱和口令。\n\n   ```Shell\n   python manage.py createsuperuser\n   ```\n\n   > **说明**：输入口令时没有回显也不能退格，需要一气呵成完成输入。\n\n3. 运行项目，在浏览器中访问`http://127.0.0.1:8000/admin`，输入刚才创建的超级用户账号和密码进行登录。\n\n   ![](/Users/Hao/Desktop/Python-100-Days/Day41-55/res/django-admin-login.png)\n\n   登录后进入管理员操作平台。\n\n   ![](/res/django-admin-apps.png)\n\n   注意，我们暂时还没能在`admin`应用中看到之前创建的模型类，为此需要在`polls`应用的`admin.py`文件中对需要管理的模型进行注册。\n\n4. 注册模型类。\n\n   ```Python\n   from django.contrib import admin\n   \n   from polls.models import Subject, Teacher\n\n   admin.site.register(Subject)\n   admin.site.register(Teacher)\n   ```\n   \n   注册模型类后，就可以在后台管理系统中看到它们。\n   \n   ![](./res/django-admin-models.png)\n\n5. 对模型进行CRUD操作。\n\n   可以在管理员平台对模型进行C（新增）、R（查看）、U（更新）、D（删除）操作，如下图所示。\n\n   - 添加学科。\n\n       ![](/res/django-admin-add-model.png)\n\n   - 查看所有学科。\n\n       ![](/res/django-admin-view-models.png)\n\n   - 删除和更新学科。\n\n       ![](/res/django-admin-delete-update-model.png)\n\n6. 注册模型管理类。\n\n   可能大家已经注意到了，刚才在后台查看部门信息的时候，显示的部门信息并不直观，为此我们再修改`admin.py`文件，通过注册模型管理类，可以在后台管理系统中更好的管理模型。\n\n   ```Python\n   from django.contrib import admin\n   \n   from polls.models import Subject, Teacher\n   \n   \n   class SubjectModelAdmin(admin.ModelAdmin):\n       list_display = ('no', 'name', 'intro', 'is_hot')\n       search_fields = ('name', )\n       ordering = ('no', )\n   \n   \n   class TeacherModelAdmin(admin.ModelAdmin):\n       list_display = ('no', 'name', 'sex', 'birth', 'good_count', 'bad_count', 'subject')\n       search_fields = ('name', )\n       ordering = ('no', )\n   \n   \n   admin.site.register(Subject, SubjectModelAdmin)\n   admin.site.register(Teacher, TeacherModelAdmin)\n   ```\n   \n   ![](/res/django-admin-view-models-subject.png)\n   \n   ![](/res/django-admin-view-models-teacher.png)\n   \n   为了更好的查看模型，我们为`Subject`类添加`__str__`魔法方法，并在该方法中返回学科名字。这样在如上图所示的查看老师的页面上显示老师所属学科时，就不再是`Subject object(1)`这样晦涩的信息，而是学科的名称。\n\n### 实现学科页和老师页效果\n\n1. 修改`polls/views.py`文件，编写视图函数实现对学科页和老师页的渲染。\n\n    ```Python\n    from django.shortcuts import render, redirect\n    \n    from polls.models import Subject, Teacher\n    \n    \n    def show_subjects(request):\n        subjects = Subject.objects.all().order_by('no')\n        return render(request, 'subjects.html', {'subjects': subjects})\n    \n    \n    def show_teachers(request):\n        try:\n            sno = int(request.GET.get('sno'))\n            teachers = []\n            if sno:\n                subject = Subject.objects.only('name').get(no=sno)\n                teachers = Teacher.objects.filter(subject=subject).order_by('no')\n            return render(request, 'teachers.html', {\n                'subject': subject,\n                'teachers': teachers\n            })\n        except (ValueError, Subject.DoesNotExist):\n            return redirect('/')\n   ```\n\n2. 修改`templates/subjects.html`和`templates/teachers.html`模板页。\n\n    `subjects.html`\n\n     ```HTML\n    <!DOCTYPE html>\n    <html lang=\"en\">\n    <head>\n        <meta charset=\"UTF-8\">\n        <title>学科信息</title>\n        <style>\n            #container {\n                width: 80%;\n                margin: 10px auto;\n            }\n            .user {\n                float: right;\n                margin-right: 10px;\n            }\n            .user>a {\n                margin-right: 10px;\n            }\n            #main>dl>dt {\n                font-size: 1.5em;\n                font-weight: bold;\n            }\n            #main>dl>dd {\n                font-size: 1.2em;\n            }\n            a {\n                text-decoration: none;\n                color: darkcyan;\n            }\n        </style>\n    </head>\n    <body>\n        <div id=\"container\">\n            <div class=\"user\">\n                <a href=\"login.html\">用户登录</a>\n                <a href=\"register.html\">快速注册</a>\n            </div>\n            <h1>扣丁学堂所有学科</h1>\n            <hr>\n            <div id=\"main\">\n                {% for subject in subjects %}\n                <dl>\n                    <dt>\n                        <a href=\"/teachers/?sno={{ subject.no }}\">{{ subject.name }}</a>\n                        {% if subject.is_hot %}\n                        <img src=\"/static/images/hot-icon-small.png\">\n                        {% endif %}\n                    </dt>\n                    <dd>{{ subject.intro }}</dd>\n                </dl>\n                {% endfor %}\n            </div>\n        </div>\n    </body>\n    </html>\n     ```\n\n    `teachers.html`\n\n    ```HTML\n    <!DOCTYPE html>\n    <html lang=\"en\">\n    <head>\n        <meta charset=\"UTF-8\">\n        <title>老师信息</title>\n        <style>\n            #container {\n                width: 80%;\n                margin: 10px auto;\n            }\n            .teacher {\n                width: 100%;\n                margin: 0 auto;\n                padding: 10px 0;\n                border-bottom: 1px dashed gray;\n                overflow: auto;\n            }\n            .teacher>div {\n                float: left;\n            }\n            .photo {\n                height: 140px;\n                border-radius: 75px;\n                overflow: hidden;\n                margin-left: 20px;\n            }\n            .info {\n                width: 75%;\n                margin-left: 30px;\n            }\n            .info div {\n                clear: both;\n                margin: 5px 10px;\n            }\n            .info span {\n                margin-right: 25px;\n            }\n            .info a {\n                text-decoration: none;\n                color: darkcyan;\n            }\n        </style>\n    </head>\n    <body>\n        <div id=\"container\">\n            <h1>{{ subject.name }}学科的老师信息</h1>\n            <hr>\n            {% if not teachers %}\n                <h2>暂无该学科老师信息</h2>\n            {% endif %}\n            {% for teacher in teachers %}\n            <div class=\"teacher\">\n                <div class=\"photo\">\n                    <img src=\"/static/images/{{ teacher.photo }}\" height=\"140\" alt=\"\">\n                </div>\n                <div class=\"info\">\n                    <div>\n                        <span><strong>姓名：{{ teacher.name }}</strong></span>\n                        <span>性别：{{ teacher.sex | yesno:'男,女' }}</span>\n                        <span>出生日期：{{ teacher.birth | date:'Y年n月j日'}}</span>\n                    </div>\n                    <div class=\"intro\">{{ teacher.intro }}</div>\n                    <div class=\"comment\">\n                        <a href=\"\">好评</a>&nbsp;(<strong>{{ teacher.good_count }}</strong>)\n                        &nbsp;&nbsp;&nbsp;&nbsp;\n                        <a href=\"\">差评</a>&nbsp;<strong>{{ teacher.bad_count }}</strong>)\n                    </div>\n                </div>\n            </div>\n            {% endfor %}\n            <a href=\"/\">返回首页</a>\n        </div>\n    </body>\n    </html>\n    ```\n\n3. 修改`vote/urls.py`文件，实现映射URL。\n\n    ```Python\n    from django.contrib import admin\n    from django.urls import path\n    \n    from polls.views import show_subjects, show_teachers\n    \n    urlpatterns = [\n        path('admin/', admin.site.urls),\n        path('', show_subjects),\n        path('teachers/', show_teachers),\n    ]\n    ```\n\n到此为止，页面上需要的图片（静态资源）还没有能够正常展示，我们在下一章节中为大家介绍如何处理模板页上的需要的静态资源。\n\n### 补充内容\n\n#### Django模型最佳实践\n\n1. 正确的为模型和关系字段命名。\n2. 设置适当的`related_name`属性。\n3. 用`OneToOneField`代替`ForeignKeyField(unique=True)`。\n4. 通过“迁移操作”（migrate）来添加模型。\n5. 用NoSQL来应对需要降低范式级别的场景。\n6. 如果布尔类型可以为空要使用`NullBooleanField`。\n7. 在模型中放置业务逻辑。\n8. 用`<ModelName>.DoesNotExists`取代`ObjectDoesNotExists`。\n9. 在数据库中不要出现无效数据。\n10. 不要对`QuerySet`调用`len()`函数。\n11. 将`QuerySet`的`exists()`方法的返回值用于`if`条件。\n12. 用`DecimalField`来存储货币相关数据而不是`FloatField`。\n13. 定义`__str__`方法。\n14. 不要将数据文件放在同一个目录中。\n\n> **说明**：以上内容来自于STEELKIWI网站的[*Best Practice working with Django models in Python*](https://steelkiwi.com/blog/best-practices-working-django-models-python/)，有兴趣的小伙伴可以阅读原文。\n\n#### 模型定义参考\n\n##### 字段\n\n对字段名称的限制\n\n- 字段名不能是Python的保留字，否则会导致语法错误\n- 字段名不能有多个连续下划线，否则影响ORM查询操作\n\nDjango模型字段类\n\n| 字段类                  | 说明                                                         |\n| ----------------------- | ------------------------------------------------------------ |\n| `AutoField`             | 自增ID字段                                                   |\n| `BigIntegerField`       | 64位有符号整数                                               |\n| `BinaryField`           | 存储二进制数据的字段，对应Python的`bytes`类型                |\n| `BooleanField`          | 存储`True`或`False`                                          |\n| `CharField`             | 长度较小的字符串                                             |\n| `DateField`             | 存储日期，有`auto_now`和`auto_now_add`属性                   |\n| `DateTimeField`         | 存储日期和日期，两个附加属性同上                             |\n| `DecimalField`          | 存储固定精度小数，有`max_digits`（有效位数）和`decimal_places`（小数点后面）两个必要的参数 |\n| `DurationField`         | 存储时间跨度                                                 |\n| `EmailField`            | 与`CharField`相同，可以用`EmailValidator`验证                |\n| `FileField`             | 文件上传字段                                                 |\n| `FloatField`            | 存储浮点数                                                   |\n| `ImageField`            | 其他同`FileFiled`，要验证上传的是不是有效图像                |\n| `IntegerField`          | 存储32位有符号整数。                                         |\n| `GenericIPAddressField` | 存储IPv4或IPv6地址                                           |\n| `NullBooleanField`      | 存储`True`、`False`或`null`值                                |\n| `PositiveIntegerField`  | 存储无符号整数（只能存储正数）                               |\n| `SlugField`             | 存储slug（简短标注）                                         |\n| `SmallIntegerField`     | 存储16位有符号整数                                           |\n| `TextField`             | 存储数据量较大的文本                                         |\n| `TimeField`             | 存储时间                                                     |\n| `URLField`              | 存储URL的`CharField`                                         |\n| `UUIDField`             | 存储全局唯一标识符                                           |\n\n##### 字段属性\n\n通用字段属性\n\n| 选项             | 说明                                                         |\n| ---------------- | ------------------------------------------------------------ |\n| `null`           | 数据库中对应的字段是否允许为`NULL`，默认为`False`            |\n| `blank`          | 后台模型管理验证数据时，是否允许为`NULL`，默认为`False`      |\n| `choices`        | 设定字段的选项，各元组中的第一个值是设置在模型上的值，第二值是人类可读的值 |\n| `db_column`      | 字段对应到数据库表中的列名，未指定时直接使用字段的名称       |\n| `db_index`       | 设置为`True`时将在该字段创建索引                             |\n| `db_tablespace`  | 为有索引的字段设置使用的表空间，默认为`DEFAULT_INDEX_TABLESPACE` |\n| `default`        | 字段的默认值                                                 |\n| `editable`       | 字段在后台模型管理或`ModelForm`中是否显示，默认为`True`      |\n| `error_messages` | 设定字段抛出异常时的默认消息的字典，其中的键包括`null`、`blank`、`invalid`、`invalid_choice`、`unique`和`unique_for_date` |\n| `help_text`      | 表单小组件旁边显示的额外的帮助文本。                         |\n| `primary_key`    | 将字段指定为模型的主键，未指定时会自动添加`AutoField`用于主键，只读。 |\n| `unique`         | 设置为`True`时，表中字段的值必须是唯一的                     |\n| `verbose_name`   | 字段在后台模型管理显示的名称，未指定时使用字段的名称         |\n\n`ForeignKey`属性\n\n1. `limit_choices_to`：值是一个Q对象或返回一个Q对象，用于限制后台显示哪些对象。\n2. `related_name`：用于获取关联对象的关联管理器对象（反向查询），如果不允许反向，该属性应该被设置为`'+'`，或者以`'+'`结尾。\n3. `to_field`：指定关联的字段，默认关联对象的主键字段。\n4. `db_constraint`：是否为外键创建约束，默认值为`True`。\n5. `on_delete`：外键关联的对象被删除时对应的动作，可取的值包括`django.db.models`中定义的：\n   - `CASCADE`：级联删除。\n   - `PROTECT`：抛出`ProtectedError`异常，阻止删除引用的对象。\n   - `SET_NULL`：把外键设置为`null`，当`null`属性被设置为`True`时才能这么做。\n   - `SET_DEFAULT`：把外键设置为默认值，提供了默认值才能这么做。\n\n`ManyToManyField`属性\n\n1. `symmetrical`：是否建立对称的多对多关系。\n2. `through`：指定维持多对多关系的中间表的Django模型。\n3. `throughfields`：定义了中间模型时可以指定建立多对多关系的字段。\n4. `db_table`：指定维持多对多关系的中间表的表名。\n\n##### 模型元数据选项\n\n| 选项                    | 说明                                                         |\n| ----------------------- | ------------------------------------------------------------ |\n| `abstract`              | 设置为True时模型是抽象父类                                   |\n| `app_label`             | 如果定义模型的应用不在INSTALLED_APPS中可以用该属性指定       |\n| `db_table`              | 模型使用的数据表名称                                         |\n| `db_tablespace`         | 模型使用的数据表空间                                         |\n| `default_related_name`  | 关联对象回指这个模型时默认使用的名称，默认为<model_name>_set |\n| `get_latest_by`         | 模型中可排序字段的名称。                                     |\n| `managed`               | 设置为True时，Django在迁移中创建数据表并在执行flush管理命令时把表移除 |\n| `order_with_respect_to` | 标记对象为可排序的                                           |\n| `ordering`              | 对象的默认排序                                               |\n| `permissions`           | 创建对象时写入权限表的额外权限                               |\n| `default_permissions`   | 默认为`('add', 'change', 'delete')`                          |\n| `unique_together`       | 设定组合在一起时必须独一无二的字段名                         |\n| `index_together`        | 设定一起建立索引的多个字段名                                 |\n| `verbose_name`          | 为对象设定人类可读的名称                                     |\n| `verbose_name_plural`   | 设定对象的复数名称                                           |\n\n#### 查询参考\n\n##### 按字段查找可以用的条件\n\n1. `exact` / `iexact`：精确匹配/忽略大小写的精确匹配查询\n2. `contains` / `icontains` / `startswith` / `istartswith` / `endswith` / `iendswith`：基于`like`的模糊查询\n3. `in` ：集合运算\n4. `gt` / `gte` / `lt` / `lte`：大于/大于等于/小于/小于等于关系运算\n5. `range`：指定范围查询（SQL中的`between…and…`）\n6. `year` / `month` / `day` / `week_day` / `hour` / `minute` / `second`：查询时间日期\n7. `isnull`：查询空值（True）或非空值（False）\n8. `search`：基于全文索引的全文检索（一般很少使用）\n9. `regex` / `iregex`：基于正则表达式的模糊匹配查询\n\n", "静态资源和Ajax请求": "## 静态资源和Ajax请求\n\n### 加载静态资源\n\n如果要在Django项目中使用静态资源，可以先创建一个用于保存静态资源的目录。在`vote`项目中，我们将静态资源置于名为`static`的文件夹中，在该文件夹包含了三个子文件夹：css、js和images，分别用来保存外部CSS文件、外部JavaScript文件和图片资源，如下图所示。\n\n![](/res/pycharm-django-static.png)\n\n为了能够找到保存静态资源的文件夹，我们还需要修改Django项目的配置文件`settings.py`，如下所示：\n\n```Python\nSTATICFILES_DIRS = [os.path.join(BASE_DIR, 'static'), ]\nSTATIC_URL = '/static/'\n```\n\n配置好静态资源之后，大家可以运行项目，然后看看之前我们写的页面上的图片是否能够正常加载出来。需要说明的是，在项目正式部署到线上环境后，我们通常会把静态资源交给专门的静态资源服务器（如Nginx、Apache）来处理，而不是有运行Python代码的服务器来管理静态资源，所以上面的配置并不适用于生产环境，仅供项目开发阶段测试使用。使用静态资源的正确姿势我们会在后续的章节为大家讲解。\n\n### Ajax概述\n\n接下来就可以实现“好评”和“差评”的功能了，很明显如果能够在不刷新页面的情况下实现这两个功能会带来更好的用户体验，因此我们考虑使用[Ajax](https://zh.wikipedia.org/wiki/AJAX)技术来实现“好评”和“差评”。Ajax是Asynchronous Javascript And XML的缩写 , 简单的说，使用Ajax技术可以在不重新加载整个页面的情况下对页面进行局部刷新。\n\n对于传统的Web应用，每次页面上需要加载新的内容都需要重新请求服务器并刷新整个页面，如果服务器短时间内无法给予响应或者网络状况并不理想，那么可能会造成浏览器长时间的空白并使得用户处于等待状态，在这个期间用户什么都做不了，如下图所示。很显然，这样的Web应用并不能带来很好的用户体验。\n\n![](/res/synchronous-web-request.png)\n\n对于使用Ajax技术的Web应用，浏览器可以向服务器发起异步请求来获取数据。异步请求不会中断用户体验，当服务器返回了新的数据，我们可以通过JavaScript代码进行DOM操作来实现对页面的局部刷新，这样就相当于在不刷新整个页面的情况下更新了页面的内容，如下图所示。\n\n![](/res/asynchronous-web-request.png)\n\n在使用Ajax技术时，浏览器跟服务器通常会交换XML或JSON格式的数据，XML是以前使用得非常多的一种数据格式，近年来几乎已经完全被JSON取代，下面是两种数据格式的对比。\n\nXML格式：\n\n```XML\n<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<message>\n\t<from>Alice</from>\n    <to>Bob</to>\n    <content>Dinner is on me!</content>\n</message>\n```\n\nJSON格式：\n\n```JSON\n{\n    \"from\": \"Alice\",\n    \"to\": \"Bob\",\n    \"content\": \"Dinner is on me!\"\n}\n```\n\n通过上面的对比，明显JSON格式的数据要紧凑得多，所以传输效率更高，而且JSON本身也是JavaScript中的一种对象表达式语法，在JavaScript代码中处理JSON格式的数据更加方便。\n\n### 用Ajax实现投票功能\n\n下面，我们使用Ajax技术来实现投票的功能，首先修改项目的`urls.py`文件，为“好评”和“差评”功能映射对应的URL。\n\n```Python\nfrom django.contrib import admin\nfrom django.urls import path\n\nfrom vote import views\n\nurlpatterns = [\n    path('', views.show_subjects),\n    path('teachers/', views.show_teachers),\n    path('praise/', views.praise_or_criticize),\n    path('criticize/', views.praise_or_criticize),\n    path('admin/', admin.site.urls),\n]\n```\n\n设计视图函数`praise_or_criticize`来支持“好评”和“差评”功能，该视图函数通过Django封装的JsonResponse类将字典序列化成JSON字符串作为返回给浏览器的响应内容。\n\n```Python\ndef praise_or_criticize(request):\n    \"\"\"好评\"\"\"\n    try:\n        tno = int(request.GET.get('tno'))\n        teacher = Teacher.objects.get(no=tno)\n        if request.path.startswith('/praise'):\n            teacher.good_count += 1\n            count = teacher.good_count\n        else:\n            teacher.bad_count += 1\n            count = teacher.bad_count\n        teacher.save()\n        data = {'code': 20000, 'mesg': '操作成功', 'count': count}\n    except (ValueError, Teacher.DoseNotExist):\n        data = {'code': 20001, 'mesg': '操作失败'}\n    return JsonResponse(data)\n```\n\n修改显示老师信息的模板页，引入jQuery库来实现事件处理、Ajax请求和DOM操作。\n\n```HTML\n<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n    <meta charset=\"UTF-8\">\n    <title>老师信息</title>\n    <style>\n        #container {\n            width: 80%;\n            margin: 10px auto;\n        }\n        .teacher {\n            width: 100%;\n            margin: 0 auto;\n            padding: 10px 0;\n            border-bottom: 1px dashed gray;\n            overflow: auto;\n        }\n        .teacher>div {\n            float: left;\n        }\n        .photo {\n            height: 140px;\n            border-radius: 75px;\n            overflow: hidden;\n            margin-left: 20px;\n        }\n        .info {\n            width: 75%;\n            margin-left: 30px;\n        }\n        .info div {\n            clear: both;\n            margin: 5px 10px;\n        }\n        .info span {\n            margin-right: 25px;\n        }\n        .info a {\n            text-decoration: none;\n            color: darkcyan;\n        }\n    </style>\n</head>\n<body>\n    <div id=\"container\">\n        <h1>{{ subject.name }}学科的老师信息</h1>\n        <hr>\n        {% if not teachers %}\n            <h2>暂无该学科老师信息</h2>\n        {% endif %}\n        {% for teacher in teachers %}\n        <div class=\"teacher\">\n            <div class=\"photo\">\n                <img src=\"/static/images/{{ teacher.photo }}\" height=\"140\" alt=\"\">\n            </div>\n            <div class=\"info\">\n                <div>\n                    <span><strong>姓名：{{ teacher.name }}</strong></span>\n                    <span>性别：{{ teacher.sex | yesno:'男,女' }}</span>\n                    <span>出生日期：{{ teacher.birth }}</span>\n                </div>\n                <div class=\"intro\">{{ teacher.intro }}</div>\n                <div class=\"comment\">\n                    <a href=\"/praise/?tno={{ teacher.no }}\">好评</a>&nbsp;&nbsp;\n                    (<strong>{{ teacher.good_count }}</strong>)\n                    &nbsp;&nbsp;&nbsp;&nbsp;\n                    <a href=\"/criticize/?tno={{ teacher.no }}\">差评</a>&nbsp;&nbsp;\n                    (<strong>{{ teacher.bad_count }}</strong>)\n                </div>\n            </div>\n        </div>\n        {% endfor %}\n        <a href=\"/\">返回首页</a>\n    </div>\n    <script src=\"https://cdn.bootcss.com/jquery/3.4.1/jquery.min.js\"></script>\n    <script>\n        $(() => {\n            $('.comment>a').on('click', (evt) => {\n                evt.preventDefault()\n                let url = $(evt.target).attr('href')\n                $.getJSON(url, (json) => {\n                    if (json.code == 20000) {\n                        $(evt.target).next().text(json.count)\n                    } else {\n                        alert(json.mesg)\n                    }\n                })\n            })\n        })\n    </script>\n</body>\n</html>\n```\n\n上面的前端代码中，使用了jQuery库封装的`getJSON`方法向服务器发送异步请求，如果不熟悉前端的jQuery库，可以参考[《jQuery API手册》](https://www.runoob.com/manual/jquery/)。\n\n### 小结\n\n到此为止，这个投票项目的核心功能已然完成，在下面的章节中我们会要求用户必须登录才能投票，没有账号的用户可以通过注册功能注册一个账号。", "Cookie和Session": "## Cookie和Session\n\n我们继续来完成上一章节中的项目，实现“用户登录”的功能，并限制只有登录的用户才能投票。\n\n### 用户登录的准备工作\n\n我们先为实现用户登录做一些准备工作。\n\n1. 创建用户模型。之前我们讲解过如果通过Django的ORM实现从二维表到模型的转换（反向工程），这次我们尝试把模型变成二维表（正向工程）。\n\n    ```Python\n    class User(models.Model):\n        \"\"\"用户\"\"\"\n        no = models.AutoField(primary_key=True, verbose_name='编号')\n        username = models.CharField(max_length=20, unique=True, verbose_name='用户名')\n        password = models.CharField(max_length=32, verbose_name='密码')\n        tel = models.CharField(max_length=20, verbose_name='手机号')\n        reg_date = models.DateTimeField(auto_now_add=True, verbose_name='注册时间')\n        last_visit = models.DateTimeField(null=True, verbose_name='最后登录时间')\n    \n        class Meta:\n            db_table = 'tb_user'\n            verbose_name = '用户'\n            verbose_name_plural = '用户'\n    ```\n    \n2. 使用下面的命令生成迁移文件并执行迁移，将`User`模型直接变成关系型数据库中的二维表`tb_user`。\n\n    ```Bash\n    python manage.py makemigrations polls\n    python manage.py migrate polls\n    ```\n\n3. 用下面的SQL语句直接插入两条测试数据，通常不能将用户的密码直接保存在数据库中，因此我们将用户密码处理成对应的MD5摘要。MD5消息摘要算法是一种被广泛使用的密码哈希函数（散列函数），可以产生出一个128位（比特）的哈希值（散列值），用于确保信息传输完整一致。在使用哈希值时，通常会将哈希值表示为16进制字符串，因此128位的MD5摘要通常表示为32个十六进制符号。\n\n    ```SQL\n    insert into `tb_user`\n        (`username`, `password`, `tel`, `reg_date`)\n    values\n        ('wangdachui', '1c63129ae9db9c60c3e8aa94d3e00495', '13122334455', now()),\n        ('hellokitty', 'c6f8cf68e5f68b0aa4680e089ee4742c', '13890006789', now());\n    ```\n\n    > **说明**：上面创建的两个用户`wangdachui`和`hellokitty`密码分别是`1qaz2wsx`和`Abc123!!`。\n\n4. 我们在应用下增加一个名为`utils.py`的模块用来保存需要使用的工具函数。Python标准库中的`hashlib`模块封装了常用的哈希算法，包括：MD5、SHA1、SHA256等。下面是使用`hashlib`中的`md5`类将字符串处理成MD5摘要的函数如下所示。\n\n    ```Python\n    import hashlib\n    \n    \n    def gen_md5_digest(content):\n        return hashlib.md5(content.encode()).hexdigest()\n    ```\n\n5. 编写用户登录的视图函数和模板页。\n\n    添加渲染登录页面的视图函数：\n\n    ```Python\n    def login(request: HttpRequest) -> HttpResponse:\n        hint = ''\n        return render(request, 'login.html', {'hint': hint})\n    ```\n\n    增加`login.html`模板页：\n\n    ```HTML\n    <!DOCTYPE html>\n    <html lang=\"en\">\n    <head>\n        <meta charset=\"UTF-8\">\n        <title>用户登录</title>\n        <style>\n            #container {\n                width: 520px;\n                margin: 10px auto;\n            }\n            .input {\n                margin: 20px 0;\n                width: 460px;\n                height: 40px;\n            }\n            .input>label {\n                display: inline-block;\n                width: 140px;\n                text-align: right;\n            }\n            .input>img {\n                width: 150px;\n                vertical-align: middle;\n            }\n            input[name=captcha] {\n                vertical-align: middle;\n            }\n            form+div {\n                margin-top: 20px;\n            }\n            form+div>a {\n                text-decoration: none;\n                color: darkcyan;\n                font-size: 1.2em;\n            }\n            .button {\n                width: 500px;\n                text-align: center;\n                margin-top: 20px;\n            }\n            .hint {\n                color: red;\n                font-size: 12px;\n            }\n        </style>\n    </head>\n    <body>\n        <div id=\"container\">\n            <h1>用户登录</h1>\n            <hr>\n            <p class=\"hint\">{{ hint }}</p>\n            <form action=\"/login/\" method=\"post\">\n                {% csrf_token %}\n                <fieldset>\n                    <legend>用户信息</legend>\n                    <div class=\"input\">\n                        <label>用户名：</label>\n                        <input type=\"text\" name=\"username\">\n                    </div>\n                    <div class=\"input\">\n                        <label>密码：</label>\n                        <input type=\"password\" name=\"password\">\n                    </div>\n                    <div class=\"input\">\n                        <label>验证码：</label>\n                        <input type=\"text\" name=\"captcha\">\n                        <img id=\"code\" src=\"/captcha/\" alt=\"\" width=\"150\" height=\"40\">\n                    </div>\n                </fieldset>\n                <div class=\"button\">\n                    <input type=\"submit\" value=\"登录\">\n                    <input type=\"reset\" value=\"重置\">\n                </div>\n            </form>\n            <div>\n                <a href=\"/\">返回首页</a>\n                <a href=\"/register/\">注册新用户</a>\n            </div>\n        </div>\n    </body>\n    </html>\n    ```\n\n    注意，在上面的表单中，我们使用了模板指令`{% csrf_token %}`为表单添加一个隐藏域（大家可以在浏览器中显示网页源代码就可以看到这个指令生成的`type`属性为`hidden`的`input`标签），它的作用是在表单中生成一个随机令牌（token）来防范[跨站请求伪造](<https://zh.wikipedia.org/wiki/%E8%B7%A8%E7%AB%99%E8%AF%B7%E6%B1%82%E4%BC%AA%E9%80%A0>)（简称为CSRF），这也是Django在提交表单时的硬性要求。如果我们的表单中没有这样的令牌，那么提交表单时，Django框架会产生一个响应状态码为`403`的响应（禁止访问），除非我们设置了免除CSRF令牌。下图是一个关于CSRF简单生动的例子。\n\n    ![](./res/csrf-simple.png)\n\n接下来，我们可以编写提供验证码和实现用户登录的视图函数，在此之前，我们先说说一个Web应用实现用户跟踪的方式以及Django框架对实现用户跟踪所提供的支持。对一个Web应用来说，用户登录成功后必然要让服务器能够记住该用户已经登录，这样服务器才能为这个用户提供更好的服务，而且上面说到的CSRF也是通过钓鱼网站来套取用户登录信息进行恶意操作的攻击手段，这些都是以用户跟踪技术为基础的。在理解了这些背景知识后，我们就清楚用户登录时到底需要执行哪些操作。\n\n### 实现用户跟踪\n\n如今，一个网站如果不通过某种方式记住你是谁以及你之前在网站的活动情况，失去的就是网站的可用性和便利性，继而很有可能导致网站用户的流式，所以记住一个用户（更专业的说法叫**用户跟踪**）对绝大多数Web应用来说都是必需的功能。\n\n在服务器端，我们想记住一个用户最简单的办法就是创建一个对象，通过这个对象就可以把用户相关的信息都保存起来，这个对象就是我们常说的session（用户会话对象）。那么问题来了，HTTP本身是一个**无连接**（每次请求和响应的过程中，服务器一旦完成对客户端请求的响应之后就断开连接）、**无状态**（客户端再次发起对服务器的请求时，服务器无法得知这个客户端之前的任何信息）的协议，即便服务器通过session对象保留了用户数据，还得通过某种方式来确定当前的请求与之前保存过的哪一个session是有关联的。相信很多人都能想到，我们可以给每个session对象分配一个全局唯一的标识符来识别session对象，我们姑且称之为sessionid，每次客户端发起请求时，只要携带上这个sessionid，就有办法找到与之对应的session对象，从而实现在两次请求之间记住该用户的信息，也就是我们之前说的用户跟踪。\n\n要让客户端记住并在每次请求时带上sessionid又有以下几种做法：\n\n1. URL重写。所谓URL重写就是在URL中携带sessionid，例如：`http://www.example.com/index.html?sessionid=123456`，服务器通过获取sessionid参数的值来取到与之对应的session对象。\n\n2. 隐藏域（隐式表单域）。在提交表单的时候，可以通过在表单中设置隐藏域向服务器发送额外的数据。例如：`<input type=\"hidden\" name=\"sessionid\" value=\"123456\">`。\n\n3. 本地存储。现在的浏览器都支持多种本地存储方案，包括：cookie、localStorage、sessionStorage、IndexedDB等。在这些方案中，cookie是历史最为悠久也是被诟病得最多的一种方案，也是我们接下来首先为大家讲解的一种方案。简单的说，cookie是一种以键值对方式保存在浏览器临时文件中的数据，每次请求时，请求头中会携带本站点的cookie到服务器，那么只要将sessionid写入cookie，下次请求时服务器只要读取请求头中的cookie就能够获得这个sessionid，如下图所示。\n\n   ![](./res/sessionid_from_cookie.png)\n\n   在HTML5时代要，除了cookie，还可以使用新的本地存储API来保存数据，就是刚才提到的localStorage、sessionStorage、IndexedDB等技术，如下图所示。\n\n   ![](./res/cookie_xstorage_indexeddb.png)\n\n**总结一下**，要实现用户跟踪，服务器端可以为每个用户会话创建一个session对象并将session对象的ID写入到浏览器的cookie中；用户下次请求服务器时，浏览器会在HTTP请求头中携带该网站保存的cookie信息，这样服务器就可以从cookie中找到session对象的ID并根据此ID获取到之前创建的session对象；由于session对象可以用键值对的方式保存用户数据，这样之前保存在session对象中的信息可以悉数取出，服务器也可以根据这些信息判定用户身份和了解用户偏好，为用户提供更好的个性化服务。\n\n### Django框架对session的支持\n\n在创建Django项目时，默认的配置文件`settings.py`文件中已经激活了一个名为`SessionMiddleware`的中间件（关于中间件的知识我们在后面的章节做详细讲解，这里只需要知道它的存在即可），因为这个中间件的存在，我们可以直接通过请求对象的`session`属性来操作会话对象。前面我们说过，`session`属性是一个像字典一样可以读写数据的容器对象，因此我们可以使用“键值对”的方式来保留用户数据。与此同时，`SessionMiddleware`中间件还封装了对cookie的操作，在cookie中保存了sessionid，这一点我们在上面已经提到过了。\n\n在默认情况下，Django将session的数据序列化后保存在关系型数据库中，在Django 1.6以后的版本中，默认的序列化数据的方式是JSON序列化，而在此之前一直使用Pickle序列化。JSON序列化和Pickle序列化的差别在于前者将对象序列化为字符串（字符形式），而后者将对象序列化为字节串（二进制形式），因为安全方面的原因，JSON序列化成为了目前Django框架默认序列化数据的方式，这就要求在我们保存在session中的数据必须是能够JSON序列化的，否则就会引发异常。还有一点需要说明的是，使用关系型数据库保存session中的数据在大多数时候并不是最好的选择，因为数据库可能会承受巨大的压力而成为系统性能的瓶颈，在后面的章节中我们会告诉大家如何将session保存到缓存服务中以提升系统的性能。\n\n### 实现用户登录验证\n\n首先，我们在刚才的`polls/utils.py`文件中编写生成随机验证码的函数`gen_random_code`，内容如下所示。\n\n```Python\nimport random\n\nALL_CHARS = '0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'\n\n\ndef gen_random_code(length=4):\n    return ''.join(random.choices(ALL_CHARS, k=length))\n```\n\n编写生成验证码图片的类`Captcha`。\n\n```Python\n\"\"\"\n图片验证码\n\"\"\"\nimport os\nimport random\nfrom io import BytesIO\n\nfrom PIL import Image\nfrom PIL import ImageFilter\nfrom PIL.ImageDraw import Draw\nfrom PIL.ImageFont import truetype\n\n\nclass Bezier:\n    \"\"\"贝塞尔曲线\"\"\"\n\n    def __init__(self):\n        self.tsequence = tuple([t / 20.0 for t in range(21)])\n        self.beziers = {}\n\n    def make_bezier(self, n):\n        \"\"\"绘制贝塞尔曲线\"\"\"\n        try:\n            return self.beziers[n]\n        except KeyError:\n            combinations = pascal_row(n - 1)\n            result = []\n            for t in self.tsequence:\n                tpowers = (t ** i for i in range(n))\n                upowers = ((1 - t) ** i for i in range(n - 1, -1, -1))\n                coefs = [c * a * b for c, a, b in zip(combinations,\n                                                      tpowers, upowers)]\n                result.append(coefs)\n            self.beziers[n] = result\n            return result\n\n\nclass Captcha:\n    \"\"\"验证码\"\"\"\n\n    def __init__(self, width, height, fonts=None, color=None):\n        self._image = None\n        self._fonts = fonts if fonts else \\\n            [os.path.join(os.path.dirname(__file__), 'fonts', font)\n             for font in ['Arial.ttf', 'Georgia.ttf', 'Action.ttf']]\n        self._color = color if color else random_color(0, 200, random.randint(220, 255))\n        self._width, self._height = width, height\n\n    @classmethod\n    def instance(cls, width=200, height=75):\n        \"\"\"用于获取Captcha对象的类方法\"\"\"\n        prop_name = f'_instance_{width}_{height}'\n        if not hasattr(cls, prop_name):\n            setattr(cls, prop_name, cls(width, height))\n        return getattr(cls, prop_name)\n\n    def _background(self):\n        \"\"\"绘制背景\"\"\"\n        Draw(self._image).rectangle([(0, 0), self._image.size],\n                                    fill=random_color(230, 255))\n\n    def _smooth(self):\n        \"\"\"平滑图像\"\"\"\n        return self._image.filter(ImageFilter.SMOOTH)\n\n    def _curve(self, width=4, number=6, color=None):\n        \"\"\"绘制曲线\"\"\"\n        dx, height = self._image.size\n        dx /= number\n        path = [(dx * i, random.randint(0, height))\n                for i in range(1, number)]\n        bcoefs = Bezier().make_bezier(number - 1)\n        points = []\n        for coefs in bcoefs:\n            points.append(tuple(sum([coef * p for coef, p in zip(coefs, ps)])\n                                for ps in zip(*path)))\n        Draw(self._image).line(points, fill=color if color else self._color, width=width)\n\n    def _noise(self, number=50, level=2, color=None):\n        \"\"\"绘制扰码\"\"\"\n        width, height = self._image.size\n        dx, dy = width / 10, height / 10\n        width, height = width - dx, height - dy\n        draw = Draw(self._image)\n        for i in range(number):\n            x = int(random.uniform(dx, width))\n            y = int(random.uniform(dy, height))\n            draw.line(((x, y), (x + level, y)),\n                      fill=color if color else self._color, width=level)\n\n    def _text(self, captcha_text, fonts, font_sizes=None, drawings=None, squeeze_factor=0.75, color=None):\n        \"\"\"绘制文本\"\"\"\n        color = color if color else self._color\n        fonts = tuple([truetype(name, size)\n                       for name in fonts\n                       for size in font_sizes or (65, 70, 75)])\n        draw = Draw(self._image)\n        char_images = []\n        for c in captcha_text:\n            font = random.choice(fonts)\n            c_width, c_height = draw.textsize(c, font=font)\n            char_image = Image.new('RGB', (c_width, c_height), (0, 0, 0))\n            char_draw = Draw(char_image)\n            char_draw.text((0, 0), c, font=font, fill=color)\n            char_image = char_image.crop(char_image.getbbox())\n            for drawing in drawings:\n                d = getattr(self, drawing)\n                char_image = d(char_image)\n            char_images.append(char_image)\n        width, height = self._image.size\n        offset = int((width - sum(int(i.size[0] * squeeze_factor)\n                                  for i in char_images[:-1]) -\n                      char_images[-1].size[0]) / 2)\n        for char_image in char_images:\n            c_width, c_height = char_image.size\n            mask = char_image.convert('L').point(lambda i: i * 1.97)\n            self._image.paste(char_image,\n                              (offset, int((height - c_height) / 2)),\n                              mask)\n            offset += int(c_width * squeeze_factor)\n\n    @staticmethod\n    def _warp(image, dx_factor=0.3, dy_factor=0.3):\n        \"\"\"图像扭曲\"\"\"\n        width, height = image.size\n        dx = width * dx_factor\n        dy = height * dy_factor\n        x1 = int(random.uniform(-dx, dx))\n        y1 = int(random.uniform(-dy, dy))\n        x2 = int(random.uniform(-dx, dx))\n        y2 = int(random.uniform(-dy, dy))\n        warp_image = Image.new(\n            'RGB',\n            (width + abs(x1) + abs(x2), height + abs(y1) + abs(y2)))\n        warp_image.paste(image, (abs(x1), abs(y1)))\n        width2, height2 = warp_image.size\n        return warp_image.transform(\n            (width, height),\n            Image.QUAD,\n            (x1, y1, -x1, height2 - y2, width2 + x2, height2 + y2, width2 - x2, -y1))\n\n    @staticmethod\n    def _offset(image, dx_factor=0.1, dy_factor=0.2):\n        \"\"\"图像偏移\"\"\"\n        width, height = image.size\n        dx = int(random.random() * width * dx_factor)\n        dy = int(random.random() * height * dy_factor)\n        offset_image = Image.new('RGB', (width + dx, height + dy))\n        offset_image.paste(image, (dx, dy))\n        return offset_image\n\n    @staticmethod\n    def _rotate(image, angle=25):\n        \"\"\"图像旋转\"\"\"\n        return image.rotate(random.uniform(-angle, angle),\n                            Image.BILINEAR, expand=1)\n\n    def generate(self, captcha_text='', fmt='PNG'):\n        \"\"\"生成验证码(文字和图片)\n        :param captcha_text: 验证码文字\n        :param fmt: 生成的验证码图片格式\n        :return: 验证码图片的二进制数据\n        \"\"\"\n        self._image = Image.new('RGB', (self._width, self._height), (255, 255, 255))\n        self._background()\n        self._text(captcha_text, self._fonts,\n                   drawings=['_warp', '_rotate', '_offset'])\n        self._curve()\n        self._noise()\n        self._smooth()\n        image_bytes = BytesIO()\n        self._image.save(image_bytes, format=fmt)\n        return image_bytes.getvalue()\n\n\ndef pascal_row(n=0):\n    \"\"\"生成毕达哥拉斯三角形（杨辉三角）\"\"\"\n    result = [1]\n    x, numerator = 1, n\n    for denominator in range(1, n // 2 + 1):\n        x *= numerator\n        x /= denominator\n        result.append(x)\n        numerator -= 1\n    if n & 1 == 0:\n        result.extend(reversed(result[:-1]))\n    else:\n        result.extend(reversed(result))\n    return result\n\n\ndef random_color(start=0, end=255, opacity=255):\n    \"\"\"获得随机颜色\"\"\"\n    red = random.randint(start, end)\n    green = random.randint(start, end)\n    blue = random.randint(start, end)\n    if opacity is None:\n        return red, green, blue\n    return red, green, blue, opacity\n```\n\n> **说明**：上面的代码中用到了三个字体文件，字体文件位于`polls/fonts`目录下，大家可以自行添加字体文件，但是需要注意字体文件的文件名跟上面代码的第45行保持一致。\n\n接下来，我们先完成提供验证码的视图函数。\n\n```Python\ndef get_captcha(request: HttpRequest) -> HttpResponse:\n    \"\"\"验证码\"\"\"\n    captcha_text = gen_random_code()\n    request.session['captcha'] = captcha_text\n    image_data = Captcha.instance().generate(captcha_text)\n    return HttpResponse(image_data, content_type='image/png')\n```\n\n注意上面代码中的第4行，我们将随机生成的验证码字符串保存到session中，稍后用户登录时，我们要将保存在session中的验证码字符串和用户输入的验证码字符串进行比对，如果用户输入了正确的验证码才能够执行后续的登录流程，代码如下所示。\n\n```Python\ndef login(request: HttpRequest) -> HttpResponse:\n    hint = ''\n    if request.method == 'POST':\n        username = request.POST.get('username')\n        password = request.POST.get('password')\n        if username and password:\n            password = gen_md5_digest(password)\n            user = User.objects.filter(username=username, password=password).first()\n            if user:\n                request.session['userid'] = user.no\n                request.session['username'] = user.username\n                return redirect('/')\n            else:\n                hint = '用户名或密码错误'\n        else:\n            hint = '请输入有效的用户名和密码'\n    return render(request, 'login.html', {'hint': hint})\n```\n\n>**说明**：上面的代码没有对用户名和密码没有进行验证，实际项目中建议使用正则表达式验证用户输入信息，否则有可能将无效的数据交给数据库进行处理或者造成其他安全方面的隐患。\n\n上面的代码中，我们设定了登录成功后会在session中保存用户的编号（`userid`）和用户名（`username`），页面会重定向到首页。接下来我们可以稍微对首页的代码进行调整，在页面的右上角显示出登录用户的用户名。我们将这段代码单独写成了一个名为header.html的HTML文件，首页中可以通过在`<body>`标签中添加`{% include 'header.html' %}`来包含这个页面，代码如下所示。\n\n```HTML\n<div class=\"user\">\n    {% if request.session.userid %}\n    <span>{{ request.session.username }}</span>\n    <a href=\"/logout\">注销</a>\n    {% else %}\n    <a href=\"/login\">登录</a>&nbsp;&nbsp;\n    {% endif %}\n    <a href=\"/register\">注册</a>\n</div>\n```\n\n如果用户没有登录，页面会显示登录和注册的超链接；而用户登录成功后，页面上会显示用户名和注销的链接，注销链接对应的视图函数如下所示，URL的映射与之前讲过的类似，不再赘述。\n\n```Python\ndef logout(request):\n    \"\"\"注销\"\"\"\n    request.session.flush()\n    return redirect('/')\n```\n\n上面的代码通过session对象`flush`方法来销毁session，一方面清除了服务器上session对象保存的用户数据，一方面将保存在浏览器cookie中的sessionid删除掉，稍后我们会对如何读写cookie的操作加以说明。\n\n我们可以通过项目使用的数据库中名为`django_session` 的表来找到所有的session，该表的结构如下所示：\n\n| session_key                      | session_data                    | expire_date                |\n| -------------------------------- | ------------------------------- | -------------------------- |\n| c9g2gt5cxo0k2evykgpejhic5ae7bfpl | MmI4YzViYjJhOGMyMDJkY2M5Yzg3... | 2019-05-25 23:16:13.898522 |\n\n其中，第1列就是浏览器cookie中保存的sessionid；第2列是经过BASE64编码后的session中的数据，如果使用Python的`base64`对其进行解码，解码的过程和结果如下所示。\n\n```Python\nimport base64\n\nbase64.b64decode('MmI4YzViYjJhOGMyMDJkY2M5Yzg3ZWIyZGViZmUzYmYxNzdlNDdmZjp7ImNhcHRjaGEiOiJzS3d0Iiwibm8iOjEsInVzZXJuYW1lIjoiamFja2ZydWVkIn0=')\n```\n\n第3列是session的过期时间，session过期后浏览器保存的cookie中的sessionid就会失效，但是数据库中的这条对应的记录仍然会存在，如果想清除过期的数据，可以使用下面的命令。\n\n```Shell\npython manage.py clearsessions\n```\n\nDjango框架默认的session过期时间为两周（1209600秒），如果想修改这个时间，可以在项目的配置文件中添加如下所示的代码。\n\n```Python\n# 配置会话的超时时间为1天（86400秒）\nSESSION_COOKIE_AGE = 86400\n```\n\n有很多对安全性要求较高的应用都必须在关闭浏览器窗口时让会话过期，不再保留用户的任何信息，如果希望在关闭浏览器窗口时就让会话过期（cookie中的sessionid失效），可以加入如下所示的配置。\n\n```Python\n# 设置为True在关闭浏览器窗口时session就过期\nSESSION_EXPIRE_AT_BROWSER_CLOSE = True\n```\n\n如果不希望将session的数据保存在数据库中，可以将其放入缓存中，对应的配置如下所示，缓存的配置和使用我们在后面讲解。\n\n```Python\n# 配置将会话对象放到缓存中存储\nSESSION_ENGINE = 'django.contrib.sessions.backends.cache'\n# 配置使用哪一组缓存来保存会话\nSESSION_CACHE_ALIAS = 'default'\n```\n\n如果要修改session数据默认的序列化方式，可以将默认的`JSONSerializer`修改为`PickleSerializer`。\n\n```Python\nSESSION_SERIALIZER = 'django.contrib.sessions.serializers.PickleSerializer'\n```\n\n接下来，我们就可以限制只有登录用户才能为老师投票，修改后的`praise_or_criticize`函数如下所示，我们通过从`request.session`中获取`userid`来判定用户是否登录。\n\n```Python\ndef praise_or_criticize(request: HttpRequest) -> HttpResponse:\n    if request.session.get('userid'):\n        try:\n            tno = int(request.GET.get('tno'))\n            teacher = Teacher.objects.get(no=tno)\n            if request.path.startswith('/praise/'):\n                teacher.good_count += 1\n                count = teacher.good_count\n            else:\n                teacher.bad_count += 1\n                count = teacher.bad_count\n            teacher.save()\n            data = {'code': 20000, 'mesg': '投票成功', 'count': count}\n        except (ValueError, Teacher.DoesNotExist):\n            data = {'code': 20001, 'mesg': '投票失败'}\n    else:\n        data = {'code': 20002, 'mesg': '请先登录'}\n    return JsonResponse(data)\n```\n\n当然，在修改了视图函数后，`teachers.html`也需要进行调整，用户如果没有登录，就将用户引导至登录页，登录成功再返回到投票页，此处不再赘述。\n\n### 在视图函数中读写cookie\n\n下面我们对如何使用cookie做一个更为细致的说明以便帮助大家在Web项目中更好的使用这项技术。Django封装的`HttpRequest`和`HttpResponse`对象分别提供了读写cookie的操作。\n\nHttpRequest封装的属性和方法：\n\n1. `COOKIES`属性 - 该属性包含了HTTP请求携带的所有cookie。\n2. `get_signed_cookie`方法 - 获取带签名的cookie，如果签名验证失败，会产生`BadSignature`异常。\n\nHttpResponse封装的方法：\n\n1. `set_cookie`方法 - 该方法可以设置一组键值对并将其最终将写入浏览器。\n2. `set_signed_cookie`方法 - 跟上面的方法作用相似，但是会对cookie进行签名来达到防篡改的作用。因为如果篡改了cookie中的数据，在不知道[密钥](<https://zh.wikipedia.org/wiki/%E5%AF%86%E9%92%A5>)和[盐](<https://zh.wikipedia.org/wiki/%E7%9B%90_(%E5%AF%86%E7%A0%81%E5%AD%A6)>)的情况下是无法生成有效的签名，这样服务器在读取cookie时会发现数据与签名不一致从而产生`BadSignature`异常。需要说明的是，这里所说的密钥就是我们在Django项目配置文件中指定的`SECRET_KEY`，而盐是程序中设定的一个字符串，你愿意设定为什么都可以，只要是一个有效的字符串。\n\n上面提到的方法，如果不清楚它们的具体用法，可以自己查阅一下Django的[官方文档](<https://docs.djangoproject.com/en/2.1/ref/request-response/>)，没有什么资料比官方文档能够更清楚的告诉你这些方法到底如何使用。\n\n刚才我们说过了，激活`SessionMiddleware`之后，每个`HttpRequest`对象都会绑定一个session属性，它是一个类似字典的对象，除了保存用户数据之外还提供了检测浏览器是否支持cookie的方法，包括：\n\n1. `set_test_cookie`方法 - 设置用于测试的cookie。\n2. `test_cookie_worked`方法 - 检测测试cookie是否工作。\n3. `delete_test_cookie`方法 - 删除用于测试的cookie。\n4. `set_expiry`方法 - 设置会话的过期时间。\n5. `get_expire_age`/`get_expire_date`方法 - 获取会话的过期时间。\n6. `clear_expired`方法 - 清理过期的会话。\n\n下面是在执行登录之前检查浏览器是否支持cookie的代码。通常情况下，浏览器默认开启了对cookie的支持，但是可能因为某种原因，用户禁用了浏览器的cookie功能，遇到这种情况我们可以在视图函数中提供一个检查功能，如果检查到用户浏览器不支持cookie，可以给出相应的提示。\n\n```Python\ndef login(request):\n    if request.method == 'POST':\n        if request.session.test_cookie_worked():\n            request.session.delete_test_cookie()\n            # Add your code to perform login process here\n        else:\n            return HttpResponse(\"Please enable cookies and try again.\")\n    request.session.set_test_cookie()\n    return render_to_response('login.html')\n```\n\n### Cookie的替代品\n\n之前我们说过了，cookie的名声一直都不怎么好，当然我们在实际开发中是不会在cookie中保存用户的敏感信息（如用户的密码、信用卡的账号等）的，而且保存在cookie中的数据一般也会做好编码和签名的工作。对于支持HTML5的浏览器来说，可以使用localStorage和sessionStorage做为cookie的替代方案，相信从名字上你就能听出二者的差别，存储在`localStorage`的数据可以长期保留；而存储在`sessionStorage`的数据会在浏览器关闭时会被清除 。关于这些cookie替代品的用法，建议大家查阅[MDN](<https://developer.mozilla.org/zh-CN/docs/Web>)来进行了解。 ", "制作报表": "## 制作报表\n\n### 导出Excel报表\n\n报表就是用表格、图表等格式来动态显示数据，所以有人用这样的公式来描述报表：\n\n```\n报表 = 多样的格式 + 动态的数据\n```\n\n有很多的三方库支持在Python程序中写Excel文件，包括[`xlwt`](<https://xlwt.readthedocs.io/en/latest/>)、[`xlwings`](<https://docs.xlwings.org/en/latest/quickstart.html>)、[`openpyxl`](<https://openpyxl.readthedocs.io/en/latest/>)、[`xlswriter`](<https://xlsxwriter.readthedocs.io/>)等，其中的xlwt虽然只支持写xls格式的Excel文件，但在性能方面的表现还是不错的。下面我们就以`xlwt`为例，来演示如何在Django项目中导出Excel报表。\n\n安装`xlwt`。\n\n```Bash\npip install xlwt\n```\n\n导出包含所有老师信息的Excel表格的视图函数。\n\n```Python\ndef export_teachers_excel(request):\n    # 创建工作簿\n    wb = xlwt.Workbook()\n    # 添加工作表\n    sheet = wb.add_sheet('老师信息表')\n    # 查询所有老师的信息\n    queryset = Teacher.objects.all()\n    # 向Excel表单中写入表头\n    colnames = ('姓名', '介绍', '好评数', '差评数', '学科')\n    for index, name in enumerate(colnames):\n        sheet.write(0, index, name)\n    # 向单元格中写入老师的数据\n    props = ('name', 'detail', 'good_count', 'bad_count', 'subject')\n    for row, teacher in enumerate(queryset):\n        for col, prop in enumerate(props):\n            value = getattr(teacher, prop, '')\n            if isinstance(value, Subject):\n                value = value.name\n            sheet.write(row + 1, col, value)\n    # 保存Excel\n    buffer = BytesIO()\n    wb.save(buffer)\n    # 将二进制数据写入响应的消息体中并设置MIME类型\n    resp = HttpResponse(buffer.getvalue(), content_type='application/vnd.ms-excel')\n    # 中文文件名需要处理成百分号编码\n    filename = quote('老师.xls')\n    # 通过响应头告知浏览器下载该文件以及对应的文件名\n    resp['content-disposition'] = f'attachment; filename*=utf-8\\'\\'{filename}'\n    return resp\n```\n\n映射URL。\n\n```Python\nurlpatterns = [\n    \n    path('excel/', views.export_teachers_excel),\n    \n]\n```\n\n### 导出PDF报表\n\n在Django项目中，如果需要导出PDF报表，可以借助三方库`reportlab`来生成PDF文件的内容，再将文件的二进制数据输出给浏览器并指定MIME类型为`application/pdf`，具体的代码如下所示。\n\n```Python\ndef export_pdf(request: HttpRequest) -> HttpResponse:\n    buffer = io.BytesIO()\n    pdf = canvas.Canvas(buffer)\n    pdf.setFont(\"Helvetica\", 80)\n    pdf.setFillColorRGB(0.2, 0.5, 0.3)\n    pdf.drawString(100, 550, 'hello, world!')\n    pdf.showPage()\n    pdf.save()\n    resp = HttpResponse(buffer.getvalue(), content_type='application/pdf')\n    resp['content-disposition'] = 'inline; filename=\"demo.pdf\"'\n    return resp\n```\n\n关于如何用`reportlab`定制PDF报表的内容，可以参考reportlab的[官方文档](https://www.reportlab.com/docs/reportlab-userguide.pdf)。\n\n### 生成前端统计图表\n\n如果项目中需要生成前端统计图表，可以使用百度的[ECharts](<https://echarts.baidu.com/>)。具体的做法是后端通过提供数据接口返回统计图表所需的数据，前端使用ECharts来渲染出柱状图、折线图、饼图、散点图等图表。例如我们要生成一个统计所有老师好评数和差评数的报表，可以按照下面的方式来做。\n\n```Python\ndef get_teachers_data(request):\n    queryset = Teacher.objects.all()\n    names = [teacher.name for teacher in queryset]\n    good_counts = [teacher.good_count for teacher in queryset]\n    bad_counts = [teacher.bad_count for teacher in queryset]\n    return JsonResponse({'names': names, 'good': good_counts, 'bad': bad_counts})\n```\n\n映射URL。\n\n```Python\nurlpatterns = [\n    path('teachers_data/', views.get_teachers_data),\n]\n```\n\n使用ECharts生成柱状图。\n\n```HTML\n<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n    <meta charset=\"UTF-8\">\n    <title>老师评价统计</title>\n</head>\n<body>\n    <div id=\"main\" style=\"width: 600px; height: 400px\"></div>\n    <p>\n        <a href=\"/\">返回首页</a>\n    </p>\n    <script src=\"https://cdn.bootcss.com/echarts/4.2.1-rc1/echarts.min.js\"></script>\n    <script>\n        var myChart = echarts.init(document.querySelector('#main'))\n        fetch('/teachers_data/')\n            .then(resp => resp.json())\n            .then(json => {\n                var option = {\n                    color: ['#f00', '#00f'],\n                    title: {\n                        text: '老师评价统计图'\n                    },\n                    tooltip: {},\n                    legend: {\n                        data:['好评', '差评']\n                    },\n                    xAxis: {\n                        data: json.names\n                    },\n                    yAxis: {},\n                    series: [\n                        {\n                            name: '好评',\n                            type: 'bar',\n                            data: json.good\n                        },\n                        {\n                            name: '差评',\n                            type: 'bar',\n                            data: json.bad\n                        }\n                    ]\n                }\n                myChart.setOption(option)\n            })\n    </script>\n</body>\n</html>\n```\n\n运行效果如下图所示。\n\n![](./res/echarts_bar_graph.png)\n", "日志和调试工具栏": "## 日志和调试工具栏\n\n### 配置日志\n\n项目开发阶段，显示足够的调试信息以辅助开发人员调试代码还是非常必要的；项目上线以后，将系统运行时出现的警告、错误等信息记录下来以备相关人员了解系统运行状况并维护代码也是很有必要的。与此同时，采集日志数据也是为网站做数字化运营奠定一个基础，通过对系统运行日志的分析，我们可以监测网站的流量以及流量分布，同时还可以挖掘出用户的使用习惯和行为模式。\n\n接下来，我们先看看如何通过Django的配置文件来配置日志。Django的日志配置基本可以参照官方文档再结合项目实际需求来进行，这些内容基本上可以从官方文档上复制下来，然后进行局部的调整即可，下面给出一些参考配置。\n\n```Python\nLOGGING = {\n    'version': 1,\n    # 是否禁用已经存在的日志器\n    'disable_existing_loggers': False,\n    # 日志格式化器\n    'formatters': {\n        'simple': {\n            'format': '%(asctime)s %(module)s.%(funcName)s: %(message)s',\n            'datefmt': '%Y-%m-%d %H:%M:%S',\n        },\n        'verbose': {\n            'format': '%(asctime)s %(levelname)s [%(process)d-%(threadName)s] '\n                      '%(module)s.%(funcName)s line %(lineno)d: %(message)s',\n            'datefmt': '%Y-%m-%d %H:%M:%S',\n        }\n    },\n    # 日志过滤器\n    'filters': {\n        # 只有在Django配置文件中DEBUG值为True时才起作用\n        'require_debug_true': {\n            '()': 'django.utils.log.RequireDebugTrue',\n        },\n    },\n    # 日志处理器\n    'handlers': {\n        # 输出到控制台\n        'console': {\n            'class': 'logging.StreamHandler',\n            'level': 'DEBUG',\n            'filters': ['require_debug_true'],\n            'formatter': 'simple',\n        },\n        # 输出到文件(每周切割一次)\n        'file1': {\n            'class': 'logging.handlers.TimedRotatingFileHandler',\n            'filename': 'access.log',\n            'when': 'W0',\n            'backupCount': 12,\n            'formatter': 'simple',\n            'level': 'INFO',\n        },\n        # 输出到文件(每天切割一次)\n        'file2': {\n            'class': 'logging.handlers.TimedRotatingFileHandler',\n            'filename': 'error.log',\n            'when': 'D',\n            'backupCount': 31,\n            'formatter': 'verbose',\n            'level': 'WARNING',\n        },\n    },\n    # 日志器记录器\n    'loggers': {\n        'django': {\n            # 需要使用的日志处理器\n            'handlers': ['console', 'file1', 'file2'],\n            # 是否向上传播日志信息\n            'propagate': True,\n            # 日志级别(不一定是最终的日志级别)\n            'level': 'DEBUG',\n        },\n    }\n}\n```\n\n大家可能已经注意到了，上面日志配置中的`formatters`是**日志格式化器**，它代表了如何格式化输出日志，其中格式占位符分别表示：\n\n1. `%(name)s` - 记录器的名称\n2. `%(levelno)s` - 数字形式的日志记录级别\n3. `%(levelname)s` - 日志记录级别的文本名称\n4. `%(filename)s` - 执行日志记录调用的源文件的文件名称\n5. `%(pathname)s` - 执行日志记录调用的源文件的路径名称\n6. `%(funcName)s` - 执行日志记录调用的函数名称\n7. `%(module)s` - 执行日志记录调用的模块名称\n8. `%(lineno)s` - 执行日志记录调用的行号\n9. `%(created)s` - 执行日志记录的时间\n10. `%(asctime)s` - 日期和时间\n11. `%(msecs)s` - 毫秒部分\n12. `%(thread)d` - 线程ID（整数）\n13. `%(threadName)s` - 线程名称\n14. `%(process)d` - 进程ID （整数）\n\n日志配置中的handlers用来指定**日志处理器**，简单的说就是指定将日志输出到控制台还是文件又或者是网络上的服务器，可用的处理器包括：\n\n1. `logging.StreamHandler(stream=None)` - 可以向类似与`sys.stdout`或者`sys.stderr`的任何文件对象输出信息\n2. `logging.FileHandler(filename, mode='a', encoding=None, delay=False)` - 将日志消息写入文件\n3. `logging.handlers.DatagramHandler(host, port)` - 使用UDP协议，将日志信息发送到指定主机和端口的网络主机上\n4. `logging.handlers.HTTPHandler(host, url)` - 使用HTTP的GET或POST方法将日志消息上传到一台HTTP 服务器\n5. `logging.handlers.RotatingFileHandler(filename, mode='a', maxBytes=0, backupCount=0, encoding=None, delay=False)` - 将日志消息写入文件，如果文件的大小超出`maxBytes`指定的值，那么将重新生成一个文件来记录日志\n6. `logging.handlers.SocketHandler(host, port)` - 使用TCP协议，将日志信息发送到指定主机和端口的网络主机上 \n7. `logging.handlers.SMTPHandler(mailhost, fromaddr, toaddrs, subject, credentials=None, secure=None, timeout=1.0)` - 将日志输出到指定的邮件地址\n8. `logging.MemoryHandler(capacity, flushLevel=ERROR, target=None, flushOnClose=True)` - 将日志输出到内存指定的缓冲区中\n\n上面每个日志处理器都指定了一个名为`level`的属性，它代表了日志的级别，不同的日志级别反映出日志中记录信息的严重性。Python中定义了六个级别的日志，按照从低到高的顺序依次是：NOTSET、DEBUG、INFO、WARNING、ERROR、CRITICAL。\n\n最后配置的**日志记录器**是用来真正输出日志的，Django框架提供了如下所示的内置记录器：\n\n1. `django` - 在Django层次结构中的所有消息记录器\n2. `django.request` - 与请求处理相关的日志消息。5xx响应被视为错误消息；4xx响应被视为为警告消息\n3. `django.server` - 与通过runserver调用的服务器所接收的请求相关的日志消息。5xx响应被视为错误消息；4xx响应被记录为警告消息；其他一切都被记录为INFO\n4. `django.template` - 与模板渲染相关的日志消息\n5. `django.db.backends` - 有与数据库交互产生的日志消息，如果希望显示ORM框架执行的SQL语句，就可以使用该日志记录器。\n\n日志记录器中配置的日志级别有可能不是最终的日志级别，因为还要参考日志处理器中配置的日志级别，取二者中级别较高者作为最终的日志级别。\n\n### 配置Django-Debug-Toolbar\n\n如果想调试你的Django项目，你一定不能不过名为Django-Debug-Toolbar的神器，它是项目开发阶段辅助调试和优化的必备工具，只要配置了它，就可以很方便的查看到如下表所示的项目运行信息，这些信息对调试项目和优化Web应用性能都是至关重要的。\n\n| 项目        | 说明                              |\n| ----------- | --------------------------------- |\n| Versions    | Django的版本                      |\n| Time        | 显示视图耗费的时间                |\n| Settings    | 配置文件中设置的值                |\n| Headers     | HTTP请求头和响应头的信息          |\n| Request     | 和请求相关的各种变量及其信息      |\n| StaticFiles | 静态文件加载情况                  |\n| Templates   | 模板的相关信息                    |\n| Cache       | 缓存的使用情况                    |\n| Signals     | Django内置的信号信息              |\n| Logging     | 被记录的日志信息                  |\n| SQL         | 向数据库发送的SQL语句及其执行时间 |\n\n1. 安装Django-Debug-Toolbar。\n\n   ```Shell\n   pip install django-debug-toolbar\n   ```\n\n2. 配置 - 修改settings.py。\n\n   ```Python\n   INSTALLED_APPS = [\n       'debug_toolbar',\n   ]\n   \n   MIDDLEWARE = [\n       'debug_toolbar.middleware.DebugToolbarMiddleware',\n   ]\n   \n   DEBUG_TOOLBAR_CONFIG = {\n       # 引入jQuery库\n       'JQUERY_URL': 'https://cdn.bootcss.com/jquery/3.3.1/jquery.min.js',\n       # 工具栏是否折叠\n       'SHOW_COLLAPSED': True,\n       # 是否显示工具栏\n       'SHOW_TOOLBAR_CALLBACK': lambda x: True,\n   }\n   ```\n\n3. 配置 - 修改urls.py。\n\n   ```Python\n   if settings.DEBUG:\n   \n       import debug_toolbar\n   \n       urlpatterns.insert(0, path('__debug__/', include(debug_toolbar.urls)))\n   ```\n\n4. 在配置好Django-Debug-Toolbar之后，页面右侧会看到一个调试工具栏，如下图所示，上面包括了如前所述的各种调试信息，包括执行时间、项目设置、请求头、SQL、静态资源、模板、缓存、信号等，查看起来非常的方便。\n\n   ![](/res/debug-toolbar.png)\n\n### 优化ORM代码\n\n在配置了日志或Django-Debug-Toolbar之后，我们可以查看一下之前将老师数据导出成Excel报表的视图函数执行情况，这里我们关注的是ORM框架生成的SQL查询到底是什么样子的，相信这里的结果会让你感到有一些意外。执行`Teacher.objects.all()`之后我们可以注意到，在控制台看到的或者通过Django-Debug-Toolbar输出的SQL是下面这样的：\n\n```SQL\nSELECT `tb_teacher`.`no`, `tb_teacher`.`name`, `tb_teacher`.`detail`, `tb_teacher`.`photo`, `tb_teacher`.`good_count`, `tb_teacher`.`bad_count`, `tb_teacher`.`sno` FROM `tb_teacher`; args=()\nSELECT `tb_subject`.`no`, `tb_subject`.`name`, `tb_subject`.`intro`, `tb_subject`.`create_date`, `tb_subject`.`is_hot` FROM `tb_subject` WHERE `tb_subject`.`no` = 101; args=(101,)\nSELECT `tb_subject`.`no`, `tb_subject`.`name`, `tb_subject`.`intro`, `tb_subject`.`create_date`, `tb_subject`.`is_hot` FROM `tb_subject` WHERE `tb_subject`.`no` = 101; args=(101,)\nSELECT `tb_subject`.`no`, `tb_subject`.`name`, `tb_subject`.`intro`, `tb_subject`.`create_date`, `tb_subject`.`is_hot` FROM `tb_subject` WHERE `tb_subject`.`no` = 101; args=(101,)\nSELECT `tb_subject`.`no`, `tb_subject`.`name`, `tb_subject`.`intro`, `tb_subject`.`create_date`, `tb_subject`.`is_hot` FROM `tb_subject` WHERE `tb_subject`.`no` = 101; args=(101,)\nSELECT `tb_subject`.`no`, `tb_subject`.`name`, `tb_subject`.`intro`, `tb_subject`.`create_date`, `tb_subject`.`is_hot` FROM `tb_subject` WHERE `tb_subject`.`no` = 103; args=(103,)\nSELECT `tb_subject`.`no`, `tb_subject`.`name`, `tb_subject`.`intro`, `tb_subject`.`create_date`, `tb_subject`.`is_hot` FROM `tb_subject` WHERE `tb_subject`.`no` = 103; args=(103,)\n```\n\n这里的问题通常被称为“1+N查询”（有的地方也将其称之为“N+1查询”），原本获取老师的数据只需要一条SQL，但是由于老师关联了学科，当我们查询到`N`条老师的数据时，Django的ORM框架又向数据库发出了`N`条SQL去查询老师所属学科的信息。每条SQL执行都会有较大的开销而且会给数据库服务器带来压力，如果能够在一条SQL中完成老师和学科的查询肯定是更好的做法，这一点也很容易做到，相信大家已经想到怎么做了。是的，我们可以使用连接查询，但是在使用Django的ORM框架时如何做到这一点呢？对于多对一关联（如投票应用中的老师和学科），我们可以使用`QuerySet`的用`select_related()`方法来加载关联对象；而对于多对多关联（如电商网站中的订单和商品），我们可以使用`prefetch_related()`方法来加载关联对象。\n\n在导出老师Excel报表的视图函数中，我们可以按照下面的方式优化代码。\n\n```Python\nqueryset = Teacher.objects.all().select_related('subject')\n```\n\n事实上，用ECharts生成前端报表的视图函数中，查询老师好评和差评数据的操作也能够优化，因为在这个例子中，我们只需要获取老师的姓名、好评数和差评数这三项数据，但是在默认的情况生成的SQL会查询老师表的所有字段。可以用`QuerySet`的`only()`方法来指定需要查询的属性，也可以用`QuerySet`的`defer()`方法来指定暂时不需要查询的属性，这样生成的SQL会通过投影操作来指定需要查询的列，从而改善查询性能，代码如下所示：\n\n```Python\nqueryset = Teacher.objects.all().only('name', 'good_count', 'bad_count')\n```\n\n当然，如果要统计出每个学科的老师好评和差评的平均数，利用Django的ORM框架也能够做到，代码如下所示：\n\n```Python\nqueryset = Teacher.objects.values('subject').annotate(good=Avg('good_count'), bad=Avg('bad_count'))\n```\n\n这里获得的`QuerySet`中的元素是字典对象，每个字典中有三组键值对，分别是代表学科编号的`subject`、代表好评数的`good`和代表差评数的`bad`。如果想要获得学科的名称而不是编号，可以按照如下所示的方式调整代码：\n\n```Python\nqueryset = Teacher.objects.values('subject__name').annotate(good=Avg('good_count'), bad=Avg('bad_count'))\n```\n\n可见，Django的ORM框架允许我们用面向对象的方式完成关系数据库中的分组和聚合查询。\n", "中间件的应用": "## 中间件的应用\n\n之前我们已经实现了用户必须登录才能投票的限制，但是一个新的问题来了。如果我们的应用中有很多功能都需要用户先登录才能执行，例如将前面导出Excel报表和查看统计图表的功能都做了必须登录才能访问的限制，那么我们是不是需要在每个视图函数中添加代码来检查session中是否包含`userid`的代码呢？答案是否定的，如果这样做了，我们的视图函数中必然会充斥着大量的重复代码。编程大师*Martin Fowler*曾经说过：**代码有很多种坏味道，重复是最坏的一种**。在Python程序中，我们可以通过装饰器来为函数提供额外的能力；在Django项目中，我们可以把类似于验证用户是否登录这样的重复性代码放到**中间件**中。\n\n### Django中间件概述\n\n中间件是安插在Web应用请求和响应过程之间的组件，它在整个Web应用中扮演了拦截过滤器的角色，通过中间件可以拦截请求和响应，并对请求和响应进行过滤（简单的说就是执行额外的处理）。通常，一个中间件组件只专注于完成一件特定的事，例如：Django框架通过`SessionMiddleware`中间件实现了对session的支持，又通过`AuthenticationMiddleware`中间件实现了基于session的请求认证。通过把多个中间件组合在一起，我们可以完成更为复杂的任务，Django框架就是这么做的。\n\nDjango项目的配置文件中就包含了对中间件的配置，代码如下所示。\n\n```Python\nMIDDLEWARE = [\n    'django.middleware.security.SecurityMiddleware',\n    'django.contrib.sessions.middleware.SessionMiddleware',\n    'django.middleware.common.CommonMiddleware',\n    'django.middleware.csrf.CsrfViewMiddleware',\n    'django.contrib.auth.middleware.AuthenticationMiddleware',\n    'django.contrib.messages.middleware.MessageMiddleware',\n    'django.middleware.clickjacking.XFrameOptionsMiddleware',\n]\n```\n\n我们稍微为大家解释一下这些中间件的作用：\n\n1. `CommonMiddleware` - 基础设置中间件，可以处理以下一些配置参数。\n   - DISALLOWED_USER_AGENTS - 不被允许的用户代理（浏览器）\n   - APPEND_SLASH - 是否追加`/`\n   - USE_ETAG - 浏览器缓存相关\n2. `SecurityMiddleware` - 安全相关中间件，可以处理和安全相关的配置项。\n   - SECURE_HSTS_SECONDS - 强制使用HTTPS的时间\n   - SECURE_HSTS_INCLUDE_SUBDOMAINS - HTTPS是否覆盖子域名\n   - SECURE_CONTENT_TYPE_NOSNIFF - 是否允许浏览器推断内容类型\n   - SECURE_BROWSER_XSS_FILTER - 是否启用跨站脚本攻击过滤器\n   - SECURE_SSL_REDIRECT - 是否重定向到HTTPS连接\n   - SECURE_REDIRECT_EXEMPT - 免除重定向到HTTPS\n3. `SessionMiddleware` - 会话中间件。\n4. `CsrfViewMiddleware` - 通过生成令牌，防范跨请求份伪的造中间件。\n5. `XFrameOptionsMiddleware` - 通过设置请求头参数，防范点击劫持攻击的中间件。\n\n在请求的过程中，上面的中间件会按照书写的顺序从上到下执行，然后是URL解析，最后请求才会来到视图函数；在响应的过程中，上面的中间件会按照书写的顺序从下到上执行，与请求时中间件执行的顺序正好相反。\n\n### 自定义中间件\n\nDjango中的中间件有两种实现方式：基于类的实现方式和基于函数的实现方式，后者更接近于装饰器的写法。装饰器实际上是代理模式的应用，将横切关注功能（与正常业务逻辑没有必然联系的功能，例如：身份认证、日志记录、编码转换之类的功能）置于代理中，由代理对象来完成被代理对象的行为并添加额外的功能。中间件对用户请求和响应进行拦截过滤并增加额外的处理，在这一点上它跟装饰器是完全一致的，所以基于函数的写法来实现中间件就跟装饰器的写法几乎一模一样。下面我们用自定义的中间件来实现用户登录验证的功能。\n\n```Python\n\"\"\"\nmiddlewares.py\n\"\"\"\nfrom django.http import JsonResponse\nfrom django.shortcuts import redirect\n\n# 需要登录才能访问的资源路径\nLOGIN_REQUIRED_URLS = {'/praise/', '/criticize/', '/excel/', '/teachers_data/'}\n\n\ndef check_login_middleware(get_resp):\n\n    def wrapper(request, *args, **kwargs):\n        # 请求的资源路径在上面的集合中\n        if request.path in LOGIN_REQUIRED_URLS:\n            # 会话中包含userid则视为已经登录\n            if 'userid' not in request.session:\n                # 判断是不是Ajax请求\n                if request.is_ajax():\n                    # Ajax请求返回JSON数据提示用户登录\n                    return JsonResponse({'code': 10003, 'hint': '请先登录'})\n                else:\n                    backurl = request.get_full_path()\n                    # 非Ajax请求直接重定向到登录页\n                    return redirect(f'/login/?backurl={backurl}')\n        return get_resp(request, *args, **kwargs)\n\n    return wrapper\n```\n\n当然，我们也可以定义一个类来充当装饰器，如果类中有`__call__`魔术方法，这个类的对象就像函数一样可调用，所以下面是另一种实现中间件的方式，道理跟上面的代码完全一样。\n\n还有一种基于类实现中间件的方式，这种方式在较新版本的Django中已经不推荐使用了，但是大家接触到的代码中，仍然有可能遇到这种写法，大致的代码如下所示。\n\n```Python\nfrom django.utils.deprecation import MiddlewareMixin\n\n\nclass MyMiddleware(MiddlewareMixin):\n\n    def process_request(self, request):\n        pass\n\n    def process_view(self, request, view_func, view_args, view_kwargs):\n        pass\n\n    def process_template_response(self, request, response):\n        pass\n\n    def process_response(self, request, response):\n        pass\n\n    def process_exception(self, request, exception):\n        pass\n```\n\n上面类中的五个方法都是中间件的钩子函数，分别在收到用户请求、进入视图函数之前、渲染模板、返回响应和出现异常的时候被回调。当然，写不写这些方法是根据中间件的需求来确定的，并不是所有的场景都需要重写五个方法，下面的图相信能够帮助大家理解这种写法。\n\n![](/res/django-middleware.png)\n\n写好中间件代码后，需要修改配置文件来激活中间件使其生效。\n\n```Python\nMIDDLEWARE = [\n    'django.middleware.security.SecurityMiddleware',\n    'django.contrib.sessions.middleware.SessionMiddleware',\n    'django.middleware.common.CommonMiddleware',\n    'django.middleware.csrf.CsrfViewMiddleware',\n    'django.contrib.auth.middleware.AuthenticationMiddleware',\n    'django.contrib.messages.middleware.MessageMiddleware',\n    'django.middleware.clickjacking.XFrameOptionsMiddleware',\n    'debug_toolbar.middleware.DebugToolbarMiddleware',\n    'vote.middlewares.check_login_middleware',\n]\n```\n\n注意上面这个中间件列表中元素的顺序，当收到来自用户的请求时，中间件按照从上到下的顺序依次执行，这行完这些中间件以后，请求才会最终到达视图函数。当然，在这个过程中，用户的请求可以被拦截，就像上面我们自定义的中间件那样，如果用户在没有登录的情况下访问了受保护的资源，中间件会将请求直接重定向到登录页，后面的中间件和视图函数将不再执行。在响应用户请求的过程中，上面的中间件会按照从下到上的顺序依次执行，这样的话我们还可以对响应做进一步的处理。\n\n中间件执行的顺序是非常重要的，对于有依赖关系的中间件必须保证被依赖的中间件要置于依赖它的中间件的前面，就好比我们刚才自定义的中间件要放到`SessionMiddleware`的后面，因为我们要依赖这个中间件为请求绑定的`session`对象才能判定用户是否登录。\n\n", "前后端分离开发入门": "## 前后端分离开发入门\n\n在传统的Web应用开发中，大多数的程序员会将浏览器作为前后端的分界线。将浏览器中为用户进行页面展示的部分称之为前端，而将运行在服务器为前端提供业务逻辑和数据准备的所有代码统称为后端。所谓前后端分离的开发，就是前后端工程师约定好数据交互接口，并行的进行开发和测试，后端只提供数据，不负责将数据渲染到页面上，前端通过HTTP请求获取数据并负责将数据渲染到页面上，这个工作是交给浏览器中的JavaScript代码来完成。\n\n使用前后端分离开发有诸多的好处，下面我们简要的说下这些好处：\n\n1. **提升开发效率**。前后端分离以后，可以实现前后端代码的解耦，只要前后端沟通约定好应用所需接口以及接口参数，便可以开始并行开发，无需等待对方的开发工作结束。在这种情况下，前后端工程师都可以只专注于自己的开发工作，有助于打造出更好的团队。除此之外，在前后端分离的开发模式下，即使需求发生变更，只要接口与数据格式不变，后端开发人员就不需要修改代码，只要前端进行变动即可。\n2. **增强代码的可维护性**。前后端分离后，应用的代码不再是前后端混合，只有在运行期才会有调用依赖关系，这样的话维护代码的工作将变得轻松愉快很多，再不会牵一发而动全身。当你的代码变得简明且整洁时，代码的可读性和可维护性都会有质的提升。\n3. **支持多终端和服务化架构**。前后端分离后，同一套数据接口可以为不同的终端提供服务，更有助于打造多终端应用；此外，由于后端提供的接口之间可以通过HTTP(S)进行调用，有助于打造服务化架构（包括微服务）。\n\n接下来我们就用前后端分离的方式来改写之前的投票应用。\n\n### 返回JSON格式的数据\n\n刚才说过，在前后端分离的开发模式下，后端需要为前端提供数据接口，这些接口通常返回JSON格式的数据。在Django项目中，我们可以先将对象处理成字典，然后就可以利用Django封装的`JsonResponse`向浏览器返回JSON格式的数据，具体的做法如下所示。\n\n```Python\ndef show_subjects(request):\n    queryset = Subject.objects.all()\n    subjects = []\n    for subject in queryset:\n        subjects.append({\n            'no': subject.no,\n            'name': subject.name,\n            'intro': subject.intro,\n            'isHot': subject.is_hot\n        })\n    return JsonResponse(subjects, safe=False)\n```\n\n上面的代码中，我们通过循环遍历查询学科得到的`QuerySet`对象，将每个学科的数据处理成一个字典，在将字典保存在名为`subjects`的列表容器中，最后利用`JsonResponse`完成对列表的序列化，向浏览器返回JSON格式的数据。由于`JsonResponse`序列化的是一个列表而不是字典，所以需要指定`safe`参数的值为`False`才能完成对`subjects`的序列化，否则会产生`TypeError`异常。\n\n可能大家已经发现了，自己写代码将一个对象转成字典是比较麻烦的，如果对象的属性很多而且某些属性又关联到一个比较复杂的对象时，情况会变得更加糟糕。为此我们可以使用一个名为`bpmappers`的三方库来简化将对象转成字典的操作，这个三方库本身也提供了对Django框架的支持。\n\n安装三方库`bpmappers`。\n\n```Shell\npip install bpmappers\n```\n\n编写映射器（实现对象到字典转换）。\n\n```Python\nfrom bpmappers.djangomodel import ModelMapper\n\nfrom poll2.models import Subject\n\n\nclass SubjectMapper(ModelMapper):\n   \n    class Meta:\n        model = Subject\n```\n\n修改视图函数。\n\n```Python\ndef show_subjects(request):\n    queryset = Subject.objects.all()\n    subjects = []\n    for subject in queryset:\n        subjects.append(SubjectMapper(subject).as_dict())\n    return JsonResponse(subjects, safe=False)\n```\n\n配置URL映射。\n\n```Python\nurlpatterns = [\n    \n    path('api/subjects/', show_subjects),\n    \n]\n```\n\n然后访问该接口，可以得到如下所示的JSON格式数据。\n\n```JSON\n[\n    {\n        \"no\": 1,\n        \"name\": \"Python全栈+人工智能\",\n        \"intro\": \"Python是一种计算机程序设计语言。是一种面向对象的动态类型语言，最初被设计用于编写自动化脚本(shell)，随着版本的不断更新和语言新功能的添加，越来越多被用于独立的、大型项目的开发。\",\n        \"is_hot\": true\n    },\n    // 此处省略下面的内容\n]\n```\n\n如果不希望在JSON数据中显示学科的成立时间，我们可以在映射器中排除`create_date`属性；如果希望将是否为热门学科对应的键取名为`isHot`（默认的名字是`is_hot`），也可以通过修改映射器来做到。具体的做法如下所示：\n\n```Python\nfrom bpmappers import RawField\nfrom bpmappers.djangomodel import ModelMapper\n\nfrom poll2.models import Subject\n\n\nclass SubjectMapper(ModelMapper):\n    isHot = RawField('is_hot')\n\n    class Meta:\n        model = Subject\n        exclude = ('is_hot', )\n```\n\n再次查看学科接口返回的JSON数据。\n\n```JSON\n[\n    {\n        \"no\": 101,\n        \"name\": \"Python全栈+人工智能\",\n        \"intro\": \"Python是一种计算机程序设计语言。是一种面向对象的动态类型语言，最初被设计用于编写自动化脚本(shell)，随着版本的不断更新和语言新功能的添加，越来越多被用于独立的、大型项目的开发。\",\n        \"isHot\": true\n    },\n    // 此处省略下面的内容\n]\n```\n\n关于`bpmappers`详细的使用指南，请参考它的[官方文档](<https://bpmappers.readthedocs.io/en/stable/>)，这个官方文档是用日语书写的，可以使用浏览器的翻译功能将它翻译成你熟悉的语言即可。\n\n### 使用Vue.js渲染页面\n\n接下来我们通过前端框架Vue.js来实现页面的渲染。如果希望全面的了解和学习Vue.js，建议阅读它的[官方教程](<https://cn.vuejs.org/v2/guide/>)或者在[YouTube](<https://www.youtube.com/>)上搜索Vue.js的新手教程（Vue.js Crash Course）进行学习。\n\n重新改写subjects.html页面，使用Vue.js来渲染页面。\n\n```HTML\n<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n    <meta charset=\"UTF-8\">\n    <title>学科信息</title>\n    <style>\n\t\t/* 此处省略层叠样式表 */\n    </style>\n</head>\n<body>\n    <div id=\"container\">\n        <h1>扣丁学堂所有学科</h1>\n        <hr>\n        <div id=\"main\">\n            <dl v-for=\"subject in subjects\">\n                <dt>\n                    <a :href=\"'/static/html/teachers.html?sno=' + subject.no\">\n                        {{ subject.name }}\n                    </a>\n                    <img v-if=\"subject.is_hot\" src=\"/static/images/hot-icon-small.png\">\n                </dt>\n                <dd>{{ subject.intro }}</dd>\n            </dl>\n        </div>\n    </div>\n    <script src=\"https://cdn.bootcdn.net/ajax/libs/vue/2.6.11/vue.min.js\"></script>\n    <script>\n        let app = new Vue({\n            el: '#main',\n            data: {\n                subjects: []\n            },\n            created() {\n                fetch('/api/subjects/')\n                    .then(resp => resp.json())\n                    .then(json => {\n                        this.subjects = json\n                    })\n            }\n        })\n    </script>\n</body>\n</html>\n```\n\n前后端分离的开发需要将前端页面作为静态资源进行部署，项目实际上线的时候，我们会对整个Web应用进行动静分离，静态资源通过Nginx或Apache服务器进行部署，生成动态内容的Python程序部署在uWSGI或者Gunicorn服务器上，对动态内容的请求由Nginx或Apache路由到uWSGI或Gunicorn服务器上。\n\n在开发阶段，我们通常会使用Django自带的测试服务器，如果要尝试前后端分离，可以先将静态页面放在之前创建的放静态资源的目录下，具体的做法可以参考[项目完整代码](https://gitee.com/jackfrued/django19062)。\n", "RESTful架构和DRF入门": "## RESTful架构和DRF入门\n\n把软件（Software）、平台（Platform）、基础设施（Infrastructure）做成服务（Service）是很多IT企业都一直在做的事情，这就是大家经常听到的SasS（软件即服务）、PasS（平台即服务）和IasS（基础设置即服务）。实现面向服务的架构（SOA）有诸多的方式，包括RPC（远程过程调用）、Web Service、REST等，在技术层面上，SOA是一种**抽象的、松散耦合的粗粒度软件架构**；在业务层面上，SOA的核心概念是“**重用**”和“**互操作**”，它将系统资源整合成可操作的、标准的服务，使得这些资源能够被重新组合和应用。在实现SOA的诸多方案中，REST被认为是最适合互联网应用的架构，符合REST规范的架构也经常被称作RESTful架构。\n\n### REST概述\n\nREST这个词，是**Roy Thomas Fielding**在他2000年的博士论文中提出的，Roy是HTTP协议（1.0和1.1版）的主要设计者、Apache服务器软件主要作者、Apache基金会第一任主席。在他的博士论文中，Roy把他对互联网软件的架构原则定名为REST，即**RE**presentational **S**tate **T**ransfer的缩写，中文通常翻译为“**表现层状态转移**”或“**表述状态转移**”。\n\n这里的“表现层”其实指的是“资源”的“表现层”。所谓资源，就是网络上的一个实体，或者说是网络上的一个具体信息。它可以是一段文本、一张图片、一首歌曲或一种服务。我们可以用一个URI（统一资源定位符）指向资源，要获取到这个资源，访问它的URI即可，URI就是资源在互联网上的唯一标识。资源可以有多种外在表现形式。我们把资源具体呈现出来的形式，叫做它的“表现层”。比如，文本可以用`text/plain`格式表现，也可以用`text/html`格式、`text/xml`格式、`application/json`格式表现，甚至可以采用二进制格式；图片可以用`image/jpeg`格式表现，也可以用`image/png`格式表现。URI只代表资源的实体，不代表它的表现形式。严格地说，有些网址最后的`.html`后缀名是不必要的，因为这个后缀名表示格式，属于“表现层”范畴，而URI应该只代表“资源”的位置，它的具体表现形式，应该在HTTP请求的头信息中用`Accept`和`Content-Type`字段指定，这两个字段才是对“表现层”的描述。\n\n访问一个网站，就代表了客户端和服务器的一个互动过程。在这个过程中，势必涉及到数据和状态的变化。Web应用通常使用HTTP作为其通信协议，客户端想要操作服务器，必须通过HTTP请求，让服务器端发生“状态转移”，而这种转移是建立在表现层之上的，所以就是“表现层状态转移”。客户端通过HTTP的动词GET、POST、PUT（或PATCH）、DELETE，分别对应对资源的四种基本操作，其中GET用来获取资源，POST用来新建资源（也可以用于更新资源），PUT（或PATCH）用来更新资源，DELETE用来删除资源。\n\n简单的说RESTful架构就是：“每一个URI代表一种资源，客户端通过四个HTTP动词，对服务器端资源进行操作，实现资源的表现层状态转移”。\n\n我们在设计Web应用时，如果需要向客户端提供资源，就可以使用REST风格的URI，这是实现RESTful架构的第一步。当然，真正的RESTful架构并不只是URI符合REST风格，更为重要的是“无状态”和“幂等性”两个词，我们在后面的课程中会为大家阐述这两点。下面的例子给出了一些符合REST风格的URI，供大家在设计URI时参考。\n\n| 请求方法（HTTP动词） | URI                        | 解释                                         |\n| -------------------- | -------------------------- | -------------------------------------------- |\n| **GET**              | `/students/`               | 获取所有学生                                 |\n| **POST**             | `/students/`               | 新建一个学生                                 |\n| **GET**              | `/students/ID/`            | 获取指定ID的学生信息                         |\n| **PUT**              | `/students/ID/`            | 更新指定ID的学生信息（提供该学生的全部信息） |\n| **PATCH**            | `/students/ID/`            | 更新指定ID的学生信息（提供该学生的部分信息） |\n| **DELETE**           | `/students/ID/`            | 删除指定ID的学生信息                         |\n| **GET**              | `/students/ID/friends/`    | 列出指定ID的学生的所有朋友                   |\n| **DELETE**                  | `/students/ID/friends/ID/` | 删除指定ID的学生的指定ID的朋友               |\n\n### DRF使用入门\n\n在Django项目中，如果要实现REST架构，即将网站的资源发布成REST风格的API接口，可以使用著名的三方库`djangorestframework` ，我们通常将其简称为DRF。\n\n#### 安装和配置DRF\n\n安装DRF。\n\n```Shell\npip install djangorestframework\n```\n\n配置DRF。\n\n```Python\nINSTALLED_APPS = [\n\n    'rest_framework',\n    \n]\n\n# 下面的配置根据项目需要进行设置\nREST_FRAMEWORK = {\n    # 配置默认页面大小\n    # 'PAGE_SIZE': 10,\n    # 配置默认的分页类\n    # 'DEFAULT_PAGINATION_CLASS': '...',\n    # 配置异常处理器\n    # 'EXCEPTION_HANDLER': '...',\n    # 配置默认解析器\n    # 'DEFAULT_PARSER_CLASSES': (\n    #     'rest_framework.parsers.JSONParser',\n    #     'rest_framework.parsers.FormParser',\n    #     'rest_framework.parsers.MultiPartParser',\n    # ),\n    # 配置默认限流类\n    # 'DEFAULT_THROTTLE_CLASSES': (\n    #     '...'\n    # ),\n    # 配置默认授权类\n    # 'DEFAULT_PERMISSION_CLASSES': (\n    #     '...',\n    # ),\n    # 配置默认认证类\n    # 'DEFAULT_AUTHENTICATION_CLASSES': (\n    #     '...',\n    # ),\n}\n```\n\n#### 编写序列化器\n\n前后端分离的开发需要后端为前端、移动端提供API数据接口，而API接口通常情况下都是返回JSON格式的数据，这就需要对模型对象进行序列化处理。DRF中封装了`Serializer`类和`ModelSerializer`类用于实现序列化操作，通过继承`Serializer`类或`ModelSerializer`类，我们可以自定义序列化器，用于将对象处理成字典，代码如下所示。\n\n```Python\nfrom rest_framework import serializers \n\n\nclass SubjectSerializer(serializers.ModelSerializer):\n\n    class Meta:\n        model = Subject\n        fields = '__all__'\n```\n\n上面的代码直接继承了`ModelSerializer`，通过`Meta`类的`model`属性指定要序列化的模型以及`fields`属性指定需要序列化的模型字段，稍后我们就可以在视图函数中使用该类来实现对`Subject`模型的序列化。\n\n#### 编写视图函数\n\nDRF框架支持两种实现数据接口的方式，一种是FBV（基于函数的视图），另一种是CBV（基于类的视图）。我们先看看FBV的方式如何实现数据接口，代码如下所示。\n\n```Python\nfrom rest_framework.decorators import api_view\nfrom rest_framework.response import Response\n\n\n@api_view(('GET', ))\ndef show_subjects(request: HttpRequest) -> HttpResponse:\n    subjects = Subject.objects.all().order_by('no')\n    # 创建序列化器对象并指定要序列化的模型\n    serializer = SubjectSerializer(subjects, many=True)\n    # 通过序列化器的data属性获得模型对应的字典并通过创建Response对象返回JSON格式的数据\n    return Response(serializer.data)\n```\n\n对比上一个章节的使用`bpmapper`实现模型序列化的代码，使用DRF的代码更加简单明了，而且DRF本身自带了一套页面，可以方便我们查看我们使用DRF定制的数据接口，如下图所示。\n\n![](/res/drf-app.png)\n\n直接使用上一节写好的页面，就可以通过Vue.js把上面接口提供的学科数据渲染并展示出来，此处不再进行赘述。\n\n#### 实现老师信息数据接口\n\n编写序列化器。\n\n```Python\nclass SubjectSimpleSerializer(serializers.ModelSerializer):\n\n    class Meta:\n        model = Subject\n        fields = ('no', 'name')\n\n\nclass TeacherSerializer(serializers.ModelSerializer):\n\n    class Meta:\n        model = Teacher\n        exclude = ('subject', )\n```\n\n编写视图函数。\n\n```Python\n@api_view(('GET', ))\ndef show_teachers(request: HttpRequest) -> HttpResponse:\n    try:\n        sno = int(request.GET.get('sno'))\n        subject = Subject.objects.only('name').get(no=sno)\n        teachers = Teacher.objects.filter(subject=subject).defer('subject').order_by('no')\n        subject_seri = SubjectSimpleSerializer(subject)\n        teacher_seri = TeacherSerializer(teachers, many=True)\n        return Response({'subject': subject_seri.data, 'teachers': teacher_seri.data})\n    except (TypeError, ValueError, Subject.DoesNotExist):\n        return Response(status=404)\n```\n\n配置URL映射。\n\n```Python\nurlpatterns = [\n    \n    path('api/teachers/', show_teachers),\n    \n]\n```\n\n通过Vue.js渲染页面。\n\n```HTML\n<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n    <meta charset=\"UTF-8\">\n    <title>老师信息</title>\n    <style>\n        /* 此处省略掉层叠样式表 */\n    </style>\n</head>\n<body>\n    <div id=\"container\">\n        <h1>{{ subject.name }}学科的老师信息</h1>\n        <hr>\n        <h2 v-if=\"loaded && teachers.length == 0\">暂无该学科老师信息</h2>\n        <div class=\"teacher\" v-for=\"teacher in teachers\">\n            <div class=\"photo\">\n                <img :src=\"'/static/images/' + teacher.photo\" height=\"140\" alt=\"\">\n            </div>\n            <div class=\"info\">\n                <div>\n                    <span><strong>姓名：{{ teacher.name }}</strong></span>\n                    <span>性别：{{ teacher.sex | maleOrFemale }}</span>\n                    <span>出生日期：{{ teacher.birth }}</span>\n                </div>\n                <div class=\"intro\">{{ teacher.intro }}</div>\n                <div class=\"comment\">\n                    <a href=\"\" @click.prevent=\"vote(teacher, true)\">好评</a>&nbsp;&nbsp;\n                    (<strong>{{ teacher.good_count }}</strong>)\n                    &nbsp;&nbsp;&nbsp;&nbsp;\n                    <a href=\"\" @click.prevent=\"vote(teacher, false)\">差评</a>&nbsp;&nbsp;\n                    (<strong>{{ teacher.bad_count }}</strong>)\n                </div>\n            </div>\n        </div>\n        <a href=\"/static/html/subjects.html\">返回首页</a>\n    </div>\n    <script src=\"https://cdn.bootcdn.net/ajax/libs/vue/2.6.11/vue.min.js\"></script>\n    <script>\n        let app = new Vue({\n            el: '#container',\n            data: {\n                subject: {},\n                teachers: [],\n                loaded: false\n            },\n            created() {\n                fetch('/api/teachers/' + location.search)\n                    .then(resp => resp.json())\n                    .then(json => {\n                        this.subject = json.subject\n                        this.teachers = json.teachers\n                    })\n            },\n            filters: {\n                maleOrFemale(sex) {\n                    return sex? '男': '女'\n                }\n            },\n            methods: {\n               vote(teacher, flag) {\n                    let url = flag? '/praise/' : '/criticize/'\n                    url += '?tno=' + teacher.no\n                    fetch(url).then(resp => resp.json()).then(json => {\n                        if (json.code === 10000) {\n                            if (flag) {\n                                teacher.good_count = json.count\n                            } else {\n                                teacher.bad_count = json.count\n                            }\n                        }\n                    })\n                }\n            }\n        })\n    </script>\n</body>\n</html>\n```\n\n### 前后端分离下的用户登录\n\n之前我们提到过， HTTP是无状态的，一次请求结束连接断开，下次服务器再收到请求，它就不知道这个请求是哪个用户发过来的。但是对于一个Web应用而言，它是需要有状态管理的，这样才能让服务器知道HTTP请求来自哪个用户，从而判断是否允许该用户请求以及为用户提供更好的服务，这个过程就是常说的**会话管理**。\n\n之前我们做会话管理（用户跟踪）的方法是：用户登录成功后，在服务器端通过一个session对象保存用户相关数据，然后把session对象的ID写入浏览器的cookie中；下一次请求时，HTTP请求头中携带cookie的数据，服务器从HTTP请求头读取cookie中的sessionid，根据这个标识符找到对应的session对象，这样就能够获取到之前保存在session中的用户数据。我们刚才说过，REST架构是最适合互联网应用的架构，它强调了HTTP的无状态性，这样才能保证应用的水平扩展能力（当并发访问量增加时，可以通过增加新的服务器节点来为系统扩容）。显然，基于session实现用户跟踪的方式需要服务器保存session对象，在做水平扩展增加新的服务器节点时，需要复制和同步session对象，这显然是非常麻烦的。解决这个问题有两种方案，一种是架设缓存服务器（如Redis），让多个服务器节点共享缓存服务并将session对象直接置于缓存服务器中；另一种方式放弃基于session的用户跟踪，使用**基于token的用户跟踪**。\n\n基于token的用户跟踪是在用户登录成功后，为用户生成身份标识并保存在浏览器本地存储（localStorage、sessionStorage、cookie等）中，这样的话服务器不需要保存用户状态，从而可以很容易的做到水平扩展。基于token的用户跟踪具体流程如下：\n\n1. 用户登录时，如果登录成功就按照某种方式为用户生成一个令牌（token），该令牌中通常包含了用户标识、过期时间等信息而且需要加密并生成指纹（避免伪造或篡改令牌），服务器将令牌返回给前端；\n2. 前端获取到服务器返回的token，保存在浏览器本地存储中（可以保存在`localStorage`或`sessionStorage`中，对于使用Vue.js的前端项目来说，还可以通过Vuex进行状态管理）；\n3. 对于使用了前端路由的项目来说，前端每次路由跳转，可以先判断`localStroage`中有无token，如果没有则跳转到登录页；\n4. 每次请求后端数据接口，在HTTP请求头里携带token；后端接口判断请求头有无token，如果没有token以及token是无效的或过期的，服务器统一返回401；\n5. 如果前端收到HTTP响应状态码401，则重定向到登录页面。\n\n通过上面的描述，相信大家已经发现了，基于token的用户跟踪最为关键是在用户登录成功时，要为用户生成一个token作为用户的身份标识。生成token的方法很多，其中一种比较成熟的解决方案是使用JSON Web Token。\n\n#### JWT概述\n\nJSON Web Token通常简称为JWT，它是一种开放标准（RFC 7519）。随着RESTful架构的流行，越来越多的项目使用JWT作为用户身份认证的方式。JWT相当于是三个JSON对象经过编码后，用`.`分隔并组合到一起，这三个JSON对象分别是头部（header）、载荷（payload）和签名（signature），如下图所示。\n\n![](/res/json-web-token.png)\n\n1. 头部\n\n    ```JSON\n    {\n      \"alg\": \"HS256\",\n      \"typ\": \"JWT\"\n    }\n    ```\n\n    其中，`alg`属性表示签名的算法，默认是HMAC SHA256（简写成`HS256`）；`typ`属性表示这个令牌的类型，JWT中都统一书写为`JWT`。\n\n2. 载荷\n\n    载荷部分用来存放实际需要传递的数据。JWT官方文档中规定了7个可选的字段：\n\n    - iss ：签发人\n    - exp：过期时间\n    - sub：主题\n    - aud：受众\n    - nbf：生效时间\n    - iat：签发时间\n    - jti：编号\n\n    除了官方定义的字典，我们可以根据应用的需要添加自定义的字段，如下所示。\n\n    ```JSON\n    {\n      \"sub\": \"1234567890\",\n      \"nickname\": \"jackfrued\",\n      \"role\": \"admin\"\n    }\n    ```\n\n3. 签名\n\n    签名部分是对前面两部分生成一个指纹，防止数据伪造和篡改。实现签名首先需要指定一个密钥。这个密钥只有服务器才知道，不能泄露给用户。然后，使用头部指定的签名算法（默认是`HS256`），按照下面的公式产生签名。\n\n    ```Python\n    HS256(base64Encode(header) + '.' + base64Encode(payload), secret)\n    ```\n\n    算出签名以后，把头部、载荷、签名三个部分拼接成一个字符串，每个部分用`.`进行分隔，这样一个JWT就生成好了。\n\n#### JWT的优缺点\n\n使用JWT的优点非常明显，包括：\n\n1. 更容易实现水平扩展，因为令牌保存在浏览器中，服务器不需要做状态管理。\n2. 更容易防范CSRF攻击，因为在请求头中添加`localStorage`或`sessionStorage`中的token必须靠JavaScript代码完成，而不是自动添加到请求头中的。\n3. 可以防伪造和篡改，因为JWT有签名，伪造和篡改的令牌无法通过签名验证，会被认定是无效的令牌。\n\n当然，任何技术不可能只有优点没有缺点，JWT也有诸多缺点，大家需要在使用的时候引起注意，具体包括：\n\n1. 可能会遭受到XSS攻击（跨站脚本攻击），通过注入恶意脚本执行JavaScript代码获取到用户令牌。\n2. 在令牌过期之前，无法作废已经颁发的令牌，要解决这个问题，还需要额外的中间层和代码来辅助。\n3. JWT是用户的身份令牌，一旦泄露，任何人都可以获得该用户的所有权限。为了降低令牌被盗用后产生的风险，JWT的有效期应该设置得比较短。对于一些比较重要的权限，使用时应通过其他方式再次对用户进行认证，例如短信验证码等。\n\n#### 使用PyJWT\n\n在Python代码中，可以使用三方库`PyJWT`生成和验证JWT，下面是安装`PyJWT`的命令。\n\n```Bash\npip install pyjwt\n```\n\n生成令牌。\n\n```Python\npayload = {\n    'exp': datetime.datetime.utcnow() + datetime.timedelta(days=1),\n    'userid': 10001\n}\ntoken = jwt.encode(payload, settings.SECRET_KEY).decode()\n```\n\n验证令牌。\n\n```Python\ntry:\n    token = 'eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJleHAiOjE1OTQ4NzIzOTEsInVzZXJpZCI6MTAwMDF9.FM-bNxemWLqQQBIsRVvc4gq71y42I9m2zt5nlFxNHUo'\n    payload = jwt.decode(token, settings.SECRET_KEY)\nexcept InvalidTokenError:\n    raise AuthenticationFailed('无效的令牌或令牌已经过期')\n```\n\n如果不清楚JWT具体的使用方式，可以先看看第55天的内容，里面提供了完整的投票项目代码的地址。", "RESTful架构和DRF进阶": "## RESTful架构和DRF进阶\n\n除了上一节讲到的方法，使用DRF创建REST风格的数据接口也可以通过CBV（基于类的视图）的方式。使用CBV创建数据接口的特点是代码简单，开发效率高，但是没有FBV（基于函数的视图）灵活，因为使用FBV的方式，数据接口对应的视图函数执行什么样的代码以及返回什么的数据是高度可定制的。下面我们以定制学科的数据接口为例，讲解通过CBV方式定制数据接口的具体做法。\n\n### 使用CBV\n\n#### 继承APIView的子类\n\n修改之前项目中的`polls/views.py`，去掉`show_subjects`视图函数，添加一个名为`SubjectView`的类，该类继承自`ListAPIView`，`ListAPIView`能接收GET请求，它封装了获取数据列表并返回JSON数据的`get`方法。`ListAPIView`是`APIView` 的子类，`APIView`还有很多的子类，例如`CreateAPIView`可以支持POST请求，`UpdateAPIView`可以支持PUT和PATCH请求，`DestoryAPIView`可以支持DELETE请求。`SubjectView` 的代码如下所示。\n\n```Python\nfrom rest_framework.generics import ListAPIView\n\n\nclass SubjectView(ListAPIView):\n    # 通过queryset指定如何获取学科数据\n    queryset = Subject.objects.all()\n    # 通过serializer_class指定如何序列化学科数据\n    serializer_class = SubjectSerializer\n```\n\n刚才说过，由于`SubjectView`的父类`ListAPIView`已经实现了`get`方法来处理获取学科列表的GET请求，所以我们只需要声明如何获取学科数据以及如何序列化学科数据，前者用`queryset`属性指定，后者用`serializer_class`属性指定。要使用上面的`SubjectView`，需要修改`urls.py`文件，如下所示。\n\n```Python\nurlpatterns = [\n    path('api/subjects/', SubjectView.as_view()),   \n]\n```\n\n很显然，上面的做法较之之前讲到的FBV要简单很多。\n\n#### 继承ModelViewSet\n\n如果学科对应的数据接口需要支持GET、POST、PUT、PATCH、DELETE请求来支持对学科资源的获取、新增、更新、删除操作，更为简单的做法是继承`ModelViewSet`来编写学科视图类。再次修改`polls/views.py`文件，去掉`SubjectView`类，添加一个名为`SubjectViewSet`的类，代码如下所示。\n\n```Python\nfrom rest_framework.viewsets import ModelViewSet\n\n\nclass SubjectViewSet(ModelViewSet):\n    queryset = Subject.objects.all()\n    serializer_class = SubjectSerializer\n```\n\n通过查看`ModelViewSet`类的源代码可以发现，该类共有6个父类，其中前5个父类分别实现对POST（新增学科）、GET（获取指定学科）、PUT/PATCH（更新学科）、DELETE（删除学科）和GET（获取学科列表）操作的支持，对应的方法分别是`create`、`retrieve`、`update`、`destroy`和`list`。由于`ModelViewSet`的父类中已经实现了这些方法，所以我们几乎没有编写任何代码就完成了学科数据全套接口的开发，我们要做的仅仅是指出如何获取到数据（通过`queryset`属性指定）以及如何序列化数据（通过`serializer_class`属性指定），这一点跟上面继承`APIView`的子类做法是一致的。\n\n```Python\nclass ModelViewSet(mixins.CreateModelMixin,\n                   mixins.RetrieveModelMixin,\n                   mixins.UpdateModelMixin,\n                   mixins.DestroyModelMixin,\n                   mixins.ListModelMixin,\n                   GenericViewSet):\n    \"\"\"\n    A viewset that provides default `create()`, `retrieve()`, `update()`,\n    `partial_update()`, `destroy()` and `list()` actions.\n    \"\"\"\n    pass\n```\n\n要使用上面的`SubjectViewSet`，需要在`urls.py`文件中进行URL映射。由于`ModelViewSet`相当于是多个视图函数的汇总，所以不同于之前映射URL的方式，我们需要先创建一个路由器并通过它注册`SubjectViewSet`，然后将注册成功后生成的URL一并添加到`urlspattern`列表中，代码如下所示。\n\n```Python\nfrom rest_framework.routers import DefaultRouter\n\nrouter = DefaultRouter()\nrouter.register('api/subjects', SubjectViewSet)\nurlpatterns += router.urls\n```\n\n除了`ModelViewSet`类外，DRF还提供了一个名为`ReadOnlyModelViewSet` 的类，从名字上就可以看出，该类是只读视图的集合，也就意味着，继承该类定制的数据接口只能支持GET请求，也就是获取单个资源和资源列表的请求。\n\n### 数据分页\n\n在使用GET请求获取资源列表时，我们通常不会一次性的加载所有的数据，除非数据量真的很小。大多数获取资源列表的操作都支持数据分页展示，也就说我们可以通过指定页码（或类似于页码的标识）和页面大小（一次加载多少条数据）来获取不同的数据。我们可以通过对`QuerySet`对象的切片操作来实现分页，也可以利用Django框架封装的`Paginator`和`Page`对象来实现分页。使用DRF时，可以在Django配置文件中修改`REST_FRAMEWORK`并配置默认的分页类和页面大小来实现分页，如下所示。\n\n```Python\nREST_FRAMEWORK = {\n    'PAGE_SIZE': 10,\n    'DEFAULT_PAGINATION_CLASS': 'rest_framework.pagination.PageNumberPagination'\n}\n```\n\n除了上面配置的`PageNumberPagination`分页器之外，DRF还提供了`LimitOffsetPagination`和`CursorPagination`分页器，值得一提的是`CursorPagination`，它可以避免使用页码分页时暴露网站的数据体量，有兴趣的读者可以自行了解。如果不希望使用配置文件中默认的分页设定，可以在视图类中添加一个`pagination_class`属性来重新指定分页器，通常可以将该属性指定为自定义的分页器，如下所示。\n\n```Python\nfrom rest_framework.pagination import PageNumberPagination\n\n\nclass CustomizedPagination(PageNumberPagination):\n    # 默认页面大小\n    page_size = 5\n    # 页面大小对应的查询参数\n    page_size_query_param = 'size'\n    # 页面大小的最大值\n    max_page_size = 50\n```\n\n```Python\nclass SubjectView(ListAPIView):\n    # 指定如何获取数据\n    queryset = Subject.objects.all()\n    # 指定如何序列化数据\n    serializer_class = SubjectSerializer\n    # 指定如何分页\n    pagination_class = CustomizedPagination\n```\n\n如果不希望数据分页，可以将`pagination_class`属性设置为`None`来取消默认的分页器。\n\n### 数据筛选\n\n如果希望使用CBV定制获取老师信息的数据接口，也可以通过继承`ListAPIView`来实现。但是因为要通过指定的学科来获取对应的老师信息，因此需要对老师数据进行筛选而不是直接获取所有老师的数据。如果想从请求中获取学科编号并通过学科编号对老师进行筛选，可以通过重写`get_queryset`方法来做到，代码如下所示。\n\n```Python\nclass TeacherView(ListAPIView):\n    serializer_class = TeacherSerializer\n\n    def get_queryset(self):\n        queryset = Teacher.objects.defer('subject')\n        try:\n            sno = self.request.GET.get('sno', '')\n            queryset = queryset.filter(subject__no=sno)\n            return queryset\n        except ValueError:\n            raise Http404('No teachers found.')\n```\n\n除了上述方式之外，还可以使用三方库`django-filter`来配合DRF实现对数据的筛选，使用`django-filter`后，可以通过为视图类配置`filter-backends`属性并指定使用`DjangoFilterBackend`来支持数据筛选。在完成上述配置后，可以使用`filter_fields` 属性或`filterset_class`属性来指定如何筛选数据，有兴趣的读者可以自行研究。", "使用缓存": "## 使用缓存\n\n通常情况下，Web应用的性能瓶颈都会出现在关系型数据库上，当并发访问量较大时，如果所有的请求都需要通过关系型数据库完成数据持久化操作，那么数据库一定会不堪重负。优化Web应用性能最为重要的一点就是使用缓存，把那些数据体量不大但访问频率非常高的数据提前加载到缓存服务器中，这又是典型的空间换时间的方法。通常缓存服务器都是直接将数据置于内存中而且使用了非常高效的数据存取策略（哈希存储、键值对方式等），在读写性能上远远优于关系型数据库的，因此我们可以让Web应用接入缓存服务器来优化其性能，其中一个非常好的选择就是使用Redis。\n\nWeb应用的缓存架构大致如下图所示。\n\n![](/res/redis-cache-service.png)\n\n### Django项目接入Redis\n\n在此前的课程中，我们介绍过Redis的安装和使用，此处不再进行赘述。如果需要在Django项目中接入Redis，可以使用三方库`django-redis`，这个三方库又依赖了一个名为`redis` 的三方库，它封装了对Redis的各种操作。\n\n安装`django-redis`。\n\n```Bash\npip install django-redis\n```\n\n修改Django配置文件中关于缓存的配置。\n\n```Python\nCACHES = {\n    'default': {\n        # 指定通过django-redis接入Redis服务\n        'BACKEND': 'django_redis.cache.RedisCache',\n        # Redis服务器的URL\n        'LOCATION': ['redis://1.2.3.4:6379/0', ],\n        # Redis中键的前缀（解决命名冲突）\n        'KEY_PREFIX': 'vote',\n        # 其他的配置选项\n        'OPTIONS': {\n            'CLIENT_CLASS': 'django_redis.client.DefaultClient',\n            # 连接池（预置若干备用的Redis连接）参数\n            'CONNECTION_POOL_KWARGS': {\n                # 最大连接数\n                'max_connections': 512,\n            },\n            # 连接Redis的用户口令\n            'PASSWORD': 'foobared',\n        }\n    },\n}\n```\n\n至此，我们的Django项目已经可以接入Redis，接下来我们修改项目代码，用Redis为之写的获取学科数据的接口提供缓存服务。\n\n### 为视图提供缓存服务\n\n#### 声明式缓存\n\n所谓声明式缓存是指不修改原来的代码，通过Python中的装饰器（代理）为原有的代码增加缓存功能。对于FBV，代码如下所示。\n\n```Python\nfrom django.views.decorators.cache import cache_page\n\n\n@api_view(('GET', ))\n@cache_page(timeout=86400, cache='default')\ndef show_subjects(request):\n    \"\"\"获取学科数据\"\"\"\n    queryset = Subject.objects.all()\n    data = SubjectSerializer(queryset, many=True).data\n    return Response({'code': 20000, 'subjects': data})\n```\n\n上面的代码通过Django封装的`cache_page`装饰器缓存了视图函数的返回值（响应对象），`cache_page`的本意是缓存视图函数渲染的页面，对于返回JSON数据的视图函数，相当于是缓存了JSON数据。在使用`cache_page`装饰器时，可以传入`timeout`参数来指定缓存过期时间，还可以使用`cache`参数来指定需要使用哪一组缓存服务来缓存数据。Django项目允许在配置文件中配置多组缓存服务，上面的`cache='default'`指定了使用默认的缓存服务（因为之前的配置文件中我们也只配置了名为`default`的缓存服务）。视图函数的返回值会被序列化成字节串放到Redis中（Redis中的str类型可以接收字节串），缓存数据的序列化和反序列化也不需要我们自己处理，因为`cache_page`装饰器会调用`django-redis`库中的`RedisCache`来对接Redis，该类使用了`DefaultClient`来连接Redis并使用了[pickle序列化](https://python3-cookbook.readthedocs.io/zh_CN/latest/c05/p21_serializing_python_objects.html)，`django_redis.serializers.pickle.PickleSerializer`是默认的序列化类。\n\n如果缓存中没有学科的数据，那么通过接口访问学科数据时，我们的视图函数会通过执行`Subject.objects.all()`向数据库发出SQL语句来获得数据，视图函数的返回值会被缓存，因此下次请求该视图函数如果缓存没有过期，可以直接从缓存中获取视图函数的返回值，无需再次查询数据库。如果想了解缓存的使用情况，可以配置数据库日志或者使用Django-Debug-Toolbar来查看，第一次访问学科数据接口时会看到查询学科数据的SQL语句，再次获取学科数据时，不会再向数据库发出SQL语句，因为可以直接从缓存中获取数据。\n\n对于CBV，可以利用Django中名为`method_decorator`的装饰器将`cache_page`这个装饰函数的装饰器放到类中的方法上，效果跟上面的代码是一样的。需要提醒大家注意的是，`cache_page`装饰器不能直接放在类上，因为它是装饰函数的装饰器，所以Django框架才提供了`method_decorator`来解决这个问题，很显然，`method_decorator`是一个装饰类的装饰器。\n\n```Python\nfrom django.utils.decorators import method_decorator\nfrom django.views.decorators.cache import cache_page\n\n\n@method_decorator(decorator=cache_page(timeout=86400, cache='default'), name='get')\nclass SubjectView(ListAPIView):\n    \"\"\"获取学科数据的视图类\"\"\"\n    queryset = Subject.objects.all()\n    serializer_class = SubjectSerializer\n```\n\n#### 编程式缓存\n\n所谓编程式缓存是指通过自己编写的代码来使用缓存服务，这种方式虽然代码量会稍微大一些，但是相较于声明式缓存，它对缓存的操作和使用更加灵活，在实际开发中使用得更多。下面的代码去掉了之前使用的`cache_page`装饰器，通过`django-redis`提供的`get_redis_connection`函数直接获取Redis连接来操作Redis。\n\n```Python\ndef show_subjects(request):\n    \"\"\"获取学科数据\"\"\"\n    redis_cli = get_redis_connection()\n    # 先尝试从缓存中获取学科数据\n    data = redis_cli.get('vote:polls:subjects')\n    if data:\n        # 如果获取到学科数据就进行反序列化操作\n        data = json.loads(data)\n    else:\n        # 如果缓存中没有获取到学科数据就查询数据库\n        queryset = Subject.objects.all()\n        data = SubjectSerializer(queryset, many=True).data\n        # 将查到的学科数据序列化后放到缓存中\n        redis_cli.set('vote:polls:subjects', json.dumps(data), ex=86400)\n    return Response({'code': 20000, 'subjects': data})\n```\n\n需要说明的是，Django框架提供了`cache`和`caches`两个现成的变量来支持缓存操作，前者访问的是默认的缓存（名为`default`的缓存），后者可以通过索引运算获取指定的缓存服务（例如：`caches['default']`）。向`cache`对象发送`get`和`set`消息就可以实现对缓存的读和写操作，但是这种方式能做的操作有限，不如上面代码中使用的方式灵活。还有一个值得注意的地方，由于可以通过`get_redis_connection`函数获得的Redis连接对象向Redis发起各种操作，包括`FLUSHDB`、`SHUTDOWN`等危险的操作，所以在实际商业项目开发中，一般都会对`django-redis`再做一次封装，例如封装一个工具类，其中只提供了项目需要用到的缓存操作的方法，从而避免了直接使用`get_redis_connection`的潜在风险。当然，自己封装对缓存的操作还可以使用“Read Through”和“Write Through”的方式实现对缓存的更新，这个在下面会介绍到。\n\n### 缓存相关问题\n\n#### 缓存数据的更新\n\n在使用缓存时，一个必须搞清楚的问题就是，当数据改变时，如何更新缓存中的数据。通常更新缓存有如下几种套路，分别是：\n\n1. Cache Aside Pattern\n2. Read/Write Through Pattern\n3. Write Behind Caching Pattern\n\n第1种方式的具体做法就是，当数据更新时，先更新数据库，再删除缓存。注意，不能够使用先更新数据库再更新缓存的方式，也不能够使用先删除缓存再更新数据库的方式，大家可以自己想一想为什么（考虑一下有并发的读操作和写操作的场景）。当然，先更新数据库再删除缓存的做法在理论上也存在风险，但是发生问题的概率是极低的，所以不少的项目都使用了这种方式。\n\n第1种方式相当于编写业务代码的开发者要自己负责对两套存储系统（缓存和关系型数据库）的操作，代码写起来非常的繁琐。第2种方式的主旨是将后端的存储系统变成一套代码，对缓存的维护封装在这套代码中。其中，Read Through指在查询操作中更新缓存，也就是说，当缓存失效的时候，由缓存服务自己负责对数据的加载，从而对应用方是透明的；而Write Through是指在更新数据时，如果没有命中缓存，直接更新数据库，然后返回。如果命中了缓存，则更新缓存，然后再由缓存服务自己更新数据库（同步更新）。刚才我们说过，如果自己对项目中的Redis操作再做一次封装，就可以实现“Read Through”和“Write Through”模式，这样做虽然会增加工作量，但无疑是一件“一劳永逸”且“功在千秋”的事情。\n\n第3种方式是在更新数据的时候，只更新缓存，不更新数据库，而缓存服务这边会**异步的批量更新**数据库。这种做法会大幅度提升性能，但代价是牺牲数据的**强一致性**。第3种方式的实现逻辑比较复杂，因为他需要追踪有哪数据是被更新了的，然后再批量的刷新到持久层上。\n\n#### 缓存穿透\n\n缓存是为了缓解数据库压力而添加的一个中间层，如果恶意的访问者频繁的访问缓存中没有的数据，那么缓存就失去了存在的意义，瞬间所有请求的压力都落在了数据库上，这样会导致数据库承载着巨大的压力甚至连接异常，类似于分布式拒绝服务攻击（DDoS）的做法。解决缓存穿透的一个办法是约定如果查询返回为空值，把这个空值也缓存起来，但是需要为这个空值的缓存设置一个较短的超时时间，毕竟缓存这样的值就是对缓存空间的浪费。另一个解决缓存穿透的办法是使用布隆过滤器，具体的做法大家可以自行了解。\n\n#### 缓存击穿\n\n在实际的项目中，可能存在某个缓存的key某个时间点过期，但恰好在这个时间点对有对该key的大量的并发请求过来，这些请求没有从缓存中找到key对应的数据，就会直接从数据库中获取数据并写回到缓存，这个时候大并发的请求可能会瞬间把数据库压垮，这种现象称为缓存击穿。比较常见的解决缓存击穿的办法是使用互斥锁，简单的说就是在缓存失效的时候，不是立即去数据库加载数据，而是先设置互斥锁（例如：Redis中的setnx），只有设置互斥锁的操作成功的请求，才能执行查询从数据库中加载数据并写入缓存，其他设置互斥锁失败的请求，可以先执行一个短暂的休眠，然后尝试重新从缓存中获取数据，如果缓存还没有数据，则重复刚才的设置互斥锁的操作，大致的参考代码如下所示。\n\n```Python\ndata = redis_cli.get(key)\nwhile not data:\n    if redis_cli.setnx('mutex', 'x'):\n        redis.expire('mutex', timeout)\n        data = db.query(...)\n        redis.set(key, data)\n        redis.delete('mutex')\n    else:\n        time.sleep(0.1)\n        data = redis_cli.get(key)\n```\n\n#### 缓存雪崩\n\n缓存雪崩是指在将数据放入缓存时采用了相同的过期时间，这样就导致缓存在某一时刻同时失效，请求全部转发到数据库，导致数据库瞬时压力过大而崩溃。解决缓存雪崩问题的方法也比较简单，可以在既定的缓存过期时间上加一个随机时间，这样可以从一定程度上避免不同的key在同一时间集体失效。还有一种办法就是使用多级缓存，每一级缓存的过期时间都不一样，这样的话即便某个级别的缓存集体失效，但是其他级别的缓存还能够提供数据，避免所有的请求都落到数据库上。", "接入三方平台": "## 接入三方平台\n\n在Web应用的开发过程中，有一些任务并不是我们自己能够完成的。例如，我们的Web项目中需要做个人或企业的实名认证，很显然我们并没有能力判断用户提供的认证信息的真实性，这个时候我们就要借助三方平台提供的服务来完成该项操作。再比如说，我们的项目中需要提供在线支付功能，这类业务通常也是借助支付网关来完成而不是自己去实现，我们只需要接入像微信、支付宝、银联这样的三方平台即可。\n\n在项目中接入三方平台基本上就两种方式：API接入和SDK接入。\n\n1. API接入指的是通过访问三方提供的URL来完成操作或获取数据。国内有很多这样的平台提供了大量常用的服务，例如[聚合数据](https://www.juhe.cn/)上提供了生活服务类、金融科技类、交通地理类、充值缴费类等各种类型的API。我们可以通过Python程序发起网络请求，通过访问URL获取数据，这些API接口跟我们项目中提供的数据接口是一样的，只不过我们项目中的API是供自己使用的，而这类三方平台提供的API是开放的。当然开放并不代表免费，大多数能够提供有商业价值的数据的API都是需要付费才能使用的。\n2. SDK接入指的是通过安装三方库并使用三方库封装的类、函数来使用三方平台提供的服务的方式。例如我们刚才说到的接入支付宝，就需要先安装支付宝的SDK，然后通过支付宝封装的类和方法完成对支付服务的调用。\n\n下面我们通过具体的例子来讲解如何接入三方平台。\n\n### 接入短信网关\n\n一个Web项目有很多地方都可以用到短信服务，例如：手机验证码登录、重要消息提醒、产品营销短信等。要实现发送短信的功能，可以通过接入短信网关来实现，国内比较有名的短信网关包括：云片短信、网易云信、螺丝帽、SendCloud等，这些短信网关一般都提供了免费试用功能。下面我们以[螺丝帽](https://luosimao.com/)平台为例，讲解如何在项目中接入短信网关，其他平台操作基本类似。\n\n1. 注册账号，新用户可以免费试用。\n\n2. 登录到管理后台，进入短信版块。\n\n3. 点击“触发发送”可以找到自己专属的API Key（身份标识）。\n\n    ![](/res/luosimao-sms-apikey.png)\n\n4. 点击“签名管理”可以添加短信签名，短信都必须携带签名，免费试用的短信要在短信中添加“【铁壳测试】”这个签名，否则短信无法发送。\n\n    ![](/res/luosimao-sms-signature.png)\n\n5. 点击“IP白名单”将运行Django项目的服务器地址（公网IP地址，本地运行可以打开[xxx]()网站查看自己本机的公网IP地址）填写到白名单中，否则短信无法发送。\n\n    ![](/res/luosimao-sms-whitelist.png)\n\n6. 如果没有剩余的短信条数，可以到“充值”页面选择“短信服务”进行充值。\n\n    ![](/res/luosimao-pay-onlinebuy.png)\n\n接下来，我们可以通过调用螺丝帽短信网关实现发送短信验证码的功能，代码如下所示。\n\n```Python\ndef send_mobile_code(tel, code):\n    \"\"\"发送短信验证码\"\"\"\n    resp = requests.post(\n        url='http://sms-api.luosimao.com/v1/send.json',\n        auth=('api', 'key-自己的APIKey'),\n        data={\n            'mobile': tel,\n            'message': f'您的短信验证码是{code}，打死也不能告诉别人哟。【Python小课】'\n        },\n        verify=False\n    )\n    return resp.json()\n```\n\n运行上面的代码需要先安装`requests`三方库，这个三方库封装了HTTP网络请求的相关功能，使用起来非常的简单，我们在之前的内容中也讲到过这个三方库。`send_mobile_code`函数有两个参数，第一个参数是手机号，第二个参数是短信验证码的内容，第5行代码需要提供自己的API Key，就是上面第2步中查看到的自己的API Key。请求螺丝帽的短信网关会返回JSON格式的数据，对于上面的代码如果返回`{'err': 0, 'msg': 'ok'}`，则表示短信发送成功，如果`err`字段的值不为`0`而是其他值，则表示短信发送失败，可以在螺丝帽官方的[开发文档](https://luosimao.com/docs/api/)页面上查看到不同的数值代表的含义，例如：`-20`表示余额不足，`-32`表示缺少短信签名。\n\n可以在视图函数中调用上面的函数来完成发送短信验证码的功能，稍后我们可以把这个功能跟用户注册结合起来。\n\n生成随机验证码和验证手机号的函数。\n\n```Python\nimport random\nimport re\n\nTEL_PATTERN = re.compile(r'1[3-9]\\d{9}')\n\n\ndef check_tel(tel):\n    \"\"\"检查手机号\"\"\"\n    return TEL_PATTERN.fullmatch(tel) is not None\n\n\ndef random_code(length=6):\n    \"\"\"生成随机短信验证码\"\"\"\n    return ''.join(random.choices('0123456789', k=length))\n```\n\n发送短信验证码的视图函数。\n\n```Python\n@api_view(('GET', ))\ndef get_mobilecode(request, tel):\n    \"\"\"获取短信验证码\"\"\"\n    if check_tel(tel):\n        redis_cli = get_redis_connection()\n        if redis_cli.exists(f'vote:block-mobile:{tel}'):\n            data = {'code': 30001, 'message': '请不要在60秒内重复发送短信验证码'}\n        else:\n            code = random_code()\n            send_mobile_code(tel, code)\n            # 通过Redis阻止60秒内容重复发送短信验证码\n            redis_cli.set(f'vote:block-mobile:{tel}', 'x', ex=60)\n            # 将验证码在Redis中保留10分钟（有效期10分钟）\n            redis_cli.set(f'vote2:valid-mobile:{tel}', code, ex=600)\n            data = {'code': 30000, 'message': '短信验证码已发送，请注意查收'}\n    else:\n        data = {'code': 30002, 'message': '请输入有效的手机号'}\n    return Response(data)\n```\n\n> **说明**：上面的代码利用Redis实现了两个额外的功能，一个是阻止用户60秒内重复发送短信验证码，一个是将用户的短信验证码保留10分钟，也就是说这个短信验证码的有效期只有10分钟，我们可以要求用户在注册时提供该验证码来验证用户手机号的真实性。\n\n### 接入云存储服务\n\n当我们提到**云存储**这个词的时候，通常是指把数据存放在由第三方提供的虚拟服务器环境下，简单的说就是将某些数据或资源通过第三平台托管。一般情况下，提供云存储服务的公司都运营着大型的数据中心，需要云存储服务的个人或组织通过向其购买或租赁存储空间来满足数据存储的需求。在开发Web应用时，可以将静态资源，尤其是用户上传的静态资源直接置于云存储服务中，云存储通常会提供对应的URL使得用户可以访问该静态资源。国内外比较有名的云存储服务（如：亚马逊的S3、阿里的OSS2等）一般都物美价廉，相比自己架设静态资源服务器，云存储的代价更小，而且一般的云存储平台都提供了CDN服务，用于加速对静态资源的访问，所以不管从哪个角度出发，使用云存储的方式管理Web应用的数据和静态资源都是非常好的选择，除非这些资源涉及到个人或商业隐私，否则就可以托管到云存储中。\n\n下面我们以接入[七牛云](https://www.qiniu.com/)为例，讲解如何实现将用户上传的文件保存到七牛云存储。七牛云是国内知名的云计算及数据服务提供商，七牛云在海量文件存储、CDN、视频点播、互动直播以及大规模异构数据的智能分析与处理等领域都有自己的产品，而且非付费用户也可以免费接入，使用其提供的服务。下面是接入七牛云的流程：\n\n1. 注册账号，登录管理控制台。\n\n    ![](/res/qiniu-manage-console.png)\n\n2. 选择左侧菜单中的对象存储。\n\n    ![](/res/qiniu-storage-service.png)\n\n3. 在空间管理中选择新建空间（例如：myvote），如果提示空间名称已被占用，更换一个再尝试即可。注意，创建空间后会提示绑定自定义域名，如果暂时还没有自己的域名，可以使用七牛云提供的临时域名，但是临时域名会在30天后被回收，所以最好准备自己的域名（域名需要备案，不清楚如何操作的请自行查阅相关资料）。\n\n    ![](/res/qiniu-storage-create.png)\n\n4. 在网页的右上角点击个人头像中的“密钥管理”，查看自己的密钥，稍后在代码中需要使用AK（AccessKey）和SK（SecretKey）两个密钥来认证用户身份。\n\n    ![](/res/qiniu-secretkey-management.png)\n\n5. 点击网页上方菜单中的“文档”，进入到[七牛开发者中心](https://developer.qiniu.com/)，选择导航菜单中的“SDK&工具”并点击“官方SDK”子菜单，找到Python（服务端）并点击“文档”查看官方文档。\n\n    ![](/res/qiniu-document-python.png)\n\n接下来，只要安装官方文档提供的示例，就可以接入七牛云，使用七牛云提供的云存储以及其他服务。首先可以通过下面的命令安装七牛云的三方库。\n\n```Bash\npip install qiniu\n```\n\n接下来可以通过`qiniu`模块中的`put_file`和`put_stream`两个函数实现文件上传，前者可以上传指定路径的文件，后者可以将内存中的二进制数据上传至七牛云，具体的代码如下所示。\n\n```Python\nimport qiniu\n\nAUTH = qiniu.Auth('密钥管理中的AccessKey', '密钥管理中的SecretKey')\nBUCKET_NAME = 'myvote'\n\n\ndef upload_file_to_qiniu(key, file_path):\n    \"\"\"上传指定路径的文件到七牛云\"\"\"\n    token = AUTH.upload_token(BUCKET_NAME, key)\n    return qiniu.put_file(token, key, file_path)\n\n\ndef upload_stream_to_qiniu(key, stream, size):\n    \"\"\"上传二进制数据流到七牛云\"\"\"\n    token = AUTH.upload_token(BUCKET_NAME, key)\n    return qiniu.put_stream(token, key, stream, None, size)\n```\n\n下面是一个文件上传的简单前端页。\n\n```HTML\n<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n    <meta charset=\"UTF-8\">\n    <title>上传文件</title>\n</head>\n<body>\n    <form action=\"/upload/\" method=\"post\" enctype=\"multipart/form-data\">\n        <div>\n            <input type=\"file\" name=\"photo\">\n            <input type=\"submit\" value=\"上传\">\n        </div>\n    </form>\n</body>\n</html>\n```\n\n> **说明**：前端如果使用表单实现文件上传，表单的method属性必须设置为post，enctype属性需要设置为multipart/form-data，表单中type属性为file的input标签，就是上传文件的文件选择器。\n\n实现上传功能的视图函数如下所示。\n\n```Python\nfrom django.views.decorators.csrf import csrf_exempt\n\n\n@csrf_exempt\ndef upload(request):\n    # 如果上传的文件小于2.5M，则photo对象的类型为InMemoryUploadedFile，文件在内存中\n    # 如果上传的文件超过2.5M，则photo对象的类型为TemporaryUploadedFile，文件在临时路径下\n    photo = request.FILES.get('photo')\n    _, ext = os.path.splitext(photo.name)\n    # 通过UUID和原来文件的扩展名生成独一无二的新的文件名\n    filename = f'{uuid.uuid1().hex}{ext}'\n    # 对于内存中的文件，可以使用上面封装好的函数upload_stream_to_qiniu上传文件到七牛云\n    # 如果文件保存在临时路径下，可以使用upload_file_to_qiniu实现文件上传\n    upload_stream_to_qiniu(filename, photo.file, photo.size)\n    return redirect('/static/html/upload.html')\n```\n\n> **注意**：上面的视图函数使用了`csrf_exempt`装饰器，该装饰器能够让表单免除必须提供CSRF令牌的要求。此外，代码第11行使用了`uuid`模块的`uuid1`函数来生成全局唯一标识符。\n\n运行项目尝试文件上传的功能，文件上传成功后，可以在七牛云“空间管理”中点击自己空间并进入“文件管理”界面，在这里可以看到我们刚才上传成功的文件，而且可以通过七牛云提供的域名获取该文件。\n\n![](/res/qiniu-file-management.png)\n\n", "异步任务和定时任务": "## 异步任务和定时任务\n\n在Web应用中，如果一个请求执行了耗时间的操作或者该请求的执行时间无法确定，而且对于用户来说只需要知道服务器接收了他的请求，并不需要马上得到请求的执行结果，这样的操作我们就应该对其进行异步化处理。如果说**使用缓存是优化网站性能的第一要义**，那么将耗时间或执行时间不确定的任务**异步化则是网站性能优化的第二要义**，简单的说就是**能推迟做的事情都不要马上做**。\n\n上一章节中讲到的发短信和上传文件到云存储为例，这两个操作前者属于时间不确定的操作（因为作为调用者，我们不能确定三方平台响应的时间），后者属于耗时间的操作（如果文件较大或者三方平台不稳定，都可能导致上传的时间较长），很显然，这两个操作都可以做异步化处理。\n\n在 Python 项目中，我们可以使用三方库Celery来完成异步任务和定时任务，关于Celery的内容，请移步到[《使用Django开发商业项目》](../Day91-100/95.使用Django开发商业项目.md)一文。\n\n", "单元测试": "## 单元测试\n\n请各位读者移步到[《使用Django开发商业项目》](../Day91-100/95.使用Django开发商业项目.md)一文。\n\n", "项目上线": "## 项目上线\n\n请各位读者移步到[《项目部署上线和性能调优》](../Day91-100/98.项目部署上线和性能调优.md)一文。\n\n", "网络数据采集概述": "## 网络数据采集概述\n\n爬虫（crawler）也经常被称为网络蜘蛛（spider），是按照一定的规则自动浏览网站并获取所需信息的机器人程序（自动化脚本代码），被广泛的应用于互联网搜索引擎和数据采集。使用过互联网和浏览器的人都知道，网页中除了供用户阅读的文字信息之外，还包含一些超链接，网络爬虫正是通过网页中的超链接信息，不断获得网络上其它页面的地址，然后持续的进行数据采集。正因如此，网络数据采集的过程就像一个爬虫或者蜘蛛在网络上漫游，所以才被形象的称为爬虫或者网络蜘蛛。\n\n### 爬虫的应用领域\n\n在理想的状态下，所有 ICP（Internet Content Provider）都应该为自己的网站提供 API 接口来共享它们允许其他程序获取的数据，在这种情况下就根本不需要爬虫程序。国内比较有名的电商平台（如淘宝、京东等）、社交平台（如微博、微信等）等都提供了自己的 API 接口，但是这类 API 接口通常会对可以抓取的数据以及抓取数据的频率进行限制。对于大多数的公司而言，及时的获取行业数据和竞对数据是企业生存的重要环节之一，然而对大部分企业来说，数据都是其与生俱来的短板。在这种情况下，合理的利用爬虫来获取数据并从中提取出有商业价值的信息对这些企业来说就显得至关重要的。\n\n爬虫的应用领域其实非常广泛，下面我们列举了其中的一部分，有兴趣的读者可以自行探索相关内容。\n\n1. 搜索引擎\n2. 新闻聚合\n3. 社交应用\n4. 舆情监控\n5. 行业数据\n\n### 爬虫合法性探讨\n\n经常听人说起“爬虫写得好，牢饭吃到饱”，那么编程爬虫程序是否违法呢？关于这个问题，我们可以从以下几个角度进行解读。\n\n1. 网络爬虫这个领域目前还属于拓荒阶段，虽然互联网世界已经通过自己的游戏规则建立起了一定的道德规范，即 Robots 协议（全称是“网络爬虫排除标准”），但法律部分还在建立和完善中，也就是说，现在这个领域暂时还是灰色地带。\n2. “法不禁止即为许可”，如果爬虫就像浏览器一样获取的是前端显示的数据（网页上的公开信息）而不是网站后台的私密敏感信息，就不太担心法律法规的约束，因为目前大数据产业链的发展速度远远超过了法律的完善程度。\n3. 在爬取网站的时候，需要限制自己的爬虫遵守 Robots 协议，同时控制网络爬虫程序的抓取数据的速度；在使用数据的时候，必须要尊重网站的知识产权（从Web 2.0时代开始，虽然Web上的数据很多都是由用户提供的，但是网站平台是投入了运营成本的，当用户在注册和发布内容时，平台通常就已经获得了对数据的所有权、使用权和分发权）。如果违反了这些规定，在打官司的时候败诉几率相当高。\n4. 适当的隐匿自己的身份在编写爬虫程序时必要的，而且最好不要被对方举证你的爬虫有破坏别人动产（例如服务器）的行为。\n5. 不要在公网（如代码托管平台）上去开源或者展示你的爬虫代码，这些行为通常会给自己带来不必要的麻烦。\n\n#### Robots协议\n\n大多数网站都会定义`robots.txt`文件，这是一个君子协议，并不是所有爬虫都必须遵守的游戏规则。下面以淘宝的[`robots.txt`](http://www.taobao.com/robots.txt)文件为例，看看淘宝网对爬虫有哪些限制。\n\n```\nUser-agent: Baiduspider\nDisallow: /\n\nUser-agent: baiduspider\nDisallow: /\n```\n\n通过上面的文件可以看出，淘宝禁止百度爬虫爬取它任何资源，因此当你在百度搜索“淘宝”的时候，搜索结果下方会出现：“由于该网站的`robots.txt`文件存在限制指令（限制搜索引擎抓取），系统无法提供该页面的内容描述”。百度作为一个搜索引擎，至少在表面上遵守了淘宝网的`robots.txt`协议，所以用户不能从百度上搜索到淘宝内部的产品信息。\n\n图1. 百度搜索淘宝的结果\n\n<img class=\"lazy\" data-src=\"/res/20210824004320.png\" style=\"zoom:50%;\">\n\n下面是豆瓣网的[`robots.txt`](https://www.douban.com/robots.txt)文件，大家可以自行解读，看看它做出了什么样的限制。\n\n```\nUser-agent: *\nDisallow: /subject_search\nDisallow: /amazon_search\nDisallow: /search\nDisallow: /group/search\nDisallow: /event/search\nDisallow: /celebrities/search\nDisallow: /location/drama/search\nDisallow: /forum/\nDisallow: /new_subject\nDisallow: /service/iframe\nDisallow: /j/\nDisallow: /link2/\nDisallow: /recommend/\nDisallow: /doubanapp/card\nDisallow: /update/topic/\nDisallow: /share/\nAllow: /ads.txt\nSitemap: https://www.douban.com/sitemap_index.xml\nSitemap: https://www.douban.com/sitemap_updated_index.xml\n# Crawl-delay: 5\n\nUser-agent: Wandoujia Spider\nDisallow: /\n\nUser-agent: Mediapartners-Google\nDisallow: /subject_search\nDisallow: /amazon_search\nDisallow: /search\nDisallow: /group/search\nDisallow: /event/search\nDisallow: /celebrities/search\nDisallow: /location/drama/search\nDisallow: /j/\n```\n\n### 超文本传输协议（HTTP）\n\n在开始讲解爬虫之前，我们稍微对超文本传输协议（HTTP）做一些回顾，因为我们在网页上看到的内容通常是浏览器执行 HTML （超文本标记语言）得到的结果，而 HTTP 就是传输 HTML 数据的协议。HTTP 和其他很多应用级协议一样是构建在 TCP（传输控制协议）之上的，它利用了 TCP 提供的可靠的传输服务实现了 Web 应用中的数据交换。按照维基百科上的介绍，设计 HTTP 最初的目的是为了提供一种发布和接收 [HTML](https://zh.wikipedia.org/wiki/HTML) 页面的方法，也就是说，这个协议是浏览器和 Web 服务器之间传输的数据的载体。关于 HTTP 的详细信息以及目前的发展状况，大家可以阅读[《HTTP 协议入门》](http://www.ruanyifeng.com/blog/2016/08/http.html)、[《互联网协议入门》](http://www.ruanyifeng.com/blog/2012/05/internet_protocol_suite_part_i.html)、[《图解 HTTPS 协议》](http://www.ruanyifeng.com/blog/2014/09/illustration-ssl.html)等文章进行了解。\n\n下图是我在四川省网络通信技术重点实验室工作期间用开源协议分析工具 Ethereal（WireShark 的前身）截取的访问百度首页时的 HTTP 请求和响应的报文（协议数据），由于 Ethereal 截取的是经过网络适配器的数据，因此可以清晰的看到从物理链路层到应用层的协议数据。\n\n图2. HTTP请求\n\n<img class=\"lazy\" data-src=\"/res/20210824003915.png\" style=\"zoom:85%;\">\n\nHTTP 请求通常是由请求行、请求头、空行、消息体四个部分构成，如果没有数据发给服务器，消息体就不是必须的部分。请求行中包含了请求方法（GET、POST 等，如下表所示）、资源路径和协议版本；请求头由若干键值对构成，包含了浏览器、编码方式、首选语言、缓存策略等信息；请求头的后面是空行和消息体。\n\n<img class=\"lazy\" data-src=\"/res/20210825002720.png\" width=\"65%\">\n\n图3. HTTP响应\n\n<img class=\"lazy\" data-src=\"/res/20210824234158.png\" style=\"zoom:85%;\">\n\nHTTP 响应通常是由响应行、响应头、空行、消息体四个部分构成，其中消息体是服务响应的数据，可能是 HTML 页面，也有可能是JSON或二进制数据等。响应行中包含了协议版本和响应状态码，响应状态码有很多种，常见的如下表所示。\n\n<img class=\"lazy\" data-src=\"/res/20210825002802.png\" width=\"65%\">\n\n#### 相关工具\n\n下面我们先介绍一些开发爬虫程序的辅助工具，这些工具相信能帮助你事半功倍。\n\n1. Chrome Developer Tools：谷歌浏览器内置的开发者工具。该工具最常用的几个功能模块是：\n\n   - 元素（ELements）：用于查看或修改 HTML 元素的属性、CSS 属性、监听事件等。CSS 可以即时修改，即时显示，大大方便了开发者调试页面。\n   - 控制台（Console）：用于执行一次性代码，查看 JavaScript 对象，查看调试日志信息或异常信息。控制台其实就是一个执行 JavaScript 代码的交互式环境。\n   - 源代码（Sources）：用于查看页面的 HTML 文件源代码、JavaScript 源代码、CSS 源代码，此外最重要的是可以调试 JavaScript 源代码，可以给代码添加断点和单步执行。\n   - 网络（Network）：用于 HTTP 请求、HTTP 响应以及与网络连接相关的信息。\n   - 应用（Application）：用于查看浏览器本地存储、后台任务等内容，本地存储主要包括Cookie、Local Storage、Session Storage等。\n\n   <img class=\"lazy\" data-src=\"/res/20210824004034.png\" style=\"zoom:40%;\">\n\n2. Postman：功能强大的网页调试与 RESTful 请求工具。Postman可以帮助我们模拟请求，非常方便的定制我们的请求以及查看服务器的响应。\n\n   <img class=\"lazy\" data-src=\"/res/20210824004048.png\" style=\"zoom:40%;\">\n\n3. HTTPie：命令行HTTP客户端。\n\n   安装。\n\n   ```Bash\n   pip install httpie\n   ```\n\n   使用。\n\n   ```Bash\n   http --header http --header https://movie.douban.com/\n   \n   HTTP/1.1 200 OK\n   Connection: keep-alive\n   Content-Encoding: gzip\n   Content-Type: text/html; charset=utf-8\n   Date: Tue, 24 Aug 2021 16:48:00 GMT\n   Keep-Alive: timeout=30\n   Server: dae\n   Set-Cookie: bid=58h4BdKC9lM; Expires=Wed, 24-Aug-22 16:48:00 GMT; Domain=.douban.com; Path=/\n   Strict-Transport-Security: max-age=15552000\n   Transfer-Encoding: chunked\n   X-Content-Type-Options: nosniff\n   X-DOUBAN-NEWBID: 58h4BdKC9lM\n   ```\n\n4. `builtwith`库：识别网站所用技术的工具。\n\n   安装。\n\n   ```Bash\n   pip install builtwith\n   ```\n\n   使用。\n\n   ```Python\n   import ssl\n   \n   import builtwith\n   \n   ssl._create_default_https_context = ssl._create_unverified_context\n   print(builtwith.parse('http://www.bootcss.com/'))\n   ```\n\n5. `python-whois`库：查询网站所有者的工具。\n\n   安装。\n\n   ```Bash\n   pip3 install python-whois\n   ```\n\n   使用。\n\n   ```Python\n   import whois\n   \n   print(whois.whois('https://www.bootcss.com'))\n   ```\n\n### 爬虫的基本工作流程\n\n一个基本的爬虫通常分为数据采集（网页下载）、数据处理（网页解析）和数据存储（将有用的信息持久化）三个部分的内容，当然更为高级的爬虫在数据采集和处理时会使用并发编程或分布式技术，这就需要有调度器（安排线程或进程执行对应的任务）、后台管理程序（监控爬虫的工作状态以及检查数据抓取的结果）等的参与。\n\n<img class=\"lazy\" data-src=\"/res/20210824004107.png\" style=\"zoom:62%;\">\n\n一般来说，爬虫的工作流程包括以下几个步骤：\n\n1. 设定抓取目标（种子页面/起始页面）并获取网页。\n2. 当服务器无法访问时，按照指定的重试次数尝试重新下载页面。\n3. 在需要的时候设置用户代理或隐藏真实IP，否则可能无法访问页面。\n4. 对获取的页面进行必要的解码操作然后抓取出需要的信息。\n5. 在获取的页面中通过某种方式（如正则表达式）抽取出页面中的链接信息。\n6. 对链接进行进一步的处理（获取页面并重复上面的动作）。\n7. 将有用的信息进行持久化以备后续的处理。\n", "用获取网络资源-1": "## 用Python获取网络数据\n\n网络数据采集是 Python 语言非常擅长的领域，上节课我们讲到，实现网络数据采集的程序通常称之为网络爬虫或蜘蛛程序。即便是在大数据时代，数据对于中小企业来说仍然是硬伤和短板，有些数据需要通过开放或付费的数据接口来获得，其他的行业数据和竞对数据则必须要通过网络数据采集的方式来获得。不管使用哪种方式获取网络数据资源，Python 语言都是非常好的选择，因为 Python 的标准库和三方库都对网络数据采集提供了良好的支持。\n\n### requests库\n\n要使用 Python 获取网络数据，我们推荐大家使用名为`requests` 的三方库，这个库我们在之前的课程中其实已经使用过了。按照官方网站的解释，`requests`是基于 Python 标准库进行了封装，简化了通过 HTTP 或 HTTPS 访问网络资源的操作。上课我们提到过，HTTP 是一个请求响应式的协议，当我们在浏览器中输入正确的 [URL](https://developer.mozilla.org/zh-CN/docs/Learn/Common_questions/What_is_a_URL)（通常也称为网址）并按下 Enter 键时，我们就向网络上的 [Web 服务器](https://developer.mozilla.org/zh-CN/docs/Learn/Common_questions/What_is_a_web_server)发送了一个 HTTP 请求，服务器在收到请求后会给我们一个 HTTP 响应。在 Chrome 浏览器中的菜单中打开“开发者工具”切换到“Network”选项卡就能够查看 HTTP 请求和响应到底是什么样子的，如下图所示。\n\n<img class=\"lazy\" data-src=\"/res/20210822093434.png\" style=\"zoom:40%;\">\n\n通过`requests`库，我们可以让 Python 程序向浏览器一样向 Web 服务器发起请求，并接收服务器返回的响应，从响应中我们就可以提取出想要的数据。浏览器呈现给我们的网页是用 [HTML](https://developer.mozilla.org/zh-CN/docs/Web/HTML) 编写的，浏览器相当于是 HTML 的解释器环境，我们看到的网页中的内容都包含在 HTML 的标签中。在获取到 HTML 代码后，就可以从标签的属性或标签体中提取内容。下面例子演示了如何获取网页 HTML 代码，我们通过`requests`库的`get`函数，获取了搜狐首页的代码。\n\n```Python\nimport requests\n\nresp = requests.get('https://www.sohu.com/')\nif resp.status_code == 200:\n    print(resp.text)\n```\n\n> **说明**：上面代码中的变量`resp`是一个`Response`对象（`requests`库封装的类型），通过该对象的`status_code`属性可以获取响应状态码，而该对象的`text`属性可以帮我们获取到页面的 HTML 代码。\n\n由于`Response`对象的`text`是一个字符串，所以我们可以利用之前讲过的正则表达式的知识，从页面的 HTML 代码中提取新闻的标题和链接，代码如下所示。\n\n```Python\nimport re\n\nimport requests\n\npattern = re.compile(r'<a.*?href=\"(.*?)\".*?title=\"(.*?)\".*?>')\nresp = requests.get('https://www.sohu.com/')\nif resp.status_code == 200:\n    all_matches = pattern.findall(resp.text)\n    for href, title in all_matches:\n        print(href)\n        print(title)\n```\n\n除了文本内容，我们也可以使用`requests`库通过 URL 获取二进制资源。下面的例子演示了如何获取百度 Logo 并保存到名为`baidu.png`的本地文件中。可以在百度的首页上右键点击百度Logo，并通过“复制图片地址”菜单项获取图片的 URL。\n\n```Python\nimport requests\n\nresp = requests.get('https://www.baidu.com/img/PCtm_d9c8750bed0b3c7d089fa7d55720d6cf.png')\nwith open('baidu.png', 'wb') as file:\n    file.write(resp.content)\n```\n\n> **说明**：`Response`对象的`content`属性可以获得服务器响应的二进制数据。\n\n`requests`库非常好用而且功能上也比较强大和完整，具体的内容我们在使用的过程中为大家一点点剖析。想解锁关于`requests`库更多的知识，可以阅读它的[官方文档](https://docs.python-requests.org/zh_CN/latest/)。\n\n### 编写爬虫代码\n\n接下来，我们以“豆瓣电影”为例，为大家讲解如何编写爬虫代码。按照上面提供的方法，我们先使用`requests`获取到网页的HTML代码，然后将整个代码看成一个长字符串，这样我们就可以使用正则表达式的捕获组从字符串提取我们需要的内容。下面的代码演示了如何从[豆瓣电影](https://movie.douban.com/)获取排前250名的电影的名称。[豆瓣电影Top250](https://movie.douban.com/top250)的页面结构和对应代码如下图所示，可以看出，每页共展示了25部电影，如果要获取到 Top250 数据，我们共需要访问10个页面，对应的地址是<https://movie.douban.com/top250?start=xxx>，这里的`xxx`如果为`0`就是第一页，如果`xxx`的值是`100`，那么我们可以访问到第五页。为了代码简单易读，我们只获取电影的标题和评分。\n\n<img class=\"lazy\" data-src=\"/res/20210822093447.png\" style=\"zoom:40%;\">\n\n```Python\nimport random\nimport re\nimport time\n\nimport requests\n\nfor page in range(1, 11):\n    resp = requests.get(\n        url=f'https://movie.douban.com/top250?start={(page - 1) * 25}',\n        # 如果不设置HTTP请求头中的User-Agent，豆瓣会检测出不是浏览器而阻止我们的请求。\n        # 通过get函数的headers参数设置User-Agent的值，具体的值可以在浏览器的开发者工具查看到。\n        # 用爬虫访问大部分网站时，将爬虫伪装成来自浏览器的请求都是非常重要的一步。\n        headers={'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.159 Safari/537.36'}\n    )\n    # 通过正则表达式获取class属性为title且标签体不以&开头的span标签并用捕获组提取标签内容\n    pattern1 = re.compile(r'<span class=\"title\">([^&]*?)</span>')\n    titles = pattern1.findall(resp.text)\n    # 通过正则表达式获取class属性为rating_num的span标签并用捕获组提取标签内容\n    pattern2 = re.compile(r'<span class=\"rating_num\".*?>(.*?)</span>')\n    ranks = pattern2.findall(resp.text)\n    # 使用zip压缩两个列表，循环遍历所有的电影标题和评分\n    for title, rank in zip(titles, ranks):\n        print(title, rank)\n    # 随机休眠1-5秒，避免爬取页面过于频繁\n    time.sleep(random.random() * 4 + 1)\n```\n\n> **说明**：通过分析豆瓣网的robots协议，我们发现豆瓣网并不拒绝百度爬虫获取它的数据，因此我们也可以将爬虫伪装成百度的爬虫，将`get`函数的`headers`参数修改为：`headers={'User-Agent': 'BaiduSpider'}`。\n\n### 使用 IP 代理\n\n让爬虫程序隐匿自己的身份对编写爬虫程序来说是比较重要的，很多网站对爬虫都比较反感的，因为爬虫会耗费掉它们很多的网络带宽并制造很多无效的流量。要隐匿身份通常需要使用**商业 IP 代理**（如蘑菇代理、芝麻代理、快代理等），让被爬取的网站无法获取爬虫程序来源的真实 IP 地址，也就无法简单的通过 IP 地址对爬虫程序进行封禁。\n\n下面以[蘑菇代理](http://www.moguproxy.com/)为例，为大家讲解商业 IP 代理的使用方法。首先需要在该网站注册一个账号，注册账号后就可以[购买](http://www.moguproxy.com/buy)相应的套餐来获得商业 IP 代理。作为商业用途，建议大家购买不限量套餐，这样可以根据实际需要获取足够多的代理 IP 地址；作为学习用途，可以购买包时套餐或根据自己的需求来决定。蘑菇代理提供了两种接入代理的方式，分别是 API 私密代理和 HTTP 隧道代理，前者是通过请求蘑菇代理的 API 接口获取代理服务器地址，后者是直接使用统一的入口（蘑菇代理提供的域名）进行接入。\n\n<img class=\"lazy\" data-src=\"/res/20210829080647.png\" width=\"75%\">\n\n下面，我们以HTTP隧道代理为例，为大家讲解接入 IP 代理的方式，大家也可以直接参考蘑菇代理官网提供的代码来为爬虫设置代理。\n\n```Python\nimport requests\n\nAPP_KEY = 'Wnp******************************XFx'\nPROXY_HOST = 'secondtransfer.moguproxy.com:9001'\n\nfor page in range(1, 11):\n    resp = requests.get(\n        url=f'https://movie.douban.com/top250?start={(page - 1) * 25}',\n        # 需要在HTTP请求头设置代理的身份认证方式\n        headers={\n            'Proxy-Authorization': f'Basic {APP_KEY}',\n            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.159 Safari/537.36',\n            'Accept-Language': 'zh-CN,zh;q=0.8,en-US;q=0.6,en;q=0.4'\n        },\n        # 设置代理服务器\n        proxies={\n            'http': f'http://{PROXY_HOST}',\n            'https': f'https://{PROXY_HOST}'\n        },\n        verify=False\n    )\n    pattern1 = re.compile(r'<span class=\"title\">([^&]*?)</span>')\n    titles = pattern1.findall(resp.text)\n    pattern2 = re.compile(r'<span class=\"rating_num\".*?>(.*?)</span>')\n    ranks = pattern2.findall(resp.text)\n    for title, rank in zip(titles, ranks):\n        print(title, rank)\n```\n\n> **说明**：上面的代码需要修改`APP_KEY`为自己创建的订单对应的`Appkey`值，这个值可以在用户中心用户订单中查看到。蘑菇代理提供了免费的 API 代理和 HTTP 隧道代理试用，但是试用的代理接通率不能保证，建议大家还是直接购买一个在自己支付能力范围内的代理服务来体验。\n\n###  总结\n\nPython 语言能做的事情真的很多，就网络数据采集这一项而言，Python 几乎是一枝独秀的，大量的企业和个人都在使用 Python 从网络上获取自己需要的数据，这可能也是你将来日常工作的一部分。另外，用编写正则表达式的方式从网页中提取内容虽然可行，但是写出一个能够满足需求的正则表达式本身也不是件容易的事情，这一点对于新手来说尤为明显。在下一节课中，我们将会为大家介绍另外两种从页面中提取数据的方法，虽然从性能上来讲，它们可能不如正则表达式，但是却降低了编码的复杂性，相信大家会喜欢上它们的。\n", "用解析HTML页面-2": "## 用Python解析HTML页面\n\n在前面的课程中，我们讲到了使用`request`三方库获取网络资源，还介绍了一些前端的基础知识。接下来，我们继续探索如何解析 HTML 代码，从页面中提取出有用的信息。之前，我们尝试过用正则表达式的捕获组操作提取页面内容，但是写出一个正确的正则表达式也是一件让人头疼的事情。为了解决这个问题，我们得先深入的了解一下 HTML 页面的结构，并在此基础上研究另外的解析页面的方法。\n\n### HTML 页面的结构\n\n我们在浏览器中打开任意一个网站，然后通过鼠标右键菜单，选择“显示网页源代码”菜单项，就可以看到网页对应的 HTML 代码。\n\n<img class=\"lazy\" data-src=\"/res/20210822094218.png\" style=\"zoom:40%;\">\n\n代码的第`1`行是文档类型声明，第`2`行的`<html>`标签是整个页面根标签的开始标签，最后一行是根标签的结束标签`</html>`。`<html>`标签下面有两个子标签`<head>`和`<body>`，放在`<body>`标签下的内容会显示在浏览器窗口中，这部分内容是网页的主体；放在`<head>`标签下的内容不会显示在浏览器窗口中，但是却包含了页面重要的元信息，通常称之为网页的头部。HTML 页面大致的代码结构如下所示。\n\n```HTML\n<!doctype html>\n<html>\n    <head>\n        <!-- 页面的元信息，如字符编码、标题、关键字、媒体查询等 -->\n    </head>\n    <body>\n        <!-- 页面的主体，显示在浏览器窗口中的内容 -->\n    </body>\n</html>\n```\n\n标签、层叠样式表（CSS）、JavaScript 是构成 HTML 页面的三要素，其中标签用来承载页面要显示的内容，CSS 负责对页面的渲染，而 JavaScript 用来控制页面的交互式行为。要实现 HTML 页面的解析，可以使用 XPath 的语法，它原本是 XML 的一种查询语法，可以根据 HTML 标签的层次结构提取标签中的内容或标签属性；此外，也可以使用 CSS 选择器来定位页面元素，就跟用 CSS 渲染页面元素是同样的道理。\n\n### XPath 解析\n\nXPath 是在 XML（eXtensible Markup Language）文档中查找信息的一种语法，XML 跟 HTML 类似也是一种用标签承载数据的标签语言，不同之处在于 XML 的标签是可扩展的，可以自定义的，而且 XML 对语法有更严格的要求。XPath 使用路径表达式来选取 XML 文档中的节点或者节点集，这里所说的节点包括元素、属性、文本、命名空间、处理指令、注释、根节点等。下面我们通过一个例子来说明如何使用 XPath 对页面进行解析。\n\n```XML\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<bookstore>\n    <book>\n      <title lang=\"eng\">Harry Potter</title>\n      <price>29.99</price>\n    </book>\n    <book>\n      <title lang=\"zh\">Learning XML</title>\n      <price>39.95</price>\n    </book>\n</bookstore>\n```\n\n对于上面的 XML 文件，我们可以用如下所示的 XPath 语法获取文档中的节点。\n\n| 路径表达式      | 结果                                                         |\n| --------------- | ------------------------------------------------------------ |\n| `/bookstore`    | 选取根元素 bookstore。**注意**：假如路径起始于正斜杠( / )，则此路径始终代表到某元素的绝对路径！ |\n| `//book`        | 选取所有 book 子元素，而不管它们在文档中的位置。             |\n| `//@lang`       | 选取名为 lang 的所有属性。                                  |\n| `/bookstore/book[1]`               | 选取属于 bookstore 子元素的第一个 book 元素。                |\n| `/bookstore/book[last()]`          | 选取属于 bookstore 子元素的最后一个 book 元素。              |\n| `/bookstore/book[last()-1]`        | 选取属于 bookstore 子元素的倒数第二个 book 元素。            |\n| `/bookstore/book[position()<3]`    | 选取最前面的两个属于 bookstore 元素的子元素的 book 元素。    |\n| `//title[@lang]`                   | 选取所有拥有名为 lang 的属性的 title 元素。                  |\n| `//title[@lang='eng']`             | 选取所有 title 元素，且这些元素拥有值为 eng 的 lang 属性。   |\n| `/bookstore/book[price>35.00]`     | 选取 bookstore 元素的所有 book 元素，且其中的 price 元素的值须大于 35.00。 |\n| `/bookstore/book[price>35.00]/title` | 选取 bookstore 元素中的 book 元素的所有 title 元素，且其中的 price 元素的值须大于 35.00。 |\n\nXPath还支持通配符用法，如下所示。\n\n| 路径表达式     | 结果                              |\n| -------------- | --------------------------------- |\n| `/bookstore/*` | 选取 bookstore 元素的所有子元素。 |\n| `//*`          | 选取文档中的所有元素。            |\n| `//title[@*]`  | 选取所有带有属性的 title 元素。   |\n\n如果要选取多个节点，可以使用如下所示的方法。\n\n| 路径表达式                         | 结果                                                         |\n| ---------------------------------- | ------------------------------------------------------------ |\n| `//book/title \\| //book/price`     | 选取 book 元素的所有 title 和 price 元素。                   |\n| `//title \\| //price`               | 选取文档中的所有 title 和 price 元素。                       |\n| `/bookstore/book/title \\| //price` | 选取属于 bookstore 元素的 book 元素的所有 title 元素，以及文档中所有的 price 元素。 |\n\n> **说明**：上面的例子来自于“菜鸟教程”网站上的 [XPath 教程](<https://www.runoob.com/xpath/xpath-tutorial.html>)，有兴趣的读者可以自行阅读原文。\n\n当然，如果不理解或不熟悉 XPath 语法，可以在浏览器的开发者工具中按照如下所示的方法查看元素的 XPath 语法，下图是在 Chrome 浏览器的开发者工具中查看豆瓣网电影详情信息中影片标题的 XPath 语法。\n\n<img class=\"lazy\" data-src=\"/res/20210822093707.png\" style=\"zoom:45%;\">\n\n实现 XPath 解析需要三方库`lxml` 的支持，可以使用下面的命令安装`lxml`。\n\n```Bash\npip install lxml\n```\n\n下面我们用 XPath 解析方式改写之前获取豆瓣电影 Top250的代码，如下所示。\n\n```Python\nfrom lxml import etree\nimport requests\n\nfor page in range(1, 11):\n    resp = requests.get(\n        url=f'https://movie.douban.com/top250?start={(page - 1) * 25}',\n        headers={'User-Agent': 'BaiduSpider'}\n    )\n    tree = etree.HTML(resp.text)\n    # 通过XPath语法从页面中提取电影标题\n    title_spans = tree.xpath('//*[@id=\"content\"]/div/div[1]/ol/li/div/div[2]/div[1]/a/span[1]')\n    # 通过XPath语法从页面中提取电影评分\n    rank_spans = tree.xpath('//*[@id=\"content\"]/div/div[1]/ol/li[1]/div/div[2]/div[2]/div/span[2]')\n    for title_span, rank_span in zip(title_spans, rank_spans):\n        print(title_span.text, rank_span.text)\n```\n\n### CSS 选择器解析\n\n对于熟悉 CSS 选择器和 JavaScript 的开发者来说，通过 CSS 选择器获取页面元素可能是更为简单的选择，因为浏览器中运行的 JavaScript 本身就可以`document`对象的`querySelector()`和`querySelectorAll()`方法基于 CSS 选择器获取页面元素。在 Python 中，我们可以利用三方库`beautifulsoup4`或`pyquery`来做同样的事情。Beautiful Soup 可以用来解析 HTML 和 XML 文档，修复含有未闭合标签等错误的文档，通过为待解析的页面在内存中创建一棵树结构，实现对从页面中提取数据操作的封装。可以用下面的命令来安装 Beautiful Soup。\n\n```Python\npip install beautifulsoup4\n```\n\n下面是使用`bs4`改写的获取豆瓣电影Top250电影名称的代码。\n\n```Python\nimport bs4\nimport requests\n\nfor page in range(1, 11):\n    resp = requests.get(\n        url=f'https://movie.douban.com/top250?start={(page - 1) * 25}',\n        headers={'User-Agent': 'BaiduSpider'}\n    )\n    # 创建BeautifulSoup对象\n    soup = bs4.BeautifulSoup(resp.text, 'lxml')\n    # 通过CSS选择器从页面中提取包含电影标题的span标签\n    title_spans = soup.select('div.info > div.hd > a > span:nth-child(1)')\n    # 通过CSS选择器从页面中提取包含电影评分的span标签\n    rank_spans = soup.select('div.info > div.bd > div > span.rating_num')\n    for title_span, rank_span in zip(title_spans, rank_spans):\n        print(title_span.text, rank_span.text)\n```\n\n关于 BeautifulSoup 更多的知识，可以参考它的[官方文档](https://www.crummy.com/software/BeautifulSoup/bs4/doc.zh/)。\n\n###  总结\n\n下面我们对三种解析方式做一个简单比较。\n\n| 解析方式       | 对应的模块       | 速度   | 使用难度 |\n| -------------- | ---------------- | ------ | -------- |\n| 正则表达式解析 | `re`             | 快     | 困难     |\n| XPath 解析     | `lxml`           | 快     | 一般     |\n| CSS 选择器解析 | `bs4`或`pyquery` | 不确定 | 简单     |\n\n", "中的并发编程-1": "## Python中的并发编程-1\n\n现如今，我们使用的计算机早已是多 CPU 或多核的计算机，而我们使用的操作系统基本都支持“多任务”，这使得我们可以同时运行多个程序，也可以将一个程序分解为若干个相对独立的子任务，让多个子任务“并行”或“并发”的执行，从而缩短程序的执行时间，同时也让用户获得更好的体验。因此当下，不管用什么编程语言进行开发，实现“并行”或“并发”编程已经成为了程序员的标配技能。为了讲述如何在 Python 程序中实现“并行”或“并发”，我们需要先了解两个重要的概念：进程和线程。\n\n### 线程和进程\n\n我们通过操作系统运行一个程序会创建出一个或多个进程，进程是具有一定独立功能的程序关于某个数据集合上的一次运行活动。简单的说，进程是操作系统分配存储空间的基本单位，每个进程都有自己的地址空间、数据栈以及其他用于跟踪进程执行的辅助数据；操作系统管理所有进程的执行，为它们合理的分配资源。一个进程可以通过 fork 或 spawn 的方式创建新的进程来执行其他的任务，不过新的进程也有自己独立的内存空间，因此两个进程如果要共享数据，必须通过进程间通信机制来实现，具体的方式包括管道、信号、套接字等。\n\n一个进程还可以拥有多个执行线索，简单的说就是拥有多个可以获得 CPU 调度的执行单元，这就是所谓的线程。由于线程在同一个进程下，它们可以共享相同的上下文，因此相对于进程而言，线程间的信息共享和通信更加容易。当然在单核 CPU 系统中，多个线程不可能同时执行，因为在某个时刻只有一个线程能够获得 CPU，多个线程通过共享 CPU 执行时间的方式来达到并发的效果。\n\n在程序中使用多线程技术通常都会带来不言而喻的好处，最主要的体现在提升程序的性能和改善用户体验，今天我们使用的软件几乎都用到了多线程技术，这一点可以利用系统自带的进程监控工具（如 macOS 中的“活动监视器”、Windows 中的“任务管理器”）来证实，如下图所示。\n\n<img class=\"lazy\" data-src=\"/res/20210822094243.png\" width=\"80%\">\n\n这里，我们还需要跟大家再次强调两个概念：**并发**（concurrency）和**并行**（parallel）。**并发**通常是指同一时刻只能有一条指令执行，但是多个线程对应的指令被快速轮换地执行。比如一个处理器，它先执行线程 A 的指令一段时间，再执行线程 B 的指令一段时间，再切回到线程 A 执行一段时间。由于处理器执行指令的速度和切换的速度极快，人们完全感知不到计算机在这个过程中有多个线程切换上下文执行的操作，这就使得宏观上看起来多个线程在同时运行，但微观上其实只有一个线程在执行。**并行**是指同一时刻，有多条指令在多个处理器上同时执行，并行必须要依赖于多个处理器，不论是从宏观上还是微观上，多个线程可以在同一时刻一起执行的。很多时候，我们并不用严格区分并发和并行两个词，所以我们有时候也把 Python 中的多线程、多进程以及异步 I/O 都视为实现并发编程的手段，但实际上前面两者也可以实现并行编程，当然这里还有一个全局解释器锁（GIL）的问题，我们稍后讨论。\n\n### 多线程编程\n\nPython 标准库中`threading`模块的`Thread`类可以帮助我们非常轻松的实现多线程编程。我们用一个联网下载文件的例子来对比使用多线程和不使用多线程到底有什么区别，代码如下所示。\n\n不使用多线程的下载。\n\n```Python\nimport random\nimport time\n\n\ndef download(*, filename):\n    start = time.time()\n    print(f'开始下载 {filename}.')\n    time.sleep(random.randint(3, 6))\n    print(f'{filename} 下载完成.')\n    end = time.time()\n    print(f'下载耗时: {end - start:.3f}秒.')\n\n\ndef main():\n    start = time.time()\n    download(filename='Python从入门到住院.pdf')\n    download(filename='MySQL从删库到跑路.avi')\n    download(filename='Linux从精通到放弃.mp4')\n    end = time.time()\n    print(f'总耗时: {end - start:.3f}秒.')\n\n\nif __name__ == '__main__':\n    main()\n```\n\n> **说明**：上面的代码并没有真正实现联网下载的功能，而是通过`time.sleep()`休眠一段时间来模拟下载文件需要一些时间上的开销，跟实际下载的状况比较类似。\n\n运行上面的代码，可以得到如下所示的运行结果。可以看出，当我们的程序只有一个工作线程时，每个下载任务都需要等待上一个下载任务执行结束才能开始，所以程序执行的总耗时是三个下载任务各自执行时间的总和。\n\n```\n开始下载Python从入门到住院.pdf.\nPython从入门到住院.pdf下载完成.\n下载耗时: 3.005秒.\n开始下载MySQL从删库到跑路.avi.\nMySQL从删库到跑路.avi下载完成.\n下载耗时: 5.006秒.\n开始下载Linux从精通到放弃.mp4.\nLinux从精通到放弃.mp3下载完成.\n下载耗时: 6.007秒.\n总耗时: 14.018秒.\n```\n\n事实上，上面的三个下载任务之间并没有逻辑上的因果关系，三者是可以“并发”的，下一个下载任务没有必要等待上一个下载任务结束，为此，我们可以使用多线程编程来改写上面的代码。\n\n```Python\nimport random\nimport time\nfrom threading import Thread\n\n\ndef download(*, filename):\n    start = time.time()\n    print(f'开始下载 {filename}.')\n    time.sleep(random.randint(3, 6))\n    print(f'{filename} 下载完成.')\n    end = time.time()\n    print(f'下载耗时: {end - start:.3f}秒.')\n\n\ndef main():\n    threads = [\n        Thread(target=download, kwargs={'filename': 'Python从入门到住院.pdf'}),\n        Thread(target=download, kwargs={'filename': 'MySQL从删库到跑路.avi'}),\n        Thread(target=download, kwargs={'filename': 'Linux从精通到放弃.mp4'})\n    ]\n    start = time.time()\n    # 启动三个线程\n    for thread in threads:\n        thread.start()\n    # 等待线程结束\n    for thread in threads:\n        thread.join()\n    end = time.time()\n    print(f'总耗时: {end - start:.3f}秒.')\n\n\nif __name__ == '__main__':\n    main()\n```\n\n某次的运行结果如下所示。\n\n```\n开始下载 Python从入门到住院.pdf.\n开始下载 MySQL从删库到跑路.avi.\n开始下载 Linux从精通到放弃.mp4.\nMySQL从删库到跑路.avi 下载完成.\n下载耗时: 3.005秒.\nPython从入门到住院.pdf 下载完成.\n下载耗时: 5.006秒.\nLinux从精通到放弃.mp4 下载完成.\n下载耗时: 6.003秒.\n总耗时: 6.004秒.\n```\n\n通过上面的运行结果可以发现，整个程序的执行时间几乎等于耗时最长的一个下载任务的执行时间，这也就意味着，三个下载任务是并发执行的，不存在一个等待另一个的情况，这样做很显然提高了程序的执行效率。简单的说，如果程序中有非常耗时的执行单元，而这些耗时的执行单元之间又没有逻辑上的因果关系，即 B 单元的执行不依赖于 A 单元的执行结果，那么 A 和 B 两个单元就可以放到两个不同的线程中，让他们并发的执行。这样做的好处除了减少程序执行的等待时间，还可以带来更好的用户体验，因为一个单元的阻塞不会造成程序的“假死”，因为程序中还有其他的单元是可以运转的。\n\n#### 使用 Thread 类创建线程对象\n\n通过上面的代码可以看出，直接使用`Thread`类的构造器就可以创建线程对象，而线程对象的`start()`方法可以启动一个线程。线程启动后会执行`target`参数指定的函数，当然前提是获得 CPU 的调度；如果`target`指定的线程要执行的目标函数有参数，需要通过`args`参数为其进行指定，对于关键字参数，可以通过`kwargs`参数进行传入。`Thread`类的构造器还有很多其他的参数，我们遇到的时候再为大家进行讲解，目前需要大家掌握的，就是`target`、`args`和`kwargs`。\n\n#### 继承 Thread 类自定义线程\n\n除了上面的代码展示的创建线程的方式外，还可以通过继承`Thread`类并重写`run()`方法的方式来自定义线程，具体的代码如下所示。\n\n```Python\nimport random\nimport time\nfrom threading import Thread\n\n\nclass DownloadThread(Thread):\n\n    def __init__(self, filename):\n        self.filename = filename\n        super().__init__()\n\n    def run(self):\n        start = time.time()\n        print(f'开始下载 {self.filename}.')\n        time.sleep(random.randint(3, 6))\n        print(f'{self.filename} 下载完成.')\n        end = time.time()\n        print(f'下载耗时: {end - start:.3f}秒.')\n\n\ndef main():\n    threads = [\n        DownloadThread('Python从入门到住院.pdf'),\n        DownloadThread('MySQL从删库到跑路.avi'),\n        DownloadThread('Linux从精通到放弃.mp4')\n    ]\n    start = time.time()\n    # 启动三个线程\n    for thread in threads:\n        thread.start()\n    # 等待线程结束\n    for thread in threads:\n        thread.join()\n    end = time.time()\n    print(f'总耗时: {end - start:.3f}秒.')\n\n\nif __name__ == '__main__':\n    main()\n```\n\n#### 使用线程池\n\n我们还可以通过线程池的方式将任务放到多个线程中去执行，通过线程池来使用线程应该是多线程编程最理想的选择。事实上，线程的创建和释放都会带来较大的开销，频繁的创建和释放线程通常都不是很好的选择。利用线程池，可以提前准备好若干个线程，在使用的过程中不需要再通过自定义的代码创建和释放线程，而是直接复用线程池中的线程。Python 内置的`concurrent.futures`模块提供了对线程池的支持，代码如下所示。\n\n```Python\nimport random\nimport time\nfrom concurrent.futures import ThreadPoolExecutor\nfrom threading import Thread\n\n\ndef download(*, filename):\n    start = time.time()\n    print(f'开始下载 {filename}.')\n    time.sleep(random.randint(3, 6))\n    print(f'{filename} 下载完成.')\n    end = time.time()\n    print(f'下载耗时: {end - start:.3f}秒.')\n\n\ndef main():\n    with ThreadPoolExecutor(max_workers=4) as pool:\n        filenames = ['Python从入门到住院.pdf', 'MySQL从删库到跑路.avi', 'Linux从精通到放弃.mp4']\n        start = time.time()\n        for filename in filenames:\n            pool.submit(download, filename=filename)\n    end = time.time()\n    print(f'总耗时: {end - start:.3f}秒.')\n\n\nif __name__ == '__main__':\n    main()\n```\n\n### 守护线程\n\n所谓“守护线程”就是在主线程结束的时候，不值得再保留的执行线程。这里的不值得保留指的是守护线程会在其他非守护线程全部运行结束之后被销毁，它守护的是当前进程内所有的非守护线程。简单的说，守护线程会跟随主线程一起挂掉，而主线程的生命周期就是一个进程的生命周期。如果不理解，我们可以看一段简单的代码。\n\n```Python\nimport time\nfrom threading import Thread\n\n\ndef display(content):\n    while True:\n        print(content, end='', flush=True)\n        time.sleep(0.1)\n\n\ndef main():\n    Thread(target=display, args=('Ping', )).start()\n    Thread(target=display, args=('Pong', )).start()\n\n\nif __name__ == '__main__':\n    main()\n```\n\n> **说明**：上面的代码中，我们将`print`函数的参数`flush`设置为`True`，这是因为`flush`参数的值如果为`False`，而`print`又没有做换行处理，就会导致每次`print`输出的内容被放到操作系统的输出缓冲区，直到缓冲区被输出的内容塞满，才会清空缓冲区产生一次输出。上述现象是操作系统为了减少 I/O 中断，提升 CPU 利用率做出的设定，为了让代码产生直观交互，我们才将`flush`参数设置为`True`，强制每次输出都清空输出缓冲区。\n\n上面的代码运行起来之后是不会停止的，因为两个子线程中都有死循环，除非你手动中断代码的执行。但是，如果在创建线程对象时，将名为`daemon`的参数设置为`True`，这两个线程就会变成守护线程，那么在其他线程结束时，即便有死循环，两个守护线程也会挂掉，不会再继续执行下去，代码如下所示。\n\n ```Python\n import time\n from threading import Thread\n \n \n def display(content):\n     while True:\n         print(content, end='', flush=True)\n         time.sleep(0.1)\n \n \n def main():\n     Thread(target=display, args=('Ping', ), daemon=True).start()\n     Thread(target=display, args=('Pong', ), daemon=True).start()\n     time.sleep(5)\n \n \n if __name__ == '__main__':\n     main()\n ```\n\n上面的代码，我们在主线程中添加了一行`time.sleep(5)`让主线程休眠5秒，在这个过程中，输出`Ping`和`Pong`的守护线程会持续运转，直到主线程在5秒后结束，这两个守护线程也被销毁，不再继续运行。\n\n> **思考**：如果将上面代码第12行的`daemon=True`去掉，代码会怎样执行？有兴趣的读者可以尝试一下，并看看实际执行的结果跟你想象的是否一致。\n\n### 资源竞争\n\n在编写多线程代码时，不可避免的会遇到多个线程竞争同一个资源（对象）的情况。在这种情况下，如果没有合理的机制来保护被竞争的资源，那么就有可能出现非预期的状况。下面的代码创建了`100`个线程向同一个银行账户（初始余额为`0`元）转账，每个线程转账金额为`1`元。在正常的情况下，我们的银行账户最终的余额应该是`100`元，但是运行下面的代码我们并不能得到`100`元这个结果。\n\n```Python\nimport time\n\nfrom concurrent.futures import ThreadPoolExecutor\n\n\nclass Account(object):\n    \"\"\"银行账户\"\"\"\n\n    def __init__(self):\n        self.balance = 0.0\n\n    def deposit(self, money):\n        \"\"\"存钱\"\"\"\n        new_balance = self.balance + money\n        time.sleep(0.01)\n        self.balance = new_balance\n\n\ndef main():\n    \"\"\"主函数\"\"\"\n    account = Account()\n    with ThreadPoolExecutor(max_workers=16) as pool:\n        for _ in range(100):\n            pool.submit(account.deposit, 1)\n    print(account.balance)\n\n\nif __name__ == '__main__':\n    main()\n```\n\n上面代码中的`Account`类代表了银行账户，它的`deposit`方法代表存款行为，参数`money`代表存入的金额，该方法通过`time.sleep`函数模拟受理存款需要一段时间。我们通过线程池的方式启动了`100`个线程向一个账户转账，但是上面的代码并不能运行出`100`这个我们期望的结果，这就是在多个线程竞争一个资源的时候，可能会遇到的数据不一致的问题。注意上面代码的第`14`行，当多个线程都执行到这行代码时，它们会在相同的余额上执行加上存入金额的操作，这就会造成“丢失更新”现象，即之前修改数据的成果被后续的修改给覆盖掉了，所以才得不到正确的结果。\n\n要解决上面的问题，可以使用锁机制，通过锁对操作数据的关键代码加以保护。Python 标准库的`threading`模块提供了`Lock`和`RLock`类来支持锁机制，这里我们不去深究二者的区别，建议大家直接使用`RLock`。接下来，我们给银行账户添加一个锁对象，通过锁对象来解决刚才存款时发生“丢失更新”的问题，代码如下所示。\n\n```Python\nimport time\n\nfrom concurrent.futures import ThreadPoolExecutor\nfrom threading import RLock\n\n\nclass Account(object):\n    \"\"\"银行账户\"\"\"\n\n    def __init__(self):\n        self.balance = 0.0\n        self.lock = RLock()\n\n    def deposit(self, money):\n        # 获得锁\n        self.lock.acquire()\n        try:\n            new_balance = self.balance + money\n            time.sleep(0.01)\n            self.balance = new_balance\n        finally:\n            # 释放锁\n            self.lock.release()\n\n\ndef main():\n    \"\"\"主函数\"\"\"\n    account = Account()\n    with ThreadPoolExecutor(max_workers=16) as pool:\n        for _ in range(100):\n            pool.submit(account.deposit, 1)\n    print(account.balance)\n\n\nif __name__ == '__main__':\n    main()\n```\n\n上面代码中，获得锁和释放锁的操作也可以通过上下文语法来实现，使用上下文语法会让代码更加简单优雅，这也是我们推荐大家使用的方式。\n\n```Python\nimport time\n\nfrom concurrent.futures import ThreadPoolExecutor\nfrom threading import RLock\n\n\nclass Account(object):\n    \"\"\"银行账户\"\"\"\n\n    def __init__(self):\n        self.balance = 0.0\n        self.lock = RLock()\n\n    def deposit(self, money):\n        # 通过上下文语法获得锁和释放锁\n        with self.lock:\n            new_balance = self.balance + money\n            time.sleep(0.01)\n            self.balance = new_balance\n\n\ndef main():\n    \"\"\"主函数\"\"\"\n    account = Account()\n    with ThreadPoolExecutor(max_workers=16) as pool:\n        for _ in range(100):\n            pool.submit(account.deposit, 1)\n    print(account.balance)\n\n\nif __name__ == '__main__':\n    main()\n```\n\n> **思考**：将上面的代码修改为5个线程向银行账户存钱，5个线程从银行账户取钱，取钱的线程在银行账户余额不足时，需要停下来等待存钱的线程将钱存入后再尝试取钱。这里需要用到线程调度的知识，大家可以自行研究下`threading`模块中的`Condition`类，看看是否能够完成这个任务。\n\n### GIL问题\n\n如果使用官方的 Python 解释器（通常称之为 CPython）运行 Python 程序，我们并不能通过使用多线程的方式将 CPU 的利用率提升到逼近400%（对于4核 CPU）或逼近800%（对于8核 CPU）这样的水平，因为 CPython 在执行代码时，会受到 GIL（全局解释器锁）的限制。具体的说，CPython 在执行任何代码时，都需要对应的线程先获得 GIL，然后每执行100条（字节码）指令，CPython 就会让获得 GIL 的线程主动释放 GIL，这样别的线程才有机会执行。因为 GIL 的存在，无论你的 CPU 有多少个核，我们编写的 Python 代码也没有机会真正并行的执行。\n\nGIL 是官方 Python 解释器在设计上的历史遗留问题，要解决这个问题，让多线程能够发挥 CPU 的多核优势，需要重新实现一个不带 GIL 的 Python 解释器。这个问题按照官方的说法，在 Python 发布4.0版本时会得到解决，就让我们拭目以待吧。当下，对于 CPython 而言，如果希望充分发挥 CPU 的多核优势，可以考虑使用多进程，因为每个进程都对应一个 Python 解释器，因此每个进程都有自己独立的 GIL，这样就可以突破 GIL 的限制。在下一个章节中，我们会为大家介绍关于多进程的相关知识，并对多线程和多进程的代码及其执行效果进行比较。\n\n", "中的并发编程-2": "## Python中的并发编程-2\n\n在上一课中我们说过，由于 GIL 的存在，CPython 中的多线程并不能发挥 CPU 的多核优势，如果希望突破 GIL 的限制，可以考虑使用多进程。对于多进程的程序，每个进程都有一个属于自己的 GIL，所以多进程不会受到 GIL 的影响。那么，我们应该如何在 Python 程序中创建和使用多进程呢？\n\n###创建进程\n\n在 Python 中可以基于`Process`类来创建进程，虽然进程和线程有着本质的差别，但是`Process`类和`Thread`类的用法却非常类似。在使用`Process`类的构造器创建对象时，也是通过`target`参数传入一个函数来指定进程要执行的代码，而`args`和`kwargs`参数可以指定该函数使用的参数值。\n\n```Python\nfrom multiprocessing import Process, current_process\nfrom time import sleep\n\n\ndef sub_task(content, nums):\n    # 通过current_process函数获取当前进程对象\n    # 通过进程对象的pid和name属性获取进程的ID号和名字\n    print(f'PID: {current_process().pid}')\n    print(f'Name: {current_process().name}')\n    # 通过下面的输出不难发现，每个进程都有自己的nums列表，进程之间本就不共享内存\n    # 在创建子进程时复制了父进程的数据结构，三个进程从列表中pop(0)得到的值都是20\n    counter, total = 0, nums.pop(0)\n    print(f'Loop count: {total}')\n    sleep(0.5)\n    while counter < total:\n        counter += 1\n        print(f'{counter}: {content}')\n        sleep(0.01)\n\n\ndef main():\n    nums = [20, 30, 40]\n    # 创建并启动进程来执行指定的函数\n    Process(target=sub_task, args=('Ping', nums)).start()\n    Process(target=sub_task, args=('Pong', nums)).start()\n    # 在主进程中执行sub_task函数\n    sub_task('Good', nums)\n\n\nif __name__ == '__main__':\n    main()\n```\n\n> **说明**：上面的代码通过`current_process`函数获取当前进程对象，再通过进程对象的`pid`属性获取进程ID。在 Python 中，使用`os`模块的`getpid`函数也可以达到同样的效果。\n\n如果愿意，也可以使用`os`模块的`fork`函数来创建进程，调用该函数时，操作系统自动把当前进程（父进程）复制一份（子进程），父进程的`fork`函数会返回子进程的ID，而子进程中的`fork`函数会返回`0`，也就是说这个函数调用一次会在父进程和子进程中得到两个不同的返回值。需要注意的是，Windows 系统并不支持`fork`函数，如果你使用的是 Linux 或 macOS 系统，可以试试下面的代码。\n\n```Python\nimport os\n\nprint(f'PID: {os.getpid()}')\npid = os.fork()\nif pid == 0:\n    print(f'子进程 - PID: {os.getpid()}')\n    print('Todo: 在子进程中执行的代码')\nelse:\n    print(f'父进程 - PID: {os.getpid()}')\n    print('Todo: 在父进程中执行的代码')\n```\n\n简而言之，我们还是推荐大家通过直接使用`Process`类、继承`Process`类和使用进程池（`ProcessPoolExecutor`）这三种方式来创建和使用多进程，这三种方式不同于上面的`fork`函数，能够保证代码的兼容性和可移植性。具体的做法跟之前讲过的创建和使用多线程的方式比较接近，此处不再进行赘述。\n\n### 多进程和多线程的比较\n\n对于爬虫这类 I/O 密集型任务来说，使用多进程并没有什么优势；但是对于计算密集型任务来说，多进程相比多线程，在效率上会有显著的提升，我们可以通过下面的代码来加以证明。下面的代码会通过多线程和多进程两种方式来判断一组大整数是不是质数，很显然这是一个计算密集型任务，我们将任务分别放到多个线程和多个进程中来加速代码的执行，让我们看看多线程和多进程的代码具体表现有何不同。\n\n我们先实现一个多线程的版本，代码如下所示。\n\n```Python\nimport concurrent.futures\n\nPRIMES = [\n    1116281,\n    1297337,\n    104395303,\n    472882027,\n    533000389,\n    817504243,\n    982451653,\n    112272535095293,\n    112582705942171,\n    112272535095293,\n    115280095190773,\n    115797848077099,\n    1099726899285419\n] * 5\n\n\ndef is_prime(n):\n    \"\"\"判断素数\"\"\"\n    for i in range(2, int(n ** 0.5) + 1):\n        if n % i == 0:\n            return False\n    return n != 1\n\n\ndef main():\n    \"\"\"主函数\"\"\"\n    with concurrent.futures.ThreadPoolExecutor(max_workers=16) as executor:\n        for number, prime in zip(PRIMES, executor.map(is_prime, PRIMES)):\n            print('%d is prime: %s' % (number, prime))\n\n\nif __name__ == '__main__':\n    main()\n```\n\n假设上面的代码保存在名为`example.py`的文件中，在 Linux 或 macOS 系统上，可以使用`time python example.py`命令执行程序并获得操作系统关于执行时间的统计，在我的 macOS 上，某次的运行结果的最后一行输出如下所示。\n\n```\npython example09.py  38.69s user 1.01s system 101% cpu 39.213 total\n```\n\n从运行结果可以看出，多线程的代码只能让 CPU 利用率达到100%，这其实已经证明了多线程的代码无法利用 CPU 多核特性来加速代码的执行，我们再看看多进程的版本，我们将上面代码中的线程池（`ThreadPoolExecutor`）更换为进程池（`ProcessPoolExecutor`）。\n\n多进程的版本。\n\n```Python\nimport concurrent.futures\n\nPRIMES = [\n    1116281,\n    1297337,\n    104395303,\n    472882027,\n    533000389,\n    817504243,\n    982451653,\n    112272535095293,\n    112582705942171,\n    112272535095293,\n    115280095190773,\n    115797848077099,\n    1099726899285419\n] * 5\n\n\ndef is_prime(n):\n    \"\"\"判断素数\"\"\"\n    for i in range(2, int(n ** 0.5) + 1):\n        if n % i == 0:\n            return False\n    return n != 1\n\n\ndef main():\n    \"\"\"主函数\"\"\"\n    with concurrent.futures.ProcessPoolExecutor(max_workers=16) as executor:\n        for number, prime in zip(PRIMES, executor.map(is_prime, PRIMES)):\n            print('%d is prime: %s' % (number, prime))\n\n\nif __name__ == '__main__':\n    main()\n```\n\n> **提示**：运行上面的代码时，可以通过操作系统的任务管理器（资源监视器）来查看是否启动了多个 Python  解释器进程。\n\n我们仍然通过`time python example.py`的方式来执行上述代码，运行结果的最后一行如下所示。\n\n```\npython example09.py 106.63s user 0.57s system 389% cpu 27.497 total\n```\n\n可以看出，多进程的版本在我使用的这台电脑上，让 CPU 的利用率达到了将近400%，而运行代码时用户态耗费的 CPU 的时间（106.63秒）几乎是代码运行总时间（27.497秒）的4倍，从这两点都可以看出，我的电脑使用了一款4核的 CPU。当然，要知道自己的电脑有几个 CPU 或几个核，可以直接使用下面的代码。\n\n```Python\nimport os\n\nprint(os.cpu_count())\n```\n\n综上所述，多进程可以突破 GIL 的限制，充分利用 CPU 多核特性，对于计算密集型任务，这一点是相当重要的。常见的计算密集型任务包括科学计算、图像处理、音视频编解码等，如果这些计算密集型任务本身是可以并行的，那么使用多进程应该是更好的选择。\n\n### 进程间通信\n\n在讲解进程间通信之前，先给大家一个任务：启动两个进程，一个输出“Ping”，一个输出“Pong”，两个进程输出的“Ping”和“Pong”加起来一共有50个时，就结束程序。听起来是不是非常简单，但是实际编写代码时，由于多个进程之间不能够像多个线程之间直接通过共享内存的方式交换数据，所以下面的代码是达不到我们想要的结果的。\n\n```Python\nfrom multiprocessing import Process\nfrom time import sleep\n\ncounter = 0\n\n\ndef sub_task(string):\n    global counter\n    while counter < 50:\n        print(string, end='', flush=True)\n        counter += 1\n        sleep(0.01)\n\n        \ndef main():\n    Process(target=sub_task, args=('Ping', )).start()\n    Process(target=sub_task, args=('Pong', )).start()\n\n\nif __name__ == '__main__':\n    main()\n```\n\n上面的代码看起来没毛病，但是最后的结果是“Ping”和“Pong”各输出了50个。再次提醒大家，当我们在程序中创建进程的时候，子进程会复制父进程及其所有的数据结构，每个子进程有自己独立的内存空间，这也就意味着两个子进程中各有一个`counter`变量，它们都会从`0`加到`50`，所以结果就可想而知了。要解决这个问题比较简单的办法是使用`multiprocessing`模块中的`Queue`类，它是可以被多个进程共享的队列，底层是通过操作系统底层的管道和信号量（semaphore）机制来实现的，代码如下所示。\n\n```Python\nimport time\nfrom multiprocessing import Process, Queue\n\n\ndef sub_task(content, queue):\n    counter = queue.get()\n    while counter < 50:\n        print(content, end='', flush=True)\n        counter += 1\n        queue.put(counter)\n        time.sleep(0.01)\n        counter = queue.get()\n\n\ndef main():\n    queue = Queue()\n    queue.put(0)\n    p1 = Process(target=sub_task, args=('Ping', queue))\n    p1.start()\n    p2 = Process(target=sub_task, args=('Pong', queue))\n    p2.start()\n    while p1.is_alive() and p2.is_alive():\n        pass\n    queue.put(50)\n\n\nif __name__ == '__main__':\n    main()\n```\n\n> **提示**：`multiprocessing.Queue`对象的`get`方法默认在队列为空时是会阻塞的，直到获取到数据才会返回。如果不希望该方法阻塞以及需要指定阻塞的超时时间，可以通过指定`block`和`timeout`参数进行设定。\n\n上面的代码通过`Queue`类的`get`和`put`方法让三个进程（`p1`、`p2`和主进程）实现了数据的共享，这就是所谓的进程间的通信，通过这种方式，当`Queue`中取出的值已经大于等于`50`时，`p1`和`p2`就会跳出`while`循环，从而终止进程的执行。代码第22行的循环是为了等待`p1`和`p2`两个进程中的一个结束，这时候主进程还需要向`Queue`中放置一个大于等于`50`的值，这样另一个尚未结束的进程也会因为读到这个大于等于`50`的值而终止。\n\n进程间通信的方式还有很多，比如使用套接字也可以实现两个进程的通信，甚至于这两个进程并不在同一台主机上，有兴趣的读者可以自行了解。\n\n###  总结\n\n在 Python 中，我们还可以通过`subprocess`模块的`call`函数执行其他的命令来创建子进程，相当于就是在我们的程序中调用其他程序，这里我们暂不探讨这些知识，有兴趣的读者可以自行研究。\n\n对于Python开发者来说，以下情况需要考虑使用多线程：\n\n1. 程序需要维护许多共享的状态（尤其是可变状态），Python 中的列表、字典、集合都是线程安全的（多个线程同时操作同一个列表、字典或集合，不会引发错误和数据问题），所以使用线程而不是进程维护共享状态的代价相对较小。\n2. 程序会花费大量时间在 I/O 操作上，没有太多并行计算的需求且不需占用太多的内存。\n\n那么在遇到下列情况时，应该考虑使用多进程：\n\n1. 程序执行计算密集型任务（如：音视频编解码、数据压缩、科学计算等）。\n2. 程序的输入可以并行的分成块，并且可以将运算结果合并。\n3. 程序在内存使用方面没有任何限制且不强依赖于 I/O 操作（如读写文件、套接字等）。\n", "中的并发编程-3": "## Python中的并发编程-3\n\n爬虫是典型的 I/O 密集型任务，I/O 密集型任务的特点就是程序会经常性的因为 I/O 操作而进入阻塞状态，比如我们之前使用`requests`获取页面代码或二进制内容，发出一个请求之后，程序必须要等待网站返回响应之后才能继续运行，如果目标网站不是很给力或者网络状况不是很理想，那么等待响应的时间可能会很久，而在这个过程中整个程序是一直阻塞在那里，没有做任何的事情。通过前面的课程，我们已经知道了可以通过多线程的方式为爬虫提速，使用多线程的本质就是，当一个线程阻塞的时候，程序还有其他的线程可以继续运转，因此整个程序就不会在阻塞和等待中浪费了大量的时间。\n\n事实上，还有一种非常适合 I/O 密集型任务的并发编程方式，我们称之为异步编程，你也可以将它称为异步 I/O。这种方式并不需要启动多个线程或多个进程来实现并发，它是通过多个子程序相互协作的方式来提升 CPU 的利用率，解决了 I/O 密集型任务 CPU  利用率很低的问题，我一般将这种方式称为“协作式并发”。这里，我不打算探讨操作系统的各种 I/O 模式，因为这对很多读者来说都太过抽象；但是我们得先抛出两组概念给大家，一组叫做“阻塞”和“非阻塞”，一组叫做“同步”和“异步”。\n\n### 基本概念\n\n#### 阻塞\n\n阻塞状态指程序未得到所需计算资源时被挂起的状态。程序在等待某个操作完成期间，自身无法继续处理其他的事情，则称该程序在该操作上是阻塞的。阻塞随时都可能发生，最典型的就是 I/O 中断（包括网络 I/O 、磁盘 I/O 、用户输入等）、休眠操作、等待某个线程执行结束，甚至包括在 CPU 切换上下文时，程序都无法真正的执行，这就是所谓的阻塞。\n\n#### 非阻塞\n\n程序在等待某操作过程中，自身不被阻塞，可以继续处理其他的事情，则称该程序在该操作上是非阻塞的。非阻塞并不是在任何程序级别、任何情况下都可以存在的。仅当程序封装的级别可以囊括独立的子程序单元时，它才可能存在非阻塞状态。显然，某个操作的阻塞可能会导程序耗时以及效率低下，所以我们会希望把它变成非阻塞的。\n\n#### 同步\n\n不同程序单元为了完成某个任务，在执行过程中需靠某种通信方式以协调一致，我们称这些程序单元是同步执行的。例如前面讲过的给银行账户存钱的操作，我们在代码中使用了“锁”作为通信信号，让多个存钱操作强制排队顺序执行，这就是所谓的同步。\n\n#### 异步\n\n不同程序单元在执行过程中无需通信协调，也能够完成一个任务，这种方式我们就称之为异步。例如，使用爬虫下载页面时，调度程序调用下载程序后，即可调度其他任务，而无需与该下载任务保持通信以协调行为。不同网页的下载、保存等操作都是不相关的，也无需相互通知协调。很显然，异步操作的完成时刻和先后顺序并不能确定。\n\n很多人都不太能准确的把握这几个概念，这里我们简单的总结一下，同步与异步的关注点是**消息通信机制**，最终表现出来的是“有序”和“无序”的区别；阻塞和非阻塞的关注点是**程序在等待消息时状态**，最终表现出来的是程序在等待时能不能做点别的。如果想深入理解这些内容，推荐大家阅读经典著作[《UNIX网络编程》](https://item.jd.com/11880047.html)，这本书非常的赞。\n\n### 生成器和协程\n\n前面我们说过，异步编程是一种“协作式并发”，即通过多个子程序相互协作的方式提升 CPU 的利用率，从而减少程序在阻塞和等待中浪费的时间，最终达到并发的效果。我们可以将多个相互协作的子程序称为“协程”，它是实现异步编程的关键。在介绍协程之前，我们先通过下面的代码，看看什么是生成器。\n\n```Python\ndef fib(max_count):\n    a, b = 0, 1\n    for _ in range(max_count):\n        a, b = b, a + b\n        yield a\n```\n\n上面我们编写了一个生成斐波那契数列的生成器，调用上面的`fib`函数并不是执行该函数获得返回值，因为`fib`函数中有一个特殊的关键字`yield`。这个关键字使得`fib`函数跟普通的函数有些区别，调用该函数会得到一个生成器对象，我们可以通过下面的代码来验证这一点。\n\n```Python\ngen_obj = fib(20)\nprint(gen_obj)\n```\n\n输出：\n\n```\n<generator object fib at 0x106daee40>\n```\n\n我们可以使用内置函数`next`从生成器对象中获取斐波那契数列的值，也可以通过`for-in`循环对生成器能够提供的值进行遍历，代码如下所示。\n\n```Python\nfor value in gen_obj:\n    print(value)\n```\n\n生成器经过预激活，就是一个协程，它可以跟其他子程序协作。\n\n```Python\ndef calc_average():\n    total, counter = 0, 0\n    avg_value = None\n    while True:\n        curr_value = yield avg_value\n        total += curr_value\n        counter += 1\n        avg_value = total / counter\n\n\ndef main():\n    obj = calc_average()\n    # 生成器预激活\n    obj.send(None)\n    for _ in range(5):\n        print(obj.send(float(input())))\n\n\nif __name__ == '__main__':\n    main()\n```\n\n上面的`main`函数首先通过生成器对象的`send`方法发送一个`None`值来将其激活为协程，也可以通过`next(obj)`达到同样的效果。接下来，协程对象会接收`main`函数发送的数据并产出（`yield`）数据的平均值。通过上面的例子，不知道大家是否看出两段子程序是怎么“协作”的。\n\n### 异步函数\n\nPython 3.5版本中，引入了两个非常有意思的元素，一个叫`async`，一个叫`await`，它们在Python 3.7版本中成为了正式的关键字。通过这两个关键字，可以简化协程代码的编写，可以用更为简单的方式让多个子程序很好的协作起来。我们通过一个例子来加以说明，请大家先看看下面的代码。\n\n```Python\nimport time\n\n\ndef display(num):\n    time.sleep(1)\n    print(num)\n\n\ndef main():\n    start = time.time()\n    for i in range(1, 10):\n        display(i)\n    end = time.time()\n    print(f'{end - start:.3f}秒')\n\n\nif __name__ == '__main__':\n    main()\n```\n\n上面的代码每次执行都会依次输出`1`到`9`的数字，每个间隔`1`秒钟，整个代码需要执行大概需要`9`秒多的时间，这一点我相信大家都能看懂。不知道大家是否意识到，这段代码就是以同步和阻塞的方式执行的，同步可以从代码的输出看出来，而阻塞是指在调用`display`函数发生休眠时，整个代码的其他部分都不能继续执行，必须等待休眠结束。\n\n接下来，我们尝试用异步的方式改写上面的代码，让`display`函数以异步的方式运转。\n\n```Python\nimport asyncio\nimport time\n\n\nasync def display(num):\n    await asyncio.sleep(1)\n    print(num)\n\n\ndef main():\n    start = time.time()\n    objs = [display(i) for i in range(1, 10)]\n    loop = asyncio.get_event_loop()\n    loop.run_until_complete(asyncio.wait(objs))\n    loop.close()\n    end = time.time()\n    print(f'{end - start:.3f}秒')\n\n\nif __name__ == '__main__':\n    main()\n```\n\nPython 中的`asyncio`模块提供了对异步 I/O 的支持。上面的代码中，我们首先在`display`函数前面加上了`async`关键字使其变成一个异步函数，调用异步函数不会执行函数体而是获得一个协程对象。我们将`display`函数中的`time.sleep(1)`修改为`await asyncio.sleep(1)`，二者的区别在于，后者不会让整个代码陷入阻塞，因为`await`操作会让其他协作的子程序有获得 CPU 资源而得以运转的机会。为了让这些子程序可以协作起来，我们需要将他们放到一个事件循环（实现消息分派传递的系统）上，因为**当协程遭遇 I/O 操作阻塞时，就会到事件循环中监听 I/O 操作是否完成，并注册自身的上下文以及自身的唤醒函数（以便恢复执行），之后该协程就变为阻塞状态**。上面的第12行代码创建了`9`个协程对象并放到一个列表中，第13行代码通过`asyncio`模块的`get_event_loop`函数获得了系统的事件循环，第14行通过`asyncio`模块的`run_until_complete`函数将协程对象挂载到事件循环上。执行上面的代码会发现，`9`个分别会阻塞`1`秒钟的协程总共只阻塞了约`1`秒种的时间，因为**阻塞的协程对象会放弃对 CPU 的占有而不是让 CPU 处于闲置状态，这种方式大大的提升了 CPU 的利用率**。而且我们还会注意到，数字并不是按照从`1`到`9`的顺序打印输出的，这正是我们想要的结果，说明它们是**异步执行**的。对于爬虫这样的 I/O 密集型任务来说，这种协作式并发在很多场景下是比使用多线程更好的选择，因为这种做法减少了管理和维护多个线程以及多个线程切换所带来的开销。\n\n### aiohttp库\n\n我们之前使用的`requests`三方库并不支持异步 I/O，如果希望使用异步 I/O 的方式来加速爬虫代码的执行，我们可以安装和使用名为`aiohttp`的三方库。\n\n安装`aiohttp`。\n\n```Bash\npip install aiohttp\n```\n\n下面的代码使用`aiohttp`抓取了`10`个网站的首页并解析出它们的标题。\n\n```Python\nimport asyncio\nimport re\n\nimport aiohttp\nfrom aiohttp import ClientSession\n\nTITLE_PATTERN = re.compile(r'<title.*?>(.*?)</title>', re.DOTALL)\n\n\nasync def fetch_page_title(url):\n    async with aiohttp.ClientSession(headers={\n        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/95.0.4638.69 Safari/537.36',\n    }) as session:  # type: ClientSession\n        async with session.get(url, ssl=False) as resp:\n            if resp.status == 200:\n                html_code = await resp.text()\n                matcher = TITLE_PATTERN.search(html_code)\n                title = matcher.group(1).strip()\n                print(title)\n\n\ndef main():\n    urls = [\n        'https://www.python.org/',\n        'https://www.jd.com/',\n        'https://www.baidu.com/',\n        'https://www.taobao.com/',\n        'https://git-scm.com/',\n        'https://www.sohu.com/',\n        'https://gitee.com/',\n        'https://www.amazon.com/',\n        'https://www.usa.gov/',\n        'https://www.nasa.gov/'\n    ]\n    objs = [fetch_page_title(url) for url in urls]\n    loop = asyncio.get_event_loop()\n    loop.run_until_complete(asyncio.wait(objs))\n    loop.close()\n\n\nif __name__ == '__main__':\n    main()\n```\n\n输出：\n\n```\n京东(JD.COM)-正品低价、品质保障、配送及时、轻松购物！\n搜狐\n淘宝网 - 淘！我喜欢\n百度一下，你就知道\nGitee - 基于 Git 的代码托管和研发协作平台\nGit\nNASA\nOfficial Guide to Government Information and Services   &#124; USAGov\nAmazon.com. Spend less. Smile more.\nWelcome to Python.org\n```\n\n从上面的输出可以看出，网站首页标题的输出顺序跟它们的 URL 在列表中的顺序没有关系。代码的第11行到第13行创建了`ClientSession`对象，通过它的`get`方法可以向指定的 URL 发起请求，如第14行所示，跟`requests`中的`Session`对象并没有本质区别，唯一的区别是这里使用了异步上下文。代码第16行的`await`会让因为 I/O 操作阻塞的子程序放弃对 CPU 的占用，这使得其他的子程序可以运转起来去抓取页面。代码的第17行和第18行使用了正则表达式捕获组操作解析网页标题。`fetch_page_title`是一个被`async`关键字修饰的异步函数，调用该函数会获得协程对象，如代码第35行所示。后面的代码跟之前的例子没有什么区别，相信大家能够理解。\n\n大家可以尝试将`aiohttp`换回到`requests`，看看不使用异步 I/O 也不使用多线程，到底和上面的代码有什么区别，相信通过这样的对比，大家能够更深刻的理解我们之前强调的几个概念：同步和异步，阻塞和非阻塞。\n", "并发编程在爬虫中的应用": "## 并发编程在爬虫中的应用\n\n之前的课程，我们已经为大家介绍了 Python 中的多线程、多进程和异步编程，通过这三种手段，我们可以实现并发或并行编程，这一方面可以加速代码的执行，另一方面也可以带来更好的用户体验。爬虫程序是典型的 I/O 密集型任务，对于 I/O 密集型任务来说，多线程和异步 I/O 都是很好的选择，因为当程序的某个部分因 I/O 操作阻塞时，程序的其他部分仍然可以运转，这样我们不用在等待和阻塞中浪费大量的时间。下面我们以爬取“[360图片](https://image.so.com/)”网站的图片并保存到本地为例，为大家分别展示使用单线程、多线程和异步 I/O 编程的爬虫程序有什么区别，同时也对它们的执行效率进行简单的对比。\n\n“360图片”网站的页面使用了 [Ajax](https://developer.mozilla.org/zh-CN/docs/Web/Guide/AJAX) 技术，这是很多网站都会使用的一种异步加载数据和局部刷新页面的技术。简单的说，页面上的图片都是通过 JavaScript 代码异步获取 JSON 数据并动态渲染生成的，而且整个页面还使用了瀑布式加载（一边向下滚动，一边加载更多的图片）。我们在浏览器的“开发者工具”中可以找到提供动态内容的数据接口，如下图所示，我们需要的图片信息就在服务器返回的 JSON 数据中。\n\n<img class=\"lazy\" data-src=\"/res/20211205221352.png\" style=\"zoom:40%;\">\n\n例如，要获取“美女”频道的图片，我们可以请求如下所示的URL，其中参数`ch`表示请求的频道，`=`后面的参数值`beauty`就代表了“美女”频道，参数`sn`相当于是页码，`0`表示第一页（共`30`张图片），`30`表示第二页，`60`表示第三页，以此类推。\n\n```\nhttps://image.so.com/zjl?ch=beauty&sn=0\n```\n\n### 单线程版本\n\n通过上面的 URL 下载“美女”频道共`90`张图片。\n\n```Python\n\"\"\"\nexample04.py - 单线程版本爬虫\n\"\"\"\nimport os\n\nimport requests\n\n\ndef download_picture(url):\n    filename = url[url.rfind('/') + 1:]\n    resp = requests.get(url)\n    if resp.status_code == 200:\n        with open(f'images/beauty/{filename}', 'wb') as file:\n            file.write(resp.content)\n\n\ndef main():\n    if not os.path.exists('images/beauty'):\n        os.makedirs('images/beauty')\n    for page in range(3):\n        resp = requests.get(f'https://image.so.com/zjl?ch=beauty&sn={page * 30}')\n        if resp.status_code == 200:\n            pic_dict_list = resp.json()['list']\n            for pic_dict in pic_dict_list:\n                download_picture(pic_dict['qhimg_url'])\n\nif __name__ == '__main__':\n    main()\n```\n\n在 macOS 或 Linux 系统上，我们可以使用`time`命令来了解上面代码的执行时间以及 CPU 的利用率，如下所示。\n\n```Bash\ntime python3 example04.py \n```\n\n下面是单线程爬虫代码在我的电脑上执行的结果。\n\n```\npython3 example04.py  2.36s user 0.39s system 12% cpu 21.578 total\n```\n\n这里我们只需要关注代码的总耗时为`21.578`秒，CPU 利用率为`12%`。\n\n### 多线程版本\n\n我们使用之前讲到过的线程池技术，将上面的代码修改为多线程版本。\n\n```Python\n\"\"\"\nexample05.py - 多线程版本爬虫\n\"\"\"\nimport os\nfrom concurrent.futures import ThreadPoolExecutor\n\nimport requests\n\n\ndef download_picture(url):\n    filename = url[url.rfind('/') + 1:]\n    resp = requests.get(url)\n    if resp.status_code == 200:\n        with open(f'images/beauty/{filename}', 'wb') as file:\n            file.write(resp.content)\n\n\ndef main():\n    if not os.path.exists('images/beauty'):\n        os.makedirs('images/beauty')\n    with ThreadPoolExecutor(max_workers=16) as pool:\n        for page in range(3):\n            resp = requests.get(f'https://image.so.com/zjl?ch=beauty&sn={page * 30}')\n            if resp.status_code == 200:\n                pic_dict_list = resp.json()['list']\n                for pic_dict in pic_dict_list:\n                    pool.submit(download_picture, pic_dict['qhimg_url'])\n\n\nif __name__ == '__main__':\n    main()\n```\n\n执行如下所示的命令。\n\n```Bash\ntime python3 example05.py\n```\n\n代码的执行结果如下所示：\n\n```\npython3 example05.py  2.65s user 0.40s system 95% cpu 3.193 total\n```\n\n### 异步I/O版本\n\n我们使用`aiohttp`将上面的代码修改为异步 I/O 的版本。为了以异步 I/O 的方式实现网络资源的获取和写文件操作，我们首先得安装三方库`aiohttp`和`aiofile`，命令如下所示。\n\n```Bash\npip install aiohttp aiofile\n```\n\n`aiohttp` 的用法在之前的课程中已经做过简要介绍，`aiofile`模块中的`async_open`函数跟 Python 内置函数`open`的用法大致相同，只不过它支持异步操作。下面是异步 I/O 版本的爬虫代码。\n\n```Python\n\"\"\"\nexample06.py - 异步I/O版本爬虫\n\"\"\"\nimport asyncio\nimport json\nimport os\n\nimport aiofile\nimport aiohttp\n\n\nasync def download_picture(session, url):\n    filename = url[url.rfind('/') + 1:]\n    async with session.get(url, ssl=False) as resp:\n        if resp.status == 200:\n            data = await resp.read()\n            async with aiofile.async_open(f'images/beauty/{filename}', 'wb') as file:\n                await file.write(data)\n\n\nasync def fetch_json():\n    async with aiohttp.ClientSession() as session:\n        for page in range(3):\n            async with session.get(\n                url=f'https://image.so.com/zjl?ch=beauty&sn={page * 30}',\n                ssl=False\n            ) as resp:\n                if resp.status == 200:\n                    json_str = await resp.text()\n                    result = json.loads(json_str)\n                    for pic_dict in result['list']:\n                        await download_picture(session, pic_dict['qhimg_url'])\n\n\ndef main():\n    if not os.path.exists('images/beauty'):\n        os.makedirs('images/beauty')\n    loop = asyncio.get_event_loop()\n    loop.run_until_complete(fetch_json())\n    loop.close()\n\n\nif __name__ == '__main__':\n    main()\n```\n\n执行如下所示的命令。\n\n```Bash\ntime python3 example06.py\n```\n\n代码的执行结果如下所示：\n\n```\npython3 example06.py  0.82s user 0.21s system 27% cpu 3.782 total\n```\n\n### 总结\n\n通过上面三段代码执行结果的比较，我们可以得出一个结论，使用多线程和异步 I/O 都可以改善爬虫程序的性能，因为我们不用将时间浪费在因 I/O 操作造成的等待和阻塞上，而`time`命令的执行结果也告诉我们，单线程的代码 CPU 利用率仅仅只有`12%`，而多线程版本的 CPU 利用率则高达`95%`；单线程版本的爬虫执行时间约`21`秒，而多线程和异步 I/O 的版本仅执行了`3`秒钟。另外，在运行时间差别不大的情况下，多线程的代码比异步 I/O 的代码耗费了更多的 CPU 资源，这是因为多线程的调度和切换也需要花费 CPU 时间。至此，三种方式在 I/O 密集型任务上的优劣已经一目了然，当然这只是在我的电脑上跑出来的结果。如果网络状况不是很理想或者目标网站响应很慢，那么使用多线程和异步 I/O 的优势将更为明显，有兴趣的读者可以自行试验。\n", "使用Selenium抓取网页动态内容": "## 使用Selenium抓取网页动态内容\n\n根据权威机构发布的全球互联网可访问性审计报告，全球约有四分之三的网站其内容或部分内容是通过JavaScript动态生成的，这就意味着在浏览器窗口中“查看网页源代码”时无法在HTML代码中找到这些内容，也就是说我们之前用的抓取数据的方式无法正常运转了。解决这样的问题基本上有两种方案，一是获取提供动态内容的数据接口，这种方式也适用于抓取手机 App 的数据；另一种是通过自动化测试工具 Selenium 运行浏览器获取渲染后的动态内容。对于第一种方案，我们可以使用浏览器的“开发者工具”或者更为专业的抓包工具（如：Charles、Fiddler、Wireshark等）来获取到数据接口，后续的操作跟上一个章节中讲解的获取“360图片”网站的数据是一样的，这里我们不再进行赘述。这一章我们重点讲解如何使用自动化测试工具 Selenium 来获取网站的动态内容。\n\n### Selenium 介绍\n\nSelenium 是一个自动化测试工具，利用它可以驱动浏览器执行特定的行为，最终帮助爬虫开发者获取到网页的动态内容。简单的说，只要我们在浏览器窗口中能够看到的内容，都可以使用 Selenium 获取到，对于那些使用了 JavaScript 动态渲染技术的网站，Selenium 会是一个重要的选择。下面，我们还是以 Chrome 浏览器为例，来讲解 Selenium 的用法，大家需要先安装 Chrome 浏览器并下载它的驱动。Chrome 浏览器的驱动程序可以在[ChromeDriver官网](https://chromedriver.chromium.org/downloads)进行下载，驱动的版本要跟浏览器的版本对应，如果没有完全对应的版本，就选择版本代号最为接近的版本。\n\n<img class=\"lazy\" data-src=\"/res/20220310134558.png\" style=\"zoom:40%\">\n\n### 使用Selenium\n\n我们可以先通过`pip`来安装 Selenium，命令如下所示。\n\n```Shell\npip install selenium\n```\n\n#### 加载页面\n\n接下来，我们通过下面的代码驱动 Chrome 浏览器打开百度。\n\n```Python\nfrom selenium import webdriver\n\n# 创建Chrome浏览器对象\nbrowser = webdriver.Chrome()\n# 加载指定的页面\nbrowser.get('https://www.baidu.com/')\n```\n\n如果不愿意使用 Chrome 浏览器，也可以修改上面的代码操控其他浏览器，只需创建对应的浏览器对象（如 Firefox、Safari 等）即可。运行上面的程序，如果看到如下所示的错误提示，那是说明我们还没有将 Chrome 浏览器的驱动添加到 PATH 环境变量中，也没有在程序中指定 Chrome 浏览器驱动所在的位置。\n\n```Shell\nselenium.common.exceptions.WebDriverException: Message: 'chromedriver' executable needs to be in PATH. Please see https://sites.google.com/a/chromium.org/chromedriver/home\n```\n\n解决这个问题的办法有三种：\n\n1. 将下载的 ChromeDriver 放到已有的 PATH 环境变量下，建议直接跟 Python 解释器放在同一个目录，因为之前安装 Python 的时候我们已经将 Python 解释器的路径放到 PATH 环境变量中了。\n\n2. 将 ChromeDriver 放到项目虚拟环境下的 `bin` 文件夹中（Windows 系统对应的目录是 `Scripts`），这样 ChromeDriver 就跟虚拟环境下的 Python 解释器在同一个位置，肯定是能够找到的。\n\n3. 修改上面的代码，在创建 Chrome 对象时，通过`service`参数配置`Service`对象，并通过创建`Service`对象的`executable_path`参数指定 ChromeDriver 所在的位置，如下所示：\n\n    ```Python\n    from selenium import webdriver\n    from selenium.webdriver.chrome.service import Service\n    \n    browser = webdriver.Chrome(service=Service(executable_path='venv/bin/chromedriver'))\n    browser.get('https://www.baidu.com/')\n    ```\n\n#### 查找元素和模拟用户行为\n\n接下来，我们可以尝试模拟用户在百度首页的文本框输入搜索关键字并点击“百度一下”按钮。在完成页面加载后，可以通过`Chrome`对象的`find_element`和`find_elements`方法来获取页面元素，Selenium 支持多种获取元素的方式，包括：CSS 选择器、XPath、元素名字（标签名）、元素 ID、类名等，前者可以获取单个页面元素（`WebElement`对象），后者可以获取多个页面元素构成的列表。获取到`WebElement`对象以后，可以通过`send_keys`来模拟用户输入行为，可以通过`click`来模拟用户点击操作，代码如下所示。\n\n```Python\nfrom selenium import webdriver\nfrom selenium.webdriver.common.by import By\n\nbrowser = webdriver.Chrome()\nbrowser.get('https://www.baidu.com/')\n# 通过元素ID获取元素\nkw_input = browser.find_element(By.ID, 'kw')\n# 模拟用户输入行为\nkw_input.send_keys('Python')\n# 通过CSS选择器获取元素\nsu_button = browser.find_element(By.CSS_SELECTOR, '#su')\n# 模拟用户点击行为\nsu_button.click()\n```\n\n如果要执行一个系列动作，例如模拟拖拽操作，可以创建`ActionChains`对象，有兴趣的读者可以自行研究。\n\n#### 隐式等待和显式等待\n\n这里还有一个细节需要大家知道，网页上的元素可能是动态生成的，在我们使用`find_element`或`find_elements`方法获取的时候，可能还没有完成渲染，这时会引发`NoSuchElementException`错误。为了解决这个问题，我们可以使用隐式等待的方式，通过设置等待时间让浏览器完成对页面元素的渲染。除此之外，我们还可以使用显示等待，通过创建`WebDriverWait`对象，并设置等待时间和条件，当条件没有满足时，我们可以先等待再尝试进行后续的操作，具体的代码如下所示。\n\n```Python\nfrom selenium import webdriver\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver.support import expected_conditions\nfrom selenium.webdriver.support.wait import WebDriverWait\n\nbrowser = webdriver.Chrome()\n# 设置浏览器窗口大小\nbrowser.set_window_size(1200, 800)\nbrowser.get('https://www.baidu.com/')\n# 设置隐式等待时间为10秒\nbrowser.implicitly_wait(10)\nkw_input = browser.find_element(By.ID, 'kw')\nkw_input.send_keys('Python')\nsu_button = browser.find_element(By.CSS_SELECTOR, '#su')\nsu_button.click()\n# 创建显示等待对象\nwait_obj = WebDriverWait(browser, 10)\n# 设置等待条件（等搜索结果的div出现）\nwait_obj.until(\n    expected_conditions.presence_of_element_located(\n        (By.CSS_SELECTOR, '#content_left')\n    )\n)\n# 截屏\nbrowser.get_screenshot_as_file('python_result.png')\n```\n\n上面设置的等待条件`presence_of_element_located`表示等待指定元素出现，下面的表格列出了常用的等待条件及其含义。\n\n| 等待条件                                 | 具体含义                              |\n| ---------------------------------------- | ------------------------------------- |\n| `title_is / title_contains`              | 标题是指定的内容 / 标题包含指定的内容 |\n| `visibility_of`                          | 元素可见                              |\n| `presence_of_element_located`            | 定位的元素加载完成                    |\n| `visibility_of_element_located`          | 定位的元素变得可见                    |\n| `invisibility_of_element_located`        | 定位的元素变得不可见                  |\n| `presence_of_all_elements_located`       | 定位的所有元素加载完成                |\n| `text_to_be_present_in_element`          | 元素包含指定的内容                    |\n| `text_to_be_present_in_element_value`    | 元素的`value`属性包含指定的内容       |\n| `frame_to_be_available_and_switch_to_it` | 载入并切换到指定的内部窗口            |\n| `element_to_be_clickable`                | 元素可点击                            |\n| `element_to_be_selected`                 | 元素被选中                            |\n| `element_located_to_be_selected`         | 定位的元素被选中                      |\n| `alert_is_present`                       | 出现 Alert 弹窗                       |\n\n#### 执行JavaScript代码\n\n对于使用瀑布式加载的页面，如果希望在浏览器窗口中加载更多的内容，可以通过浏览器对象的`execute_scripts`方法执行 JavaScript 代码来实现。对于一些高级的爬取操作，也很有可能会用到类似的操作，如果你的爬虫代码需要 JavaScript 的支持，建议先对 JavaScript 进行适当的了解，尤其是 JavaScript 中的 BOM 和 DOM 操作。我们在上面的代码中截屏之前加入下面的代码，这样就可以利用 JavaScript 将网页滚到最下方。\n\n```Python\n# 执行JavaScript代码\nbrowser.execute_script('document.documentElement.scrollTop = document.documentElement.scrollHeight')\n```\n\n#### Selenium反爬的破解\n\n有一些网站专门针对 Selenium 设置了反爬措施，因为使用 Selenium 驱动的浏览器，在控制台中可以看到如下所示的`webdriver`属性值为`true`，如果要绕过这项检查，可以在加载页面之前，先通过执行 JavaScript 代码将其修改为`undefined`。\n\n<img class=\"lazy\" data-src=\"/res/20220310154246.png\" style=\"zoom:50%\">\n\n另一方面，我们还可以将浏览器窗口上的“Chrome正受到自动测试软件的控制”隐藏掉，完整的代码如下所示。\n\n```Python\n# 创建Chrome参数对象\noptions = webdriver.ChromeOptions()\n# 添加试验性参数\noptions.add_experimental_option('excludeSwitches', ['enable-automation'])\noptions.add_experimental_option('useAutomationExtension', False)\n# 创建Chrome浏览器对象并传入参数\nbrowser = webdriver.Chrome(options=options)\n# 执行Chrome开发者协议命令（在加载页面时执行指定的JavaScript代码）\nbrowser.execute_cdp_cmd(\n    'Page.addScriptToEvaluateOnNewDocument',\n    {'source': 'Object.defineProperty(navigator, \"webdriver\", {get: () => undefined})'}\n)\nbrowser.set_window_size(1200, 800)\nbrowser.get('https://www.baidu.com/')\n```\n\n#### 无头浏览器\n\n很多时候，我们在爬取数据时并不需要看到浏览器窗口，只要有 Chrome 浏览器以及对应的驱动程序，我们的爬虫就能够运转起来。如果不想看到浏览器窗口，我们可以通过下面的方式设置使用无头浏览器。\n\n```Python\noptions = webdriver.ChromeOptions()\noptions.add_argument('--headless')\nbrowser = webdriver.Chrome(options=options)\n```\n\n### API参考\n\nSelenium 相关的知识还有很多，我们在此就不一一赘述了，下面为大家罗列一些浏览器对象和`WebElement`对象常用的属性和方法。具体的内容大家还可以参考 Selenium [官方文档的中文翻译](https://selenium-python-zh.readthedocs.io/en/latest/index.html)。\n\n#### 浏览器对象\n\n表1. 常用属性\n\n| 属性名                  | 描述                             |\n| ----------------------- | -------------------------------- |\n| `current_url`           | 当前页面的URL                    |\n| `current_window_handle` | 当前窗口的句柄（引用）           |\n| `name`                  | 浏览器的名称                     |\n| `orientation`           | 当前设备的方向（横屏、竖屏）     |\n| `page_source`           | 当前页面的源代码（包括动态内容） |\n| `title`                 | 当前页面的标题                   |\n| `window_handles`        | 浏览器打开的所有窗口的句柄       |\n\n表2. 常用方法\n\n| 方法名                                 | 描述                                |\n| -------------------------------------- | ----------------------------------- |\n| `back` / `forward`                     | 在浏览历史记录中后退/前进           |\n| `close` / `quit`                       | 关闭当前浏览器窗口 / 退出浏览器实例 |\n| `get`                                  | 加载指定 URL 的页面到浏览器中       |\n| `maximize_window`                      | 将浏览器窗口最大化                  |\n| `refresh`                              | 刷新当前页面                        |\n| `set_page_load_timeout`                | 设置页面加载超时时间                |\n| `set_script_timeout`                   | 设置 JavaScript 执行超时时间        |\n| `implicit_wait`                        | 设置等待元素被找到或目标指令完成    |\n| `get_cookie` / `get_cookies`           | 获取指定的Cookie / 获取所有Cookie   |\n| `add_cookie`                           | 添加 Cookie 信息                    |\n| `delete_cookie` / `delete_all_cookies` | 删除指定的 Cookie / 删除所有 Cookie |\n| `find_element` / `find_elements`       | 查找单个元素 / 查找一系列元素       |\n\n#### WebElement对象\n\n表1. WebElement常用属性\n\n| 属性名     | 描述           |\n| ---------- | -------------- |\n| `location` | 元素的位置     |\n| `size`     | 元素的尺寸     |\n| `text`     | 元素的文本内容 |\n| `id`       | 元素的 ID      |\n| `tag_name` | 元素的标签名   |\n\n表2. 常用方法\n\n| 方法名                           | 描述                                 |\n| -------------------------------- | ------------------------------------ |\n| `clear`                          | 清空文本框或文本域中的内容           |\n| `click`                          | 点击元素                             |\n| `get_attribute`                  | 获取元素的属性值                     |\n| `is_displayed`                   | 判断元素对于用户是否可见             |\n| `is_enabled`                     | 判断元素是否处于可用状态             |\n| `is_selected`                    | 判断元素（单选框和复选框）是否被选中 |\n| `send_keys`                      | 模拟输入文本                         |\n| `submit`                         | 提交表单                             |\n| `value_of_css_property`          | 获取指定的CSS属性值                  |\n| `find_element` / `find_elements` | 获取单个子元素 / 获取一系列子元素    |\n| `screenshot`                     | 为元素生成快照                       |\n\n### 简单案例\n\n下面的例子演示了如何使用 Selenium 从“360图片”网站搜索和下载图片。\n\n```Python\nimport os\nimport time\nfrom concurrent.futures import ThreadPoolExecutor\n\nimport requests\nfrom selenium import webdriver\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver.common.keys import Keys\n\nDOWNLOAD_PATH = 'images/'\n\n\ndef download_picture(picture_url: str):\n    \"\"\"\n    下载保存图片\n    :param picture_url: 图片的URL\n    \"\"\"\n    filename = picture_url[picture_url.rfind('/') + 1:]\n    resp = requests.get(picture_url)\n    with open(os.path.join(DOWNLOAD_PATH, filename), 'wb') as file:\n        file.write(resp.content)\n\n\nif not os.path.exists(DOWNLOAD_PATH):\n    os.makedirs(DOWNLOAD_PATH)\nbrowser = webdriver.Chrome()\nbrowser.get('https://image.so.com/z?ch=beauty')\nbrowser.implicitly_wait(10)\nkw_input = browser.find_element(By.CSS_SELECTOR, 'input[name=q]')\nkw_input.send_keys('苍老师')\nkw_input.send_keys(Keys.ENTER)\nfor _ in range(10):\n    browser.execute_script(\n        'document.documentElement.scrollTop = document.documentElement.scrollHeight'\n    )\n    time.sleep(1)\nimgs = browser.find_elements(By.CSS_SELECTOR, 'div.waterfall img')\nwith ThreadPoolExecutor(max_workers=32) as pool:\n    for img in imgs:\n        pic_url = img.get_attribute('src')\n        pool.submit(download_picture, pic_url)\n```\n\n运行上面的代码，检查指定的目录下是否下载了根据关键词搜索到的图片。\n", "爬虫框架Scrapy简介": "## 爬虫框架Scrapy简介\n\n当你写了很多个爬虫程序之后，你会发现每次写爬虫程序时，都需要将页面获取、页面解析、爬虫调度、异常处理、反爬应对这些代码从头至尾实现一遍，这里面有很多工作其实都是简单乏味的重复劳动。那么，有没有什么办法可以提升我们编写爬虫代码的效率呢？答案是肯定的，那就是利用爬虫框架，而在所有的爬虫框架中，Scrapy 应该是最流行、最强大的框架。\n\n### Scrapy 概述\n\nScrapy 是基于 Python 的一个非常流行的网络爬虫框架，可以用来抓取 Web 站点并从页面中提取结构化的数据。下图展示了 Scrapy 的基本架构，其中包含了主要组件和系统的数据处理流程（图中带数字的红色箭头）。\n\n<img class=\"lazy\" data-src=\"/res/20210824003638.png\" style=\"zoom:50%;\">\n\n#### Scrapy的组件\n\n我们先来说说 Scrapy 中的组件。\n\n1. Scrapy 引擎（Engine）：用来控制整个系统的数据处理流程。\n2. 调度器（Scheduler）：调度器从引擎接受请求并排序列入队列，并在引擎发出请求后返还给它们。\n3. 下载器（Downloader）：下载器的主要职责是抓取网页并将网页内容返还给蜘蛛（Spiders）。\n4. 蜘蛛程序（Spiders）：蜘蛛是用户自定义的用来解析网页并抓取特定URL的类，每个蜘蛛都能处理一个域名或一组域名，简单的说就是用来定义特定网站的抓取和解析规则的模块。\n5. 数据管道（Item Pipeline）：管道的主要责任是负责处理有蜘蛛从网页中抽取的数据条目，它的主要任务是清理、验证和存储数据。当页面被蜘蛛解析后，将被发送到数据管道，并经过几个特定的次序处理数据。每个数据管道组件都是一个 Python 类，它们获取了数据条目并执行对数据条目进行处理的方法，同时还需要确定是否需要在数据管道中继续执行下一步或是直接丢弃掉不处理。数据管道通常执行的任务有：清理 HTML 数据、验证解析到的数据（检查条目是否包含必要的字段）、检查是不是重复数据（如果重复就丢弃）、将解析到的数据存储到数据库（关系型数据库或 NoSQL 数据库）中。\n6. 中间件（Middlewares）：中间件是介于引擎和其他组件之间的一个钩子框架，主要是为了提供自定义的代码来拓展 Scrapy 的功能，包括下载器中间件和蜘蛛中间件。\n\n#### 数据处理流程\n\nScrapy 的整个数据处理流程由引擎进行控制，通常的运转流程包括以下的步骤：\n\n1. 引擎询问蜘蛛需要处理哪个网站，并让蜘蛛将第一个需要处理的 URL 交给它。\n\n2. 引擎让调度器将需要处理的 URL 放在队列中。\n\n3. 引擎从调度那获取接下来进行爬取的页面。\n\n4. 调度将下一个爬取的 URL 返回给引擎，引擎将它通过下载中间件发送到下载器。\n\n5. 当网页被下载器下载完成以后，响应内容通过下载中间件被发送到引擎；如果下载失败了，引擎会通知调度器记录这个 URL，待会再重新下载。\n\n6. 引擎收到下载器的响应并将它通过蜘蛛中间件发送到蜘蛛进行处理。\n\n7. 蜘蛛处理响应并返回爬取到的数据条目，此外还要将需要跟进的新的 URL 发送给引擎。\n\n8. 引擎将抓取到的数据条目送入数据管道，把新的 URL 发送给调度器放入队列中。\n\n上述操作中的第2步到第8步会一直重复直到调度器中没有需要请求的 URL，爬虫就停止工作。\n\n### 安装和使用Scrapy\n\n可以使用 Python 的包管理工具`pip`来安装 Scrapy。\n\n```Shell\npip install scrapy\n```\n\n在命令行中使用`scrapy`命令创建名为`demo`的项目。\n\n```Bash\nscrapy startproject demo\n```\n\n项目的目录结构如下图所示。\n\n```Shell\ndemo\n|____ demo\n|________ spiders\n|____________ __init__.py\n|________ __init__.py\n|________ items.py\n|________ middlewares.py\n|________ pipelines.py\n|________ settings.py\n|____ scrapy.cfg\n```\n\n切换到`demo` 目录，用下面的命令创建名为`douban`的蜘蛛程序。\n\n```Bash\nscrapy genspider douban movie.douban.com\n```\n\n#### 一个简单的例子\n\n接下来，我们实现一个爬取豆瓣电影 Top250 电影标题、评分和金句的爬虫。\n\n1. 在`items.py`的`Item`类中定义字段，这些字段用来保存数据，方便后续的操作。\n\n   ```Python\n   import scrapy\n   \n   \n   class DoubanItem(scrapy.Item):\n       title = scrapy.Field()\n       score = scrapy.Field()\n       motto = scrapy.Field()\n   ```\n   \n2. 修改`spiders`文件夹中名为`douban.py` 的文件，它是蜘蛛程序的核心，需要我们添加解析页面的代码。在这里，我们可以通过对`Response`对象的解析，获取电影的信息，代码如下所示。\n\n   ```Python\n   import scrapy\n   from scrapy import Selector, Request\n   from scrapy.http import HtmlResponse\n   \n   from demo.items import MovieItem\n   \n   \n   class DoubanSpider(scrapy.Spider):\n       name = 'douban'\n       allowed_domains = ['movie.douban.com']\n       start_urls = ['https://movie.douban.com/top250?start=0&filter=']\n   \n       def parse(self, response: HtmlResponse):\n           sel = Selector(response)\n           movie_items = sel.css('#content > div > div.article > ol > li')\n           for movie_sel in movie_items:\n               item = MovieItem()\n               item['title'] = movie_sel.css('.title::text').extract_first()\n               item['score'] = movie_sel.css('.rating_num::text').extract_first()\n               item['motto'] = movie_sel.css('.inq::text').extract_first()\n               yield item\n   ```\n   通过上面的代码不难看出，我们可以使用 CSS 选择器进行页面解析。当然，如果你愿意也可以使用 XPath 或正则表达式进行页面解析，对应的方法分别是`xpath`和`re`。\n\n   如果还要生成后续爬取的请求，我们可以用`yield`产出`Request`对象。`Request`对象有两个非常重要的属性，一个是`url`，它代表了要请求的地址；一个是`callback`，它代表了获得响应之后要执行的回调函数。我们可以将上面的代码稍作修改。\n\n   ```Python\n   import scrapy\n   from scrapy import Selector, Request\n   from scrapy.http import HtmlResponse\n   \n   from demo.items import MovieItem\n   \n   \n   class DoubanSpider(scrapy.Spider):\n       name = 'douban'\n       allowed_domains = ['movie.douban.com']\n       start_urls = ['https://movie.douban.com/top250?start=0&filter=']\n   \n       def parse(self, response: HtmlResponse):\n           sel = Selector(response)\n           movie_items = sel.css('#content > div > div.article > ol > li')\n           for movie_sel in movie_items:\n               item = MovieItem()\n               item['title'] = movie_sel.css('.title::text').extract_first()\n               item['score'] = movie_sel.css('.rating_num::text').extract_first()\n               item['motto'] = movie_sel.css('.inq::text').extract_first()\n               yield item\n   \n           hrefs = sel.css('#content > div > div.article > div.paginator > a::attr(\"href\")')\n           for href in hrefs:\n               full_url = response.urljoin(href.extract())\n               yield Request(url=full_url)\n   ```\n\n   到这里，我们已经可以通过下面的命令让爬虫运转起来。\n\n   ```Shell\n   scrapy crawl movie\n   ```\n\n   可以在控制台看到爬取到的数据，如果想将这些数据保存到文件中，可以通过`-o`参数来指定文件名，Scrapy 支持我们将爬取到的数据导出成 JSON、CSV、XML 等格式。\n\n   ```Shell\n   scrapy crawl moive -o result.json\n   ```\n\n   不知大家是否注意到，通过运行爬虫获得的 JSON 文件中有`275`条数据，那是因为首页被重复爬取了。要解决这个问题，可以对上面的代码稍作调整，不在`parse`方法中解析获取新页面的 URL，而是通过`start_requests`方法提前准备好待爬取页面的 URL，调整后的代码如下所示。\n\n   ```Python\n   import scrapy\n   from scrapy import Selector, Request\n   from scrapy.http import HtmlResponse\n   \n   from demo.items import MovieItem\n   \n   \n   class DoubanSpider(scrapy.Spider):\n       name = 'douban'\n       allowed_domains = ['movie.douban.com']\n   \n       def start_requests(self):\n           for page in range(10):\n               yield Request(url=f'https://movie.douban.com/top250?start={page * 25}')\n   \n       def parse(self, response: HtmlResponse):\n           sel = Selector(response)\n           movie_items = sel.css('#content > div > div.article > ol > li')\n           for movie_sel in movie_items:\n               item = MovieItem()\n               item['title'] = movie_sel.css('.title::text').extract_first()\n               item['score'] = movie_sel.css('.rating_num::text').extract_first()\n               item['motto'] = movie_sel.css('.inq::text').extract_first()\n               yield item\n   ```\n\n3. 如果希望完成爬虫数据的持久化，可以在数据管道中处理蜘蛛程序产生的`Item`对象。例如，我们可以通过前面讲到的`openpyxl`操作 Excel 文件，将数据写入 Excel 文件中，代码如下所示。\n\n   ```Python\n   import openpyxl\n   \n   from demo.items import MovieItem\n   \n   \n   class MovieItemPipeline:\n   \n       def __init__(self):\n           self.wb = openpyxl.Workbook()\n           self.sheet = self.wb.active\n           self.sheet.title = 'Top250'\n           self.sheet.append(('名称', '评分', '名言'))\n   \n       def process_item(self, item: MovieItem, spider):\n           self.sheet.append((item['title'], item['score'], item['motto']))\n           return item\n   \n       def close_spider(self, spider):\n           self.wb.save('豆瓣电影数据.xlsx')\n   ```\n\n   上面的`process_item`和`close_spider`都是回调方法（钩子函数）， 简单的说就是 Scrapy 框架会自动去调用的方法。当蜘蛛程序产生一个`Item`对象交给引擎时，引擎会将该`Item`对象交给数据管道，这时我们配置好的数据管道的`parse_item`方法就会被执行，所以我们可以在该方法中获取数据并完成数据的持久化操作。另一个方法`close_spider`是在爬虫结束运行前会自动执行的方法，在上面的代码中，我们在这个地方进行了保存 Excel 文件的操作，相信这段代码大家是很容易读懂的。\n\n   总而言之，数据管道可以帮助我们完成以下操作：\n\n   - 清理 HTML 数据，验证爬取的数据。\n   - 丢弃重复的不必要的内容。\n   - 将爬取的结果进行持久化操作。\n\n4. 修改`settings.py`文件对项目进行配置，主要需要修改以下几个配置。\n\n   ```Python\n   # 用户浏览器\n   USER_AGENT = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.159 Safari/537.36'\n   \n   # 并发请求数量 \n   CONCURRENT_REQUESTS = 4\n   \n   # 下载延迟\n   DOWNLOAD_DELAY = 3\n   # 随机化下载延迟\n   RANDOMIZE_DOWNLOAD_DELAY = True\n   \n   # 是否遵守爬虫协议\n   ROBOTSTXT_OBEY = True\n   \n   # 配置数据管道\n   ITEM_PIPELINES = {\n      'demo.pipelines.MovieItemPipeline': 300,\n   }\n   ```\n\n   > **说明**：上面配置文件中的`ITEM_PIPELINES`选项是一个字典，可以配置多个处理数据的管道，后面的数字代表了执行的优先级，数字小的先执行。\n\n", "数据分析概述": "## 数据分析概述\n\n当今世界，各行各业对信息技术的依赖程度在不断加深，每天都会有大量的数据产生，我们常常会感到数据越来越多，但是要从中发现有价值的信息却越来越难。这里所说的信息，可以理解为对数据集处理之后的结果，是从数据集中提炼出的可用于支撑和指导决策的东西，而**从原始数据中抽取出有价值的信息**的这个过程我们就称之为**数据分析**，它是数据科学的重要组成部分。\n\n<img class=\"lazy\" data-src=\"/res/data_science.png\" style=\"zoom:50%;\">\n\n> **定义1**：数据分析是有针对性的收集、加工、整理数据并采用统计、挖掘等技术对数据进行探索、分析、呈现和解释的科学。\n>\n> **定义2**：数据分析是通过收集、整理和分析数据，从中提取有价值的信息和洞察，以支持决策和优化过程的活动。（GPT-4o）\n>\n> **定义3**：数据分析是通过系统性的收集、整理、处理、检验和解释数据，从中提取有价值的信息、形成结论并支持决策的过程，其核心是利用统计、算法和逻辑方法揭示数据背后的规律、趋势或关联。（DeepSeek）\n\n对于想从事数据分析工作的人来说，需要掌握两个部分的技能，一是“数据思维”，二是“分析工具”，如下图所示。\n\n![](/res/contents_of_data_analysis.png)\n\n上图中，分析工具部分其实是比较容易掌握的，像 SQL 或 Python 这样的编程语言，只要经过系统的学习和适量的练习，大部分人都是可以驾驭的；像 Power BI、Tableau 这样的商业智能工具，更是让我们通过“拖拉拽”操作就能完成数据的可视化并在此基础上产生商业洞察，上手难度会更低。相反，数据思维部分的内容对大多数新手来说是不太容易驾驭的，例如“统计思维”，很多人在读书的时候都学习过“概率论和统计学”这样的课程，但是当面对实际的业务场景时，却很难将这些知识映射到业务场景来解决现实的问题。此外，如果没有掌握基本的分析方法、没有理解常用的分析模型，没有相关业务知识的积累，即便我们拿到再多有用的数据，也会感觉无从下手，更不用说产生业务洞察发现商业价值了。所以，数据思维这个部分，除了系统的学习相关知识技能，还需要不断的在实际业务场景中积累和沉淀。\n\n### 数据分析师的职责\n\nHR在发布招聘需求时，通常将数据工程、数据分析、数据挖掘等岗位都统称为数据分析岗位，但是根据工作性质的不同，又可以分为偏工程的**数据治理方向**、偏业务的**商业分析方向**、偏算法的**数据挖掘方向**、偏应用的**数据开发方向**、偏产品的**数据产品经理**。我们通常所说的数据分析师主要是指**业务数据分析师**，很多数据分析师的职业生涯都是从这个岗位开始的，而且这个岗位也是招聘数量最多的岗位。有些公司会将业务数据分析师归属到具体的业务部门（市场、运营、产品等），有些公司有专门的数据部门（数据分析团队或数据科学团队），还有些公司数据分析师会直接服务高层决策，属于企业战略部门。正因如此，你在招聘网站上看到的把数据分析师称为**数据运营**、**商业分析师**、**BI工程师**就不会感到奇怪了。通常，我们在招聘网站看到的对业务数据分析师岗位职责（JD）的描述如下所示：\n\n1. 负责相关报表的输出。\n2. 建立和优化指标体系。\n3. 监控数据波动和异常，找出问题。\n4. 优化和驱动业务，推动数字化运营。\n5. 找出潜在的市场和产品的上升空间。\n\n根据上面的描述，作为业务数据分析师，我们的工作不是给出一个简单浅显的结论，而是结合公司的业务，完成**监控数据**、**揪出异常**、**找到原因**、**探索趋势**等工作。不管你是用 Python 语言、Excel、Tableau、SPSS或其他的商业智能工具，工具只是达成目标的手段，**数据思维是核心技能**，从实际业务问题出发到最终**发现数据中的商业价值**是终极目标。数据分析师在很多公司只是一个基础岗位，精于业务的数据分析师可以向**数据分析经理**或**数据运营总监**等管理岗位发展；对于熟悉机器学习算法的数据分析师来说，可以向**数据挖掘工程师**或**算法专家**方向发展，这些岗位除了需要相应的数学和统计学知识，在编程能力方面也比数据分析师有更高的要求，可能还需要有大数据存储和处理的相关经验。\n\n这里顺便说一下其他几个方向，数据治理岗位主要是帮助公司建设数据仓库或数据湖，实现数据从业务系统、埋点系统、日志系统到数据仓库或数据湖的转移，为后续的数据分析和挖掘提供基础设施。数据治理岗位对 SQL 和 HiveSQL 有着较高的要求，需要熟练的使用 ETL 工具，此外还需要对 Hadoop 生态圈有较好的认知。作为数据产品经理，除了传统产品经理的技能栈之外，也需要较强的技术能力，例如要了解常用的推荐算法、机器学习模型，能够为算法的改进提供依据，能够制定相关埋点的规范和口径，虽然不需要精通各种算法，但是要站在产品的角度去考虑数据模型、指标、算法等的落地。\n\n### 数据分析师的技能栈\n\n数据分析师的技能栈也包括硬技能和软技能，以下是我对这个职位的理解，仅供参考。\n\n1. 计算机科学（数据分析工具、编程语言、数据库）\n2. 数学和统计学（数据思维、统计思维）\n3. 人工智能（机器学习和深度学习算法）\n4. 业务理解能力（沟通、表达、经验）\n5. 总结和表述能力（总结、汇报、商业 PPT）\n\n当然，对于一个新手来收，不可能用短时间掌握整个技能栈的内容，但是随着这份工作的深入，上面提到的东西多多少少都会涉猎到，大家可以根据实际工作的需求去深耕其中的某个或某些技能。\n\n### 数据分析通用流程\n\n我们提到数据分析这个词很多时候可能指的都是**狭义的数据分析**，这类数据分析主要目标就是生成可视化报表并通过这些报表来洞察业务中的问题，这类工作一般都是具有滞后性的。**广义的数据分析**还包含了数据挖掘的部分，不仅要通过数据实现对业务的监控和分析，还要利用机器学习算法，找出隐藏在数据背后的知识，并利用这些知识为将来的决策提供支撑，具备一定的前瞻性。\n\n基本的数据分析工作一般包含以下几个方面的内容，当然因为行业和工作内容的不同会略有差异。\n\n1. 确定目标（输入）：理解业务，确定指标口径\n2. 获取数据：数据仓库、电子表格、三方接口、网络爬虫、开放数据集等\n3. 清洗数据：缺失值、重复值、异常值的处理以及其他预处理（格式化、离散化、二值化等）\n4. 数据透视：排序、统计、分组聚合、交叉表、透视表等\n5. 数据呈现（输出）：数据可视化，发布工作成果（数据分析报告）\n6. 分析洞察（后续）：解释数据的变化，提出对应的方案\n\n深入的数据挖掘工作通常包含以下几个方面的内容，当然因为行业和工作内容的不同会略有差异。\n\n1. 确定目标（输入）：理解业务，明确挖掘目标\n2. 数据准备：数据采集、数据描述、数据探索、质量判定等\n3. 数据加工：提取数据、清洗数据、数据变换、特殊编码、降维、特征选择等\n4. 数据建模：模型比较、模型选择、算法应用\n5. 模型评估：交叉检验、参数调优、结果评价\n6. 模型部署（输出）：模型落地、业务改进、运营监控、报告撰写\n\n### 数据分析相关库\n\n使用 Python 从事数据分析相关的工作是一个非常棒的选择，首先 Python 语言非常容易上手，而且整个 Python 生态圈中，有非常多成熟的用于数据科学的软件包和工具库。不同于其他的数据科学编程语言（如：Julia、R等），Python 除了可以用于数据科学，还能做很多其他的事情。\n\n#### 经典的三大神器\n\n1. [NumPy](https://numpy.org/)：支持常见的数组和矩阵操作，通过`ndarray`类实现了对多维数组的封装，提供了操作这些数组的方法和函数。由于 NumPy 内置了并行运算功能，当使用多核 CPU 时，NumPy 会自动做并行计算。\n2. [Pandas](https://pandas.pydata.org/)：pandas 的核心是其特有的数据结构`DataFrame`和`Series`，这使得 pandas 可以处理包含不同类型数据的表格和时间序列，这一点是 NumPy 的`ndarray`做不到的。使用 pandas，可以轻松顺利的加载各种形式的数据，然后对数据进行切片、切块、重塑、清洗、聚合、呈现等操作。\n3. [Matplotlib](https://matplotlib.org/)：matplotlib 是一个包含各种绘图模块的库，能够根据我们提供的数据创建高质量的图表。此外，matplotlib 还提供了 pylab 模块，这个模块包含了很多像 [MATLAB](https://www.mathworks.com/products/matlab.html) 一样的绘图组件。\n\n#### 其他相关库\n\n1. [SciPy](https://scipy.org/)：完善了 NumPy 的功能，封装了大量科学计算的算法，包括线性代数、统计检验、稀疏矩阵、信号和图像处理、最优化问题、快速傅里叶变换等。\n2. [Polars](https://pola.rs/)：一个高性能的数据分析库，旨在提供比 pandas 更快的数据操作。它支持大规模数据处理，并能够利用多核 CPU 来加速计算，在处理大规模数据集时可以用来替代 pandas。\n3. [Seaborn](https://seaborn.pydata.org/)：seaborn 是基于 matplotlib 的图形可视化工具，直接使用 matplotlib 虽然可以定制出漂亮的统计图表，但是总体来说还不够简单方便，seaborn 相当于是对 matplotlib 做了封装，让用户能够以更简洁有效的方式做出各种有吸引力的统计图表。\n4. [Scikit-learn](https://scikit-learn.org/)：scikit-learn 最初是 SciPy 的一部分，提供了大量机器学习可能用到的工具，包括数据预处理、监督学习（分类、回归）、无监督学习（聚类）、模式选择、交叉检验等。\n5. [Statsmodels](https://www.statsmodels.org/stable/index.html)：包含了经典统计学和计量经济学算法的库，帮助帮助用户完成数据探索、回归分析、假设检验等任务。\n6. [PySpark](https://spark.apache.org/)：Apache Spark（大数据处理引擎）的 Python 版本，用于大规模数据处理和分布式计算，能够在分布式环境中高效地进行数据清洗、转化和分析。\n7. [Tensorflow](https://www.tensorflow.org/)：TensorFlow 是一个开源的深度学习框架，由 Google 开发，主要面向深度学习任务，常用于构建和训练机器学习模型（尤其是复杂的神经网络模型）。\n8. [Keras](https://keras.io/)：Keras 是一个高层次的神经网络 API，主要用于构建和训练深度学习模型。Keras 适合深度学习初学者和研究人员，因为它让构建和训练神经网络变得更加简单。\n9. [PyTorch](https://pytorch.org/)：PyTorch 是一个开源的深度学习框架，由 Facebook 开发，广泛用于研究和生产环境。PyTorch 是深度学习研究中的热门框架，在计算机视觉、自然语言处理等领域得到了广泛应用。\n10. [NLTK](https://www.nltk.org/) / [SpaCy](https://spacy.io/)：自然语言处理（NLP）库。\n", "环境准备": "## 环境准备\n\n如果希望快速开始使用 Python 处理数据科学相关的工作，建议大家直接安装 Anaconda，然后使用 Anaconda 中集成的 Notebook 或 JupyterLab 工具来编写代码。因为对于新手来说，先安装官方的 Python 解释器，再逐个安装工作中会使用到的三方库文件会比较麻烦，尤其是在 Windows 环境下，经常会因为构建工具或 DLL 文件的缺失导致安装失败，而一般新手也很难根据错误提示信息采取正确的解决措施，容易产生严重的挫败感。如果计算机上已经有 Python 解释器环境了，也可以直接使用 Python 的包管理工具 pip 安装 Jupyter，再根据实际工作的需要安装三方库，这种方式适合有一定经验的用户。\n\n### 安装和使用 Anaconda\n\n对于个人用户来说，可以从 Anaconda 的[官方网站](https://www.anaconda.com/)下载它的“个人版（Individual Edition）”安装程序，安装完成后，你的计算机上不仅拥有了 Python 环境和 Spyder（类似于 PyCharm 的集成开发工具），还拥有了与数据科学工作相关的近200个工具包，包括我们上面提到 Python 数据分析三大神器。除此之外，Anaconda 还提供了一个名为 conda 的包管理工具，通过这个工具不仅可以管理 Python 的工具包，还可以用于创建运行 Python 程序的虚拟环境。\n\n<img class=\"lazy\" data-src=\"/res/download-anaconda.png\" style=\"zoom:50%;\">\n\n如上图所示，可以通过 Anaconda 官网提供的下载链接选择适合自己操作系统的安装程序，建议大家选择图形化的安装程序，下载完成后双击安装程序开始安装。安装过程基本使用默认设置即可，完成安装后，macOS 用户可以在“应用程序”或“启动台”中找到名为“Anaconda-Navigator”的应用程序，运行该程序可以看到如下所示的界面，我们可以在这里选择需要执行的操作。\n\n<img class=\"lazy\" data-src=\"/res/anaconda_navigator.png\" style=\"zoom:50%;\">\n\n对于 Windows 用户，建议按照安装向导的提示和推荐的选项来安装 Anaconda（除了安装路径，基本也没有什么需要选择的），安装完成后可以在“开始菜单”中找到“Anaconda3”。\n\n> **提示**：可以选择 Miniconda 作为 Anaconda 的替代品，Miniconda 只会安装 Python 解释器环境和一些必要的工具，其他的三方库由用户自行选择安装。**其实我个人并不喜欢 Anaconda，因为它是给小白用户使用的，我们有了 Python 环境以后完全可以按照自己的意愿来安装需要的三方库**。\n\n#### conda命令\n\n对于非新手用户，如果希望使用 conda 工具来管理依赖项或者创建项目的虚拟环境，可以在终端或命令行提示符中使用 conda 命令。Windows 用户可以在“开始菜单”中找到“Anaconda3”，然后点击“Anaconda Prompt”或“Anaconda PowerShell”来启动支持 conda 的命令行提示符。新手用户如果想创建新的虚拟环境或管理三方库（依赖项），建议直接使用“Anaconda-Navigator”中的“Environments”，通过可视化的方式对虚拟环境和依赖项进行管理。\n\n1. 版本和帮助信息。\n\n    - 查看版本：`conda -V`或`conda --version`\n    - 获取帮助：`conda -h`或`conda --help`\n    - 相关信息：`conda list`\n\n2. 虚拟环境相关。\n\n    - 显示所有虚拟环境：`conda env list`\n    - 创建虚拟环境：`conda create --name venv`\n    - 指定 Python 版本创建虚拟环境：`conda create --name venv python=3.7`\n    - 指定 Python 版本创建虚拟环境并安装指定依赖项：`conda create --name venv python=3.7 numpy pandas`\n    - 通过克隆现有虚拟环境的方式创建虚拟环境：`conda create --name venv2 --clone venv`\n    - 分享虚拟环境并重定向到指定的文件中：`conda env export > environment.yml`\n    - 通过分享的虚拟环境文件创建虚拟环境：`conda env create -f environment.yml`\n    - 激活虚拟环境：`conda activate venv`\n    - 退出虚拟环境：`conda deactivate`\n    - 删除虚拟环境：`conda remove --name venv --all`\n\n    > **说明**：上面的命令中，`venv`和`venv2`是虚拟环境文件夹的名字，可以将其替换为自己喜欢的名字，但是**强烈建议**使用英文且不要有特殊字符。\n\n3. 包（三方库或工具）管理。\n\n    - 查看已经安装的包：`conda list`\n    - 搜索指定的包：`conda search matplotlib`\n    - 安装指定的包：`conda install matplotlib`\n    - 更新指定的包：`conda update matplotlib`\n    - 移除指定的包：`conda remove matplotlib`\n\n    > **说明**：在搜索、安装和更新软件包时，默认会连接到官方网站进行操作，如果觉得速度不给力，可以将默认的官方网站替换为国内的镜像网站，推荐使用清华大学的开源镜像网站。将默认源更换为国内镜像的命令是：`conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/`和`conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main`。如果需要换回默认源，可以使用命令`conda config --remove-key channels`。\n\n### 安装和使用JupyterLab\n\n#### 安装和启动\n\n如果已经安装了 Anaconda，可以按照上面所说的方式在“Anaconda-Navigator”中直接启动 Notebook 或 JupyterLab。按照官方的说法，JupyterLab 是下一代的 Notebook，提供了更友好的界面和更强大的功能，我们也推荐大家使用 JupyterLab。Windows 用户也可以在开始菜单中打开“Anaconda Prompt”或“Anaconda PowerShell”，由于已经激活了 Anaconda 默认的虚拟环境，只需要输入`jupyter lab`命令来启动JupyterLab。macOS 系统在安装 Anaconda以后，每次打开终端时会自动激活 Anaconda 默认的虚拟环境，也是通过输入`jupyter lab`命令就可以启动JupyterLab。\n\n对于安装了 Python 环境但是没有安装 Anaconda 的用户，可以用 Python 的包管理工具`pip`来安装 JupyterLab，安装成功后在终端或命令行提示符中执行`jupyter lab`命令来启动 JupyterLab，如下所示。\n\n安装 JupyterLab：\n\n```Bash\npip install jupyterlab\n```\n\n安装 Python 数据分析三大神器：\n\n```Bash\npip install numpy pandas matplotlib\n```\n\n启动 JupyterLab：\n\n```Bash\njupyter lab\n```\n\nJupyterLab 是基于网页的用于交互计算的应用程序，可以用于代码开发、文档撰写、代码运行和结果展示。简单的说，你可以在网页中直接**编写代码**和**运行代码**，代码的运行结果也会直接在代码块下方进行展示。如在编写代码的过程中需要编写说明文档，可在同一个页面中使用 Markdown 格式进行编写，而且可以直接看到渲染后的效果。此外，Notebook 的设计初衷是提供一个能够支持多种编程语言的工作环境，目前它能够支持超过40种编程语言，包括 Python、R、Julia、Scala 等。\n\n首先，我们可以创建一个用于书写 Python 代码的 Notebook，如下图所示。\n\n<img class=\"lazy\" data-src=\"/res/JupyterLab_1.png\" style=\"zoom:50%;\">\n\n接下来，我们就可以编写代码、撰写文档和运行程序啦，如下图所示。\n\n<img class=\"lazy\" data-src=\"/res/JupyterLab_2.png\" style=\"zoom:50%;\">\n\n#### 使用技巧\n\n如果使用 Python 做工程化的项目开发，PyCharm 肯定是最好的选择，它提供了一个集成开发环境应该具有的所有功能，尤其是智能提示、代码补全、自动纠错这类功能会让开发人员感到非常舒服。如果使用 Python 做数据科学相关的工作，JupyterLab 并不比 PyCharm 逊色，在数据和图表展示方面 JupyterLab 更加优秀。为此，JetBrains 公司还专门开发了一个对标 JupyterLab 的新工具 DataSpell，有兴趣的读者可以自行了解。下面我们为大家介绍一些 JupyterLab 的使用技巧，希望能够帮助大家提升工作效率。\n\n1. 自动补全。在使用 JupyterLab 编写代码时，按`Tab`键会获得代码提示和补全功能。\n\n2. 获得帮助。如果希望了解一个对象（如变量、类、函数等）的相关信息或使用方式，可以在对象后面使用`?`并运行代码， 窗口下方会显示出对应的信息，帮助我们了解该对象，如下所示。\n\n    <img class=\"lazy\" data-src=\"/res/JupyterLab_3.png\" style=\"zoom:100%;\">\n\n3. 搜索命名。如果只记得一个类或一个函数名字的一部分，可以使用通配符`*`并配合`?`进行搜索，如下所示。\n\n    <img class=\"lazy\" data-src=\"/res/JupyterLab_4.png\" style=\"zoom:100%;\">\n\n4. 调用命令。可以在 JupyterLab 中使用`!`后面跟系统命令的方式来执行系统命令。\n\n5. 魔法指令。JupyterLab 中有很多非常有趣且有用的魔法指令，例如可以使用`%timeit`测试语句的执行时间，可以使用`%pwd`查看当前工作目录等。如果想查看所有的魔法指令，可以使用`%lsmagic`，如果了解魔法指令的用法，可以使用`%magic`来查看，如下图所示。\n\n    <img class=\"lazy\" data-src=\"/res/JupyterLab_5.png\" style=\"zoom:100%;\">\n\n    常用的魔法指令有：\n\n    | 魔法指令                                    | 功能说明                                   |\n    | ------------------------------------------- | ------------------------------------------ |\n    | `%pwd`                                      | 查看当前工作目录                           |\n    | `%ls`                                       | 列出当前或指定文件夹下的内容               |\n    | `%cat`                                      | 查看指定文件的内容                         |\n    | `%hist`                                     | 查看输入历史                               |\n    | `%matplotlib inline`                        | 设置在页面中嵌入matplotlib输出的统计图表   |\n    | `%config Inlinebackend.figure_format='svg'` | 设置统计图表使用SVG格式（矢量图）          |\n    | `%run`                                      | 运行指定的程序                             |\n    | `%load`                                     | 加载指定的文件到单元格中                   |\n    | `%quickref`                                 | 显示IPython的快速参考                      |\n    | `%timeit`                                   | 多次运行代码并统计代码执行时间             |\n    | `%prun`                                     | 用`cProfile.run`运行代码并显示分析器的输出 |\n    | `%who` / `%whos`                            | 显示命名空间中的变量                       |\n    | `%xdel`                                     | 删除一个对象并清理所有对它的引用           |\n\n6. 快捷键。JupyterLab 中的很多操作可以通过快捷键来实现，使用快捷键可以提升工作效率。JupyterLab 的快捷键可以分为命令模式下的快捷键和编辑模式下的快捷键，所谓编辑模式就是处于输入代码或撰写文档状态的模式，在编辑模式下按`Esc`可以回到命令模式，在命令模式下按`Enter`可以进入编辑模式。\n\n    命令模式下的快捷键：\n\n    | 快捷键                                   | 功能说明                                     |\n    | ---------------------------------------- | -------------------------------------------- |\n    | `Alt` + `Enter`                          | 运行当前单元格并在下面插入新的单元格         |\n    | `Shift` + `Enter`                        | 运行当前单元格并选中下方的单元格             |\n    | `Ctrl` + `Enter`                         | 运行当前单元格                               |\n    | `j` / `k`、`Shift` + `j` / `Shift` + `k` | 选中下方/上方单元格、连续选中下方/上方单元格 |\n    | `a` / `b`                                | 在下方/上方插入新的单元格                    |\n    | `c` / `x`                                | 复制单元格 / 剪切单元格                      |\n    | `v` / `Shift` + `v`                      | 在下方/上方粘贴单元格                        |\n    | `dd` / `z`                               | 删除单元格 / 恢复删除的单元格                |\n    | `Shift` + `l`                            | 显示或隐藏当前/所有单元格行号                |\n    | `Space` / `Shift` + `Space`              | 向下/向上滚动页面                            |\n\n    编辑模式下的快捷键：\n\n    | 快捷键                     | 功能说明                               |\n    | -------------------------- | -------------------------------------- |\n    | `Shift` + `Tab`            | 获得提示信息                           |\n    | `Ctrl` + `]`/ `Ctrl` + `[` | 增加/减少缩进                          |\n    | `Alt` + `Enter`            | 运行当前单元格并在下面插入新的单元格   |\n    | `Shift` + `Enter`          | 运行当前单元格并选中下方的单元格       |\n    | `Ctrl` + `Enter`           | 运行当前单元格                         |\n    | `Ctrl` + `Left` / `Right`  | 光标移到行首/行尾                      |\n    | `Ctrl` + `Up` / `Down`     | 光标移动代码开头/结尾处                |\n    | `Up` / `Down`              | 光标上移/下移一行或移到上/下一个单元格 |\n\n    > **说明**：对于 macOS 系统可以将`Alt`键替换成`Option`键，将`Ctrl`键替换成`Command`键。\n", "NumPy的应用-1": "## NumPy的应用-1\n\nNumpy 是一个开源的 Python 科学计算库，**用于快速处理任意维度的数组**。Numpy **支持常见的数组和矩阵操作**，对于同样的数值计算任务，使用 NumPy 不仅代码要简洁的多，而且 NumPy 在性能上也远远优于原生 Python，至少是一到两个数量级的差距，而且数据量越大，NumPy 的优势就越明显。\n\nNumPy 最为核心的数据类型是`ndarray`，使用`ndarray`可以处理一维、二维和多维数组，该对象相当于是一个快速而灵活的大数据容器。NumPy 底层代码使用 C 语言编写，解决了 GIL 的限制，`ndarray`在存取数据的时候，数据与数据的地址都是连续的，这确保了可以进行高效率的批量操作，性能上远远优于 Python 中的`list`；另一方面`ndarray`对象提供了更多的方法来处理数据，尤其获取数据统计特征的方法，这些方法也是 Python 原生的`list`没有的。\n\n ### 准备工作\n\n1. 启动 JupyterLab\n\n    ```Bash\n    jupyter lab\n    ```\n\n    > **提示**：在启动 JupyterLab 之前，建议先安装好数据分析相关依赖项，包括之前提到的三大神器以及相关依赖项。如果使用 Anaconda，则无需单独安装，可以通过 Anaconda 的 Navigator 来启动。\n\n2. 导入\n\n    ```Python\n    import numpy as np\n    import pandas as pd\n    import matplotlib.pyplot as plt\n    ```\n\n    > **说明**：如果已经启动了 JupyterLab 但尚未安装相关依赖库，例如尚未安装`numpy`，可以在单元格中输入`%pip install numpy`并运行该单元格来安装 NumPy。当然，我们也可以在单元格中输入`%pip install numpy pandas matplotlib`把 Python 数据分析三个核心的三方库都安装上。注意上面的代码，我们不仅导入了 NumPy，还将 pandas 和 matplotlib 库一并导入了。\n\n### 创建数组对象\n\n创建`ndarray`对象有很多种方法，下面我们介绍一些常用的方法。\n\n方法一：使用`array`函数，通过`list`创建数组对象\n\n代码：\n\n```Python\narray1 = np.array([1, 2, 3, 4, 5])\narray1\n```\n\n输出：\n\n```\narray([1, 2, 3, 4, 5])\n```\n\n代码：\n\n```Python\narray2 = np.array([[1, 2, 3], [4, 5, 6]])\narray2\n```\n\n输出：\n\n```\narray([[1, 2, 3],\n       [4, 5, 6]])\n```\n\n方法二：使用`arange`函数，指定取值范围和跨度创建数组对象\n\n代码：\n\n```Python\narray3 = np.arange(0, 20, 2)\narray3\n```\n\n输出：\n\n```\narray([ 0,  2,  4,  6,  8, 10, 12, 14, 16, 18])\n```\n\n方法三：使用`linspace`函数，用指定范围和元素个数创建数组对象，生成等差数列\n\n代码：\n\n```Python\narray4 = np.linspace(-1, 1, 11)\narray4\n```\n\n输出：\n\n```\narray([-1. , -0.8, -0.6, -0.4, -0.2,  0. ,  0.2,  0.4,  0.6,  0.8,  1. ])\n```\n\n方法四：使用`logspace`函数，生成等比数列\n\n代码：\n\n```python\narray5 = np.logspace(1, 10, num=10, base=2)\narray5\n```\n\n> **注意**：等比数列的起始值是 $\\small{2^1}$ ，等比数列的终止值是 $\\small{2^{10}}$ ，`num`是元素的个数，`base`就是底数。\n\n输出：\n\n```\narray([   2.,    4.,    8.,   16.,   32.,   64.,  128.,  256.,  512., 1024.])\n```\n\n方法五：通过`fromstring`函数从字符串提取数据创建数组对象\n\n代码：\n\n```Python\narray6 = np.fromstring('1, 2, 3, 4, 5', sep=',', dtype='i8')\narray6 \n```\n\n输出：\n\n```\narray([1, 2, 3, 4, 5])\n```\n\n方法六：通过`fromiter`函数从生成器（迭代器）中获取数据创建数组对象\n\n代码：\n\n```Python\ndef fib(how_many):\n    a, b = 0, 1\n    for _ in range(how_many):\n        a, b = b, a + b\n        yield a\n\n\ngen = fib(20)\narray7 = np.fromiter(gen, dtype='i8')\narray7\n```\n\n输出：\n\n```\narray([   1,    1,    2,    3,    5,    8,   13,   21,   34,   55,   89,\n        144,  233,  377,  610,  987, 1597, 2584, 4181, 6765])\n```\n\n方法七：使用`numpy.random`模块的函数生成随机数创建数组对象\n\n产生 10 个 $\\small{[0, 1)}$ 范围的随机小数，代码：\n\n```Python\narray8 = np.random.rand(10)\narray8\n```\n\n输出：\n\n```\narray([0.45556132, 0.67871326, 0.4552213 , 0.96671509, 0.44086463,\n       0.72650875, 0.79877188, 0.12153022, 0.24762739, 0.6669852 ])\n```\n\n产生 10 个 $\\small{[1, 100)}$ 范围的随机整数，代码：\n\n```Python\narray9 = np.random.randint(1, 100, 10)\narray9\n```\n\n输出：\n\n```\narray([29, 97, 87, 47, 39, 19, 71, 32, 79, 34])\n```\n\n产生 20 个 $\\small{\\mu=50}$ ， $\\small{\\sigma=10}$ 的正态分布随机数，代码：\n\n```Python\narray10 = np.random.normal(50, 10, 20)\narray10\n```\n\n输出：\n\n```\narray([55.04155586, 46.43510797, 20.28371158, 62.67884053, 61.23185964,\n       38.22682148, 53.17126151, 43.54741592, 36.11268017, 40.94086676,\n       63.27911699, 46.92688903, 37.1593374 , 67.06525656, 67.47269463,\n       23.37925889, 31.45312239, 48.34532466, 55.09180924, 47.95702787])\n```\n\n产生 $\\small{[0, 1)}$ 范围的随机小数构成的 3 行 4 列的二维数组，代码：\n\n```Python\narray11 = np.random.rand(3, 4)\narray11\n```\n\n输出：\n\n```\narray([[0.54017809, 0.46797771, 0.78291445, 0.79501326],\n       [0.93973783, 0.21434806, 0.03592874, 0.88838892],\n       [0.84130479, 0.3566601 , 0.99935473, 0.26353598]])\n```\n\n产生 $\\small{[1, 100)}$ 范围的随机整数构成的三维数组，代码：\n\n```Python\narray12 = np.random.randint(1, 100, (3, 4, 5))\narray12\n```\n\n输出：\n\n```\narray([[[94, 26, 49, 24, 43],\n        [27, 27, 33, 98, 33],\n        [13, 73,  6,  1, 77],\n        [54, 32, 51, 86, 59]],\n\n       [[62, 75, 62, 29, 87],\n        [90, 26,  6, 79, 41],\n        [31, 15, 32, 56, 64],\n        [37, 84, 61, 71, 71]],\n\n       [[45, 24, 78, 77, 41],\n        [75, 37,  4, 74, 93],\n        [ 1, 36, 36, 60, 43],\n        [23, 84, 44, 89, 79]]])\n```\n\n方法八：创建全0、全1或指定元素的数组\n\n使用`zeros`函数，代码：\n\n```Python\narray13 = np.zeros((3, 4))\narray13\n```\n\n输出：\n\n```\narray([[0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.]])\n```\n\n使用`ones`函数，代码：\n\n```Python\narray14 = np.ones((3, 4))\narray14\n```\n\n输出：\n\n```\narray([[1., 1., 1., 1.],\n       [1., 1., 1., 1.],\n       [1., 1., 1., 1.]])\n```\n\n使用`full`函数，代码：\n\n```Python\narray15 = np.full((3, 4), 10)\narray15\n```\n\n输出：\n\n```\narray([[10, 10, 10, 10],\n       [10, 10, 10, 10],\n       [10, 10, 10, 10]])\n```\n\n方法九：使用`eye`函数创建单位矩阵\n\n代码：\n\n```Python\nnp.eye(4)\n```\n\n输出：\n\n```\narray([[1., 0., 0., 0.],\n       [0., 1., 0., 0.],\n       [0., 0., 1., 0.],\n       [0., 0., 0., 1.]])\n```\n\n方法十：读取图片获得对应的三维数组\n\n代码：\n\n```Python\narray16 = plt.imread('guido.jpg')\narray16\n```\n\n输出：\n\n```\narray([[[ 36,  33,  28],\n        [ 36,  33,  28],\n        [ 36,  33,  28],\n        ...,\n        [ 32,  31,  29],\n        [ 32,  31,  27],\n        [ 31,  32,  26]],\n\n       [[ 37,  34,  29],\n        [ 38,  35,  30],\n        [ 38,  35,  30],\n        ...,\n        [ 31,  30,  28],\n        [ 31,  30,  26],\n        [ 30,  31,  25]],\n\n       [[ 38,  35,  30],\n        [ 38,  35,  30],\n        [ 38,  35,  30],\n        ...,\n        [ 30,  29,  27],\n        [ 30,  29,  25],\n        [ 29,  30,  25]],\n\n       ...,\n\n       [[239, 178, 123],\n        [237, 176, 121],\n        [235, 174, 119],\n        ...,\n        [ 78,  68,  56],\n        [ 75,  67,  54],\n        [ 73,  65,  52]],\n\n       [[238, 177, 120],\n        [236, 175, 118],\n        [234, 173, 116],\n        ...,\n        [ 82,  70,  58],\n        [ 78,  68,  56],\n        [ 75,  66,  51]],\n\n       [[238, 176, 119],\n        [236, 175, 118],\n        [234, 173, 116],\n        ...,\n        [ 84,  70,  61],\n        [ 81,  69,  57],\n        [ 79,  67,  53]]], dtype=uint8)\n```\n\n> **说明**：上面的代码读取了当前路径下名为`guido.jpg` 的图片文件，计算机系统中的图片通常由若干行若干列的像素点构成，而每个像素点又是由红绿蓝三原色构成的，刚好可以用三维数组来表示。读取图片用到了`matplotlib`库的`imread`函数。\n\n### 数组对象的属性\n\n`size`属性：获取数组元素个数。\n\n代码：\n\n```Python\narray17 = np.arange(1, 100, 2)\narray18 = np.random.rand(3, 4)\nprint(array16.size)\nprint(array17.size)\nprint(array18.size)\n```\n\n输出：\n\n```\n1125000\n50\n12\n```\n\n`shape`属性：获取数组的形状。\n\n代码：\n\n```Python\nprint(array16.shape)\nprint(array17.shape)\nprint(array18.shape)\n```\n\n输出：\n\n```\n(750, 500, 3)\n(50,)\n(3, 4)\n```\n\n`dtype`属性：获取数组元素的数据类型。\n\n代码：\n\n```Python\nprint(array16.dtype)\nprint(array17.dtype)\nprint(array18.dtype)\n```\n\n输出：\n\n```\nuint8\nint64\nfloat64\n```\n\n`ndarray`对象元素的数据类型可以参考如下所示的表格。\n\n<img class=\"lazy\" data-src=\"/res/dtype.jpg\" style=\"zoom:50%;\">\n\n`ndim`属性：获取数组的维度。\n\n代码：\n\n```Python\nprint(array16.ndim)\nprint(array17.ndim)\nprint(array18.ndim)\n```\n\n输出：\n\n```\n3\n1\n2\n```\n\n`itemsize`属性：获取数组单个元素占用内存空间的字节数。\n\n代码：\n\n```Python\nprint(array16.itemsize)\nprint(array17.itemsize)\nprint(array18.itemsize)\n```\n\n输出：\n\n```\n1\n8\n8\n```\n\n`nbytes`属性：获取数组所有元素占用内存空间的字节数。\n\n代码：\n\n```Python\nprint(array16.nbytes)\nprint(array17.nbytes)\nprint(array18.nbytes)\n```\n\n输出：\n\n```\n1125000\n400\n96\n```\n\n### 数组的索引运算\n\n和 Python 中的列表类似，NumPy 的`ndarray`对象可以进行索引和切片操作，通过索引可以获取或修改数组中的元素，通过切片操作可以取出数组的一部分，我们把切片操作也称为切片索引。\n\n#### 普通索引\n\n类似于 Python 中`list`类型的索引运算。\n\n代码：\n\n```Python\narray19 = np.arange(1, 10)\nprint(array19[0], array19[array19.size - 1])\nprint(array19[-array20.size], array19[-1])\n```\n\n输出：\n\n```\n1 9\n1 9\n```\n\n代码：\n\n```Python\narray20 = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\narray20[2]\n```\n\n输出：\n\n```\narray([7, 8, 9])\n```\n\n代码：\n\n```Python\nprint(array20[0][0])\nprint(array20[-1][-1])\n```\n\n输出：\n\n```\n1\n9\n```\n\n代码：\n\n```Python\nprint(array20[1][1])\nprint(array20[1, 1])\n```\n\n输出：\n\n```\n5\n5\n```\n\n代码：\n\n```Python\narray20[1][1] = 10\narray20\n```\n\n输出：\n\n```\narray([[ 1,  2,  3],\n       [ 4, 10,  6],\n       [ 7,  8,  9]])\n```\n\n代码：\n\n```Python\narray20[1] = [10, 11, 12]\narray20\n```\n\n输出：\n\n```\narray([[ 1,  2,  3],\n       [10, 11, 12],\n       [ 7,  8,  9]])\n```\n\n#### 切片索引\n\n切片索引是形如`[开始索引:结束索引:跨度]`的语法，通过指定**开始索引**（默认值无穷小）、**结束索引**（默认值无穷大）和**跨度**（默认值1），从数组中取出指定部分的元素并构成新的数组。因为开始索引、结束索引和步长都有默认值，所以它们都可以省略，如果不指定步长，第二个冒号也可以省略。一维数组的切片运算跟 Python 中的`list`类型的切片非常类似，此处不再赘述，二维数组的切片可以参考下面的代码，相信非常容易理解。\n\n代码：\n\n```Python\narray20[:2, 1:]\n```\n\n输出：\n\n```\narray([[ 2,  3],\n       [11, 12]])\n```\n\n代码：\n\n```Python\narray20[2, :]\n```\n\n输出：\n\n```\narray([7, 8, 9])\n```\n\n代码：\n\n```Python\narray20[2:, :]\n```\n\n输出：\n\n```\narray([[7, 8, 9]])\n```\n\n代码：\n\n```Python\narray20[:, :2]\n```\n\n输出：\n\n```\narray([[ 1,  2],\n       [10, 11],\n       [ 7,  8]])\n```\n\n代码：\n\n```Python\narray20[::2, ::2]\n```\n\n输出：\n\n```\narray([[1, 3],\n       [7, 9]])\n```\n\n代码：\n\n```Python\narray20[::-2, ::-2]\n```\n\n输出：\n\n```\narray([[9, 7],\n       [3, 1]])\n```\n\n关于数组的索引和切片运算，大家可以通过下面的两张图来增强印象，这两张图来自[《利用Python进行数据分析》](https://item.jd.com/12398725.html)一书，它是 pandas 库的作者 Wes McKinney 撰写的 Python 数据分析领域的经典教科书，有兴趣的读者可以购买和阅读原书。\n\n图1：二维数组的普通索引\n\n<img class=\"lazy\" data-src=\"/res/ndarray-index.png\" style=\"zoom:60%;\">\n\n图2：二维数组的切片索引\n\n<img class=\"lazy\" data-src=\"/res/ndarray-slice.png\" style=\"zoom:60%;\">\n\n#### 花式索引\n\n花式索引是用保存整数的数组充当一个数组的索引，这里所说的数组可以是 NumPy 的`ndarray`，也可以是 Python 中`list`、`tuple`等可迭代类型，可以使用正向或负向索引。\n\n代码：\n\n```Python\narray19[[0, 1, 1, -1, 4, -1]]\n```\n\n输出：\n\n```\narray([1, 2, 2, 9, 5, 9])\n```\n\n代码：\n\n```Python\narray20[[0, 2]]\n```\n\n输出：\n\n```\narray([[1, 2, 3],\n       [7, 8, 9]])\n```\n\n代码：\n\n```Python\narray20[[0, 2], [1, 2]]\n```\n\n输出：\n\n```\narray([2, 9])\n```\n\n代码：\n\n```Python\narray20[[0, 2], 1]\n```\n\n输出：\n\n```\narray([2, 8])\n```\n\n#### 布尔索引\n\n布尔索引就是通过保存布尔值的数组充当一个数组的索引，布尔值为`True`的元素保留，布尔值为`False`的元素不会被选中。布尔值的数组可以手动构造，也可以通过关系运算来产生。\n\n代码：\n\n```Python\narray19[[True, True, False, False, True, False, False, True, True]]\n```\n\n输出：\n\n```\narray([1, 2, 5, 8, 9])\n```\n\n代码：\n\n```Python\narray19 > 5\n```\n\n输出：\n\n```\narray([False, False, False, False, False,  True,  True,  True,  True])\n```\n\n代码：\n\n```Python\n~(array19 > 5)\n```\n\n输出：\n\n```\narray([ True,  True,  True,  True,  True, False, False, False, False])\n```\n\n> **说明**：`~`运算符可以对布尔数组中的布尔值进行逻辑取反，也就是原来的`True`会变成`False`，原来的`False`会变成`True`。\n\n代码：\n\n```Python\narray19[array19 > 5]\n```\n\n输出：\n\n```\narray([6, 7, 8, 9])\n```\n\n代码：\n\n```Python\narray19 % 2 == 0\n```\n\n输出：\n\n```\narray([False,  True, False,  True, False,  True, False,  True, False])\n```\n\n代码：\n\n```Python\narray19[array19 % 2 == 0]\n```\n\n输出：\n\n```\narray([2, 4, 6, 8])\n```\n\n代码：\n\n```Python\n(array19 > 5) & (array19 % 2 == 0)\n```\n\n输出：\n\n```\narray([False, False, False, False, False,  True, False,  True, False])\n```\n\n> **说明**：`&`运算符可以作用于两个布尔数组，如果两个数组对应元素都是`True`，那么运算的结果就是`True`，否则就是`False`，该运算符的运算规则类似于 Python 中的 `and` 运算符，只不过作用的对象是两个布尔数组。\n\n代码：\n\n```Python\narray19[(array19 > 5) & (array19 % 2 == 0)]\n```\n\n输出：\n\n```\narray([6, 8])\n```\n\n代码：\n\n```Python\narray19[(array19 > 5) | (array19 % 2 == 0)]\n```\n\n输出：\n\n```\narray([2, 4, 6, 7, 8, 9])\n```\n\n> **说明**：`|`运算符可以作用于两个布尔数组，如果两个数组对应元素都是`False`，那么运算的结果就是`False`，否则就是`True`，该运算符的运算规则类似于 Python 中的 `or` 运算符，只不过作用的对象是两个布尔数组。\n\n代码：\n\n```Python\narray20[array21 % 2 != 0]\n```\n\n输出：\n\n```\narray([1, 3, 5, 7, 9])\n```\n\n关于索引运算需要说明的是，切片索引虽然创建了新的数组对象，但是新数组和原数组共享了数组中的数据，简单的说，无论你通过新数组对象或原数组对象修改数组中的数据，修改的其实是内存中的同一块数据。花式索引和布尔索引也会创建新的数组对象，而且新数组复制了原数组的元素，新数组和原数组并不是共享数据的关系，这一点可以查看数组对象的`base`属性，有兴趣的读者可以自行探索。\n\n### 案例：通过数组切片处理图像\n\n学习基础知识总是比较枯燥且没有成就感的，所以我们还是来个案例为大家演示下上面学习的数组索引和切片操作到底有什么用。前面我们说到过，可以用三维数组来表示图像，那么通过图像对应的三维数组进行操作，就可以实现对图像的处理，如下所示。\n\n读入图片创建三维数组对象。\n\n```Python\nguido_image = plt.imread('guido.jpg')\nplt.imshow(guido_image)\n```\n\n<img class=\"lazy\" data-src=\"/res/guido_slice_1.png\" style=\"zoom:65%;\">\n\n对数组的0轴进行反向切片，实现图像的垂直翻转。\n\n```Python\nplt.imshow(guido_image[::-1])\n```\n\n<img class=\"lazy\" data-src=\"/res/guido_slice_2.png\" style=\"zoom:65%;\">\n\n对数组的1轴进行反向切片，实现图像的水平翻转。\n\n```Python\nplt.imshow(guido_image[:,::-1])\n```\n\n<img class=\"lazy\" data-src=\"/res/guido_slice_3.png\" style=\"zoom:65%;\">\n\n通过切片操作实现抠图，将吉多大叔的头抠出来。\n\n```Python\nplt.imshow(guido_image[30:350, 90:300])\n```\n\n<img class=\"lazy\" data-src=\"/res/guido_slice_4.png\" style=\"zoom:65%;\">\n\n通过切片操作实现降采样。\n\n```Python\nplt.imshow(guido_image[::10, ::10])\n```\n\n<img class=\"lazy\" data-src=\"/res/guido_slice_5.png\" style=\"zoom:65%;\">\n\n", "NumPy的应用-2": "## NumPy的应用-2\n\n### 数组对象的方法\n\n#### 获取描述统计信息\n\n描述统计信息主要包括数据的集中趋势、离散程度和频数分析等，其中集中趋势主要看均值和中位数，离散程度可以看极值、方差、标准差等，详细的内容大家可以阅读[《统计思维系列课程01：解读数据》](https://zhuanlan.zhihu.com/p/595273755)。\n\n```Python\narray1 = np.random.randint(1, 100, 10)\narray1\n```\n\n输出：\n\n```\narray([46, 51, 15, 42, 53, 71, 20, 62,  6, 94])\n```\n\n**计算总和、均值和中位数。**\n\n代码：\n\n```Python\nprint(array1.sum())\nprint(np.sum(array1))\nprint(array1.mean())\nprint(np.mean(array1))\nprint(np.median(array1))\nprint(np.quantile(array1, 0.5))\n```\n\n> **说明**：上面代码中的`mean`、`median`和`quantile`分别是 NumPy 中计算算术平均值、中位数和分位数的函数，其中`quantitle`函数的第二个参数设置为0.5表示计算50%分位数，也就是中位数。\n\n输出：\n\n```\n460\n460\n46.0\n46.0\n48.5\n48.5\n```\n\n**极值、全距和四分位距离。**\n\n代码：\n\n```Python\nprint(array1.max())\nprint(np.amax(array1))\nprint(array1.min())\nprint(np.amin(array1))\nprint(np.ptp(array1))\nprint(np.ptp(array1))\nq1, q3 = np.quantile(array1, [0.25, 0.75])\nprint(q3 - q1)\n```\n\n输出：\n\n```\n94\n94\n6\n6\n88\n88\n34.25\n```\n\n**方差、标准差和变异系数。**\n\n代码：\n\n```Python\nprint(array1.var())\nprint(np.var(array1))\nprint(array1.std())\nprint(np.std(array1))\nprint(array1.std() / array1.mean())\n```\n\n输出：\n\n```\n651.2\n651.2\n25.51862065237853\n25.51862065237853\n0.5547526228777941\n```\n\n**绘制箱线图。**\n\n箱线图又称为盒须图，是显示一组数据分散情况的统计图，因形状如箱子而得名。 它主要用于反映原始数据分布的特征，还可以进行多组数据分布特征的比较。\n\n代码：\n\n```Python\nplt.boxplot(array1, showmeans=True)\nplt.ylim([-20, 120])\nplt.show()\n```\n\n输出：\n\n<img class=\"lazy\" data-src=\"/res/box_plot_1.png\" style=\"zoom:40%;\">\n\n值得注意的是，对于二维或更高维的数组，在获取描述统计信息时，可以通过名为`axis`的参数指定均值、方差等运算是沿着哪一个轴来执行，`axis`参数不同，执行的结果可能是大相径庭的，如下所示。\n\n代码：\n\n```Python\narray2 = np.random.randint(60, 101, (5, 3))\narray2\n```\n\n输出：\n\n```\narray([[72, 64, 73],\n       [61, 73, 61],\n       [76, 85, 77],\n       [97, 88, 90],\n       [63, 93, 82]])\n```\n\n代码：\n\n```Python\narray2.mean()\n```\n\n输出：\n\n```\n77.0\n```\n\n代码：\n\n```Python\narray2.mean(axis=0)\n```\n\n输出：\n\n```\narray([73.8, 80.6, 76.6])\n```\n\n代码：\n\n```Python\narray2.mean(axis=1)\n```\n\n输出：\n\n```\narray([69.66666667, 65.        , 79.33333333, 91.66666667, 79.33333333])\n```\n\n代码：\n\n```Python\narray2.max(axis=0)\n```\n\n输出：\n\n```\narray([97, 93, 90])\n```\n\n代码：\n\n```Python\narray2.max(axis=1)\n```\n\n输出：\n\n```\narray([73, 73, 85, 97, 93])\n```\n\n再看看绘制箱线图，对于二维数组每一列都会产生一个统计图形，如下所示。\n\n代码：\n\n```Python\nplt.boxplot(array2, showmeans=True)\nplt.ylim([-20, 120])\nplt.show()\n```\n\n输出：\n\n<img class=\"lazy\" data-src=\"/res/box_plot_2.png\" style=\"zoom:75%;\">\n\n> **说明**：箱线图中的小圆圈用来表示离群点，也就是大于 $\\small{Q_3 + 1.5 \\times IQR}$ 或小于 $\\small{Q_1 - 1.5 \\times IQR}$ 的值。公式中的常量 1.5 可以通过绘制箱线图的`boxplot`函数的`whis`参数进行修改，常用的值是 1.5 和 3，修改为 3 通常是为了标识出极度离群点。\n\n需要说明的是，NumPy 的数组对象并没有提供计算几何平均值、调和平均值、去尾平均值等的方法，如果有这方面的需求，可以使用名为 scipy 的三方库，它的`stats`模块中提供了这些函数。此外，该模块还提供了计算众数、变异系数、偏态、峰度的函数，代码如下所示。\n\n代码：\n\n```python\nfrom scipy import stats\n\nprint(np.mean(array1))                # 算术平均值\nprint(stats.gmean(array1))            # 几何平均值\nprint(stats.hmean(array1))            # 调和平均值\nprint(stats.tmean(array1, [10, 90]))  # 去尾平均值\nprint(stats.variation(array1))        # 变异系数\nprint(stats.skew(array1))             # 偏态系数\nprint(stats.kurtosis(array1))         # 峰度系数\n```\n\n输出：\n\n```\n46.0\n36.22349548825599\n24.497219530825497\n45.0\n0.5547526228777941\n0.11644192634527782\n-0.7106251396024126\n```\n\n#### 其他相关方法概述\n\n1. `all()` / `any()`方法：判断数组是否所有元素都是`True` / 判断数组是否有为`True`的元素。\n\n2. `astype()`方法：拷贝数组，并将数组中的元素转换为指定的类型。\n\n3. `reshape()`方法：调整数组对象的形状。\n\n4. `dump()`方法：保存数组到二进制文件中，可以通过 NumPy 中的`load()`函数从保存的文件中加载数据创建数组。\n\n    代码：\n\n    ```Python\n    array.dump('array1-data')\n    array3 = np.load('array1-data', allow_pickle=True)\n    array3\n    ```\n\n    输出：\n\n    ```\n    array([46, 51, 15, 42, 53, 71, 20, 62,  6, 94])\n    ```\n\n5. `tofile()`方法：将数组对象写入文件中。\n\n   ```Python\n   array1.tofile('array.txt', sep=',')\n   ```\n\n6. `fill()`方法：向数组中填充指定的元素。\n\n7. `flatten()`方法：将多维数组扁平化为一维数组。\n\n    代码：\n\n    ```Python\n    array2.flatten()\n    ```\n\n    输出：\n\n    ```\n    array([1, 2, 3, 4, 5, 6, 7, 8, 9])\n    ```\n\n8. `nonzero()`方法：返回非0元素的索引。\n\n9. `round()`方法：对数组中的元素做四舍五入操作。\n\n10. `sort()`方法：对数组进行就地排序。\n\n    代码：\n\n    ```Python\n    array1.sort()\n    array1\n    ```\n\n    输出：\n\n    ```\n    array([ 6, 15, 20, 42, 46, 51, 53, 62, 71, 94])\n    ```\n\n11. `swapaxes()`和`transpose()`方法：交换数组指定的轴和转置。\n\n    代码：\n\n    ```Python\n    array2.swapaxes(0, 1)\n    ```\n\n    输出：\n\n    ```\n    array([[1, 4, 7],\n           [2, 5, 8],\n           [3, 6, 9]])\n    ```\n\n    代码：\n\n    ```Python\n    array2.transpose()\n    ```\n\n    输出：\n\n    ```\n    array([[1, 4, 7],\n           [2, 5, 8],\n           [3, 6, 9]])\n    ```\n\n12. `tolist()`方法：将数组转成 Python 中的`list`。\n\n    代码：\n\n    ```Python\n    print(array2.tolist())\n    print(type(array2.tolist()))\n    ```\n\n    输出：\n\n    ```\n    [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n    <class 'list'>\n    ```\n", "NumPy的应用-3": "## NumPy的应用-3\n\n### 数组的运算\n\n使用 NumPy 最为方便的是当需要对数组元素进行运算时，不用编写循环代码遍历每个元素，所有的运算都会自动的**矢量化**。简单的说就是，NumPy 中的数学运算和数学函数会自动作用于数组中的每个成员。\n\n#### 数组跟标量的运算\n\nNumPy 的数组可以跟一个数值进行加、减、乘、除、求模、求幂等运算，对应的运算会作用到数组的每一个元素上，如下所示。\n\n代码：\n\n```python\narray1 = np.arange(1, 10)\nprint(array1 + 10)\nprint(array1 * 10)\n```\n\n输出：\n\n```\n[11 12 13 14 15 16 17 18 19]\n[10 20 30 40 50 60 70 80 90]\n```\n\n除了上述的运算，关系运算也是没有问题的，之前讲布尔索引的时候已经遇到过了。\n\n代码：\n\n```python\nprint(array1 > 5)\nprint(array1 % 2 == 0)\n```\n\n输出：\n\n```\n[False False False False False  True  True  True  True]\n[False  True False  True False  True False  True False]\n```\n\n#### 数组跟数组的运算\n\nNumPy 的数组跟数组也可以执行算术运算和关系运算，运算会作用于两个数组对应的元素上，这就要求两个数组的形状（`shape`属性）要相同，如下所示。\n\n代码：\n\n```python\narray2 = np.array([1, 1, 1, 2, 2, 2, 3, 3, 3])\nprint(array1 + array2)\nprint(array1 * array2)\nprint(array1 ** array2)\n```\n\n输出：\n\n```\n[ 2  3  4  6  7  8 10 11 12]\n[ 1  2  3  8 10 12 21 24 27]\n[  1   2   3  16  25  36 343 512 729]\n```\n\n代码：\n\n```python\nprint(array1 > array2)\nprint(array1 % array2 == 0)\n```\n\n输出：\n\n```\n[False  True  True  True  True  True  True  True  True]\n[ True  True  True  True False  True False False  True]\n```\n\n#### 通用一元函数\n\nNumPy 中通用一元函数的参数是一个数组对象，函数会对数组进行元素级的处理，例如：`sqrt`函数会对数组中的每个元素计算平方根，而`log2`函数会对数组中的每个元素计算以2为底的对数，代码如下所示。\n\n代码：\n\n```python\nprint(np.sqrt(array1))\nprint(np.log2(array1))\n```\n\n输出：\n\n```\n[1.         1.41421356 1.73205081 2.         2.23606798 2.44948974\n 2.64575131 2.82842712 3.        ]\n[0.         1.         1.5849625  2.         2.32192809 2.5849625\n 2.80735492 3.         3.169925  ]\n```\n\n**表1：通用一元函数**\n\n| 函数                             | 说明                                          |\n| -------------------------------- | --------------------------------------------- |\n| `abs` / `fabs`                   | 求绝对值的函数                                |\n| `sqrt`                           | 求平方根的函数，相当于`array ** 0.5 `         |\n| `square`                         | 求平方的函数，相当于`array ** 2`              |\n| `exp`                            | 计算 $\\small{e^x}$ 的函数                               |\n| `log` / `log10` / `log2`         | 对数函数（`e`为底 / `10`为底 / `2`为底）      |\n| `sign`                           | 符号函数（`1` - 正数；`0` - 零；`-1` - 负数） |\n| `ceil` / `floor`                 | 上取整 /  下取整                              |\n| `isnan`                          | 返回布尔数组，NaN对应`True`，非NaN对应`False` |\n| `isfinite` / `isinf`             | 判断数值是否为无穷大的函数                    |\n| `cos` / `cosh` / `sin`           | 三角函数                                      |\n| `sinh` / `tan` / `tanh`          | 三角函数                                      |\n| `arccos` / `arccosh` / `arcsin`  | 反三角函数                                    |\n| `arcsinh` / `arctan` / `arctanh` | 反三角函数                                    |\n| `rint` / `round`                 | 四舍五入函数                                  |\n\n#### 通用二元函数\n\nNumPy 中通用二元函数的参数是两个数组对象，函数会对两个数组中的对应元素进行运算，例如：`maximum`函数会对两个数组中对应的元素找最大值，而`power`函数会对两个数组中对应的元素进行求幂操作，代码如下所示。\n\n代码：\n\n```python\narray3 = np.array([[4, 5, 6], [7, 8, 9]])\narray4 = np.array([[1, 2, 3], [3, 2, 1]])\nprint(np.maximum(array3, array4))\nprint(np.power(array3, array4))\n```\n\n输出：\n\n```\n[[4 5 6]\n [7 8 9]]\n[[  4  25 216]\n [343  64   9]]\n```\n\n**表2：通用二元函数**\n\n| 函数                               | 说明                                                         |\n| ---------------------------------- | ------------------------------------------------------------ |\n| `add(x, y)` / `substract(x, y)`    | 加法函数 / 减法函数                                          |\n| `multiply(x, y)` / `divide(x, y)`  | 乘法函数 / 除法函数                                          |\n| `floor_divide(x, y)` / `mod(x, y)` | 整除函数 / 求模函数                                          |\n| `allclose(x, y)`                   | 检查数组`x`和`y`元素是否几乎相等                             |\n| `power(x, y)`                      | 数组`x`的元素 $\\small{x_{i}}$ 和数组`y`的元素 $\\small{y_{i}}$，计算 $\\small{x_{i}^{y_{i}}}$ |\n| `maximum(x, y)` / `fmax(x, y)`     | 两两比较元素获取最大值 / 获取最大值（忽略NaN）               |\n| `minimum(x, y)` / `fmin(x, y)`     | 两两比较元素获取最小值 / 获取最小值（忽略NaN）               |\n| `dot(x, y)`                        | 点积运算（数量积，通常记为 $\\small{\\cdot}$ ，用于欧几里得空间（Euclidean space）） |\n| `inner(x, y)`                      | 内积运算（内积的含义要高于点积，点积相当于是内积在欧几里得空间 $\\small{\\mathbb{R}^{n}}$ 的特例，而内积可以推广到赋范向量空间，只要它满足平行四边形法则即可） |\n| `cross(x, y) `                     | 叉积运算（向量积，通常记为 $\\small{\\times}$ ，运算结果是一个向量）     |\n| `outer(x, y)`                      | 外积运算（张量积，通常记为 $\\small{\\bigotimes}$ ，运算结果通常是一个矩阵） |\n| `intersect1d(x, y)`                | 计算`x`和`y`的交集，返回这些元素构成的有序数组               |\n| `union1d(x, y)`                    | 计算`x`和`y`的并集，返回这些元素构成的有序数组               |\n| `in1d(x, y)`                       | 返回由判断`x` 的元素是否在`y`中得到的布尔值构成的数组        |\n| `setdiff1d(x, y)`                  | 计算`x`和`y`的差集，返回这些元素构成的数组                   |\n| `setxor1d(x, y)`                   | 计算`x`和`y`的对称差，返回这些元素构成的数组                 |\n\n>**说明**：关于向量和矩阵的运算，我们在下一个章节加以说明。\n\n#### 广播机制\n\n上面数组运算的例子中，两个数组的形状（`shape`属性）是完全相同的，我们再来研究一下，两个形状不同的数组是否可以直接做二元运算或使用通用二元函数进行运算，请看下面的例子。\n\n代码：\n\n```python\narray5 = np.array([[0, 0, 0], [1, 1, 1], [2, 2, 2], [3, 3, 3]])\narray6 = np.array([1, 2, 3])\narray5 + array6\n```\n\n输出：\n\n```\narray([[1, 2, 3],\n       [2, 3, 4],\n       [3, 4, 5],\n       [4, 5, 6]])\n```\n\n代码：\n\n```python\narray7 = np.array([[1], [2], [3], [4]])\narray5 + array7\n```\n\n输出：\n\n```\narray([[1, 1, 1],\n       [3, 3, 3],\n       [5, 5, 5],\n       [7, 7, 7]])\n```\n\n通过上面的例子，我们发现形状不同的数组仍然有机会进行二元运算，但这不代表任意形状的数组都可以进行二元运算。简单的说，只有两个数组后缘维度相同或者后缘维度不同但其中一个数组后缘维度为1时，广播机制才会被触发。通过广播机制，NumPy 将两个原本形状不相同的数组变成形状相同，才能进行二元运算。所谓后缘维度，指的是数组形状（`shape`属性）从后往前看对应的部分，我们举例说明。\n\n<img class=\"lazy\" data-src=\"/res/broadcast-1.png\" style=\"zoom:100%;\">\n\n上图中，一个数组的形状是`(4, 3)`，另一个数组的形状是`(3, )`，从后往前看对应的部分都是`3`，属于后缘维度相同，可以应用广播机制，第二个数组会沿着缺失元素那个轴的方向去广播自己，最终让两个数组形状达成一致。\n\n<img class=\"lazy\" data-src=\"/res/broadcast-3.png\" style=\"zoom:100%;\">\n\n上图中，一个数组的形状是`(3, 4, 2)`，另一个数组的形状是`(4, 2)`，从后往前看对应的部分都是`(4, 2)`，属于后缘维度相同，可以应用广播机制，第二个数组会沿着缺失元素那个轴的方向去广播自己，最终让两个数组形状达成一致。\n\n<img class=\"lazy\" data-src=\"/res/broadcast-2.png\" style=\"zoom:100%;\">\n\n上图中，一个数组的形状是`(4, 3)`，另一个数组的形状是`(4, 1)`，这是后缘维度不相同的情况，但是第二个数组跟第一个数组不同的地方为`1`，第二个数组可以沿着为`1` 的那个轴广播自己，最终让两个数组形状达成一致。\n\n> **思考**：一个3行1列的二维数组和一个1行3列的二维数组能够执行加法运算吗？\n\n### 其他常用函数\n\n除了上面讲到的函数外，NumPy 中还提供了很多用于处理数组的函数，`ndarray`对象的很多方法也可以通过调用函数来实现，下表给出了一些常用的函数。\n\n**表3：NumPy其他常用函数**\n\n| 函数                           | 说明                                             |\n| ------------------------------ | ------------------------------------------------ |\n| `unique`                       | 去除数组重复元素，返回唯一元素构成的有序数组     |\n| `copy`                         | 返回拷贝数组得到的数组                           |\n| `sort`                         | 返回数组元素排序后的拷贝                         |\n| `split` / `hsplit` / `vsplit`  | 将数组拆成若干个子数组                           |\n| `stack` / `hstack` / `vstack`  | 将多个数组堆叠成新数组                           |\n| `concatenate`                  | 沿着指定的轴连接多个数组构成新数组               |\n| `append` / `insert`            | 向数组末尾追加元素 / 在数组指定位置插入元素      |\n| `argwhere`                     | 找出数组中非0元素的位置                          |\n| `extract` / `select` / `where` | 按照指定的条件从数组中抽取或处理数组元素         |\n| `flip`                         | 沿指定的轴翻转数组中的元素                       |\n| `fromregex`                    | 通过读取文件和正则表达式解析获取数据创建数组对象 |\n| `repeat` / `tile`              | 通过对元素的重复来创建新数组                     |\n| `roll`                         | 沿指定轴对数组元素进行移位                       |\n| `resize`                       | 重新调整数组的大小                               |\n| `place` / `put`                | 将数组中满足条件的元素/指定的元素替换为指定的值  |\n| `partition`                    | 用选定的元素对数组进行一次划分并返回划分后的数组 |\n\n**去重（重复元素只保留一项）**。\n\n代码：\n\n```python\nnp.unique(array5)\n```\n\n输出：\n\n```\narray([0, 1, 2, 3])\n```\n\n**堆叠和拼接**。\n\n代码：\n\n```python\narray8 = np.array([[1, 1, 1], [2, 2, 2], [3, 3, 3]])\narray9 = np.array([[4, 4, 4], [5, 5, 5], [6, 6, 6]])\nnp.hstack((array8, array9))\n```\n\n输出：\n\n```\narray([[1, 1, 1, 4, 4, 4],\n       [2, 2, 2, 5, 5, 5],\n       [3, 3, 3, 6, 6, 6]])\n```\n\n代码：\n\n```python\nnp.vstack((array8, array9))\n```\n\n输出：\n\n```\narray([[1, 1, 1],\n       [2, 2, 2],\n       [3, 3, 3],\n       [4, 4, 4],\n       [5, 5, 5],\n       [6, 6, 6]])\n```\n\n代码：\n\n```python\nnp.concatenate((array8, array9))\n```\n\n输出：\n\n```\narray([[1, 1, 1],\n       [2, 2, 2],\n       [3, 3, 3],\n       [4, 4, 4],\n       [5, 5, 5],\n       [6, 6, 6]])\n```\n\n代码：\n\n```python\nnp.concatenate((array8, array9), axis=1)\n```\n\n输出：\n\n```\narray([[1, 1, 1, 4, 4, 4],\n       [2, 2, 2, 5, 5, 5],\n       [3, 3, 3, 6, 6, 6]])\n```\n\n**追加和插入元素**。\n\n代码：\n\n```python\nnp.append(array1, [10, 100])\n```\n\n输出：\n\n```\narray([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10, 100])\n```\n\n代码：\n\n```python\nnp.insert(array1, 1, [98, 99, 100])\n```\n\n输出：\n\n```\narray([  1,  98,  99, 100,   2,   3,   4,   5,   6,   7,   8,   9])\n```\n\n**抽取和处理元素**。\n\n代码：\n\n```python\nnp.extract(array1 % 2 != 0, array1)\n```\n\n输出：\n\n```\narray([1, 3, 5, 7, 9])\n```\n\n> **说明**：上面`extract`函数的操作相当于我们之前讲的布尔索引。\n\n代码：\n\n```python\nnp.select([array1 <= 3, array1 >= 7], [array1 * 10, array1 ** 2])\n```\n\n输出：\n\n```\narray([10, 20, 30,  0,  0,  0, 49, 64, 81])\n```\n\n> **说明**：上面`select`函数的第一个参数设置了两个条件，满足第一个条件的元素执行了乘以10的操作，满足第二个条件的元素执行了求平方的操作，两个条件都不能满足的数组元素会被处理为0。\n\n代码：\n\n```python\nnp.where(array1 <= 5, array1 * 10, array1 ** 2)\n```\n\n输出：\n\n```\narray([10, 20, 30, 40, 50, 36, 49, 64, 81])\n```\n\n> **说明**：上面`where`函数的第一个参数给出了条件，满足条件的元素执行了乘以10的操作，不能满足条件的元素执行了求平方的操作。\n\n**重复数组元素创建新数组**。\n\n代码：\n\n```python\nnp.repeat(array1, 3)\n```\n\n输出：\n\n```\narray([1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6, 7, 7, 7, 8, 8, 8, 9, 9, 9])\n```\n\n代码：\n\n```python\nnp.tile(array1, 2)\n```\n\n输出：\n\n```\narray([1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n```\n\n**调整数组大小**。\n\n代码：\n\n```python\nnp.resize(array1, (5, 3))\n```\n\n输出：\n\n```\narray([[1, 2, 3],\n       [4, 5, 6],\n       [7, 8, 9],\n       [1, 2, 3],\n       [4, 5, 6]])\n```\n\n> **提示**：`array1`原本是一个有9个元素的一维数组，通过`resize`函数调整成为5行3列共15个元素的二维数组，缺少的元素通过复用原数组中的元素来补充。\n\n代码：\n\n```python\n np.resize(array5, (2, 4))\n```\n\n输出：\n\n```\narray([[0, 0, 0, 1],\n       [1, 1, 2, 2]])\n```\n\n**替换数组元素**。\n\n代码：\n\n```python\nnp.put(array1, [0, 1, -1, 3, 5], [100, 200])\narray1\n```\n\n输出：\n\n```\narray([100, 200,   3, 200,   5, 100,   7,   8, 100])\n```\n\n> **说明**：上面`put`函的第二个参数给出了要被替换的元素的索引，但是用来作为替换值的元素只有`100`和`200`，所以这两个值会被循环使用，因此索引为`0`、`1`、`-1`、`3`、`5`的元素被依次替换成了`100`、`200`、`100`、`200`、`100`。\n\n代码：\n\n```python\nnp.place(array1, array1 > 5, [1, 2, 3])\narray1\n```\n\n输出：\n\n```\narray([1, 2, 3, 3, 5, 1, 2, 3, 1])\n```\n\n> **注意**：`put`函数和`place`函数都没有返回新的数组对象，而是在原来的数组上直接进行替换。\n", "NumPy的应用-4": "## NumPy的应用-4\n\n### 向量\n\n**向量**（*vector*）也叫**矢量**，是一个同时具有大小和方向，且满足平行四边形法则的几何对象。与向量相对的概念叫**标量**或**数量**，标量只有大小，绝大多数情况下没有方向。我们通常用带箭头的线段来表示向量，在平面直角坐标系中的向量如下图所示。需要注意的是，向量是表达大小和方向的量，并没有规定起点和终点，所以相同的向量可以画在任意位置，例如下图中 $\\small{\\boldsymbol{w}}$ 和 $\\small{\\boldsymbol{u}}$ 两个向量并没有什么区别。\n\n<img class=\"lazy\" data-src=\"/res/vector_1.png\" style=\"zoom:40%;\">\n\n向量有很多种代数表示法，对于二维空间的向量，下面几种写法都是可以的。\n\n$$\n\\boldsymbol{a} = \\langle a_1, a_2 \\rangle = (a_1, a_2) = \\begin{pmatrix} a_1 \\\\\\\\ a_2 \\end{pmatrix} = \\begin{bmatrix} a_1 \\\\\\\\ a_2 \\end{bmatrix}\n$$\n\n向量的大小称为向量的模，它是一个标量，对于二维空间的向量，模可以通过下面的公式计算。\n\n$$\n\\lvert \\boldsymbol{a} \\rvert = \\sqrt{a_{1}^{2} + a_{2}^{2}}\n$$\n\n注意，这里的 $\\small{\\lvert \\boldsymbol{a} \\rvert}$ 并不是绝对值，你可以将其称为向量 $\\small{\\boldsymbol{a}}$ 的二范数，这是数学中的符号重用现象。上面的写法和概念也可以推广到 $\\small{n}$ 维空间，我们通常用 $\\small{\\boldsymbol{R^{n}}}$ 表示 $\\small{n}$ 维空间，我们刚才说的二维空间可以记为 $\\small{\\boldsymbol{R^{2}}}$ ，三维空间可以记为 $\\small{\\boldsymbol{R^{3}}}$ 。虽然生活在三维空间的我们很难想象四维空间、五维空间是什么样子，但是这并不影响我们探讨高维空间，机器学习中，我们经常把有 $\\small{n}$ 个特征的训练样本称为一个 $\\small{n}$ 维向量。\n\n#### 向量的加法\n\n相同维度的向量可以相加得到一个新的向量，运算的方法是将向量的每个分量相加，如下所示。\n\n$$\n\\boldsymbol{u} = \\begin{bmatrix} u_1 \\\\\\\\ u_2 \\\\\\\\ \\vdots \\\\\\\\ u_n \\end{bmatrix}, \\quad\n\\boldsymbol{v} = \\begin{bmatrix} v_1 \\\\\\\\ v_2 \\\\\\\\ \\vdots \\\\\\\\ v_n \\end{bmatrix}, \\quad\n\\boldsymbol{u} + \\boldsymbol{v} = \\begin{bmatrix} u_1 + v_1 \\\\\\\\ u_2 + v_2 \\\\\\\\ \\vdots \\\\\\\\ u_n + v_n \\end{bmatrix}\n$$\n\n向量的加法满足“平行四边形法则”，即两个向量 $\\small{\\boldsymbol{u}}$ 和 $\\small{\\boldsymbol{v}}$ 构成了平行四边形的两条邻边，相加的结果是平行四边形的对角线，如下图所示。\n\n<img class=\"lazy\" data-src=\"/res/vector_2.png\" style=\"zoom:58%;\">\n\n#### 向量的数乘\n\n一个向量 $\\small{\\boldsymbol{v}}$ 可以和一个标量 $\\small{k}$ 相乘，运算的方法是将向量中的每个分量与该标量相乘即可，如下所示。\n\n$$\n\\boldsymbol{v} = \\begin{bmatrix} v_1 \\\\\\\\ v_2 \\\\\\\\ \\vdots \\\\\\\\ v_n \\end{bmatrix}, \\quad\nk \\cdot \\boldsymbol{v} = \\begin{bmatrix} k \\cdot v_1 \\\\\\\\ k \\cdot v_2 \\\\\\\\ \\vdots \\\\\\\\ k \\cdot v_n \\end{bmatrix}\n$$\n\n我们可以用 NumPy 的数组来表示向量，向量的加法可以通过两个数组的加法来实现，向量的数乘可以通过数组和标量的乘法来实现，此处不再进行赘述。\n\n#### 向量的点积\n\n点积（*dot product*）是两个向量之间最为重要的运算之一，运算的方法是将两个向量对应分量的乘积求和，所以点积的结果是一个标量，其几何意义是两个向量的模乘以二者夹角的余弦如下所示。\n\n$$\n\\boldsymbol{u} = \\begin{bmatrix} u_1 \\\\\\\\ u_2 \\\\\\\\ \\vdots \\\\\\\\ u_n \\end{bmatrix}, \\quad\n\\boldsymbol{v} = \\begin{bmatrix} v_1 \\\\\\\\ v_2 \\\\\\\\ \\vdots \\\\\\\\ v_n \\end{bmatrix} \\quad\n$$\n\n$$\n\\boldsymbol{u} \\cdot \\boldsymbol{v} = \\sum_{i=1}^{n}{u_iv_i} = \\lvert \\boldsymbol{u} \\rvert \\lvert \\boldsymbol{v} \\rvert cos\\theta\n$$\n\n假如我们用三维向量来表示用户对喜剧片、言情片和动作片这三类电影的偏好，我们用 1 到 5 的数字来表示喜欢的程度，其中 5 表示非常喜欢，4 表示比较喜欢，3 表示无感，2 表示比较反感，1 表示特别反感。那么，下面的向量表示用户非常喜欢喜剧片，特别反感言情片，对动作片不喜欢也不反感。\n\n$$\n\\boldsymbol{u} = \\begin{pmatrix} 5 \\\\\\\\ 1 \\\\\\\\ 3 \\end{pmatrix}\n$$\n\n现在有两部电影上映了，一部属于言情喜剧片，一部属于喜剧动作片，我们把两部电影也通过3维向量的方式进行表示，如下所示。\n\n$$\n\\boldsymbol{m_1} = \\begin{pmatrix} 4 \\\\\\\\ 5 \\\\\\\\ 1 \\end{pmatrix}, \\quad \\boldsymbol{m_2} = \\begin{pmatrix} 5 \\\\\\\\ 1 \\\\\\\\ 5 \\end{pmatrix}\n$$\n\n如果现在我们需要向刚才的用户推荐一部电影，我们应该给他推荐哪一部呢？我们可以将代表用户的向量 $\\small{\\boldsymbol{u}}$ 和代表电影的向量 $\\small{\\boldsymbol{m_{1}}}$ 和 $\\small{\\boldsymbol{m_{2}}}$ 分别进行点积运算，再除以向量的模长，得到向量夹角的余弦值，余弦值越接近 1，说明向量的夹角越接近 0 度，也就是两个向量的相似度越高。很显然，我们应该向用户推荐跟他观影喜好相似度更高的电影。\n\n$$\ncos\\theta_1 = \\frac{\\boldsymbol{u} \\cdot \\boldsymbol{m1}}{|\\boldsymbol{u}||\\boldsymbol{m1}|} \\approx \\frac{4 \\times 5 + 5 \\times 1 + 3 \\times 1}{5.92 \\times 6.48} \\approx 0.73\n$$\n\n$$\ncos\\theta_2 = \\frac{\\boldsymbol{u} \\cdot \\boldsymbol{m2}}{|\\boldsymbol{u}||\\boldsymbol{m2}|} \\approx \\frac{5 \\times 5 + 1 \\times 1 + 3 \\times 5}{5.92 \\times 7.14} \\approx 0.97\n$$\n\n大家可能会说，向量 $\\small{\\boldsymbol{m_{2}}}$ 代表的电影肉眼可见跟用户是更加匹配的。的确，对于一个三维向量我们凭借直觉也能够给出正确的答案，但是对于一个 $\\small{n}$ 维向量，当 $\\small{n}$ 的值非常大时，你还有信心凭借肉眼的观察和本能的直觉给出准确的答案吗？向量的点积可以通过`dot`函数来计算，而向量的模长可以通过 NumPy 的`linalg`模块中的`norm`函数来计算，代码如下所示。\n\n```python\nu = np.array([5, 1, 3])\nm1 = np.array([4, 5, 1])\nm2 = np.array([5, 1, 5])\nprint(np.dot(u, m1) / (np.linalg.norm(u) * np.linalg.norm(m1)))  # 0.7302967433402214\nprint(np.dot(u, m2) / (np.linalg.norm(u) * np.linalg.norm(m2)))  # 0.9704311900788593\n```\n\n#### 向量的叉积\n\n在二维空间，两个向量的叉积是这样定义的：\n\n$$\n\\boldsymbol{A} = \\begin{pmatrix} a_{1} \\\\\\\\ a_{2} \\end{pmatrix}, \\quad \\boldsymbol{B} = \\begin{pmatrix} b_{1} \\\\\\\\ b_{2} \\end{pmatrix}\n$$\n\n$$\n\\boldsymbol{A} \\times \\boldsymbol{B} = \\begin{vmatrix} a_{1} \\quad a_{2} \\\\\\\\ b_{1} \\quad b_{2} \\end{vmatrix} = a_{1}b_{2} - a_{2}b_{1}\n$$\n\n对于三维空间，两个向量的叉积结果是一个向量，如下所示：\n\n$$\n\\boldsymbol{A} = \\begin{pmatrix} a_{1} \\\\\\\\ a_{2} \\\\\\\\ a_{3} \\end{pmatrix}, \\quad \\boldsymbol{B} = \\begin{pmatrix} b_{1} \\\\\\\\ b_{2} \\\\\\\\ b_{3} \\end{pmatrix}\n$$\n\n$$\n\\boldsymbol{A} \\times \\boldsymbol{B} = \\begin{vmatrix} \\boldsymbol{\\hat{i}} \\quad \\boldsymbol{\\hat{j}} \\quad \\boldsymbol{\\hat{k}} \\\\\\\\ a_{1} \\quad a_{2} \\quad a_{3} \\\\\\\\ b_{1} \\quad b_{2} \\quad b_{3} \\end{vmatrix} = \\langle \\boldsymbol{\\hat{i}}\\begin{vmatrix} a_{2} \\quad a_{3} \\\\\\\\ b_{2} \\quad b_{3} \\end{vmatrix}, -\\boldsymbol{\\hat{j}}\\begin{vmatrix} a_{1} \\quad a_{3} \\\\\\\\ b_{1} \\quad b_{3} \\end{vmatrix}, \\boldsymbol{\\hat{k}}\\begin{vmatrix} a_{1} \\quad a_{2} \\\\\\\\ b_{1} \\quad b_{2} \\end{vmatrix} \\rangle\n$$\n\n因为叉积的结果是向量，所以 $\\small{\\boldsymbol{A} \\times \\boldsymbol{B}}$ 和 $\\small{\\boldsymbol{B} \\times \\boldsymbol{A}}$ 的结果并不相同，事实上：\n\n$$\n\\boldsymbol{A} \\times \\boldsymbol{B} = -(\\boldsymbol{B} \\times \\boldsymbol{A})\n$$\n\nNumPy 中可以通过`cross`函数来计算向量的叉积，代码如下所示。\n\n```python\nprint(np.cross(u, m1))  # [-14   7  21]\nprint(np.cross(m1, u))  # [ 14  -7 -21]\n```\n\n### 行列式\n\n**行列式**（*determinant*）通常记作 $\\small{det(\\boldsymbol{A})}$ 或 $\\small{ \\lvert \\boldsymbol{A} \\rvert}$ ，其中 $\\small{\\boldsymbol{A}}$ 是一个 $\\small{n}$ 阶方阵。行列式可以看做是有向面积或体积的概念在一般欧几里得空间的推广，或者说行列式描述的是一个线性变换对“体积”所造成的影响。行列式的概念最早出现在解线性方程组的过程中，十七世纪晚期，关孝和（日本江户时代的数学家）与莱布尼茨的著作中已经使用行列式来确定线性方程组解的个数以及形式；十八世纪开始，行列式开始作为独立的数学概念被研究；十九世纪以后，行列式理论进一步得到发展和完善。\n\n#### 行列式的性质\n\n行列式是由向量引出的，所以行列式解释的其实是向量的性质。\n\n**性质1**：如果 $\\small{det(\\boldsymbol{A})}$ 中某行（或某列）的元素全部为 0，那么 $\\small{det(\\boldsymbol{A}) = 0}$ 。\n\n**性质2**：如果 $\\small{det(\\boldsymbol{A})}$ 中某行（或某列）有公共因子 $\\small{k}$ ，则可以提出 $\\small{k}$ ，得到行列式 $\\small{det(\\boldsymbol{A^{'}})}$ ，且 $\\small{det(\\boldsymbol{A}) = k \\cdot det(\\boldsymbol{A^{'}})}$ 。\n\n$$\ndet(\\boldsymbol{A})={\\begin{vmatrix}a_{11}&a_{12}&\\dots &a_{1n}\\\\\\\\\\vdots &\\vdots &\\ddots &\\vdots \\\\\\\\{\\color {blue}k}a_{i1}&{\\color {blue}k}a_{i2}&\\dots &{\\color {blue}k}a_{in}\\\\\\\\\\vdots &\\vdots &\\ddots &\\vdots \\\\\\\\a_{n1}&a_{n2}&\\dots &a_{nn}\\end{vmatrix}}={\\color {blue}k}{\\begin{vmatrix}a_{11}&a_{12}&\\dots &a_{1n}\\\\\\\\\\vdots &\\vdots &\\ddots &\\vdots \\\\\\\\a_{i1}&a_{i2}&\\dots &a_{in}\\\\\\\\\\vdots &\\vdots &\\ddots &\\vdots \\\\\\\\a_{n1}&a_{n2}&\\dots &a_{nn}\\end{vmatrix}}={\\color {blue}k} \\cdot det(\\boldsymbol{A^{'}})\n$$\n\n**性质3**：如果 $\\small{det(\\boldsymbol{A})}$ 中某行（或某列）的每个元素是两数之和，则此行列式可拆分为两个行列式相加，如下所示。\n\n$$\n{\\begin{vmatrix}a_{11}&a_{12}&\\dots &a_{1n}\\\\\\\\\\vdots &\\vdots &\\ddots &\\vdots \\\\\\\\{\\color {blue}a_{i1}}+{\\color {OliveGreen}b_{i1}}&{\\color {blue}a_{i2}}+{\\color {OliveGreen}b_{i2}}&\\dots &{\\color {blue}a_{in}}+{\\color {OliveGreen}b_{in}}\\\\\\\\\\vdots &\\vdots &\\ddots &\\vdots \\\\\\\\a_{n1}&a_{n2}&\\dots &a_{nn}\\end{vmatrix}}={\\begin{vmatrix}a_{11}&a_{12}&\\dots &a_{1n}\\\\\\\\\\vdots &\\vdots &\\ddots &\\vdots \\\\\\\\{\\color {blue}a_{i1}}&{\\color {blue}a_{i2}}&\\dots &{\\color {blue}a_{in}}\\\\\\\\\\vdots &\\vdots &\\ddots &\\vdots \\\\\\\\a_{n1}&a_{n2}&\\dots &a_{nn}\\end{vmatrix}}+{\\begin{vmatrix}a_{11}&a_{12}&\\dots &a_{1n}\\\\\\\\\\vdots &\\vdots &\\ddots &\\vdots \\\\\\\\{\\color {OliveGreen}b_{i1}}&{\\color {OliveGreen}b_{i2}}&\\dots &{\\color {OliveGreen}b_{in}}\\\\\\\\\\vdots &\\vdots &\\ddots &\\vdots \\\\\\\\a_{n1}&a_{n2}&\\dots &a_{nn}\\end{vmatrix}}\n$$\n\n**性质4**：如果 $\\small{det(\\boldsymbol{A})}$ 中两行（或两列）元素对应成比例，那么 $\\small{det(\\boldsymbol{A}) = 0}$ 。\n\n**性质5**：如果 $\\small{det(\\boldsymbol{A})}$ 中两行（或两列）互换得到 $\\small{det(\\boldsymbol{A^{'}})}$ ，那么 $\\small{det(\\boldsymbol{A}) = -det(\\boldsymbol{A^{'}})}$ 。\n\n**性质6**：将 $\\small{det(\\boldsymbol{A})}$ 中某行（或某列）的 $\\small{k}$ 倍加进另一行（或另一列）里，行列式的值不变，如下所示。\n\n$$\n{\\begin{vmatrix}\\vdots &\\vdots &\\vdots &\\vdots \\\\\\\\ a_{i1}&a_{i2}&\\dots &a_{in} \\\\\\\\ a_{j1}&a_{j2}&\\dots &a_{jn}\\\\\\\\\\vdots &\\vdots &\\vdots &\\vdots \\\\\\\\ \\end{vmatrix}}={\\begin{vmatrix}\\vdots &\\vdots &\\vdots &\\vdots \\\\\\\\ a_{i1}&a_{i2}&\\dots &a_{in} \\\\\\\\ a_{j1}{\\color {blue}+ka_{i1}}&a_{j2}{\\color {blue}+ka_{i2}}&\\dots &a_{jn}{\\color {blue}+ka_{in}} \\\\\\\\ \\vdots &\\vdots &\\vdots &\\vdots \\\\\\\\ \\end{vmatrix}}\n$$\n\n**性质7**：将行列式的行列互换，行列式的值不变，如下所示。\n\n$$\n{\\begin{vmatrix}a_{11}&a_{12}&\\dots &a_{1n} \\\\\\\\ a_{21}&a_{22}&\\dots &a_{2n} \\\\\\\\ \\vdots &\\vdots &\\ddots &\\vdots  \\\\\\\\ a_{n1}&a_{n2}&\\dots &a_{nn}\\end{vmatrix}}={\\begin{vmatrix}a_{11}&a_{21}&\\dots &a_{n1} \\\\\\\\ a_{12}&a_{22}&\\dots &a_{n2} \\\\\\\\ \\vdots &\\vdots &\\ddots &\\vdots  \\\\\\\\ a_{1n}&a_{2n}&\\dots &a_{nn}\\end{vmatrix}}\n$$\n\n**性质8**：方块矩阵 $\\small{\\boldsymbol{A}}$ 和 $\\small{\\boldsymbol{B}}$ 的乘积的行列式等于其行列式的乘积，即 $\\small{det(\\boldsymbol{A}\\boldsymbol{B}) = det(\\boldsymbol{A})det(\\boldsymbol{B})}$ 。特别的，若将矩阵中的每一行都乘以常数 $\\small{r}$ ，那么行列式的值将是原来的 $\\small{r^{n}}$ 倍，即 $\\small{det(r\\boldsymbol{A}) = det(r\\boldsymbol{I_{n}} \\cdot \\boldsymbol{A}) = r^{n}det(\\boldsymbol{A})}$ ，其中 $\\small{\\boldsymbol{I_{n}}}$ 是 $\\small{n}$ 阶单位矩阵。\n\n**性质9**：若 $\\small{\\boldsymbol{A}}$ 是可逆矩阵，那么 $\\small{det(\\boldsymbol{A}^{-1}) = (det(\\boldsymbol{A}))^{-1}}$ 。\n\n#### 行列式的计算\n\n$\\small{n}$ 阶行列式的计算公式如下所示：\n\n$$\ndet(\\boldsymbol{A})=\\sum_{n!} \\pm {a_{1\\alpha}a_{2\\beta} \\cdots a_{n\\omega}}\n$$\n\n对于二阶行列式，上面的公式相当于：\n\n$$\n\\begin{vmatrix} a_{11} \\quad a_{12} \\\\\\\\ a_{21} \\quad a_{22} \\end{vmatrix} = a_{11}a_{22} - a_{12}a_{21}\n$$\n\n对于三阶行列式，上面的计算公式相当于：\n\n$$\n\\begin{vmatrix} a_{11} \\quad a_{12} \\quad a_{13} \\\\\\\\ a_{21} \\quad a_{22} \\quad a_{23} \\\\\\\\ a_{31} \\quad a_{32} \\quad a_{33} \\end{vmatrix} = a_{11}a_{22}a_{33} + a_{12}a_{23}a_{31} + a_{13}a_{21}a_{32} - a_{11}a_{23}a_{32} - a_{12}a_{21}a_{33} - a_{13}a_{22}a_{31}\n$$\n\n高阶行列式可以用**代数余子式**（*cofactor*）展开成多个低阶行列式，如下所示：\n\n$$\ndet(\\boldsymbol{A})=a_{11}C_{11}+a_{12}C_{12}+ \\cdots +a_{1n}C_{1n} = \\sum_{i=1}^{n}{a_{1i}C_{1i}}\n$$\n\n其中， $\\small{C_{11}}$ 是原行列式去掉 $\\small{a_{11}}$ 所在行和列之后剩余的部分构成的行列式，以此类推。\n\n### 矩阵\n\n**矩阵**（*matrix*）是由一系列元素排成的矩形阵列，矩阵里的元素可以是数字、符号或数学公式。矩阵可以进行**加法**、**减法**、**数乘**、**转置**、**矩阵乘法**等运算，如下图所示。\n\n<img class=\"lazy\" data-src=\"/res/matrix_operation.png\" style=\"zoom:62%;\">\n\n值得一提的是矩阵乘法运算，该运算仅当第一个矩阵 $\\small{\\boldsymbol{A}}$ 的列数和另一个矩阵 $\\small{\\boldsymbol{B}}$ 的行数相等时才能定义。如果 $\\small{\\boldsymbol{A}}$ 是一个 $\\small{m \\times n}$ 的矩阵， $\\small{\\boldsymbol{B}}$ 是一个 $\\small{n \\times k}$ 矩阵，它们的乘积是一个 $\\small{m \\times k}$ 的矩阵，如下图所示。\n\n<img class=\"lazy\" data-src=\"/res/matrix_multiply.png\" style=\"zoom:35%;\">\n\n例如：\n\n$$\n\\begin{bmatrix} 1 & 0 & 2 \\\\\\\\ -1 & 3 & 1 \\end{bmatrix} \\times \\begin{bmatrix} 3 & 1 \\\\\\\\ 2 & 1 \\\\\\\\ 1 & 0 \\end{bmatrix} = \\begin{bmatrix} (1 \\times 3  +  0 \\times 2  +  2 \\times 1) & (1 \\times 1   +   0 \\times 1   +   2 \\times 0) \\\\\\\\ (-1 \\times 3  +  3 \\times 2  +  1 \\times 1) & (-1 \\times 1   +   3 \\times 1   +   1 \\times 0) \\end{bmatrix} = \\begin{bmatrix} 5 & 1 \\\\\\\\ 4 & 2 \\end{bmatrix}\n$$\n\n矩阵的乘法满足结合律和对矩阵加法的分配律：\n\n结合律： $\\small{(\\boldsymbol{AB})\\boldsymbol{C} = \\boldsymbol{A}(\\boldsymbol{BC})}$ 。\n\n左分配律： $\\small{(\\boldsymbol{A} + \\boldsymbol{B})\\boldsymbol{C} = \\boldsymbol{AC} + \\boldsymbol{BC}}$ 。\n\n右分配律： $\\small{\\boldsymbol{C}(\\boldsymbol{A} + \\boldsymbol{B}) = \\boldsymbol{CA} + \\boldsymbol{CB}}$。\n\n**矩阵乘法不满足交换律**。一般情况下，矩阵 $\\small{\\boldsymbol{A}}$ 和 $\\small{\\boldsymbol{B}}$ 的乘积 $\\small{\\boldsymbol{AB}}$ 存在，但 $\\small{\\boldsymbol{BA}}$ 不一定存在，即便 $\\small{\\boldsymbol{BA}}$ 存在，大多数时候 $\\small{\\boldsymbol{AB} \\neq \\boldsymbol{BA}}$ 。\n\n矩阵乘法的一个基本应用是在线性方程组上。线性方程组是方程组的一种，它符合以下的形式：\n\n$$\n\\begin{cases}\n     a_{1,1}x_{1} + a_{1,2}x_{2} + \\cdots + a_{1,n}x_{n}=  b_{1} \\\\\\\\\n     a_{2,1}x_{1} + a_{2,2}x_{2} + \\cdots + a_{2,n}x_{n}=  b_{2} \\\\\\\\\n     \\vdots \\quad \\quad \\quad \\vdots \\\\\\\\\n     a_{m,1}x_{1} + a_{m,2}x_{2} + \\cdots + a_{m,n}x_{n}=  b_{m}\n \\end{cases}\n$$\n\n运用矩阵的方式，可以将线性方程组写成一个向量方程：\n\n$$\n\\boldsymbol{Ax} = \\boldsymbol{b}\n$$\n\n其中， $\\small{\\boldsymbol{A}}$ 是由方程组里未知数的系数排成的 $\\small{m \\times n}$ 矩阵， $\\small{\\boldsymbol{x}}$ 是含有 $\\small{n}$ 个元素的行向量， $\\small{\\boldsymbol{b}}$ 是含有 $\\small{m}$ 个元素的行向量。\n\n矩阵是线性变换（保持向量加法和标量乘法的函数）的便利表达法。矩阵乘法的本质在联系到线性变换的时候最能体现，因为矩阵乘法和线性变换的合成有以下的联系，即每个 $\\small{m \\times n}$ 的矩阵 $\\small{\\boldsymbol{A}}$ 都代表了一个从 $\\small{\\boldsymbol{R}^{n}}$ 射到 $\\small{\\boldsymbol{R}^{m}}$ 的线性变换。如果无法理解上面这些内容，推荐大家看看B站上名为[《线性代数的本质》](https://www.bilibili.com/video/BV1ib411t7YR/)的视频，相信这套视频会让你对线性代数有一个更好的认知。\n\n下图是一个来自于维基百科的例子，图中展示了一些典型的二维实平面上的线性变换对平面向量（图形）造成的效果以及它们对应的二维矩阵，其中每个线性变换将蓝色图形映射成绿色图形；平面的原点 $\\small{(0, 0)}$ 用黑点表示。\n\n<img class=\"lazy\" data-src=\"/res/linear_transformation.png\" style=\"zoom:45%;\">\n\n#### 矩阵对象\n\nNumPy 中提供了专门用于线性代数（*linear algebra*）的模块和表示矩阵的类型`matrix`，当然我们通过二维数组也可以表示一个矩阵，官方并不推荐使用`matrix`类而是建议使用二维数组，而且有可能在将来的版本中会移除`matrix`类。无论如何，利用这些已经封装好的类和函数，我们可以轻松愉快的实现很多对矩阵的操作。\n\n我们可以通过下面的代码来创建矩阵（`matrix`）对象。\n\n代码：\n\n```Python\nm1 = np.matrix('1 2 3; 4 5 6')\nm1\n```\n\n> **说明**：`matrix`构造器可以传入类数组对象也可以传入字符串来构造矩阵对象。\n\n输出：\n\n```\nmatrix([[1, 2, 3],\n        [4, 5, 6]])\n```\n\n代码：\n\n```Python\nm2 = np.asmatrix(np.array([[1, 1], [2, 2], [3, 3]]))\nm2\n```\n\n> **说明**：`asmatrix`函数也可以用`mat`函数代替，这两个函数其实是同一个函数。\n\n输出：\n\n```\nmatrix([[1, 1],\n        [2, 2],\n        [3, 3]])\n```\n\n代码：\n\n```Python\nm1 * m2\n```\n\n输出：\n\n```\nmatrix([[14, 14],\n        [32, 32]])\n```\n\n> **说明**：注意`matrix`对象和`ndarray`对象乘法运算的差别，`matrix`对象的`*`运算是矩阵乘法运算。如果两个二维数组要做矩阵乘法运算，应该使用`@`运算符或`matmul`函数，而不是`*`运算符。\n\n矩阵对象的属性如下表所示。\n\n| 属性    | 说明                                      |\n| ------- | ----------------------------------------- |\n| `A`     | 获取矩阵对象对应的`ndarray`对象           |\n| `A1`    | 获取矩阵对象对应的扁平化后的`ndarray`对象 |\n| `I`     | 可逆矩阵的逆矩阵                          |\n| `T`     | 矩阵的转置                                |\n| `H`     | 矩阵的共轭转置                            |\n| `shape` | 矩阵的形状                                |\n| `size`  | 矩阵元素的个数                            |\n\n矩阵对象的方法跟之前讲过的`ndarray`数组对象的方法基本差不多，此处不再进行赘述。\n\n#### 线性代数模块\n\nNumPy 的`linalg`模块中有一组标准的矩阵分解运算以及诸如求逆和行列式之类的函数，它们跟 MATLAB 和 R 等语言所使用的是相同的行业标准线性代数库，下面的表格列出了`numpy`以及`linalg`模块中一些常用的线性代数相关函数。\n\n| 函数          | 说明                                                         |\n| ------------- | ------------------------------------------------------------ |\n| `diag`        | 以一维数组的形式返回方阵的对角线元素或将一维数组转换为方阵（非对角元素元素为0） |\n| `matmul`      | 矩阵乘法运算                                                 |\n| `trace`       | 计算对角线元素的和                                           |\n| `norm`        | 求矩阵或向量的范数                                           |\n| `det`         | 计算行列式的值                                               |\n| `matrix_rank` | 计算矩阵的秩                                                 |\n| `eig`         | 计算矩阵的特征值（*eigenvalue*）和特征向量（*eigenvector*）  |\n| `inv`         | 计算非奇异矩阵（ $\\small{n}$ 阶方阵）的逆矩阵                |\n| `pinv`        | 计算矩阵的摩尔-彭若斯（*Moore-Penrose*）广义逆               |\n| `qr`          | QR分解（把矩阵分解成一个正交矩阵与一个上三角矩阵的积）       |\n| `svd`         | 计算奇异值分解（*singular value decomposition*）             |\n| `solve`       | 解线性方程组 $\\small{\\boldsymbol{Ax}=\\boldsymbol{b}}$，其中 $\\small{\\boldsymbol{A}}$ 是一个方阵 |\n| `lstsq`       | 计算 $\\small{\\boldsymbol{Ax}=\\boldsymbol{b}}$ 的最小二乘解   |\n\n下面我们简单尝试一下上面的函数，先试一试求逆矩阵。\n\n代码：\n\n```Python\nm3 = np.array([[1., 2.], [3., 4.]])\nm4 = np.linalg.inv(m3)\nm4\n```\n\n输出：\n\n```\narray([[-2. ,  1. ],\n       [ 1.5, -0.5]])\n```\n\n代码：\n\n```Python\nnp.around(m3 @ m4)\n```\n\n> **说明**：`around`函数对数组元素进行四舍五入操作，默认小数点后面的位数为0。\n\n输出：\n\n```\narray([[1., 0.],\n       [0., 1.]])\n```\n\n> **说明**：矩阵和它的逆矩阵做矩阵乘法会得到单位矩阵。\n\n计算行列式的值。\n\n代码：\n\n```Python\nm5 = np.array([[1, 3, 5], [2, 4, 6], [4, 7, 9]])\nnp.linalg.det(m5)\n```\n\n输出：\n\n```\n2\n```\n\n计算矩阵的秩。\n\n代码：\n\n```Python\nnp.linalg.matrix_rank(m5)\n```\n\n输出：\n\n```\n3\n```\n\n求解线性方程组。\n\n$$\n\\begin{cases}\nx_1 + 2x_2 + x_3 = 8 \\\\\\\\\n3x_1 + 7x_2 + 2x_3 = 23 \\\\\\\\\n2x_1 + 2x_2 + x_3 = 9\n\\end{cases}\n$$\n\n对于上面的线性方程组，我们可以用矩阵的形式来表示它，如下所示。\n\n$$\n\\boldsymbol{A} = \\begin{bmatrix}\n1 & 2 & 1 \\\\\\\\\n3 & 7 & 2 \\\\\\\\\n2 & 2 & 1\n\\end{bmatrix}, \\quad\n\\boldsymbol{x} = \\begin{bmatrix}\nx_1 \\\\\\\\\nx_2 \\\\\\\\\nx_3\n\\end{bmatrix}, \\quad\n\\boldsymbol{b} = \\begin{bmatrix}\n8 \\\\\\\\\n23 \\\\\\\\\n9\n\\end{bmatrix}\n$$\n\n$$\n\\boldsymbol{Ax} = \\boldsymbol{b}\n$$\n\n线性方程组有唯一解的条件：系数矩阵 $\\small{\\boldsymbol{A}}$ 的秩等于增广矩阵 $\\small{\\boldsymbol{Ab}}$ 的秩，而且跟未知数的个数相同。\n\n代码：\n\n```Python\nA = np.array([[1, 2, 1], [3, 7, 2], [2, 2, 1]])\nb = np.array([8, 23, 9]).reshape(-1, 1)\nprint(np.linalg.matrix_rank(A))\nprint(np.linalg.matrix_rank(np.hstack((A, b))))\n```\n\n> **说明**：使用数组对象的`reshape`方法调形时，如果其中一个参数为-1，那么该维度有多少个元素是通过数组元素个数（`size`属性）和其他维度的元素个数自动计算出来的。\n\n输出：\n\n```\n3\n3\n```\n\n代码：\n\n```Python\nnp.linalg.solve(A, b)\n```\n\n输出：\n\n```\narray([[1.],\n       [2.],\n       [3.]])\n```\n\n> **说明**：上面的结果表示，线性方程组的解为： $\\small{x_1 = 1, x_2 = 2, x_3 = 3}$ 。\n\n下面是另一种求解线性方程组的方法，大家可以停下来思考下为什么。\n\n$$\n\\boldsymbol{x} = \\boldsymbol{A}^{-1} \\cdot \\boldsymbol{b}\n$$\n\n代码：\n\n```Python\nnp.linalg.inv(A) @ b\n```\n\n输出：\n\n```\narray([[1.],\n       [2.],\n       [3.]])\n```\n\n### 多项式\n\n除了数组，NumPy 中还封装了用于**多项式**（*polynomial*）运算的数据类型。多项式是变量的整数次幂与系数的乘积之和，形如：\n\n$$\nf(x)=a_nx^n + a_{n-1}x^{n-1} + \\cdots + a_1x^{1} + a_0x^{0}\n$$\n\n在 NumPy 1.4版本之前，我们可以用`poly1d`类型来表示多项式，目前它仍然可用，但是官方提供了新的模块`numpy.polynomial`，它除了支持基本的幂级数多项式外，还可以支持切比雪夫多项式、拉盖尔多项式等。\n\n#### 创建多项式对象\n\n创建`poly1d`对象，例如： $\\small{f(x)=3x^{2}+2x+1}$ 。\n\n代码：\n\n```python\np1 = np.poly1d([3, 2, 1])\np2 = np.poly1d([1, 2, 3])\nprint(p1)\nprint(p2)\n```\n\n输出：\n\n```\n   2\n3 x + 2 x + 1\n   2\n1 x + 2 x + 3\n```\n\n#### 多项式的操作\n\n**获取多项式的系数**\n\n代码：\n\n```python\nprint(p1.coefficients)\nprint(p2.coeffs)\n```\n\n输出：\n\n```\n[3 2 1]\n[1 2 3]\n```\n\n**两个多项式的四则运算**\n\n代码：\n\n```python\nprint(p1 + p2)\nprint(p1 * p2)\n```\n\n输出：\n\n```\n   2\n4 x + 4 x + 4\n   4     3      2\n3 x + 8 x + 14 x + 8 x + 3\n```\n\n**带入 $\\small{x}$ 求多项式的值**\n\n代码：\n\n```python\nprint(p1(3))\nprint(p2(3))\n```\n\n输出：\n\n```\n34\n18\n```\n\n**多项式求导和不定积分**\n\n代码：\n\n```python\nprint(p1.deriv())\nprint(p1.integ())\n```\n\n输出：\n\n```\n\n6 x + 2\n   3     2\n1 x + 1 x + 1 x\n```\n\n**求多项式的根**\n\n例如有多项式 $\\small{f(x)=x^2+3x+2}$ ，多项式的根即一元二次方程 $\\small{x^2+3x+2=0}$ 的解。\n\n代码：\n\n```python\np3 = np.poly1d([1, 3, 2])\nprint(p3.roots)\n```\n\n输出：\n\n```\n[-2. -1.]\n```\n\n如果使用`numpy.polynomial`模块的`Polynomial`类来表示多项式对象，那么对应的操作如下所示。\n\n代码：\n\n```python\nfrom numpy.polynomial import Polynomial\n\np3 = Polynomial((2, 3, 1))\nprint(p3)           # 输出多项式\nprint(p3(3))        # 令x=3，计算多项式的值\nprint(p3.roots())   # 计算多项式的根\nprint(p3.degree())  # 获得多项式的次数\nprint(p3.deriv())   # 求导\nprint(p3.integ())   # 求不定积分\n```\n\n输出：\n\n```\n2.0 + 3.0·x + 1.0·x²\n20.0\n[-2. -1.]\n2\n3.0 + 2.0·x\n0.0 + 2.0·x + 1.5·x² + 0.33333333·x³\n```\n\n#### 最小二乘解\n\n`Polynomial`类还有一个名为`fit`的类方法，它可以给多项式求最小二乘解。所谓最小二乘解（least-squares solution），是用最小二乘法通过最小化误差的平方和来寻找数据的最佳匹配函数的系数。假设多项式为 $\\small{f(x)=ax+b}$ ，最小二乘解就是让下面的残差平方和 $\\small{RSS}$ 达到最小的 $\\small{a}$ 和 $\\small{b} $。\n\n$$\nRSS = \\sum_{i=0}^{k}{(f(x_i) - y_i)^{2}}\n$$\n\n例如，我们想利用收集到的月收入和网购支出的历史数据来建立一个预测模型，以达到通过某人的月收入预测他网购支出金额的目标，下面是我们收集到的收入和网购支出的数据，保存在两个数组中。\n\n```python\nx = np.array([\n    25000, 15850, 15500, 20500, 22000, 20010, 26050, 12500, 18500, 27300,\n    15000,  8300, 23320,  5250,  5800,  9100,  4800, 16000, 28500, 32000,\n    31300, 10800,  6750,  6020, 13300, 30020,  3200, 17300,  8835,  3500\n])\ny = np.array([\n    2599, 1400, 1120, 2560, 1900, 1200, 2320,  800, 1650, 2200,\n     980,  580, 1885,  600,  400,  800,  420, 1380, 1980, 3999,\n    3800,  725,  520,  420, 1200, 4020,  350, 1500,  560,  500\n])\n```\n\n我们可以先绘制散点图来了解两组数据是否具有正相关或负相关关系。正相关意味着数组`x`中较大的值对应到数组`y`中也是较大的值，而负相关则意味着数组`x`中较大的值对应到数组`y`中较小的值。\n\n```python\nimport matplotlib.pyplot as plt\n\nplt.figure(dpi=120)\nplt.scatter(x, y, color='blue')\nplt.show()\n```\n\n输出：\n\n<img class=\"lazy\" data-src=\"/res/in_out_scatter_plot.png\" style=\"zoom:50%;\">\n\n如果需要定量的研究两组数据的相关性，我们可以计算协方差或相关系数，对应的 NumPy 函数分别是`cov`和`corrcoef`。\n\n代码：\n\n```python\nnp.corrcoef(x, y)\n```\n\n输出：\n\n```\narray([[1.        , 0.92275889],\n       [0.92275889, 1.        ]])\n```\n\n> **说明**：相关系数是一个`-1`到`1`之间的值，越靠近`1` 说明正相关性越强，越靠近`-1`说明负相关性越强，靠近`0`则说明两组数据没有明显的相关性。上面月收入和网购支出之间的相关系数是`0.92275889`，说明二者是强正相关关系。\n\n通过上面的操作，我们确定了收入和网购支出之前存在强正相关关系，于是我们用这些数据来创建一个回归模型，找出一条能够很好的拟合这些数据点的直线。这里，我们就可以用到上面提到的`fit`方法，具体的代码如下所示。\n\n代码：\n\n```python\nfrom numpy.polynomial import Polynomial\n\nPolynomial.fit(x, y, deg=1).convert().coef\n```\n\n> **说明**：`deg=1`说明回归模型最高次项就是1次项，回归模型形如 $\\small{y=ax+b}$ ；如果要生一个类似于 $\\small{y=ax^2+bx+c}$ 的模型，就需要设置`deg=2`，以此类推。\n\n输出：\n\n```\narray([-2.94883437e+02,  1.10333716e-01])\n```\n\n根据上面输出的结果，我们的回归方程应该是 $\\small{y=0.110333716x-294.883437}$ 。我们将这个回归方程绘制到刚才的散点图上，红色的点是我们的预测值，蓝色的点是历史数据，也就是真实值。\n\n代码：\n\n```python\nimport matplotlib.pyplot as plt\n\nplt.scatter(x, y, color='blue')\nplt.scatter(x, 0.110333716 * x - 294.883437, color='red')\nplt.plot(x, 0.110333716 * x - 294.883437, color='darkcyan')\nplt.show()\n```\n\n输出：\n\n<img class=\"lazy\" data-src=\"/res/in_out_regression_result.png\" style=\"zoom:50%;\">\n\n如果不使用`Polynomial`类型的`fit`方法，我们也可以通过 NumPy 提供的`polyfit`函数来完成同样的操作，有兴趣的读者可以自行研究。\n\n> **说明**：本章部分图片来自于维基百科。", "深入浅出pandas-1": "## 深入浅出pandas-1\n\nPandas 是 Wes McKinney 在2008年开发的一个强大的**分析结构化数据**的工具集。Pandas 以 NumPy 为基础（实现数据存储和运算），提供了专门用于数据分析的类型、方法和函数，对数据分析和数据挖掘提供了很好的支持；同时 pandas 还可以跟数据可视化工具 matplotlib 很好的整合在一起，非常轻松愉快的实现数据可视化呈现。\n\nPandas 核心的数据类型是`Series`（数据系列）、`DataFrame`（数据窗/数据框），分别用于处理一维和二维的数据，除此之外，还有一个名为`Index`的类型及其子类型，它们为`Series`和`DataFrame`提供了索引功能。日常工作中`DataFrame`使用得最为广泛，因为二维的数据结构刚好可以对应有行有列的表格。`Series`和`DataFrame`都提供了大量的处理数据的方法，数据分析师以此为基础，可以实现对数据的筛选、合并、拼接、清洗、预处理、聚合、透视和可视化等各种操作。\n\n### 创建Series对象\n\nPandas 库中的`Series`对象可以用来表示一维数据结构，但是多了索引和一些额外的功能。`Series`类型的内部结构包含了两个数组，其中一个用来保存数据，另一个用来保存数据的索引。我们可以通过列表或数组创建`Series`对象，代码如下所示。\n\n代码：\n\n```Python\nimport numpy as np\nimport pandas as pd\n\nser1 = pd.Series(data=[120, 380, 250, 360], index=['一季度', '二季度', '三季度', '四季度'])\nser1\n```\n\n> **说明**：`Series`构造器中的`data`参数表示数据，`index`参数表示数据的索引，相当于数据对应的标签。\n\n输出：\n\n```\n一季度    120\n二季度    380\n三季度    250\n四季度    360\ndtype: int64\n```\n\n通过字典创建Series对象。\n\n代码：\n\n```Python\nser2 = pd.Series({'一季度': 320, '二季度': 180, '三季度': 300, '四季度': 405})\nser2\n```\n\n> **说明**：通过字典创建`Series`对象时，字典的键就是数据的标签（索引），键对应的值就是数据。\n\n输出：\n\n```\n一季度    320\n二季度    180\n三季度    300\n四季度    405\ndtype: int64\n```\n\n### Series对象的运算\n\n#### 标量运算\n\n我们尝试给刚才的`ser1`每个季度加上`10`，代码如下所示。\n\n代码：\n\n```python\nser1 += 10\nser1\n```\n\n输出：\n\n```\n一季度    130\n二季度    390\n三季度    260\n四季度    370\ndtype: int64\n```\n\n#### 矢量运算\n\n我们尝试把`ser1`和`ser2`对应季度的数据加起来，代码如下所示。\n\n代码：\n\n```python\nser1 + ser2\n```\n\n输出：\n\n```\n一季度    450\n二季度    570\n三季度    560\n四季度    775\ndtype: int64\n```\n\n#### 索引运算\n\n##### 普通索引\n\n跟数组一样，`Series`对象也可以进行索引和切片操作，不同的是`Series`对象因为内部维护了一个保存索引的数组，所以除了可以使用整数索引检索数据外，还可以通过自己设置的索引（标签）获取对应的数据。\n\n使用整数索引。\n\n代码：\n\n```Python\nser1[2]\n```\n\n输出：\n\n```\n260\n```\n\n使用自定义索引。\n\n代码：\n\n```Python\nser1['三季度']\n```\n\n输出：\n\n```\n260\n```\n\n代码：\n\n```Python\nser1['一季度'] = 380\nser1\n```\n\n输出：\n\n```\n一季度    380\n二季度    390\n三季度    260\n四季度    370\ndtype: int64\n```\n\n##### 切片索引\n\n`Series`对象的切片操作跟列表、数组类似，通过给出起始和结束索引，从原来的`Series`对象中取出或修改部分数据，这里也可以使用整数索引和自定义的索引，代码如下所示。\n\n代码：\n\n```Python\nser2[1:3]\n```\n\n输出：\n\n```\n二季度    180\n三季度    300\ndtype: int64\n```\n\n代码：\n\n```Python\nser2['二季度':'四季度']\n```\n\n输出：\n\n```\n二季度    180\n三季度    300\n四季度    405\ndtype: int64\n```\n\n>**提示**：在使用自定义索引进行切片时，结束索引对应的元素也是可以取到的。\n\n代码：\n\n```Python\nser2[1:3] = 400, 500\nser2\n```\n\n输出：\n\n```\n一季度    320\n二季度    400\n三季度    500\n四季度    405\ndtype: int64\n```\n\n##### 花式索引\n\n代码：\n\n```Python\nser2[['二季度', '四季度']]\n```\n\n输出：\n\n```\n二季度    400\n四季度    405\ndtype: int64\n```\n\n代码：\n\n```Python\nser2[['二季度', '四季度']] = 600, 520\nser2\n```\n\n输出：\n\n```\n一季度    320\n二季度    600\n三季度    500\n四季度    520\ndtype: int64\n```\n\n##### 布尔索引\n\n代码：\n\n```Python\nser2[ser2 >= 500]\n```\n\n输出：\n\n```\n二季度    600\n三季度    500\n四季度    520\ndtype: int64\n```\n\n### Series对象的属性和方法\n\n`Series`对象的属性和方法非常多，我们就捡着重要的跟大家讲吧。先看看下面的表格，它展示了`Series`对象常用的属性。\n\n| 属性                      | 说明                                    |\n| ------------------------- | --------------------------------------- |\n| `dtype` / `dtypes`        | 返回`Series`对象的数据类型              |\n| `hasnans`                 | 判断`Series`对象中有没有空值            |\n| `at` / `iat`              | 通过索引访问`Series`对象中的单个值      |\n| `loc` / `iloc`            | 通过索引访问`Series`对象中的单个值或一组值 |\n| `index`                   | 返回`Series`对象的索引（`Index`对象）     |\n| `is_monotonic`            | 判断`Series`对象中的数据是否单调        |\n| `is_monotonic_increasing` | 判断`Series`对象中的数据是否单调递增    |\n| `is_monotonic_decreasing` | 判断`Series`对象中的数据是否单调递减    |\n| `is_unique`               | 判断`Series`对象中的数据是否独一无二    |\n| `size`                    | 返回`Series`对象中元素的个数            |\n| `values`                  | 以`ndarray`的方式返回`Series`对象中的值（`ndarray`对象） |\n\n我们可以通过下面的代码来了解`Series`对象的属性。\n\n代码：\n\n```python\nprint(ser2.dtype)                    # 数据类型\nprint(ser2.hasnans)                  # 有没有空值\nprint(ser2.index)                    # 索引\nprint(ser2.values)                   # 值\nprint(ser2.is_monotonic_increasing)  # 是否单调递增\nprint(ser2.is_unique)                # 是否每个值都独一无二\n```\n\n输出：\n\n```\nint64\nFalse\nIndex(['一季度', '二季度', '三季度', '四季度'], dtype='object')\n[320 600 500 520]\nFalse\nTrue\n```\n\n`Series`对象的方法很多，下面我们通过一些代码片段为大家介绍常用的方法。\n\n#### 统计相关\n\n`Series`对象支持各种获取描述性统计信息的方法。\n\n代码：\n\n```Python\nprint(ser2.count())   # 计数\nprint(ser2.sum())     # 求和\nprint(ser2.mean())    # 求平均\nprint(ser2.median())  # 找中位数\nprint(ser2.max())     # 找最大\nprint(ser2.min())     # 找最小\nprint(ser2.std())     # 求标准差\nprint(ser2.var())     # 求方差\n```\n\n输出：\n\n```\n4\n1940\n485.0\n510.0\n600\n320\n118.18065267490557\n13966.666666666666\n```\n\n`Series`对象还有一个名为`describe()`的方法，可以获得上述所有的描述性统计信息，如下所示。\n\n代码：\n\n```Python\nser2.describe()\n```\n\n输出：\n\n```\ncount      4.000000\nmean     485.000000\nstd      118.180653\nmin      320.000000\n25%      455.000000\n50%      510.000000\n75%      540.000000\nmax      600.000000\ndtype: float64\n```\n\n> **提示**：因为`describe()`返回的也是一个`Series`对象，所以也可以用`ser2.describe()['mean']`来获取平均值，用`ser2.describe()[['max', 'min']]`来获取最大值和最小值。\n\n如果`Series`对象有重复的值，我们可以使用`unique()`方法获得由独一无二的值构成的数组；可以使用`nunique()`方法统计不重复值的数量；如果想要统计每个值重复的次数，可以使用`value_counts()`方法，这个方法会返回一个`Series`对象，它的索引就是原来的`Series`对象中的值，而每个值出现的次数就是返回的`Series`对象中的数据，在默认情况下会按照出现次数做降序排列，如下所示。\n\n代码：\n\n```Python\nser3 = pd.Series(data=['apple', 'banana', 'apple', 'pitaya', 'apple', 'pitaya', 'durian'])\nser3.value_counts()\n```\n\n输出：\n\n```\napple     3\npitaya    2\ndurian    1\nbanana    1\ndtype: int64\n```\n\n代码：\n\n```Python\nser3.nunique()\n```\n\n输出：\n\n```\n4\n```\n\n对于`ser3`，我们还可以用`mode()`方法来找出数据的众数，由于众数可能不唯一，所以`mode()`方法的返回值仍然是一个`Series`对象。\n\n代码：\n\n```python\nser3.mode()\n```\n\n输出：\n\n```\n0    apple\ndtype: object\n```\n\n#### 处理数据\n\n`Series`对象的`isna()`和`isnull()`方法可以用于空值的判断，`notna()`和`notnull()`方法可以用于非空值的判断，代码如下所示。\n\n代码：\n\n```Python\nser4 = pd.Series(data=[10, 20, np.nan, 30, np.nan])\nser4.isna()\n```\n\n> **说明**：`np.nan`是一个IEEE 754标准的浮点小数，专门用来表示“不是一个数”，在上面的代码中我们用它来代表空值；当然，也可以用 Python 中的`None`来表示空值，在 pandas 中`None`也会被处理为`np.nan`。\n\n输出：\n\n```\n0    False\n1    False\n2     True\n3    False\n4     True\ndtype: bool\n```\n\n代码：\n\n```Python\nser4.notna()\n```\n\n输出：\n\n```\n0     True\n1     True\n2    False\n3     True\n4    False\ndtype: bool\n```\n\n`Series`对象的`dropna()`和`fillna()`方法分别用来删除空值和填充空值，具体的用法如下所示。\n\n代码：\n\n```Python\nser4.dropna()\n```\n\n输出：\n\n```\n0    10.0\n1    20.0\n3    30.0\ndtype: float64\n```\n\n代码：\n\n```Python\nser4.fillna(value=40)  # 将空值填充为40\n```\n\n输出：\n\n```\n0    10.0\n1    20.0\n2    40.0\n3    30.0\n4    40.0\ndtype: float64\n```\n\n代码：\n\n```Python\nser4.fillna(method='ffill')  # 用空值前面的非空值填充\n```\n\n输出：\n\n```\n0    10.0\n1    20.0\n2    20.0\n3    30.0\n4    30.0\ndtype: float64\n```\n\n需要提醒大家注意的是，`dropna()`和`fillna()`方法都有一个名为`inplace`的参数，它的默认值是`False`，表示删除空值或填充空值不会修改原来的`Series`对象，而是返回一个新的`Series`对象。如果将`inplace`参数的值修改为`True`，那么删除或填充空值会就地操作，直接修改原来的`Series`对象，此时方法的返回值是`None`。后面我们会接触到的很多方法，包括`DataFrame`对象的很多方法都会有这个参数，它们的意义跟这里是一样的。\n\n`Series`对象的`mask()`和`where()`方法可以将满足或不满足条件的值进行替换，如下所示。\n\n代码：\n\n```Python\nser5 = pd.Series(range(5))\nser5.where(ser5 > 0)\n```\n\n输出：\n\n```\n0    NaN\n1    1.0\n2    2.0\n3    3.0\n4    4.0\ndtype: float64\n```\n\n代码：\n\n```Python\nser5.where(ser5 > 1, 10)\n```\n\n输出：\n\n```\n0    10\n1    10\n2     2\n3     3\n4     4\ndtype: int64\n```\n\n代码：\n\n```Python\nser5.mask(ser5 > 1, 10)\n```\n\n输出：\n\n```\n0     0\n1     1\n2    10\n3    10\n4    10\ndtype: int64\n```\n\n`Series`对象的`duplicated()`方法可以帮助我们找出重复的数据，而`drop_duplicates()`方法可以帮我们删除重复数据。\n\n代码：\n\n```Python\nser3.duplicated()\n```\n\n输出：\n\n```\n0    False\n1    False\n2     True\n3    False\n4     True\n5     True\n6    False\ndtype: bool\n```\n\n代码：\n\n```Python\nser3.drop_duplicates()\n```\n\n输出：\n\n```\n0     apple\n1    banana\n3    pitaya\n6    durian\ndtype: object\n```\n\n`Series`对象的`apply()`和`map()`方法非常重要，它们可以通过字典或者指定的函数来处理数据，把数据映射或转换成我们想要的样子。这两个方法在数据准备阶段非常重要，我们先来试一试这个名为`map`的方法。\n\n代码：\n\n```Python\nser6 = pd.Series(['cat', 'dog', np.nan, 'rabbit'])\nser6\n```\n\n输出：\n\n```\n0       cat\n1       dog\n2       NaN\n3    rabbit\ndtype: object\n```\n\n代码：\n\n```Python\nser6.map({'cat': 'kitten', 'dog': 'puppy'})\n```\n\n> **说明**：通过字典给出的映射规则对数据进行处理。\n\n输出：\n\n```\n0    kitten\n1     puppy\n2       NaN\n3       NaN\ndtype: object\n```\n\n代码：\n\n```Python\nser6.map('I am a {}'.format, na_action='ignore')\n```\n\n> **说明**：将指定字符串的`format`方法作用到数据系列的数据上，忽略掉所有的空值。\n\n输出：\n\n```\n0       I am a cat\n1       I am a dog\n2              NaN\n3    I am a rabbit\ndtype: object\n```\n\n我们创建一个新的`Series`对象，\n\n```Python\nser7 = pd.Series([20, 21, 12],  index=['London', 'New York', 'Helsinki'])\nser7\n```\n\n输出：\n\n```\nLondon      20\nNew York    21\nHelsinki    12\ndtype: int64\n```\n\n代码：\n\n```Python\nser7.apply(np.square)\n```\n\n> **说明**：将求平方的函数作用到数据系列的数据上，也可以将参数`np.square`替换为`lambda x: x ** 2`。\n\n输出：\n\n```\nLondon      400\nNew York    441\nHelsinki    144\ndtype: int64\n```\n\n代码：\n\n```Python\nser7.apply(lambda x, value: x - value, args=(5, ))\n```\n\n> 注意：上面`apply`方法中的`lambda`函数有两个参数，第一个参数是数据系列中的数据，而第二个参数需要我们传入，所以我们给`apply`方法增加了`args`参数，用于给`lambda`函数的第二个参数传值。\n\n输出：\n\n```\nLondon      15\nNew York    16\nHelsinki     7\ndtype: int64\n```\n\n#### 取头部值和排序\n\n`Series`对象的`sort_index()`和`sort_values()`方法可以用于对索引和数据的排序，排序方法有一个名为`ascending`的布尔类型参数，该参数用于控制排序的结果是升序还是降序；而名为`kind`的参数则用来控制排序使用的算法，默认使用了`quicksort`，也可以选择`mergesort`或`heapsort`；如果存在空值，那么可以用`na_position`参数空值放在最前还是最后，默认是`last`，代码如下所示。\n\n代码：\n\n```Python\nser8 = pd.Series(\n    data=[35, 96, 12, 57, 25, 89], \n    index=['grape', 'banana', 'pitaya', 'apple', 'peach', 'orange']\n)\nser8.sort_values()  # 按值从小到大排序\n```\n\n输出：\n\n```\npitaya    12\npeach     25\ngrape     35\napple     57\norange    89\nbanana    96\ndtype: int64\n```\n\n代码：\n\n```Python\nser8.sort_index(ascending=False)  # 按索引从大到小排序\n```\n\n输出：\n\n```\npitaya    12\npeach     25\norange    89\ngrape     35\nbanana    96\napple     57\ndtype: int64\n```\n\n如果要从`Series`对象中找出元素中最大或最小的“Top-N”，我们不需要对所有的值进行排序的，可以使用`nlargest()`和`nsmallest()`方法来完成，如下所示。\n\n代码：\n\n```Python\nser8.nlargest(3)  # 值最大的3个\n```\n\n输出：\n\n```\nbanana    96\norange    89\napple     57\ndtype: int64\n```\n\n代码：\n\n```Python\nser8.nsmallest(2)  # 值最小的2个\n```\n\n输出：\n\n```\npitaya    12\npeach     25\ndtype: int64\n```\n\n#### 绘制图表\n\n`Series`对象有一个名为`plot`的方法可以用来生成图表，如果选择生成折线图、饼图、柱状图等，默认会使用`Series`对象的索引作为横坐标，使用`Series`对象的数据作为纵坐标。下面我们创建一个`Series`对象并基于它绘制柱状图，代码如下所示。\n\n代码：\n\n```Python\nimport matplotlib.pyplot as plt\n\nser9 = pd.Series({'Q1': 400, 'Q2': 520, 'Q3': 180, 'Q4': 380})\n# 通过plot方法的kind指定图表类型为柱状图\nser9.plot(kind='bar')\n# 定制纵轴的取值范围\nplt.ylim(0, 600)\n# 定制横轴刻度（旋转到0度）\nplt.xticks(rotation=0)\n# 为柱子增加数据标签\nfor i in range(ser9.size):\n    plt.text(i, ser9[i] + 5, ser9[i], ha='center')\nplt.show()\n```\n\n输出：\n\n<img class=\"lazy\" data-src=\"/res/ser_bar_graph.png\" style=\"zoom:35%;\">\n\n我们也可以将其绘制为饼图，代码如下所示。\n\n代码：\n\n```Python\n# plot方法的kind参数指定了图表类型为饼图\n# autopct会自动计算并显示百分比\n# pctdistance用来控制百分比到圆心的距离\nser9.plot(kind='pie', autopct='%.1f%%', pctdistance=0.65)\nplt.show()\n```\n\n输出：\n\n<img class=\"lazy\" data-src=\"/res/ser_pie_graph.png\" style=\"zoom:35%;\">", "深入浅出pandas-2": "## 深入浅出pandas-2\n\n如果使用 pandas 做数据分析，那么`DataFrame`一定是被使用得最多的类型，它可以用来保存和处理异质的二维数据。这里所谓的“异质”是指`DataFrame`中每个列的数据类型不需要相同，这也是它区别于 NumPy 二维数组的地方。`DataFrame`提供了极为丰富的属性和方法，帮助我们实现对数据的重塑、清洗、预处理、透视、呈现等一系列操作。\n\n### 创建DataFrame对象\n\n#### 通过二维数组创建DataFrame对象\n\n代码：\n\n```python\nscores = np.random.randint(60, 101, (5, 3))\ncourses = ['语文', '数学', '英语']\nstu_ids = np.arange(1001, 1006)\ndf1 = pd.DataFrame(data=scores, columns=courses, index=stu_ids)\ndf1\n```\n\n输出：\n\n```\n        语文  数学  英语\n1001    69    80    79\n1002    71    60    100\n1003    94    81    93\n1004    88    88    67\n1005    82    66    60\n```\n\n#### 通过字典创建DataFrame对象\n\n代码：\n\n```python\nscores = {\n    '语文': [62, 72, 93, 88, 93],\n    '数学': [95, 65, 86, 66, 87],\n    '英语': [66, 75, 82, 69, 82],\n}\nstu_ids = np.arange(1001, 1006)\ndf2 = pd.DataFrame(data=scores, index=stu_ids)\ndf2\n```\n\n输出：\n\n```\n        语文  数学  英语\n1001    62    95    66\n1002    72    65    75\n1003    93    86    82\n1004    88    66    69\n1005    93    87    82\n```\n\n#### 读取CSV文件创建DataFrame对象\n\n可以通过`pandas` 模块的`read_csv`函数来读取 CSV 文件，`read_csv`函数的参数非常多，下面介绍几个比较重要的参数。\n\n- `sep` / `delimiter`：分隔符，默认是`,`。\n- `header`：表头（列索引）的位置，默认值是`infer`，用第一行的内容作为表头（列索引）。\n- `index_col`：用作行索引（标签）的列。\n- `usecols`：需要加载的列，可以使用序号或者列名。\n- `true_values` / `false_values`：哪些值被视为布尔值`True` / `False`。\n- `skiprows`：通过行号、索引或函数指定需要跳过的行。\n- `skipfooter`：要跳过的末尾行数。\n- `nrows`：需要读取的行数。\n- `na_values`：哪些值被视为空值。\n- `iterator`：设置为`True`，函数返回迭代器对象。\n- `chunksize`：配合上面的参数，设置每次迭代获取的数据体量。\n\n代码：\n\n```python\ndf3 = pd.read_csv('data/2018年北京积分落户数据.csv', index_col='id')\ndf3\n```\n\n> **提示**：上面代码中的CSV文件是用相对路径进行获取的，也就是说当前工作路径下有名为`data`的文件夹，而“2018年北京积分落户数据.csv”就在这个文件夹下。如果使用Windows系统，在写路径分隔符时也建议使用`/`而不是`\\`，如果想使用`\\`，建议在字符串前面添加一个`r`，使用原始字符串来避开转义字符，例如`r'c:\\new\\data\\2018年北京积分落户数据.csv'`。\n\n输出：\n\n```\n      name   birthday      company          score\nid                                             \n1     杨xx   1972-12       北京利德华福xxxx  122.59\n2     纪xx   1974-12       北京航天数据xxxx  121.25\n3     王x    1974-05       品牌联盟(北京)xx  118.96\n4     杨x    1975-07       中科专利商标xxxx  118.21\n5     张xx   1974-11       北京阿里巴巴xxxx  117.79\n...   ...      ...                  ...     ...\n6015  孙xx   1978-08       华为海洋网络xxxx   90.75\n6016  刘xx   1976-11       福斯（上海）xxxx   90.75\n6017  周x    1977-10       赢创德固赛xxxxxx   90.75\n6018  赵x    1979-07       澳科利耳医疗xxxx   90.75\n6019  贺x    1981-06       北京宝洁技术xxxx   90.75\n\n[6019 rows x 4 columns]\n```\n\n> **说明**： 上面输出的内容隐去了姓名（name）和公司名称（company）字段中的部分信息。如果需要上面例子中的 CSV 文件，可以通过百度云盘获取，链接：<https://pan.baidu.com/s/1rQujl5RQn9R7PadB2Z5g_g>，提取码：e7b4。\n\n#### 读取Excel工作表创建DataFrame对象\n\n可以通过`pandas` 模块的`read_excel`函数来读取 Excel 文件，该函数与上面的`read_csv`非常类似，多了一个`sheet_name`参数来指定数据表的名称，但是不同于 CSV 文件，没有`sep`或`delimiter`这样的参数。假设有名为“2022年股票数据.xlsx”的 Excel 文件，里面有用股票代码命名的五个表单，分别是阿里巴巴（BABA）、百度（BIDU）、京东（JD）、亚马逊（AMZN）、甲骨文（ORCL）这五个公司2022年的股票数据，如果想加载亚马逊的股票数据，代码如下所示。\n\n代码：\n\n```python\ndf4 = pd.read_excel('data/2022年股票数据.xlsx', sheet_name='AMZN', index_col='Date')\ndf4\n```\n\n> **说明**：上面例子中的 CSV 文件可以通过百度云盘获取，链接：<https://pan.baidu.com/s/1rQujl5RQn9R7PadB2Z5g_g>，提取码：e7b4。\n\n输出：\n\n```\n               Open     High       Low    Close    Volume\nDate                                                     \n2022-12-30   83.120   84.050   82.4700   84.000  62401194\n2022-12-29   82.870   84.550   82.5500   84.180  54995895\n2022-12-28   82.800   83.480   81.6900   81.820  58228575\n2022-12-27   84.970   85.350   83.0000   83.040  57284035\n2022-12-23   83.250   85.780   82.9344   85.250  57433655\n...             ...      ...       ...      ...       ...\n2022-01-07  163.839  165.243  162.0310  162.554  46605900\n2022-01-06  163.450  164.800  161.9370  163.254  51957780\n2022-01-05  166.883  167.126  164.3570  164.357  64302720\n2022-01-04  170.438  171.400  166.3490  167.522  70725160\n2022-01-03  167.550  170.704  166.1600  170.404  63869140\n\n[251 rows x 5 columns]\n```\n\n#### 读取关系数据库二维表创建DataFrame对象\n\n`pandas`模块的`read_sql`函数可以通过 SQL 语句从数据库中读取数据创建`DataFrame`对象，该函数的第二个参数代表了需要连接的数据库。对于 MySQL 数据库，我们可以通过`pymysql`或`mysqlclient`来创建数据库连接（需要提前安装好三方库），得到一个`Connection` 对象，而这个对象就是`read_sql`函数需要的第二个参数，代码如下所示。\n\n代码：\n\n```python\nimport pymysql\n\n# 创建一个MySQL数据库的连接对象\nconn = pymysql.connect(\n    host='101.42.16.8', port=3306,\n    user='guest', password='Guest.618',\n    database='hrs', charset='utf8mb4'\n)\n# 通过SQL从数据库二维表读取数据创建DataFrame\ndf5 = pd.read_sql('select * from tb_emp', conn, index_col='eno')\ndf5\n```\n\n> **提示**：执行上面的代码需要先安装`pymysql`库，如果尚未安装，可以先在单元格中先执行魔法指令`%pip install pymysql`，然后再运行上面的代码。上面的代码连接的是我部署在腾讯云上的 MySQL 数据库，公网 IP 地址：`101.42.16.8`，用户名：`guest`，密码：`Guest.618`，数据库：`hrs`，字符集：`utf8mb4`，大家可以使用这个数据库，但是不要进行恶意的访问。`hrs`数据库一共有三张表，分别是：`tb_dept`（部门表）、`tb_emp`（员工表）、`tb_emp2`（员工表2）。\n\n输出：\n\n```\n       ename   job     mgr     sal    comm    dno\neno                                        \n1359   胡一刀   销售员  3344.0  1800   200.0   30\n2056    乔峰   分析师   7800.0  5000  1500.0   20\n3088   李莫愁   设计师  2056.0  3500   800.0   20\n3211   张无忌   程序员  2056.0  3200     NaN   20\n3233   丘处机   程序员  2056.0  3400     NaN   20\n3244   欧阳锋   程序员  3088.0  3200     NaN   20\n3251   张翠山   程序员  2056.0  4000     NaN   20\n3344    黄蓉  销售主管  7800.0  3000   800.0   30\n3577    杨过    会计    5566.0  2200     NaN   10\n3588   朱九真    会计   5566.0  2500     NaN   10\n4466   苗人凤   销售员  3344.0  2500     NaN   30\n5234    郭靖    出纳    5566.0  2000     NaN   10\n5566   宋远桥   会计师  7800.0  4000  1000.0   10\n7800   张三丰    总裁     NaN   9000  1200.0   20\n```\n\n执行上面的代码会出现一个警告，因为 pandas 库希望我们使用`SQLAlchemy`三方库接入数据库，具体内容是：“UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.”。如果不想看到这个警告，我们可以试一试下面的解决方案。\n\n首先，安装三方库`SQLAlchemy`，在 Jupyter 中可以使用`%pip`魔法指令。\n\n```python\n%pip install sqlalchemy\n```\n\n通过`SQLAlchemy`的`create_engine`函数创建`Engine`对象作为`read_sql`函数的第二个参数，此时`read_sql`函数的第一个参数可以是 SQL 语句，也可以是二维表的表名。\n\n```python\nfrom sqlalchemy import create_engine\n\n# 通过指定的URL（统一资源定位符）访问数据库\nengine = create_engine('mysql+pymysql://guest:Guest.618@101.42.16.8:3306/hrs')\n# 直接通过表名加载整张表的数据\ndf5 = pd.read_sql('tb_emp', engine, index_col='eno')\ndf5\n```\n\n> **说明**：如果通过表名加载二维表数据，也可以将上面的函数换成`read_sql_table`。\n\n我们再来加载部门表的数据创建`DataFrame`对象。\n\n```python\ndf6 = pd.read_sql('select dno, dname, dloc from tb_dept', engine, index_col='dno')\ndf6\n```\n\n> **说明**：如果通过 SQL 查询获取数据，也可以将上面的函数换成`read_sql_query`。\n\n输出：\n\n```\n      dname   dloc\ndno           \n10    会计部   北京\n20    研发部   成都\n30    销售部   重庆\n40    运维部   深圳\n```\n\n在完成数据加载后，如果希望释放数据库连接，可以使用下面的代码。\n\n```python\nengine.connect().close()\n```\n\n### 基本属性和方法\n\n在开始讲解`DataFrame`的属性和方法前，我们先从之前提到的`hrs`数据库中读取三张表的数据，创建出三个`DataFrame`对象，完整的代码如下所示。\n\n```python\nfrom sqlalchemy import create_engine\n\nengine = create_engine('mysql+pymysql://guest:Guest.618@101.42.16.8:3306/hrs')\ndept_df = pd.read_sql_table('tb_dept', engine, index_col='dno')\nemp_df = pd.read_sql_table('tb_emp', engine, index_col='eno')\nemp2_df = pd.read_sql_table('tb_emp2', engine, index_col='eno')\n```\n\n得到的三个`DataFrame`对象如下所示。\n\n部门表（`dept_df`），其中`dno`是部门的编号，`dname`和`dloc`分别是部门的名称和所在地。\n\n```\n    dname  dloc\ndno\n10  会计部  北京\n20  研发部  成都\n30  销售部  重庆\n40  运维部  深圳\n```\n\n员工表（`emp_df`），其中`eno`是员工编号，`ename`、`job`、`mgr`、`sal`、`comm`和`dno`分别代表员工的姓名、职位、主管编号、月薪、补贴和部门编号。\n\n```\n        ename    job        mgr      sal     comm    dno\neno\n1359    胡一刀    销售员      3344.0    1800    200.0    30\n2056    乔峰      分析师      7800.0    5000    1500.0   20\n3088    李莫愁    设计师      2056.0    3500    800.0    20\n3211    张无忌     程序员     2056.0    3200    NaN     20\n3233    丘处机     程序员     2056.0    3400    NaN     20\n3244    欧阳锋     程序员     3088.0    3200    NaN     20\n3251    张翠山     程序员     2056.0    4000    NaN     20\n3344    黄蓉      销售主管    7800.0    3000    800.0   30\n3577    杨过      会计       5566.0    2200     NaN     10\n3588    朱九真     会计       5566.0    2500    NaN     10\n4466    苗人凤     销售员     3344.0    2500    NaN     30\n5234    郭靖       出纳      5566.0    2000    NaN      10\n5566    宋远桥     会计师     7800.0    4000    1000.0   10\n7800    张三丰     总裁       NaN      9000    1200.0    20\n```\n\n> **说明**：在数据库中`mgr`和`comm`两个列的数据类型是`int`，但是因为有缺失值（空值），读取到`DataFrame`之后，列的数据类型变成了`float`，因为我们通常会用`float`类型的`NaN`来表示空值。\n\n员工表（`emp2_df`），跟上面的员工表结构相同，但是保存了不同的员工数据。\n\n```\n       ename    job      mgr      sal    comm    dno\neno                                      \n9500   张三丰   总裁      NaN      50000  8000    20\n9600   王大锤   程序员    9800.0   8000   600     20\n9700   张三丰   总裁      NaN      60000  6000    20\n9800   小明     架构师    7800.0   30000  5000    20\n9900   陈小刀   分析师    9800.0   10000  1200    20\n```\n\n`DataFrame`对象的属性如下表所示。\n\n| 属性名         | 说明                                |\n| -------------- | ----------------------------------- |\n| `at` / `iat`   | 通过标签获取`DataFrame`中的单个值。 |\n| `columns`      | `DataFrame`对象列的索引             |\n| `dtypes`       | `DataFrame`对象每一列的数据类型     |\n| `empty`        | `DataFrame`对象是否为空             |\n| `loc` / `iloc` | 通过标签获取`DataFrame`中的一组值。 |\n| `ndim`         | `DataFrame`对象的维度               |\n| `shape`        | `DataFrame`对象的形状（行数和列数） |\n| `size`         | `DataFrame`对象中元素的个数         |\n| `values`       | `DataFrame`对象的数据对应的二维数组 |\n\n关于`DataFrame`的方法，首先需要了解的是`info()`方法，它可以帮助我们了解`DataFrame`的相关信息，如下所示。\n\n代码：\n\n```python\nemp_df.info()\n```\n\n输出：\n\n```\n<class 'pandas.core.frame.DataFrame'>\nInt64Index: 14 entries, 1359 to 7800\nData columns (total 6 columns):\n #   Column  Non-Null Count  Dtype  \n---  ------  --------------  -----  \n 0   ename   14 non-null     object \n 1   job     14 non-null     object \n 2   mgr     13 non-null     float64\n 3   sal     14 non-null     int64  \n 4   comm    6 non-null      float64\n 5   dno     14 non-null     int64  \ndtypes: float64(2), int64(2), object(2)\nmemory usage: 1.3+ KB\n```\n\n如果需要查看`DataFrame`的头部或尾部的数据，可以使用`head()`或`tail()`方法，这两个方法的默认参数是`5`，表示获取`DataFrame`最前面5行或最后面5行的数据，如下所示。\n\n```python\nemp_df.head()\n```\n\n输出：\n\n```\n        ename    job    mgr    sal    comm  dno\neno\n1359    胡一刀   销售员   3344   1800   200   30\n2056    乔峰     分析师   7800   5000   1500  20\n3088    李莫愁    设计师   2056   3500  800   20\n3211    张无忌    程序员   2056   3200  NaN   20\n3233    丘处机    程序员   2056   3400  NaN   20\n```\n\n### 操作数据\n\n#### 索引和切片\n\n如果要获取`DataFrame`的某一列，例如取出上面`emp_df`的`ename`列，可以使用下面的两种方式。\n\n```python\nemp_df.ename\n```\n\n或者\n\n```python\nemp_df['ename']\n```\n\n执行上面的代码可以发现，我们获得的是一个`Series`对象。事实上，`DataFrame`对象就是将多个`Series`对象组合到一起的结果。\n\n如果要获取`DataFrame`的某一行，可以使用整数索引或我们设置的索引，例如取出员工编号为`2056`的员工数据，代码如下所示。\n\n```python\nemp_df.iloc[1]\n```\n\n或者\n\n```python\nemp_df.loc[2056]\n```\n\n通过执行上面的代码我们发现，单独取`DataFrame` 的某一行或某一列得到的都是`Series`对象。我们当然也可以通过花式索引来获取多个行或多个列的数据，花式索引的结果仍然是一个`DataFrame`对象。\n\n获取多个列：\n\n```python\nemp_df[['ename', 'job']]\n```\n\n获取多个行：\n\n```python\nemp_df.loc[[2056, 7800, 3344]]\n```\n\n如果要获取或修改`DataFrame` 对象某个单元格的数据，需要同时指定行和列的索引，例如要获取员工编号为`2056`的员工的职位信息，代码如下所示。\n\n```python\nemp_df['job'][2056]\n```\n\n或者\n\n```python\nemp_df.loc[2056]['job']\n```\n\n或者\n\n```python\nemp_df.loc[2056, 'job']\n```\n\n我们推荐大家使用第三种做法，因为它只做了一次索引运算。如果要将该员工的职位修改为“架构师”，可以使用下面的代码。\n\n```python\nemp_df.loc[2056, 'job'] = '架构师'\n```\n\n当然，我们也可以通过切片操作来获取多行多列，相信大家一定已经想到了这一点。\n\n```python\nemp_df.loc[2056:3344]\n```\n\n输出：\n\n```\n        ename    job        mgr      sal     comm    dno\neno\n2056    乔峰      分析师     7800.0    5000    1500.0   20\n3088    李莫愁    设计师     2056.0    3500    800.0    20\n3211    张无忌    程序员     2056.0    3200    NaN      20\n3233    丘处机    程序员     2056.0    3400    NaN      20\n3244    欧阳锋    程序员     3088.0    3200    NaN      20\n3251    张翠山    程序员     2056.0    4000    NaN      20\n3344    黄蓉     销售主管    7800.0    3000    800.0    30\n```\n\n#### 数据筛选\n\n上面我们提到了花式索引，相信大家已经联想到了布尔索引。跟`ndarray`和`Series`一样，我们可以通过布尔索引对`DataFrame`对象进行数据筛选，例如我们要从`emp_df`中筛选出月薪超过`3500`的员工，代码如下所示。\n\n```python\nemp_df[emp_df.sal > 3500]\n```\n\n输出：\n\n```\n        ename    job        mgr      sal     comm    dno\neno\n2056    乔峰      分析师      7800.0   5000    1500.0    20\n3251    张翠山    程序员      2056.0    4000    NaN      20\n5566    宋远桥    会计师      7800.0    4000    1000.0   10\n7800    张三丰    总裁        NaN      9000    1200.0    20\n```\n\n当然，我们也可以组合多个条件来进行数据筛选，例如从`emp_df`中筛选出月薪超过`3500`且部门编号为`20`的员工，代码如下所示。\n\n```python\nemp_df[(emp_df.sal > 3500) & (emp_df.dno == 20)]\n```\n\n输出：\n\n```\n        ename    job        mgr      sal     comm    dno\neno\n2056    乔峰      分析师      7800.0   5000   1500.0    20\n3251    张翠山     程序员     2056.0   4000    NaN       20\n7800    张三丰     总裁       NaN      9000   1200.0    20\n```\n\n除了使用布尔索引，`DataFrame`对象的`query`方法也可以实现数据筛选，`query`方法的参数是一个字符串，它代表了筛选数据使用的表达式，而且更符合 Python 程序员的使用习惯。下面我们使用`query`方法将上面的效果重新实现一遍，代码如下所示。\n\n```python\nemp_df.query('sal > 3500 and dno == 20')\n```\n", "深入浅出pandas-3": "## 深入浅出pandas-3\n\n在完成数据加载之后，我们可能需要对事实表和维度表进行连接，这是对数据进行多维度拆解的基础；我们可能从不同的数据源加载了结构相同的数据，我们需要将这些数据拼接起来；我们把这些操作统称为数据重塑。当然，由于企业的信息化水平以及数据中台建设水平的差异，我们拿到的数据未必是质量很好的，可能还需要对数据中的缺失值、重复值、异常值进行适当的处理。即便我们获取的数据在质量上是没有问题的，但也可能需要对数据进行一系列的预处理，才能满足我们做数据分析的需求。接下来，我们就为大家讲解和梳理这方面的知识。\n\n### 数据重塑\n\n有的时候，我们做数据分析需要的原始数据可能并不是来自一个地方，就像上一章的例子中，我们从关系型数据库中读取了三张表，得到了三个`DataFrame`对象，但实际工作可能需要我们把他们的数据整合到一起。例如：`emp_df`和`emp2_df`其实都是员工的数据，而且数据结构完全一致，我们可以使用`pandas`提供的`concat`函数实现两个或多个`DataFrame`的数据拼接，代码如下所示。\n\n```Python\nall_emp_df = pd.concat([emp_df, emp2_df])\n```\n\n输出：\n\n```\n        ename    job        mgr      sal     comm    dno\neno\n1359    胡一刀    销售员\t   3344.0\t1800\t200.0\t30\n2056    乔峰\t    分析师\t    7800.0\t 5000\t 1500.0\t 20\n3088    李莫愁\t   设计师\t   2056.0\t3500\t800.0\t20\n3211    张无忌\t   程序员\t   2056.0\t3200\tNaN     20\n3233    丘处机\t   程序员\t   2056.0\t3400\tNaN\t    20\n3244    欧阳锋\t   程序员\t   3088.0\t3200\tNaN     20\n3251    张翠山\t   程序员\t   2056.0\t4000\tNaN\t    20\n3344    黄蓉\t    销售主管   7800.0\t3000\t800.0\t30\n3577    杨过\t    会计\t     5566.0\t  2200\t  NaN\t  10\n3588    朱九真\t   会计\t    5566.0\t 2500\t NaN\t 10\n4466    苗人凤\t   销售员\t   3344.0\t2500\tNaN\t    30\n5234    郭靖\t    出纳\t     5566.0\t  2000\t  NaN\t  10\n5566    宋远桥\t   会计师\t   7800.0\t4000\t1000.0\t10\n7800    张三丰\t   总裁\t    NaN      9000\t 1200.0\t 20\n9500\t张三丰\t   总裁\t    NaN\t     50000\t 8000.0\t 20\n9600\t王大锤    程序员\t   9800.0\t8000\t600.0\t20\n9700\t张三丰\t   总裁\t    NaN\t     60000\t 6000.0\t 20\n9800\t小明\t    架构师\t    7800.0\t 30000\t 5000.0\t 20\n9900\t陈小刀\t   分析师\t   9800.0\t10000\t1200.0\t20\n```\n\n上面的代码将两个代表员工数据的`DataFrame`拼接到了一起，接下来我们使用`merge`函数将员工表和部门表的数据合并到一张表中，代码如下所示。\n\n先使用`reset_index`方法重新设置`all_emp_df`的索引，这样`eno` 不再是索引而是一个普通列，`reset_index`方法的`inplace`参数设置为`True`表示，重置索引的操作直接在`all_emp_df`上执行，而不是返回修改后的新对象。\n\n```Python\nall_emp_df.reset_index(inplace=True)\n```\n\n通过`merge`函数合并数据，当然，也可以调用`DataFrame`对象的`merge`方法来达到同样的效果。\n\n```Python\npd.merge(all_emp_df, dept_df, how='inner', on='dno')\n```\n\n输出：\n\n```\n    eno\t    ename\tjob\t     mgr\t sal\t comm\t dno\tdname\t dloc\n0\t1359\t胡一刀\t 销售员\t3344.0\t1800\t200.0\t30\t   销售部\t 重庆\n1\t3344\t黄蓉\t  销售主管\t7800.0\t3000\t800.0\t30\t   销售部\t 重庆\n2\t4466\t苗人凤\t 销售员\t3344.0\t2500\tNaN\t    30\t   销售部\t 重庆\n3\t2056\t乔峰\t  分析师\t 7800.0\t 5000\t 1500.0\t 20\t    研发部\t  成都\n4\t3088\t李莫愁\t 设计师\t2056.0\t3500\t800.0\t20\t   研发部\t 成都\n5\t3211\t张无忌  程序员\t2056.0\t3200\tNaN\t    20\t   研发部\t 成都\n6\t3233\t丘处机\t 程序员\t2056.0\t3400\tNaN\t    20\t   研发部\t 成都\n7\t3244\t欧阳锋\t 程序员\t3088.0\t3200\tNaN\t    20\t   研发部\t 成都\n8\t3251\t张翠山\t 程序员\t2056.0\t4000\tNaN\t    20\t   研发部\t 成都\n9\t7800\t张三丰\t 总裁\t     NaN\t 9000\t 1200.0\t 20\t    研发部\t  成都\n10\t9500\t张三丰\t 总裁\t     NaN\t 50000\t 8000.0\t 20\t    研发部\t  成都\n11\t9600\t王大锤\t 程序员\t9800.0\t8000\t600.0\t20\t   研发部\t 成都\n12\t9700\t张三丰\t 总裁\t     NaN\t 60000\t 6000.0\t 20\t    研发部\t  成都\n13\t9800\t小明\t  架构师\t 7800.0\t 30000\t 5000.0\t 20\t    研发部\t  成都\n14\t9900\t陈小刀\t 分析师\t9800.0\t10000\t1200.0\t20\t   研发部\t 成都\n15\t3577\t杨过\t  会计\t  5566.0  2200\t  NaN\t  10\t会计部\t  北京\n16\t3588\t朱九真\t 会计\t     5566.0\t 2500\t NaN\t 10\t   会计部\t 北京\n17\t5234\t郭靖\t  出纳\t  5566.0  2000\t  NaN\t  10\t会计部\t  北京\n18\t5566\t宋远桥\t 会计师\t7800.0\t4000\t1000.0\t10\t  会计部\t北京\n```\n\n`merge`函数的一个参数代表合并的左表、第二个参数代表合并的右表，有SQL编程经验的同学对这两个词是不是感觉到非常亲切。正如大家猜想的那样，`DataFrame`对象的合并跟数据库中的表连接非常类似，所以上面代码中的`how`代表了合并两张表的方式，有`left`、`right`、`inner`、`outer`四个选项；而`on`则代表了基于哪个列实现表的合并，相当于 SQL 表连接中的连表条件，如果左右两表对应的列列名不同，可以用`left_on`和`right_on`参数取代`on`参数分别进行指定。\n\n如果对上面的代码稍作修改，将`how`参数修改为`'right'`，大家可以思考一下代码执行的结果。\n\n```Python\npd.merge(all_emp_df, dept_df, how='right', on='dno')\n```\n\n运行结果比之前的输出多出了如下所示的一行，这是因为`how='right'`代表右外连接，也就意味着右表`dept_df`中的数据会被完整的查出来，但是在`all_emp_df`中又没有编号为`40` 部门的员工，所以对应的位置都被填入了空值。\n\n```\n19\tNaN    NaN    NaN    NaN    NaN     NaN    40    运维部    深圳\n```\n\n### 数据清洗\n\n通常，我们从 Excel、CSV 或数据库中获取到的数据并不是非常完美的，里面可能因为系统或人为的原因混入了重复值或异常值，也可能在某些字段上存在缺失值；再者，`DataFrame`中的数据也可能存在格式不统一、量纲不统一等各种问题。因此，在开始数据分析之前，对数据进行清洗就显得特别重要。\n\n#### 缺失值\n\n可以使用`DataFrame`对象的`isnull`或`isna`方法来找出数据表中的缺失值，如下所示。\n\n```Python\nemp_df.isnull()\n```\n\n或者\n\n```Python\nemp_df.isna()\n```\n\n输出：\n\n```\n        ename   job\t    mgr     sal     comm    dno\neno\t\t\t\t\t\t\n1359\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\n2056\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\n3088\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\n3211\tFalse\tFalse\tFalse\tFalse\tTrue\tFalse\n3233\tFalse\tFalse\tFalse\tFalse\tTrue\tFalse\n3244\tFalse\tFalse\tFalse\tFalse\tTrue\tFalse\n3251\tFalse\tFalse\tFalse\tFalse\tTrue\tFalse\n3344\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\n3577\tFalse\tFalse\tFalse\tFalse\tTrue\tFalse\n3588\tFalse\tFalse\tFalse\tFalse\tTrue\tFalse\n4466\tFalse\tFalse\tFalse\tFalse\tTrue\tFalse\n5234\tFalse\tFalse\tFalse\tFalse\tTrue\tFalse\n5566\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\n7800\tFalse\tFalse\tTrue\tFalse\tFalse\tFalse\n```\n\n相对应的，`notnull`和`notna`方法可以将非空的值标记为`True`。如果想删除这些缺失值，可以使用`DataFrame`对象的`dropna`方法，该方法的`axis`参数可以指定沿着0轴还是1轴删除，也就是说当遇到空值时，是删除整行还是删除整列，默认是沿0轴进行删除的，代码如下所示。\n\n```Python\nemp_df.dropna()\n```\n\n输出：\n\n```\n        ename   job      mgr\t sal    comm     dno\neno\t\t\t\t\t\t\n1359\t胡一刀  销售员\t3344.0\t1800   200.0\t30\n2056\t乔峰    架构师\t 7800.0\t 5000\t1500.0\t 20\n3088\t李莫愁  设计师\t2056.0\t3500   800.0\t20\n3344\t黄蓉    销售主管\t7800.0\t3000   800.0\t30\n5566\t宋远桥  会计师\t7800.0\t4000   1000.0\t10\n```\n\n如果要沿着1轴进行删除，可以使用下面的代码。\n\n```Python\nemp_df.dropna(axis=1)\n```\n\n输出：\n\n```\n        ename    job      sal    dno\neno\t\t\t\t\n1359\t胡一刀   销售员    1800\t30\n2056\t乔峰     架构师\t  5000\t 20\n3088\t李莫愁   设计师    3500\t20\n3211\t张无忌   程序员    3200\t20\n3233\t丘处机   程序员    3400\t20\n3244\t欧阳锋   程序员    3200\t20\n3251\t张翠山   程序员    4000\t20\n3344\t黄蓉     销售主管  3000\t30\n3577\t杨过     会计\t   2200\t  10\n3588\t朱九真   会计\t  2500\t 10\n4466\t苗人凤   销售员\t 2500   30\n5234\t郭靖     出纳      2000   10\n5566\t宋远桥   会计师    4000   10\n7800\t张三丰   总裁      9000   20\n```\n\n> **注意**：`DataFrame`对象的很多方法都有一个名为`inplace`的参数，该参数的默认值为`False`，表示我们的操作不会修改原来的`DataFrame`对象，而是将处理后的结果通过一个新的`DataFrame`对象返回。如果将该参数的值设置为`True`，那么我们的操作就会在原来的`DataFrame`上面直接修改，方法的返回值为`None`。简单的说，上面的操作并没有修改`emp_df`，而是返回了一个新的`DataFrame`对象。\n\n在某些特定的场景下，我们可以对空值进行填充，对应的方法是`fillna`，填充空值时可以使用指定的值（通过`value`参数进行指定），也可以用表格中前一个单元格（通过设置参数`method=ffill`）或后一个单元格（通过设置参数`method=bfill`）的值进行填充，当代码如下所示。\n\n```Python\nemp_df.fillna(value=0)\n```\n\n> **注意**：填充的值如何选择也是一个值得探讨的话题，实际工作中，可能会使用某种统计量（如：均值、众数等）进行填充，或者使用某种插值法（如：随机插值法、拉格朗日插值法等）进行填充，甚至有可能通过回归模型、贝叶斯模型等对缺失数据进行填充。\n\n输出：\n\n```\n        ename    job        mgr      sal     comm    dno\neno\n1359\t胡一刀    销售员\t   3344.0\t1800\t200.0\t30\n2056\t乔峰\t    分析师\t    7800.0\t 5000\t 1500.0\t 20\n3088\t李莫愁\t   设计师\t   2056.0\t3500\t800.0\t20\n3211\t张无忌\t   程序员\t   2056.0\t3200\t0.0     20\n3233\t丘处机\t   程序员\t   2056.0\t3400\t0.0\t    20\n3244\t欧阳锋\t   程序员\t   3088.0\t3200\t0.0     20\n3251\t张翠山\t   程序员\t   2056.0\t4000\t0.0\t    20\n3344\t黄蓉\t    销售主管   7800.0\t3000\t800.0\t30\n3577\t杨过\t    会计\t     5566.0\t  2200\t  0.0\t  10\n3588\t朱九真\t   会计\t    5566.0\t 2500\t 0.0\t 10\n4466\t苗人凤\t   销售员\t   3344.0\t2500\t0.0\t    30\n5234\t郭靖\t    出纳\t     5566.0\t  2000\t  0.0\t  10\n5566\t宋远桥\t   会计师\t   7800.0\t4000\t1000.0\t10\n7800\t张三丰\t   总裁\t    0.0      9000\t 1200.0\t 20\n```\n\n#### 重复值\n\n接下来，我们先给之前的部门表添加两行数据，让部门表中名为“研发部”和“销售部”的部门各有两个。\n\n```Python\ndept_df.loc[50] = {'dname': '研发部', 'dloc': '上海'}\ndept_df.loc[60] = {'dname': '销售部', 'dloc': '长沙'}\ndept_df\n```\n\n输出:\n\n```\n    dname  dloc\ndno\t\t\n10\t会计部\t北京\n20\t研发部\t成都\n30\t销售部\t重庆\n40\t运维部\t天津\n50\t研发部\t上海\n60\t销售部\t长沙\n```\n\n现在，我们的数据表中有重复数据了，我们可以通过`DataFrame`对象的`duplicated`方法判断是否存在重复值，该方法在不指定参数时默认判断行索引是否重复，我们也可以指定根据部门名称`dname`判断部门是否重复，代码如下所示。\n\n```Python\ndept_df.duplicated('dname')\n```\n\n输出：\n\n```\ndno\n10    False\n20    False\n30    False\n40    False\n50     True\n60     True\ndtype: bool\n```\n\n从上面的输出可以看到，`50`和`60`两个部门从部门名称上来看是重复的，如果要删除重复值，可以使用`drop_duplicates`方法，该方法的`keep`参数可以控制在遇到重复值时，保留第一项还是保留最后一项，或者多个重复项一个都不用保留，全部删除掉。\n\n```Python\ndept_df.drop_duplicates('dname')\n```\n\n输出：\n\n```\n\tdname\tdloc\ndno\t\t\n10\t会计部\t北京\n20\t研发部\t成都\n30\t销售部\t重庆\n40\t运维部\t天津\n```\n\n将`keep`参数的值修改为`last`。\n\n```Python\ndept_df.drop_duplicates('dname', keep='last')\n```\n\n输出：\n\n```\n\tdname\tdloc\ndno\t\t\n10\t会计部\t北京\n40\t运维部\t天津\n50\t研发部\t上海\n60\t销售部\t长沙\n```\n\n使用同样的方式，我们也可以清除`all_emp_df`中的重复数据，例如我们认定“ename”和“job”两个字段完全相同的就是重复数据，我们可以用下面的代码去除重复数据。\n\n```python\nall_emp_df.drop_duplicates(['ename', 'job'], inplace=True)\n```\n\n> **说明**：上面的`drop_duplicates`方法添加了参数`inplace=True`，该方法不会返回新的`DataFrame`对象，而是在原来的`DataFrame`对象上直接删除，大家可以查看`all_emp_df`看看是不是已经移除了重复的员工数据。\n\n#### 异常值\n\n异常值在统计学上的全称是疑似异常值，也称作离群点（outlier），异常值的分析也称作离群点分析。异常值是指样本中出现的“极端值”，数据值看起来异常大或异常小，其分布明显偏离其余的观测值。实际工作中，有些异常值可能是由系统或人为原因造成的，但有些异常值却不是，它们能够重复且稳定的出现，属于正常的极端值，例如很多游戏产品中头部玩家的数据往往都是离群的极端值。所以，我们既不能忽视异常值的存在，也不能简单地把异常值从数据分析中剔除。重视异常值的出现，分析其产生的原因，常常成为发现问题进而改进决策的契机。\n\n异常值的检测有Z-score 方法、IQR 方法、DBScan 聚类、孤立森林等，这里我们对前两种方法做一个简单的介绍。\n\n<img class=\"lazy\" data-src=\"/res/3sigma.png\" style=\"zoom:50%;\">\n\n如果数据服从正态分布，依据3σ法则，异常值被定义与平均值的偏差超过三倍标准差的值。在正态分布下，距离平均值3σ之外的值出现的概率为 $\\small{P(\\lvert x - \\mu \\rvert \\gt 3 \\sigma) < 0.003}$ ，属于小概率事件。如果数据不服从正态分布，那么可以用远离均值的多少倍的标准差来描述，这里的倍数就是Z-score。Z-score以标准差为单位去度量某一原始分数偏离平均值的距离，公式如下所示。\n\n$$\nz = \\frac {X - \\mu} {\\sigma}\n$$\n\n$$\n\\lvert z \\rvert > 3\n$$\n\nZ-score需要根据经验和实际情况来决定，通常把远离标准差 3 倍距离以上的数据点视为离群点，下面的代给出了如何通过Z-score方法检测异常值。\n\n```Python\ndef detect_outliers_zscore(data, threshold=3):\n    avg_value = np.mean(data)\n    std_value = np.std(data)\n    z_score = np.abs((data - avg_value) / std_value)\n    return data[z_score > threshold]\n```\n\nIQR 方法中的 IQR（Inter-Quartile Range）代表四分位距离，即上四分位数（Q3）和下四分位数（Q1）的差值。通常情况下，可以认为小于 $\\small{Q1 - 1.5 \\times IQR}$ 或大于 $\\small{Q3 + 1.5 \\times IQR}$ 的就是异常值，而这种检测异常值的方法也是箱线图（后面会讲到）默认使用的方法。下面的代码给出了如何通过 IQR 方法检测异常值。\n\n```Python\ndef detect_outliers_iqr(data, whis=1.5):\n    q1, q3 = np.quantile(data, [0.25, 0.75])\n    iqr = q3 - q1\n    lower, upper = q1 - whis * iqr, q3 + whis * iqr\n    return data[(data < lower) | (data > upper)]\n```\n\n如果要删除异常值，可以使用`DataFrame`对象的`drop`方法，该方法可以根据行索引或列索引删除指定的行或列。例如我们认为月薪低于`2000`或高于`8000`的是员工表中的异常值，可以用下面的代码删除对应的记录。\n\n```Python\nemp_df.drop(emp_df[(emp_df.sal > 8000) | (emp_df.sal < 2000)].index)\n```\n\n如果要替换掉异常值，可以通过给单元格赋值的方式来实现，也可以使用`replace`方法将指定的值替换掉。例如我们要将月薪为`1800`和`9000`的替换为月薪的平均值，补贴为`800`的替换为`1000`，代码如下所示。\n\n```Python\navg_sal = np.mean(emp_df.sal).astype(int)\nemp_df.replace({'sal': [1800, 9000], 'comm': 800}, {'sal': avg_sal, 'comm': 1000})\n```\n\n#### 预处理\n\n对数据进行预处理也是一个很大的话题，它包含了对数据的拆解、变换、归约、离散化等操作。我们先来看看数据的拆解。如果数据表中的数据是一个时间日期，我们通常都需要从年、季度、月、日、星期、小时、分钟等维度对其进行拆解，如果时间日期是用字符串表示的，可以先通过`pandas`的`to_datetime`函数将其处理成时间日期。\n\n在下面的例子中，我们先读取 Excel 文件，获取到一组销售数据，其中第一列就是销售日期，我们将其拆解为“月份”、“季度”和“星期”，代码如下所示。\n\n```Python\nsales_df = pd.read_excel(\n    'data/2020年销售数据.xlsx',\n    usecols=['销售日期', '销售区域', '销售渠道', '品牌', '销售额']\n)\nsales_df.info()\n```\n\n> **说明**：上面代码中使用了相对路径来获取 Excel 文件，也就是说 Excel 文件在当前工作路径下名为`data`的文件夹中。如果需要上面例子中的 Excel 文件，可以通过下面的百度云盘地址进行获取。链接：<https://pan.baidu.com/s/1rQujl5RQn9R7PadB2Z5g_g>，提取码：e7b4。\n\n输出：\n\n```\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1945 entries, 0 to 1944\nData columns (total 5 columns):\n #   Column  Non-Null Count  Dtype         \n---  ------  --------------  -----         \n 0   销售日期    1945 non-null   datetime64[ns]\n 1   销售区域    1945 non-null   object        \n 2   销售渠道    1945 non-null   object        \n 3   品牌        1945 non-null   object        \n 4   销售额      1945 non-null   int64         \ndtypes: datetime64[ns](1), int64(1), object(3)\nmemory usage: 76.1+ KB\n```\n\n```Python\nsales_df['月份'] = sales_df['销售日期'].dt.month\nsales_df['季度'] = sales_df['销售日期'].dt.quarter\nsales_df['星期'] = sales_df['销售日期'].dt.weekday\nsales_df\n```\n\n输出：\n\n```\n\t    销售日期\t 销售区域\t销售渠道\t品牌\t  销售额\t月份\t季度\t星期\n0\t    2020-01-01\t上海\t     拼多多\t 八匹马   8217\t    1\t 1\t   2\n1\t    2020-01-01\t上海\t     抖音\t      八匹马\t6351\t 1\t  1\t    2\n2\t    2020-01-01\t上海\t     天猫\t      八匹马\t14365\t 1\t  1\t    2\n3\t    2020-01-01\t上海\t     天猫       八匹马\t2366\t 1\t  1     2\n4\t    2020-01-01\t上海\t     天猫 \t  皮皮虾\t15189\t 1\t  1     2\n...     ...         ...        ...       ...      ...     ...  ...   ...\n1940    2020-12-30\t北京\t     京东\t      花花姑娘 6994     12\t 4\t   2\n1941    2020-12-30\t福建\t     实体\t      八匹马\t7663\t 12\t  4\t    2\n1942    2020-12-31\t福建\t     实体\t      花花姑娘 14795    12\t 4\t   3\n1943    2020-12-31\t福建\t     抖音\t      八匹马\t3481\t 12\t  4\t    3\n1944    2020-12-31\t福建\t     天猫\t      八匹马\t2673\t 12\t  4\t    3\n```\n\n在上面的代码中，通过日期时间类型的`Series`对象的`dt` 属性，获得一个访问日期时间的对象，通过该对象的`year`、`month`、`quarter`、`hour`等属性，就可以获取到年、月、季度、小时等时间信息，获取到的仍然是一个`Series`对象，它包含了一组时间信息，所以我们通常也将这个`dt`属性称为“日期时间向量”。\n\n我们再来说一说字符串类型的数据的处理，我们先从指定的 Excel 文件中读取某招聘网站的招聘数据。\n\n```Python\njobs_df = pd.read_csv(\n    'data/某招聘网站招聘数据.csv',\n    usecols=['city', 'companyFullName', 'positionName', 'salary']\n)\njobs_df.info()\n```\n\n> **说明**：上面代码中使用了相对路径来获取 CSV 文件，也就是说 CSV 文件在当前工作路径下名为`data`的文件夹中。如果需要上面例子中的 CSV 文件，可以通过下面的百度云盘地址进行获取。链接：<https://pan.baidu.com/s/1rQujl5RQn9R7PadB2Z5g_g>，提取码：e7b4。\n\n输出：\n\n```\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 3140 entries, 0 to 3139\nData columns (total 4 columns):\n #   Column           Non-Null Count  Dtype \n---  ------           --------------  ----- \n 0   city             3140 non-null   object\n 1   companyFullName  3140 non-null   object\n 2   positionName     3140 non-null   object\n 3   salary           3140 non-null   object\ndtypes: object(4)\nmemory usage: 98.2+ KB\n```\n\n查看前`5`条数据。\n\n```Python\njobs_df.head()\n```\n\n输出：\n\n```\n    city    companyFullName              positionName    salary\n0   北京\t  达疆网络科技（上海）有限公司    数据分析岗       15k-30k\n1   北京\t  北京音娱时光科技有限公司        数据分析        10k-18k\n2   北京\t  北京千喜鹤餐饮管理有限公司\t     数据分析        20k-30k\n3   北京\t  吉林省海生电子商务有限公司\t     数据分析        33k-50k\n4   北京\t  韦博网讯科技（北京）有限公司\t数据分析        10k-15k\n```\n\n上面的数据表一共有`3140`条数据，但并非所有的职位都是“数据分析”的岗位，如果要筛选出数据分析的岗位，可以通过检查`positionName`字段是否包含“数据分析”这个关键词，这里需要模糊匹配，应该如何实现呢？我们可以先获取`positionName`列，因为这个`Series`对象的`dtype`是字符串，所以可以通过`str`属性获取对应的字符串向量，然后就可以利用我们熟悉的字符串的方法来对其进行操作，代码如下所示。\n\n```Python\njobs_df = jobs_df[jobs_df.positionName.str.contains('数据分析')]\njobs_df.shape\n```\n\n输出：\n\n```\n(1515, 4)\n```\n\n可以看出，筛选后的数据还有`1515`条。接下来，我们还需要对`salary`字段进行处理，如果我们希望统计所有岗位的平均工资或每个城市的平均工资，首先需要将用范围表示的工资处理成其中间值，代码如下所示。\n\n```Python\njobs_df.salary.str.extract(r'(\\d+)[kK]?-(\\d+)[kK]?')\n```\n\n> **说明**：上面的代码通过正则表达式捕获组从字符串中抽取出两组数字，分别对应工资的下限和上限，对正则表达式不熟悉的读者，可以阅读我的知乎专栏“从零开始学Python”中的[《正则表达式的应用》](https://zhuanlan.zhihu.com/p/158929767)一文。\n\n输出：\n\n```\n        0     1\n0\t    15    30\n1\t    10\t  18\n2       20    30\n3       33    50\n4       10    15\n...     ...   ...\n3065    8     10\n3069    6     10\n3070    2     4\n3071    6     12\n3088    8     12\n```\n\n需要提醒大家的是，抽取出来的两列数据都是字符串类型的值，我们需要将其转换成`int`类型，才能计算平均值，对应的方法是`DataFrame`对象的`applymap`方法，该方法的参数是一个函数，而该函数会作用于`DataFrame`中的每个元素。完成这一步之后，我们就可以使用`apply`方法将上面的`DataFrame`处理成中间值，`apply`方法的参数也是一个函数，可以通过指定`axis`参数使其作用于`DataFrame` 对象的行或列，代码如下所示。\n\n```Python\ntemp_df = jobs_df.salary.str.extract(r'(\\d+)[kK]?-(\\d+)[kK]?').applymap(int)\ntemp_df.apply(np.mean, axis=1)\n```\n\n 输出：\n\n```\n0       22.5\n1       14.0\n2       25.0\n3       41.5\n4       12.5\n        ... \n3065    9.0\n3069    8.0\n3070    3.0\n3071    9.0\n3088    10.0\nLength: 1515, dtype: float64\n```\n\n接下来，我们可以用上面的结果替换掉原来的`salary`列或者增加一个新的列来表示职位对应的工资，完整的代码如下所示。\n\n```Python\ntemp_df = jobs_df.salary.str.extract(r'(\\d+)[kK]?-(\\d+)[kK]?').applymap(int)\njobs_df['salary'] = temp_df.apply(np.mean, axis=1)\njobs_df.head()\n```\n\n输出：\n\n```\n    city    companyFullName              positionName    salary\n0   北京\t  达疆网络科技（上海）有限公司    数据分析岗       22.5\n1   北京\t  北京音娱时光科技有限公司        数据分析        14.0\n2   北京\t  北京千喜鹤餐饮管理有限公司\t     数据分析        25.0\n3   北京\t  吉林省海生电子商务有限公司\t     数据分析        41.5\n4   北京\t  韦博网讯科技（北京）有限公司\t数据分析        12.5\n```\n\n`applymap`和`apply`两个方法在数据预处理的时候经常用到，`Series`对象也有`apply`方法，也是用于数据的预处理，但是`DataFrame`对象还有一个名为`transform` 的方法，也是通过传入的函数对数据进行变换，类似`Series`对象的`map`方法。需要强调的是，`apply`方法具有归约效果的，简单的说就是能将较多的数据处理成较少的数据或一条数据；而`transform`方法没有归约效果，只能对数据进行变换，原来有多少条数据，处理后还是有多少条数据。\n\n如果要对数据进行深度的分析和挖掘，字符串、日期时间这样的非数值类型都需要处理成数值，因为非数值类型没有办法计算相关性，也没有办法进行 $\\small{\\chi^{2}}$ 检验等操作。对于字符串类型，通常可以其分为以下三类，再进行对应的处理。\n\n1. 有序变量（Ordinal Variable）：字符串表示的数据有顺序关系，那么可以对字符串进行序号化处理。\n2. 分类变量（Categorical Variable）/ 名义变量（Nominal Variable）：字符串表示的数据没有大小关系和等级之分，那么就可以使用独热编码的方式处理成哑变量（虚拟变量）矩阵。\n3. 定距变量（Scale Variable）：字符串本质上对应到一个有大小高低之分的数据，而且可以进行加减运算，那么只需要将字符串处理成对应的数值即可。\n\n对于第1类和第3类，我们可以用上面提到的`apply`或`transform`方法来处理，也可以利用`scikit-learn`中的`OrdinalEncoder`处理第1类字符串，这个我们在后续的课程中会讲到。对于第2类字符串，可以使用`pandas`的`get_dummies()`函数来生成哑变量（虚拟变量）矩阵，代码如下所示。\n\n```Python\npersons_df = pd.DataFrame(\n    data={\n        '姓名': ['关羽', '张飞', '赵云', '马超', '黄忠'],\n        '职业': ['医生', '医生', '程序员', '画家', '教师'],\n        '学历': ['研究生', '大专', '研究生', '高中', '本科']\n    }\n)\npersons_df\n```\n\n输出：\n\n```\n\t姓名\t职业\t学历\n0\t关羽\t医生\t研究生\n1\t张飞\t医生\t大专\n2\t赵云\t程序员\t研究生\n3\t马超\t画家\t高中\n4\t黄忠\t教师\t本科\n```\n\n将职业处理成哑变量矩阵。\n\n```Python\npd.get_dummies(persons_df['职业'])\n```\n\n输出：\n\n```\n    医生 教师  画家  程序员\n0\t1    0    0    0\n1\t1    0    0    0\n2\t0    0    0    1\n3\t0    0    1    0\n4\t0    1    0    0\n```\n\n将学历处理成大小不同的值。\n\n```Python\ndef handle_education(x):\n    edu_dict = {'高中': 1, '大专': 3, '本科': 5, '研究生': 10}\n    return edu_dict.get(x, 0)\n\n\npersons_df['学历'].apply(handle_education)\n```\n\n输出：\n\n```\n0    10\n1     3\n2    10\n3     1\n4     5\nName: 学历, dtype: int64\n```\n\n我们再来说说数据离散化。离散化也叫分箱，如果变量的取值是连续值，那么它的取值有无数种可能，在进行数据分组的时候就会非常的不方便，这个时候将连续变量离散化就显得非常重要。之所以把离散化叫做分箱，是因为我们可以预先设置一些箱子，每个箱子代表了数据取值的范围，这样就可以将连续的值分配到不同的箱子中，从而实现离散化。下面的例子读取了2018年北京积分落户数据，我们可以根据落户积分对数据进行分组，具体的做法如下所示。\n\n```Python\nluohu_df = pd.read_csv('data/2018年北京积分落户数据.csv', index_col='id')\nluohu_df.score.describe()\n```\n\n输出：\n\n```\ncount    6019.000000\nmean       95.654552\nstd         4.354445\nmin        90.750000\n25%        92.330000\n50%        94.460000\n75%        97.750000\nmax       122.590000\nName: score, dtype: float64\n```\n\n可以看出，落户积分的最大值是`122.59`，最小值是`90.75`，那么我们可以构造一个从`90`分到`125`分，每`5`分一组的`7`个箱子，`pandas`的`cut`函数可以帮助我们首先数据分箱，代码如下所示。\n\n```Python\nbins = np.arange(90, 126, 5)\npd.cut(luohu_df.score, bins, right=False)\n```\n\n> **说明**：`cut`函数的`right`参数默认值为`True`，表示箱子左开右闭；修改为`False`可以让箱子的右边界为开区间，左边界为闭区间，大家看看下面的输出就明白了。\n\n输出：\n\n```\nid\n1       [120, 125)\n2       [120, 125)\n3       [115, 120)\n4       [115, 120)\n5       [115, 120)\n           ...    \n6015      [90, 95)\n6016      [90, 95)\n6017      [90, 95)\n6018      [90, 95)\n6019      [90, 95)\nName: score, Length: 6019, dtype: category\nCategories (7, interval[int64, left]): [[90, 95) < [95, 100) < [100, 105) < [105, 110) < [110, 115) < [115, 120) < [120, 125)]\n```\n\n我们可以根据分箱的结果对数据进行分组，然后使用聚合函数对每个组进行统计，这是数据分析中经常用到的操作，下一个章节会为大家介绍。除此之外，`pandas`还提供了一个名为`qcut`的函数，可以指定分位数对数据进行分箱，有兴趣的读者可以自行研究。\n\n", "深入浅出pandas-4": "## 深入浅出pandas-4\n\n### 数据透视\n\n经过前面的学习，我们已经将数据准备就绪而且变成了我们想要的样子，接下来就是最为重要的数据透视阶段了。当我们拿到一大堆数据的时候，如何从数据中迅速的解读出有价值的信息，把繁杂的数据变成容易解读的统计图表并再此基础上产生业务洞察，这就是数据分析要解决的核心问题。\n\n#### 获取描述性统计信息\n\n首先，我们可以获取数据的描述性统计信息，通过描述性统计信息，我们可以了解数据的集中趋势和离散趋势。\n\n例如，我们有如下所示的学生成绩表。\n\n```Python\nscores = np.random.randint(50, 101, (5, 3))\nnames = ('关羽', '张飞', '赵云', '马超', '黄忠')\ncourses = ('语文', '数学', '英语')\ndf = pd.DataFrame(data=scores, columns=courses, index=names)\ndf\n```\n\n输出：\n\n```\n     语文   数学   英语\n关羽  96    72    73\n张飞  72    70\t97\n赵云  74    51\t79\n马超  100   54\t54\n黄忠  89    100\t88\n```\n\n我们可以通过`DataFrame`对象的方法`mean`、`max`、`min`、`std`、`var`等方法分别获取每个学生或每门课程的平均分、最高分、最低分、标准差、方差等信息，也可以直接通过`describe`方法直接获取描述性统计信息，代码如下所示。\n\n计算每门课程成绩的平均分。\n\n```Python\ndf.mean()\n```\n\n输出：\n\n```\n语文    86.2\n数学    69.4\n英语    78.2\ndtype: float64\n```\n\n计算每个学生成绩的平均分。\n\n```Python\ndf.mean(axis=1)\n```\n\n输出：\n\n```\n关羽    80.333333\n张飞    79.666667\n赵云    68.000000\n马超    69.333333\n黄忠    92.333333\ndtype: float64\n```\n\n计算每门课程成绩的方差。\n\n```Python\ndf.var()\n```\n\n输出：\n\n```\n语文    161.2\n数学    379.8\n英语    265.7\ndtype: float64\n```\n\n> **说明**：通过方差可以看出，数学成绩波动最大，两极分化可能更严重。\n\n获取每门课程的描述性统计信息。\n\n```Python\ndf.describe()\n```\n\n输出：\n\n```\n        语文        数学         英语\ncount   5.000000\t5.000000\t5.000000\nmean    86.200000\t69.400000\t78.200000\nstd     12.696456\t19.488458\t16.300307\nmin     72.000000\t51.000000\t54.000000\n25%     74.000000\t54.000000\t73.000000\n50%     89.000000\t70.000000\t79.000000\n75%     96.000000\t72.000000\t88.000000\nmax     100.000000\t100.000000\t97.000000\n```\n\n#### 排序和取头部值\n\n如果需要对数据进行排序，可以使用`DataFrame`对象的`sort_values`方法，该方法的`by`参数可以指定根据哪个列或哪些列进行排序，而`ascending`参数可以指定升序或是降序。例如，下面的代码展示了如何将学生表按语文成绩排降序。\n\n```Python\ndf.sort_values(by='语文', ascending=False)\n```\n\n输出：\n\n```\n      语文   数学   英语\n马超\t100    54\t  54\n关羽\t96     72     73\n黄忠\t89     100    88\n赵云\t74     51     79\n张飞\t72     70     97\n```\n\n如果`DataFrame`数据量很大，排序将是一个非常耗费时间的操作。有的时候我们只需要获得排前N名或后N名的数据，这个时候其实没有必要对整个数据进行排序，而是直接利用堆结构找出Top-N的数据。`DataFrame`的`nlargest`和`nsmallest`方法就提供对Top-N操作的支持，代码如下所示。\n\n找出语文成绩前3名的学生信息。\n\n```Python\ndf.nlargest(3, '语文')\n```\n\n输出：\n\n```\n      语文   数学   英语\n马超\t100    54\t  54\n关羽\t96     72     73\n黄忠\t89     100    88\n```\n\n找出数学成绩最低的3名学生的信息。\n\n```Python\ndf.nsmallest(3, '数学')\n```\n\n输出：\n\n```\n      语文  数学  英语\n赵云  74    51\t79\n马超  100   54\t54\n张飞  72    70\t97\n```\n\n#### 分组聚合\n\n我们先从之前使用过的 Excel 文件中读取2020年销售数据，然后再为大家演示如何进行分组聚合操作。\n\n```Python\ndf = pd.read_excel('data/2020年销售数据.xlsx')\ndf.head()\n```\n\n输出：\n\n```\n    销售日期\t 销售区域   销售渠道  销售订单     品牌    售价  销售数量\n0   2020-01-01  上海       拼多多    182894-455  八匹马  99    83\n1   2020-01-01  上海       抖音      205635-402  八匹马  219   29\n2   2020-01-01  上海       天猫      205654-021  八匹马  169   85\n3   2020-01-01  上海       天猫      205654-519  八匹马  169   14\n4   2020-01-01  上海       天猫      377781-010  皮皮虾  249   61\n```\n\n如果我们要统计每个销售区域的销售总额，可以先通过“售价”和“销售数量”计算出销售额，为`DataFrame`添加一个列，代码如下所示。\n\n```Python\ndf['销售额'] = df['售价'] * df['销售数量']\ndf.head()\n```\n\n输出：\n\n```\n    销售日期\t 销售区域   销售渠道  销售订单     品牌    售价  销售数量  销售额\n0   2020-01-01  上海       拼多多    182894-455  八匹马  99    83        8217\n1   2020-01-01  上海       抖音      205635-402  八匹马  219   29        6351\n2   2020-01-01  上海       天猫      205654-021  八匹马  169   85        14365\n3   2020-01-01  上海       天猫      205654-519  八匹马  169   14        2366\n4   2020-01-01  上海       天猫      377781-010  皮皮虾  249   61        15189\n```\n\n然后再根据“销售区域”列对数据进行分组，这里我们使用的是`DataFrame`对象的`groupby`方法。分组之后，我们取“销售额”这个列在分组内进行求和处理，代码和结果如下所示。\n\n```Python\ndf.groupby('销售区域').销售额.sum()\n```\n\n输出：\n\n```\n销售区域\n上海    11610489\n北京    12477717\n安徽      895463\n广东     1617949\n江苏     2304380\n浙江      687862\n福建    10178227\nName: 销售额, dtype: int64\n```\n\n如果我们要统计每个月的销售总额，我们可以将“销售日期”作为groupby`方法的参数，当然这里需要先将“销售日期”处理成月，代码和结果如下所示。\n\n```Python\ndf.groupby(df['销售日期'].dt.month).销售额.sum()\n```\n\n输出：\n\n```\n销售日期\n1     5409855\n2     4608455\n3     4164972\n4     3996770\n5     3239005\n6     2817936\n7     3501304\n8     2948189\n9     2632960\n10    2375385\n11    2385283\n12    1691973\nName: 销售额, dtype: int64\n```\n\n接下来我们将难度升级，统计每个销售区域每个月的销售总额，这又该如何处理呢？事实上，`groupby`方法的第一个参数可以是一个列表，列表中可以指定多个分组的依据，大家看看下面的代码和输出结果就明白了。\n\n```Python\ndf.groupby(['销售区域', df['销售日期'].dt.month]).销售额.sum()\n```\n\n输出：\n\n```\n销售区域  销售日期\n上海    1       1679125\n        2       1689527\n        3       1061193\n        4       1082187\n        5        841199\n        6        785404\n        7        863906\n        8        734937\n        9       1107693\n        10       412108\n       11       825169\n       12       528041\n北京    1       1878234\n        2       1807787\n        3       1360666\n        4       1205989\n        5        807300\n        6       1216432\n        7       1219083\n        8        645727\n        9        390077\n        10       671608\n        11       678668\n        12       596146\n安徽    4        341308\n        5        554155\n广东    3        388180\n        8        469390\n        9        365191\n        11       395188\n江苏    4        537079\n        7        841032\n        10       710962\n        12       215307\n浙江    3        248354\n        8        439508\n福建    1       1852496\n        2       1111141\n        3       1106579\n        4        830207\n        5       1036351\n        6        816100\n        7        577283\n        8        658627\n        9        769999\n        10       580707\n        11       486258\n        12       352479\nName: 销售额, dtype: int64\n```\n\n如果希望统计出每个区域的销售总额以及每个区域单笔金额的最高和最低，我们可以在`DataFrame`或`Series`对象上使用`agg`方法并指定多个聚合函数，代码和结果如下所示。\n\n```Python\ndf.groupby('销售区域').销售额.agg(['sum', 'max', 'min'])\n```\n\n输出：\n\n```\n           sum     max   min\n销售区域                        \n上海    11610489  116303   948\n北京    12477717  133411   690\n安徽      895463   68502  1683\n广东     1617949  120807   990\n江苏     2304380  114312  1089\n浙江      687862   90909  3927\n福建    10178227   87527   897\n```\n\n如果希望自定义聚合后的列的名字，可以使用如下所示的方法。\n\n```Python\ndf.groupby('销售区域').销售额.agg(销售总额='sum', 单笔最高='max', 单笔最低='min')\n```\n\n输出：\n\n```\n          销售总额    单笔最高  单笔最低\n销售区域                        \n上海      11610489     116303     948\n北京      12477717     133411     690\n安徽        895463      68502    1683\n广东       1617949     120807     990\n江苏       2304380     114312    1089\n浙江        687862      90909    3927\n福建      10178227      87527     897\n```\n\n如果需要对多个列使用不同的聚合函数，例如“统计每个销售区域销售额的总和以及销售数量的最低值和最高值”，我们可以按照下面的方式来操作。\n\n```Python\ndf.groupby('销售区域')[['销售额', '销售数量']].agg({\n    '销售额': 'sum', '销售数量': ['max', 'min']\n})\n```\n\n输出：\n\n```\n           销售额  销售数量    \n           sum    max min\n销售区域                   \n上海    11610489  100  10\n北京    12477717  100  10\n安徽      895463   98  16\n广东     1617949   98  10\n江苏     2304380  100  11\n浙江      687862   95  20\n福建    10178227  100  10\n```\n\n#### 透视表和交叉表\n\n上面的例子中，“统计每个销售区域每个月的销售总额”会产生一个看起来很长的结果，在实际工作中我们通常把那些行很多列很少的表成为“窄表”，如果我们不想得到这样的一个“窄表”，可以使用`DataFrame`的`pivot_table`方法或者是`pivot_table`函数来生成透视表。透视表的本质就是对数据进行分组聚合操作，**根据 A 列对 B 列进行统计**，如果大家有使用 Excel 的经验，相信对透视表这个概念一定不会陌生。例如，我们要“统计每个销售区域的销售总额”，那么“销售区域”就是我们的 A 列，而“销售额”就是我们的 B 列，在`pivot_table`函数中分别对应`index`和`values`参数，这两个参数都可以是单个列或者多个列。\n\n```Python\npd.pivot_table(df, index='销售区域', values='销售额', aggfunc='sum')\n```\n\n输出：\n\n```\n           销售额\n销售区域          \n上海    11610489\n北京    12477717\n安徽      895463\n广东     1617949\n江苏     2304380\n浙江      687862\n福建    10178227\n```\n\n> **注意**：上面的结果操作跟之前用`groupby`的方式得到的结果有一些区别，`groupby`操作后，如果对单个列进行聚合，得到的结果是一个`Series`对象，而上面的结果是一个`DataFrame` 对象。\n\n如果要统计每个销售区域每个月的销售总额，也可以使用`pivot_table`函数，代码如下所示。\n\n```Python\ndf['月份'] = df['销售日期'].dt.month\npd.pivot_table(df, index=['销售区域', '月份'], values='销售额', aggfunc='sum')\n```\n\n上面的操作结果是一个`DataFrame`，但也是一个长长的“窄表”，如果希望做成一个行比较少列比较多的“宽表”，可以将`index`参数中的列放到`columns`参数中，代码如下所示。\n\n```Python\npd.pivot_table(df, index='销售区域', columns='月份', values='销售额', aggfunc='sum', fill_value=0)\n```\n\n> **说明**：`pivot_table`函数的`fill_value=0`会将空值处理为`0`。\n\n输出：\n\n<img class=\"lazy\" data-src=\"/res/pivot_table_1.png\" style=\"zoom:50%;\">\n\n使用`pivot_table`函数时，还可以通过添加`margins`和`margins_name`参数对分组聚合的结果做一个汇总，具体的操作和效果如下所示。\n\n```Python\npd.pivot_table(df, index='销售区域', columns='月份', values='销售额', aggfunc='sum', fill_value=0, margins=True, margins_name='总计')\n```\n\n输出：\n\n<img class=\"lazy\" data-src=\"/res/pivot_table_2.png\" style=\"zoom:50%;\">\n\n交叉表就是一种特殊的透视表，它不需要先构造一个`DataFrame`对象，而是直接通过数组或`Series`对象指定两个或多个因素进行运算得到统计结果。例如，我们要统计每个销售区域的销售总额，也可以按照如下所示的方式来完成，我们先准备三组数据。\n\n```Python\nsales_area, sales_month, sales_amount = df['销售区域'], df['月份'], df['销售额']\n```\n\n使用`crosstab`函数生成交叉表。\n\n```Python\npd.crosstab(index=sales_area, columns=sales_month, values=sales_amount, aggfunc='sum').fillna(0).astype('i8')\n```\n\n> **说明**：上面的代码使用了`DataFrame`对象的`fillna`方法将空值处理为0，再使用`astype`方法将数据类型处理成整数。\n\n### 数据呈现\n\n一图胜千言，我们对数据进行透视的结果，最终要通过图表的方式呈现出来，因为图表具有极强的表现力，能够让我们迅速的解读数据中隐藏的价值。和`Series`一样，`DataFrame`对象提供了`plot`方法来支持绘图，底层仍然是通过`matplotlib`库实现图表的渲染。关于`matplotlib`的内容，我们在下一个章节进行详细的探讨，这里我们只简单的讲解`plot`方法的用法。 \n\n例如，我们想通过一张柱状图来比较“每个销售区域的销售总额”，可以直接在透视表上使用`plot`方法生成柱状图。我们先导入`matplotlib.pyplot`模块，通过修改绘图的参数使其支持中文显示。\n\n```Python\nimport matplotlib.pyplot as plt\n\nplt.rcParams['font.sans-serif'] = 'FZJKai-Z03S'\n```\n\n> **说明**：上面的`FZJKai-Z03S`是我电脑上已经安装的一种支持中文的字体的名称，字体的名称可以通过查看用户主目录下`.matplotlib`文件夹下名为`fontlist-v330.json`的文件来获得，而这个文件在执行上面的命令后就会生成。\n\n使用魔法指令配置生成矢量图。\n\n```Python\n%config InlineBackend.figure_format = 'svg'\n```\n\n绘制“每个销售区域销售总额”的柱状图。\n\n```Python\ntemp = pd.pivot_table(df, index='销售区域', values='销售额', aggfunc='sum')\ntemp.plot(figsize=(8, 4), kind='bar')\nplt.xticks(rotation=0)\nplt.show()\n```\n\n> **说明**：上面的第3行代码会将横轴刻度上的文字旋转到0度，第4行代码会显示图像。\n\n输出：\n\n<img class=\"lazy\" data-src=\"/res/sales_bar_graph.png\" style=\"zoom:45%;\">\n\n如果要绘制饼图，可以修改`plot`方法的`kind`参数为`pie`，然后使用定制饼图的参数对图表加以定制，代码如下所示。\n\n```Python\ntemp.sort_values(by='销售额', ascending=False).plot(\n    figsize=(6, 6),\n    kind='pie',\n    y='销售额',\n    ylabel='',\n    autopct='%.2f%%',\n    pctdistance=0.8,\n    wedgeprops=dict(linewidth=1, width=0.35),\n    legend=False\n)\nplt.show()\n```\n\n输出：\n\n<img class=\"lazy\" data-src=\"/res/sales_pie_graph.png\" style=\"zoom:35%;\">\n\n", "深入浅出pandas-5": "## 深入浅出pandas-5\n\n我们再来补充一些使用`DataFrame`做数据分析时会使用到的操作，这些操作不仅常见而且也非常重要。\n\n### 计算同比环比\n\n我们之前讲过一个统计月度销售额的例子，我们可以通过`groupby`方法做分组聚合，也可以通过`pivot_table`生成透视表，如下所示。\n\n```python\nsales_df = pd.read_excel('data/2020年销售数据.xlsx')\nsales_df['月份'] = sales_df.销售日期.dt.month\nsales_df['销售额'] = sales_df.售价 * sales_df.销售数量\nresult_df = sales_df.pivot_table(index='月份', values='销售额', aggfunc='sum')\nresult_df.rename(columns={'销售额': '本月销售额'}, inplace=True)\nresult_df\n```\n\n输出：\n\n```\n      本月销售额\n月份         \n1       5409855\n2       4608455\n3       4164972\n4       3996770\n5       3239005\n6       2817936\n7       3501304\n8       2948189\n9       2632960\n10      2375385\n11      2385283\n12      1691973\n```\n\n在得到月度销售额之后，如果我们需要计算月环比，这里有两种方案。第一种方案是我们可以使用`shift`方法对数据进行移动，将上一个月的数据与本月数据对齐，然后通过`(本月销售额 - 上月销售额) / 上月销售额`来计算月环比，代码如下所示。\n\n```python\nresult_df['上月销售额'] = result_df.本月销售额.shift(1)\nresult_df\n```\n\n输出：\n\n```\n      本月销售额      上月销售额\n月份                    \n1       5409855            NaN\n2       4608455      5409855.0\n3       4164972      4608455.0\n4       3996770      4164972.0\n5       3239005      3996770.0\n6       2817936      3239005.0\n7       3501304      2817936.0\n8       2948189      3501304.0\n9       2632960      2948189.0\n10      2375385      2632960.0\n11      2385283      2375385.0\n12      1691973      2385283.0\n```\n\n在上面的例子中，`shift`方法的参数为`1`表示将数据向下移动一个单元，当然我们可以使用参数`-1`将数据向上移动一个单元。相信大家能够想到，如果我们有更多年份的数据，我们可以将参数设置为`12`，这样就可以计算今年的每个月与去年的每个月之间的同比。\n\n```python\nresult_df['环比'] = (result_df.本月销售额 - result_df.上月销售额) / result_df.上月销售额\nresult_df.style.format(\n    formatter={'上月销售额': '{:.0f}', '环比': '{:.2%}'},\n    na_rep='--------'\n)\n```\n\n输出：\n\n```\n      本月销售额      上月销售额         环比\n月份                    \n1       5409855       --------     -------- \n2       4608455        5409855      -14.81%     \n3       4164972        4608455       -9.62%\n4       3996770        4164972       -4.04%\n5       3239005        3996770      -18.96%\n6       2817936        3239005      -13.00%\n7       3501304        2817936       24.25%\n8       2948189        3501304      -15.80%\n9       2632960        2948189      -10.69%\n10      2375385        2632960       -9.78%\n11      2385283        2375385        0.42%\n12      1691973        2385283      -29.07%\n```\n\n> **说明**：使用 JupyterLab 时，可以通过`DataFrame`对象的`style`属性在网页中对其进行渲染，上面的代码通过`Styler`对象的`format`方法将环比格式化为百分比进行显示，此外还指定了将空值替换为`--------`。\n\n更为简单的第二种方案是直接使用`pct_change`方法计算变化的百分比，我们先将之前的上月销售额和环比列删除掉。\n\n```python\nresult_df.drop(columns=['上月销售额', '环比'], inplace=True)\n```\n\n接下来，我们使用`DataFrame`对象的`pct_change`方法完成环比的计算。值得一提的是，`pct_change`方法有一个名为`periods`的参数，它的默认值是`1`，计算相邻两项数据变化的百分比，这不就是我们想要的环比吗？如果我们有很多年的数据，在计算时把这个参数的值修改为`12`，就可以得到相邻两年的月同比。\n\n```python\nresult_df['环比'] = result_df.pct_change()\nresult_df\n```\n\n### 窗口计算\n\n`DataFrame`对象的`rolling`方法允许我们将数据置于窗口中，然后用函数对窗口中的数据进行运算和处理。例如，我们获取了某只股票近期的数据，想制作5日均线和10日均线，那么就需要先设置窗口再进行运算。我们先用如下所示的代码读取2022年百度的股票数据，数据文件可以通过下面的链接来获取。\n\n```Python\nbaidu_df = pd.read_excel('data/2022年股票数据.xlsx', sheet_name='BIDU')\nbaidu_df.sort_index(inplace=True)\nbaidu_df\n```\n\n输出：\n\n<img class=\"lazy\" data-src=\"/res/baidu_stock.png\" style=\"zoom:50%;\">\n\n上面的`DataFrame`有`Open`、`High`、`Low`、`Close`、`Volume`五个列，分别代表股票的开盘价、最高价、最低价、收盘价和成交量，接下来我们对百度的股票数据进行窗口计算。\n\n```Python\nbaidu_df.rolling(5).mean()\n```\n\n输出：\n\n<img class=\"lazy\" data-src=\"/res/baidu_stock_ma5.png\" style=\"zoom:50%;\">\n\n我们也可以在`Series`上使用`rolling`设置窗口并在窗口内完成运算，例如我们可以对上面的百度股票收盘价（`Close`列）计算5日均线和10日均线，并使用`merge`函数将其组装到一个`DataFrame`对象中并绘制出双均线图，代码如下所示。\n\n```Python\nclose_ma5 = baidu_df.Close.rolling(5).mean()\nclose_ma10 = baidu_df.Close.rolling(10).mean()\nresult_df = pd.merge(close_ma5, close_ma10, left_index=True, right_index=True)\nresult_df.rename(columns={'Close_x': 'MA5', 'Close_y': 'MA10'}, inplace=True)\nresult_df.plot(kind='line', figsize=(10, 6))\nplt.show()\n```\n\n输出：\n\n<img class=\"lazy\" data-src=\"/res/baidu_double_MA.png\" style=\"zoom:50%;\">\n\n### 相关性判定\n\n在统计学中，我们通常使用协方差（covariance）来衡量两个随机变量的联合变化程度。如果变量 $\\small{X}$ 的较大值主要与另一个变量 $\\small{Y}$ 的较大值相对应，而两者较小值也相对应，那么两个变量倾向于表现出相似的行为，协方差为正。如果一个变量的较大值主要对应于另一个变量的较小值，则两个变量倾向于表现出相反的行为，协方差为负。简单的说，协方差的正负号显示着两个变量的相关性。方差是协方差的一种特殊情况，即变量与自身的协方差。\n\n$$\ncov(X,Y) = E((X - \\mu)(Y - \\upsilon)) = E(X \\cdot Y) - \\mu\\upsilon\n$$\n\n如果 $\\small{X}$ 和 $\\small{Y}$ 是统计独立的，那么二者的协方差为 0，这是因为在 $\\small{X}$ 和 $\\small{Y}$ 独立的情况下：\n\n$$\nE(X \\cdot Y) = E(X) \\cdot E(Y) = \\mu\\upsilon\n$$\n\n协方差的数值大小取决于变量的大小，通常是不容易解释的，但是正态形式的协方差可以显示两变量线性关系的强弱。在统计学中，皮尔逊积矩相关系数就是正态形式的协方差，它用于度量两个变量 $\\small{X}$ 和 $\\small{Y}$ 之间的相关程度（线性相关），其值介于 -1 到 1 之间。\n\n$$\n\\frac {cov(X, Y)} {\\sigma_{X}\\sigma_{Y}}\n$$\n\n估算样本的协方差和标准差，可以得到样本皮尔逊系数，通常用希腊字母 $\\small{\\rho}$ 表示。\n\n$$\n\\rho = \\frac {\\sum_{i=1}^{n}(X_i - \\bar{X})(Y_i - \\bar{Y})} {\\sqrt{\\sum_{i=1}^{n}(X_i - \\bar{X})^2} \\sqrt{\\sum_{i=1}^{n}(Y_i - \\bar{Y})^2}}\n$$\n\n我们用 $\\small{\\rho}$ 值判断指标的相关性时遵循以下两个步骤。\n\n1. 判断指标间是正相关、负相关，还是不相关。\n    - 当 $\\small{\\rho \\gt 0}$，认为变量之间是正相关，也就是两者的趋势一致。\n    - 当 $\\small{\\rho \\lt 0}$，认为变量之间是负相关，也就是两者的趋势相反。\n    - 当 $\\small{\\rho \\approx 0}$，认为变量之间是不相关的，但并不代表两个指标是统计独立的。\n2. 判断指标间的相关程度。\n    - 当 $\\small{\\rho}$ 的绝对值在 $\\small{[0.6,1]}$ 之间，认为变量之间是强相关的。\n    - 当 $\\small{\\rho}$ 的绝对值在 $\\small{[0.1,0.6)}$ 之间，认为变量之间是弱相关的。\n    - 当 $\\small{\\rho}$ 的绝对值在 $\\small{[0,0.1)}$ 之间，认为变量之间没有相关性。\n\n皮尔逊相关系数适用于：\n\n1. 两个变量之间是线性关系，都是连续数据。\n2. 两个变量的总体是正态分布，或接近正态的单峰分布。\n3. 两个变量的观测值是成对的，每对观测值之间相互独立。\n\n这里，我们顺便说一下，如果两组变量并不是来自于正态总体的连续值，我们该如何判断相关性呢？对于定序尺度（等级），我们可以使用斯皮尔曼秩相关系数，其计算公式如下所示：\n\n$$\nr_{s}=1-{\\frac {6\\sum d_{i}^{2}}{n(n^{2}-1)}}\n$$\n\n其中， $\\small{d_{i}=\\operatorname {R} (X_{i})-\\operatorname {R} (Y_{i})}$ ，即每组观测中两个变量的等级差值， $\\small{n}$ 为观测样本数。\n\n对于定类尺度（类别），我们可以使用卡方检验的方式来判定其是否相关。其实很多时候，连续值也可以通过分箱的方式处理成离散的等级或类别，然后使用斯皮尔曼秩相关系数或卡方检验的方式来判定相关性。\n\n`DataFrame`对象的`cov`方法和`corr`方法分别用于计算协方差和相关系数，`corr`方法有一个名为`method`的参数，其默认值是`pearson`，表示计算皮尔逊相关系数；除此之外，还可以指定`kendall`或`spearman`来计算肯德尔系数或斯皮尔曼秩相关系数。\n\n我们从名为`boston_house_price.csv`的文件中获取著名的波士顿房价数据集来创建一个`DataFrame`。\n\n```python\nboston_df = pd.read_csv('data/boston_house_price.csv')\nboston_df\n```\n\n输出：\n\n<img class=\"lazy\" data-src=\"/res/boston_house_price.png\" style=\"zoom:50%;\">\n\n> **说明**：上面代码中使用了相对路径来访问 CSV 文件，也就是说 CSV 文件在当前工作路径下名为`data`的文件夹中。如果需要上面例子中的 CSV 文件，可以通过下面的百度云盘地址进行获取。链接：<https://pan.baidu.com/s/1rQujl5RQn9R7PadB2Z5g_g?pwd=e7b4>，提取码：e7b4。\n\n可以看出，该数据集中包含了诸多影响房价的特征，包括犯罪率、一氧化氮浓度、平均房间数、低收入人群占比等，其中`PRICE`代表房价，具体情况如下所示。\n\n<img class=\"lazy\" data-src=\"/res/boston_house_price_features.png\" style=\"zoom:50%;\">\n\n接下来，我们将其中可以视为来自于正态总体的连续值，通过`corr`方法计算皮尔逊相关系数，看看哪些跟房价是正相关或负相关的关系，代码如下所示。\n\n```Python\nboston_df[['NOX', 'RM', 'PTRATIO', 'LSTAT', 'PRICE']].corr()\n```\n\n输出：\n\n<img class=\"lazy\" data-src=\"/res/boston_person_correlation.png\" style=\"zoom:50%;\">\n\n可以看出，平均房间数（`RM`）跟房价有较强的正相关性，而低收入人群占比（`LSTAT`）跟房价之间存在明显的负相关性。\n\n斯皮尔曼秩相关系数对数据条件的要求没有皮尔逊相关系数严格，只要两个变量的观测值是成对的等级数据，或者是由连续变量转化成等级的数据，不论两个变量的总体分布形态、样本容量的大小如何，都可以用斯皮尔曼等级相关系数来进行研究。我们可以通过下面的方式对部分特征进行预处理，然后计算斯皮尔曼秩相关系数。\n\n```Python\nboston_df['CRIM'] = boston_df.CRIM.apply(lambda x: x // 5 if x < 25 else 5).map(int)\nboston_df['ZN'] = pd.qcut(boston_df.ZN, q=[0, 0.75, 0.8, 0.85, 0.9, 0.95, 1], labels=np.arange(6))\nboston_df['AGE'] = (boston_df.AGE // 20).map(int)\nboston_df['DIS'] = (boston_df.DIS // 2.05).map(int)\nboston_df['B'] = (boston_df.B // 66).map(int)\nboston_df['PRICE'] = pd.qcut(boston_df.PRICE, q=[0, 0.15, 0.3, 0.5, 0.7, 0.85, 1], labels=np.arange(6))\nboston_df[['CRIM', 'ZN', 'AGE', 'DIS', 'B', 'PRICE']].corr(method='spearman')\n```\n\n输出：\n\n<img class=\"lazy\" data-src=\"/res/boston_spearman_correlation.png\" style=\"zoom:50%;\">\n\n可以看出，房价跟犯罪率（`CRIM`）和房龄（`AGE`）之间存在较为明显的负相关关系，跟住房用地尺寸（`ZN`）存在微弱的正相关关系。相关性可以帮助我们在实际工作中找到业务抓手，即找到那些能够影响或改变工作结果的相关因素。\n\n", "深入浅出pandas-6": "## 深入浅出pandas-6\n\n我们再来看看`Index`类型，它为`Series`和`DataFrame`对象提供了索引服务，有了索引我们就可以排序数据（`sort_index`方法）、对齐数据（在运算和合并数据时非常重要）并实现对数据的快速检索（索引运算）。由于`DataFrame`类型表示的是二维数据，所以它的行和列都有索引，分别是`index`和`columns`。`Index`类型的创建的比较简单，通常给出`data`、`dtype`和`name`三个参数即可，分别表示作为索引的数据、索引的数据类型和索引的名称。由于`Index`本身也是一维的数据，索引它的方法和属性跟`Series`非常类似，你可以尝试创建一个`Index`对象，然后尝试一下之前学过的属性和方法在`Index`类型上是否生效。接下来，我们主要看看`Index`的几种子类型。\n\n### 范围索引\n\n范围索引是由具有单调性的整数构成的索引，我们可以通过`RangeIndex`构造器来创建范围索引，也可以通过`RangeIndex`类的类方法`from_range`来创建范围索引，代码如下所示。\n\n代码：\n\n```Python\nsales_data = np.random.randint(400, 1000, 12)\nindex = pd.RangeIndex(1, 13, name='月份')\nser = pd.Series(data=sales_data, index=index)\nser\n```\n\n输出：\n\n```\n月份\n1     703\n2     705\n3     557\n4     943\n5     961\n6     615\n7     788\n8     985\n9     921\n10    951\n11    874\n12    609\ndtype: int64\n```\n\n### 分类索引\n\n分类索引是由定类尺度构成的索引。如果我们需要通过索引将数据分组，然后再进行聚合操作，分类索引就可以派上用场。分类索引还有一个名为`reorder_categories`的方法，可以给索引指定一个顺序，分组聚合的结果会按照这个指定的顺序进行呈现，代码如下所示。\n\n代码：\n\n```Python\nsales_data = [6, 6, 7, 6, 8, 6]\nindex = pd.CategoricalIndex(\n    data=['苹果', '香蕉', '苹果', '苹果', '桃子', '香蕉'],\n    categories=['苹果', '香蕉', '桃子'],\n    ordered=True\n)\nser = pd.Series(data=sales_data, index=index)\nser\n```\n\n输出：\n\n```\n苹果    6\n香蕉    6\n苹果    7\n苹果    6\n桃子    8\n香蕉    6\ndtype: int64\n```\n\n基于索引分组数据，然后使用`sum`进行求和。\n\n```Python\nser.groupby(level=0).sum()\n```\n\n输出：\n\n```\n苹果    19\n香蕉    12\n桃子     8\ndtype: int64\n```\n\n指定索引的顺序。\n\n```python\nser.index = index.reorder_categories(['香蕉', '桃子', '苹果'])\nser.groupby(level=0).sum()\n```\n\n输出：\n\n```\n香蕉    12\n桃子     8\n苹果    19\ndtype: int64\n```\n\n### 多级索引\n\nPandas 中的`MultiIndex`类型用来表示层次或多级索引。可以使用`MultiIndex`类的类方法`from_arrays`、`from_product`、`from_tuples`等来创建多级索引，我们给大家举几个例子。\n\n代码：\n\n```python\ntuples = [(1, 'red'), (1, 'blue'), (2, 'red'), (2, 'blue')]\nindex = pd.MultiIndex.from_tuples(tuples, names=['no', 'color'])\nindex\n```\n\n输出：\n\n```\nMultiIndex([(1,  'red'),\n            (1, 'blue'),\n            (2,  'red'),\n            (2, 'blue')],\n           names=['no', 'color'])\n```\n\n代码：\n\n```python\narrays = [[1, 1, 2, 2], ['red', 'blue', 'red', 'blue']]\nindex = pd.MultiIndex.from_arrays(arrays, names=['no', 'color'])\nindex\n```\n\n输出：\n\n```\nMultiIndex([(1,  'red'),\n            (1, 'blue'),\n            (2,  'red'),\n            (2, 'blue')],\n           names=['no', 'color'])\n```\n\n代码：\n\n```python\nsales_data = np.random.randint(1, 100, 4)\nser = pd.Series(data=sales_data, index=index)\nser\n```\n\n输出：\n\n```\nno  color\n1   red      43\n    blue     31\n2   red      55\n    blue     75\ndtype: int64\n```\n\n代码：\n\n```python\nser.groupby('no').sum()\n```\n\n输出：\n\n```\nno\n1     74\n2    130\ndtype: int64\n```\n\n代码：\n\n```python\nser.groupby(level=1).sum()\n```\n\n输出：\n\n```\ncolor\nblue    106\nred      98\ndtype: int64\n```\n\n代码：\n\n```Python\nstu_ids = np.arange(1001, 1006)\nsemisters = ['期中', '期末']\nindex = pd.MultiIndex.from_product((stu_ids, semisters), names=['学号', '学期'])\ncourses = ['语文', '数学', '英语']\nscores = np.random.randint(60, 101, (10, 3))\ndf = pd.DataFrame(data=scores, columns=courses, index=index)\ndf\n```\n\n输出：\n\n```\n             语文 数学 英语\n学号\t学期\t\t\t\n1001  期中\t93\t77\t60\n      期末\t93\t98\t84\n1002  期中\t64\t78\t71\n      期末\t70\t71\t97\n1003  期中\t72\t88\t97\n      期末\t99\t100\t63\n1004  期中\t80\t71\t61\n      期末\t91\t62\t72\n1005  期中\t82\t95\t67\n      期末\t84\t78\t86\n```\n\n根据第一级索引分组数据，按照期中成绩占`25%`，期末成绩占`75%` 的方式计算每个学生每门课的成绩。\n\n代码：\n\n```Python\ndf.groupby(level=0).agg(lambda x: x.values[0] * 0.25 + x.values[1] * 0.75)\n```\n\n输出：\n\n```\n        语文    数学    英语\n学号\t\t\t\n1001\t93.00\t92.75\t78.00\n1002\t68.50\t72.75\t90.50\n1003\t92.25\t97.00\t71.50\n1004\t88.25\t64.25\t69.25\n1005\t83.50\t82.25\t81.25\n```\n\n### 间隔索引\n\n间隔索引顾名思义是使用固定的间隔范围充当索引，我们通常会使用`interval_range`函数来创建间隔索引，代码如下所示。\n\n代码：\n\n```python\nindex = pd.interval_range(start=0, end=5)\nindex\n```\n\n输出：\n\n```\nIntervalIndex([(0, 1], (1, 2], (2, 3], (3, 4], (4, 5]], dtype='interval[int64, right]')\n```\n\n`IntervalIndex`有一个名为`contains`的方法，可以检查范围内是否包含了某个元素，如下所示。\n\n代码：\n\n```python\nindex.contains(1.5)\n```\n\n输出：\n\n```\narray([False,  True, False, False, False])\n```\n\n`IntervalIndex`还有一个名为`overlaps`的方法，可以检查一个范围跟其他的范围是否有重叠，如下所示。\n\n代码：\n\n```python\nindex.overlaps(pd.Interval(1.5, 3.5))\n```\n\n输出：\n\n```\narray([False,  True,  True,  True, False])\n```\n\n如果希望间隔范围是左闭右开的状态，可以在创建间隔索引时通过`closed='left'`来做到；如果希望两边都是关闭状态，可以将`close`参数的值赋值为`both`，代码如下所示。\n\n代码：\n\n```python\nindex = pd.interval_range(start=0, end=5, closed='left')\nindex\n```\n\n输出：\n\n```\nIntervalIndex([[0, 1), [1, 2), [2, 3), [3, 4), [4, 5)], dtype='interval[int64, left]')\n```\n\n代码：\n\n```python\nindex = pd.interval_range(start=pd.Timestamp('2022-01-01'), end=pd.Timestamp('2022-01-04'), closed='both')\nindex\n```\n\n输出：\n\n```\nIntervalIndex([[2022-01-01, 2022-01-02], [2022-01-02, 2022-01-03], [2022-01-03, 2022-01-04]], dtype='interval[datetime64[ns], both]')\n```\n\n\n### 日期时间索引\n\n`DatetimeIndex`应该是众多索引中最复杂最重要的一种索引，我们通常会使用`date_range()`函数来创建日期时间索引，该函数有几个非常重要的参数`start`、`end`、`periods`、`freq`、`tz`，分别代表起始日期时间、结束日期时间、生成周期、采样频率和时区。我们先来看看如何创建`DatetimeIndex`对象，再来讨论它的相关运算和操作，代码如下所示。\n\n代码：\n\n```Python\npd.date_range('2021-1-1', '2021-6-30', periods=10)\n```\n\n输出：\n\n```\nDatetimeIndex(['2021-01-01', '2021-01-21', '2021-02-10', '2021-03-02',\n               '2021-03-22', '2021-04-11', '2021-05-01', '2021-05-21',\n               '2021-06-10', '2021-06-30'],\n              dtype='datetime64[ns]', freq=None)\n```\n\n代码：\n\n```Python\npd.date_range('2021-1-1', '2021-6-30', freq='W')\n```\n\n> **说明**：`freq=W`表示采样周期为一周，它会默认星期日是一周的开始；如果你希望星期一表示一周的开始，你可以将其修改为`freq=W-MON`；你也可以试着将该参数的值修改为`12H`，`M`，`Q`等，看看会发生什么，相信你不难猜到它们的含义。\n\n输出：\n\n```\nDatetimeIndex(['2021-01-03', '2021-01-10', '2021-01-17', '2021-01-24',\n               '2021-01-31', '2021-02-07', '2021-02-14', '2021-02-21',\n               '2021-02-28', '2021-03-07', '2021-03-14', '2021-03-21',\n               '2021-03-28', '2021-04-04', '2021-04-11', '2021-04-18',\n               '2021-04-25', '2021-05-02', '2021-05-09', '2021-05-16',\n               '2021-05-23', '2021-05-30', '2021-06-06', '2021-06-13',\n               '2021-06-20', '2021-06-27'],\n              dtype='datetime64[ns]', freq='W-SUN')\n```\n\n`DatatimeIndex`可以跟`DateOffset`类型进行运算，这一点很好理解，以为我们可以设置一个时间差让时间向前或向后偏移，具体的操作如下所示。\n\n代码：\n\n```Python\nindex = pd.date_range('2021-1-1', '2021-6-30', freq='W')\nindex - pd.DateOffset(days=2)\n```\n\n输出：\n\n```\nDatetimeIndex(['2021-01-01', '2021-01-08', '2021-01-15', '2021-01-22',\n               '2021-01-29', '2021-02-05', '2021-02-12', '2021-02-19',\n               '2021-02-26', '2021-03-05', '2021-03-12', '2021-03-19',\n               '2021-03-26', '2021-04-02', '2021-04-09', '2021-04-16',\n               '2021-04-23', '2021-04-30', '2021-05-07', '2021-05-14',\n               '2021-05-21', '2021-05-28', '2021-06-04', '2021-06-11',\n               '2021-06-18', '2021-06-25'],\n              dtype='datetime64[ns]', freq=None)\n```\n\n代码：\n\n```Python\nindex + pd.DateOffset(hours=2, minutes=10)\n```\n\n输出：\n\n```\nDatetimeIndex(['2021-01-03 02:10:00', '2021-01-10 02:10:00',\n               '2021-01-17 02:10:00', '2021-01-24 02:10:00',\n               '2021-01-31 02:10:00', '2021-02-07 02:10:00',\n               '2021-02-14 02:10:00', '2021-02-21 02:10:00',\n               '2021-02-28 02:10:00', '2021-03-07 02:10:00',\n               '2021-03-14 02:10:00', '2021-03-21 02:10:00',\n               '2021-03-28 02:10:00', '2021-04-04 02:10:00',\n               '2021-04-11 02:10:00', '2021-04-18 02:10:00',\n               '2021-04-25 02:10:00', '2021-05-02 02:10:00',\n               '2021-05-09 02:10:00', '2021-05-16 02:10:00',\n               '2021-05-23 02:10:00', '2021-05-30 02:10:00',\n               '2021-06-06 02:10:00', '2021-06-13 02:10:00',\n               '2021-06-20 02:10:00', '2021-06-27 02:10:00'],\n              dtype='datetime64[ns]', freq=None)\n```\n\n如果`Series`对象或`DataFrame`对象使用了`DatetimeIndex`类型的索引，此时我们可以通过`asfreq()`方法指定一个时间频率来实现对数据的抽样，我们仍然以之前讲过的百度股票数据为例，给大家做一个演示。\n\n代码：\n\n```Python\nbaidu_df = pd.read_excel('data/2022年股票数据.xlsx', sheet_name='BIDU', index_col='Date')\nbaidu_df.sort_index(inplace=True)\nbaidu_df.asfreq('5D')\n```\n\n输出：\n\n<img class=\"lazy\" data-src=\"/res/baidu_stock_asfreq.png\" style=\"zoom:50%;\">\n\n大家可能注意到了，每5天抽取1天有可能会抽中非交易日，那么对应的列都变成了空值，为了解决这个问题，在使用`asfreq`方法时可以通过`method`参数来指定一种填充空值的方法，可以将相邻的交易日的数据填入进来。\n\n代码：\n\n```Python\nbaidu_df.asfreq('5D', method='ffill')\n```\n\n输出：\n\n<img class=\"lazy\" data-src=\"/res/baidu_stock_asfreq_ffill.png\" style=\"zoom:50%;\">\n\n当使用`DatetimeIndex`索引时，我们也可以通过`resample()`方法基于时间对数据进行重采样，相当于根据时间周期对数据进行了分组操作，分组之后还可以进行聚合统计，代码如下所示。\n\n代码：\n\n```Python\nbaidu_df.resample('1M').mean()\n```\n\n输出：\n\n<img class=\"lazy\" data-src=\"/res/baidu_stock_resample.png\" style=\"zoom:50%;\">\n\n代码：\n\n```python\nbaidu_df.resample('1M').agg(['mean', 'std'])\n```\n\n输出：\n\n<img class=\"lazy\" data-src=\"/res/baidu_stock_resample_agg.png\" style=\"zoom:100%;\">\n\n> **提示**：不知大家是否注意到，上面输出的`DataFrame` 的列索引是一个`MultiIndex`对象。你可以访问上面的`DataFrame`对象的`columns`属性看看。\n\n如果要实现日期时间的时区转换，我们可以先用`tz_localize()`方法将日期时间本地化，代码如下所示。\n\n代码：\n\n```Python\nbaidu_df = baidu_df.tz_localize('Asia/Chongqing')\nbaidu_df\n```\n\n输出：\n\n<img class=\"lazy\" data-src=\"/res/baidu_stock_tz_localize.png\" style=\"zoom:50%;\">\n\n在对时间本地化以后，我们再使用`tz_convert()`方法就可以实现转换时区，代码如下所示。\n\n代码：\n\n```Python\nbaidu_df.tz_convert('America/New_York')\n```\n\n输出：\n\n<img class=\"lazy\" data-src=\"/res/baidu_stock_tz_convert.png\" style=\"zoom:50%;\">\n\n如果你的数据使用了`DatetimeIndex`类型的索引，那么你就很有可能要对数据进行时间序列分析，关于时间序列分析的方法和模型并不是本章节要探讨的内容，我们在其他的专栏中为大家分享。\n", "数据可视化-1": "## 数据可视化-1\n\n在完成了对数据的透视之后，我们可以将数据透视的结果通过可视化的方式呈现出来，简单的说，就是将数据变成漂亮的统计图表，因为人类对颜色和形状会更加敏感，然后再进一步解读数据背后隐藏的商业价值。在之前的课程中，我们已经为大家展示过用使用`Series`或`DataFrame`对象的`plot`方法生成可视化图表的操作，本章我们为大家讲解这个绘图方法的基石，它就是大名鼎鼎的 matplotlib 库。\n\n在讲解 matplotlib 之前，请大家先看看下面这张图，它给出了常用的图表类型及其应用场景。我们在选择统计图表时，如果不知道做出怎样的选择最合适，相信这张图就能帮到你。简单的说，看趋势折线图，比数据柱状图，定关系散点图，查占比饼状图，看分布直方图，找离群箱线图。\n\n<img class=\"lazy\" data-src=\"/res/choose_your_chart.png\" style=\"zoom:65%;\">\n\n### 导入和配置\n\n之前的课程中，我们为大家讲解过如何安装和导入 matplotlib 库，如果不确定是否已经安装了 matplotlib，可以使用下面的魔法指令尝试安装或升级你的 matplotlib。\n\n```\n%pip install -U matplotlib\n```\n\n为了解决 matplotlib 图表中文显示的问题，我们需要修改`pyplot`模块的`rcParams`配置参数，具体的操作如下所示。\n\n```Python\nimport matplotlib.pyplot as plt\n\nplt.rcParams['font.sans-serif'].insert(0, 'SimHei')\nplt.rcParams['axes.unicode_minus'] = False\n```\n\n> **说明**：上面代码中的`SimHei`是字体名称，大家可以通过百度云盘下载并安装该字体，链接地址：https://pan.baidu.com/s/1rQujl5RQn9R7PadB2Z5g_g?pwd=e7b4。你可以尝试安装其他的中文字体，安装之后如果不知道字体叫什么名字，可以到用户主目录下名为`.matplotlib`的文件夹中找到`fontlist-v330.json`文件，打开后可以看到字体文件的路径和字体的名称等信息。需要注意的是，使用中文字体后坐标轴上的负号将会无法显示，需要将`axes.unicode_minus`参数设置为`False`，这样才能让坐标轴上的负号正常显示。\n\n通过下面的魔法指令，我们可以在绘图时生成[矢量图](https://zh.wikipedia.org/wiki/%E7%9F%A2%E9%87%8F%E5%9B%BE%E5%BD%A2)（SVG - Scalable Vector Graphics），矢量图的特点是不会因为放大、缩小或旋转等操作而失真，看起来会舒服很多。\n\n```Python\n%config InlineBackend.figure_format='svg'\n```\n\n### 创建画布\n\n`pyplot`模块的`figure`函数可以用来创建画布，创建画布时，可以通过`figsize`参数指定画布的尺寸（默认值是`[6.4, 4.8]`）；可以通过`dpi`参数设置绘图的分辨率，因为`dpi`代表了每英寸的像素点数量。除此之外，还可以通过`facecolor`参数设置画布的背景色。`figure`函数的返回值是一个`Figure`对象，它代表了绘图使用的画布，我们可以基于画布来创建绘图使用的坐标系。\n\n```Python\nplt.figure(figsize=(8, 4), dpi=120, facecolor='darkgray')\n```\n\n### 创建坐标系\n\n可以直接使用`pyplot`模块的`subplot`函数来创建坐标系，该函数会返回`Axes`对象。`subplot`的前三个参数分别用来指定整个画布分成几行几列以及当前坐标系的索引，这三个参数的默认值都是`1`。如果没有创建坐标系，我们绘图时会使用画布上默认的也是唯一的一个坐标系；如果需要在画布上创建多个坐标系，就可以使用该函数。当然，我们也可以通过上面创建的`Figure`对象的`add_subplot`方法或`add_axes`方法来创建坐标系，前者跟`subplot`函数的作用一致，后者会产生嵌套的坐标系。\n\n```Python\nplt.subplot(2, 2, 1)\n```\n\n### 绘制图表\n\n#### 折线图\n\n在绘图时，如果没有先调用`figure`函数和`subplot`函数，我们将使用默认的画布和坐标系，如果要绘制折线图，可以使用`pyplot`模块的`plot`函数，并指定横轴和纵轴的数据。折线图最适合用来观察数据的趋势，尤其是当横坐标代表时间的情况下。我们可以使用`plot`函数的`color`参数来定制折线的颜色，可以使用`marker`参数来定制数据点的标记（例如：`*`表示五角星，`^`表示三角形，`o`表示小圆圈等），可以使用`linestyle`参数来定制折线的样式（例如：`-`表示实线，`--`表示虚线，`:`表示点线等），可以使用`linewidth`参数来定制折线的粗细。 下面的代码绘制了一条正弦曲线，其中`marker='*'`会将数据点的标记设置为五角星形状，而`color='red'`会将折线绘制为红色。\n\n代码：\n\n```Python\nimport numpy as np\n\nx = np.linspace(-2 * np.pi, 2 * np.pi, 120)\ny = np.sin(x)\n\n# 创建画布\nplt.figure(figsize=(8, 4), dpi=120)\n# 绘制折线图\nplt.plot(x, y, linewidth=2, marker='*', color='red')\n# 显示绘图\nplt.show()\n```\n\n输出：\n\n<img class=\"lazy\" data-src=\"/res/20220501173344.png\" style=\"zoom:50%;\">\n\n如果要在一个坐标系上同时绘制正弦和余弦曲线，可以对上面的代码稍作修改。\n\n代码：\n\n```Python\nx = np.linspace(-2 * np.pi, 2 * np.pi, 120)\ny1, y2 = np.sin(x), np.cos(x)\n\nplt.figure(figsize=(8, 4), dpi=120)\nplt.plot(x, y1, linewidth=2, marker='*', color='red')\nplt.plot(x, y2, linewidth=2, marker='^', color='blue')\n# 定制图表上的标注（annotate函数的参数如果不理解可以先不管它）\nplt.annotate('sin(x)', xytext=(0.5, -0.75), xy=(0, -0.25), fontsize=12, arrowprops={\n    'arrowstyle': '->', 'color': 'darkgreen', 'connectionstyle': 'angle3, angleA=90, angleB=0'\n})\nplt.annotate('cos(x)', xytext=(-3, 0.75), xy=(-1.25, 0.5), fontsize=12, arrowprops={\n    'arrowstyle': '->', 'color': 'darkgreen', 'connectionstyle': 'arc3, rad=0.35'\n})\nplt.show()\n```\n\n输出：\n\n<img class=\"lazy\" data-src=\"/res/20220502095949.png\" style=\"zoom:50%;\">\n\n如果要使用两个坐标系分别绘制正弦和余弦，可以用上面提到的`subplot`函数来创建坐标系，然后再绘图。\n\n代码：\n\n```Python\nplt.figure(figsize=(8, 4), dpi=120)\n# 创建坐标系（第1个图）\nplt.subplot(2, 1, 1)\nplt.plot(x, y1, linewidth=2, marker='*', color='red')\n# 创建坐标系（第2个图）\nplt.subplot(2, 1, 2)\nplt.plot(x, y2, linewidth=2, marker='^', color='blue')\nplt.show()\n```\n\n输出：\n\n<img class=\"lazy\" data-src=\"/res/20220501173446.png\" style=\"zoom:50%;\">\n\n当然也可以像下面这么做，大家可以运行代码看看跟上面的图有什么区别。\n\n```Python\nplt.figure(figsize=(8, 4), dpi=120)\nplt.subplot(1, 2, 1)\nplt.plot(x, y1, linewidth=2, marker='*', color='red')\nplt.subplot(1, 2, 2)\nplt.plot(x, y2, linewidth=2, marker='^', color='blue')\nplt.show()\n```\n\n然后，再试一试下面这个代码，看看运行效果如何。\n\n```Python\nfig = plt.figure(figsize=(10, 4), dpi=120)\nplt.plot(x, y1, linewidth=2, marker='*', color='red')\n# 用Figure对象的add_axes方法在现有坐标系中嵌套一个新的坐标系，该方法的参数是一个四元组，\n# 代表了新坐标系在原坐标系中的位置，前两个值是左下角的位置，后两个值是坐标系的宽度和高度\nax = fig.add_axes((0.595, 0.6, 0.3,0.25))\nax.plot(x, y2, marker='^', color='blue')\nax = fig.add_axes((0.155, 0.2, 0.3,0.25))\nax.plot(x, y2, marker='^', color='green')\nplt.show()\n```\n\n#### 散点图\n\n散点图可以帮助我们了解两个变量的关系，如果需要了解三个变量的关系，可以将散点图升级为气泡图。下面的代码中，`x`和`y`两个数组分别表示每个月的收入和每个月网购的支出，如果我们想了解`x`和`y`是否存在相关关系，就可以绘制如下所示的散点图。\n\n代码：\n\n```Python\nx = np.array([5550, 7500, 10500, 15000, 20000, 25000, 30000, 40000])\ny = np.array([800, 1800, 1250, 2000, 1800, 2100, 2500, 3500])\n\nplt.figure(figsize=(6, 4), dpi=120)\nplt.scatter(x, y)\nplt.show()\n```\n\n输出：\n\n<img class=\"lazy\" data-src=\"/res/20220501173034.png\" style=\"zoom:50%;\">\n\n#### 柱状图\n\n在对比数据的差异时，柱状图是非常棒的选择，我们可以使用`pyplot`模块的`bar`函数来生成柱状图，也可以使用`barh`函数来生成水平柱状图（也称为“条状图”）。我们先为柱状图准备一些数据，代码如下所示。\n\n```Python\nx = np.arange(4)\ny1 = np.random.randint(20, 50, 4)\ny2 = np.random.randint(10, 60, 4)\n```\n\n绘制柱状图的代码。\n\n代码：\n\n```Python\nplt.figure(figsize=(6, 4), dpi=120)\n# 通过横坐标的偏移，让两组数据对应的柱子分开，width参数控制柱子的粗细，label参数为柱子添加标签\nplt.bar(x - 0.1, y1, width=0.2, label='销售A组')\nplt.bar(x + 0.1, y2, width=0.2, label='销售B组')\n# 定制横轴的刻度\nplt.xticks(x, labels=['Q1', 'Q2', 'Q3', 'Q4'])\n# 定制显示图例\nplt.legend()\nplt.show()\n```\n\n输出：\n\n<img class=\"lazy\" data-src=\"/res/20220501173557.png\" style=\"zoom:50%;\">\n\n如果想绘制堆叠柱状图，可以对上面的代码稍作修改，如下所示。\n\n代码：\n\n```Python\nlabels = ['Q1', 'Q2', 'Q3', 'Q4']\nplt.figure(figsize=(6, 4), dpi=120)\nplt.bar(labels, y1, width=0.4, label='销售A组')\n# 注意：堆叠柱状图的关键是将之前的柱子作为新柱子的底部，可以通过bottom参数指定底部数据，新柱子绘制在底部数据之上\nplt.bar(labels, y2, width=0.4, bottom=y1, label='销售B组')\nplt.legend(loc='lower right')\nplt.show()\n```\n\n输出：\n\n<img class=\"lazy\" data-src=\"/res/20220501173645.png\" style=\"zoom:50%;\">\n\n#### 饼状图\n\n饼状图通常简称为饼图，是一个将数据划分为几个扇形区域的统计图表，它主要用于描述数量、频率等之间的相对关系。在饼图中，每个扇形区域的大小就是其所表示的数量的比例，这些扇形区域合在一起刚好是一个完整的饼。在需要展示数据构成的场景下，饼状图、树状图和瀑布图是不错的选择，我们可以使用`pyplot`模块的`pie`函数来绘制饼图，代码如下所示。\n\n代码：\n\n```Python\ndata = np.random.randint(100, 500, 7)\nlabels = ['苹果', '香蕉', '桃子', '荔枝', '石榴', '山竹', '榴莲']\n\nplt.figure(figsize=(5, 5), dpi=120)\nplt.pie(\n    data,\n    # 自动显示百分比\n    autopct='%.1f%%',\n    # 饼图的半径\n    radius=1,\n    # 百分比到圆心的距离\n    pctdistance=0.8,\n    # 颜色（随机生成）\n    colors=np.random.rand(7, 3),\n    # 分离距离\n    # explode=[0.05, 0, 0.1, 0, 0, 0, 0],\n    # 阴影效果\n    # shadow=True,\n    # 字体属性\n    textprops=dict(fontsize=8, color='black'),\n    # 楔子属性（生成环状饼图的关键）\n    wedgeprops=dict(linewidth=1, width=0.35),\n    # 标签\n    labels=labels\n)\n# 定制图表的标题\nplt.title('水果销售额占比')\nplt.show()\n```\n\n输出：\n\n<img class=\"lazy\" data-src=\"/res/20220502094128.png\" style=\"zoom:50%;\">\n\n>**说明**：大家可以试一试将上面代码中被注释的部分恢复，看看有什么样的效果。\n\n#### 直方图\n\n在统计学中，直方图是一种展示数据分布情况的图形，是一种二维统计图表，它的两个坐标分别是统计样本和该样本对应的某个属性的度量。下面的数据是某学校100名男学生的身高，如果我们想知道数据的分布，就可以使用直方图。\n\n```Python\nheights = np.array([\n    170, 163, 174, 164, 159, 168, 165, 171, 171, 167, \n    165, 161, 175, 170, 174, 170, 174, 170, 173, 173, \n    167, 169, 173, 153, 165, 169, 158, 166, 164, 173, \n    162, 171, 173, 171, 165, 152, 163, 170, 171, 163, \n    165, 166, 155, 155, 171, 161, 167, 172, 164, 155, \n    168, 171, 173, 169, 165, 162, 168, 177, 174, 178, \n    161, 180, 155, 155, 166, 175, 159, 169, 165, 174, \n    175, 160, 152, 168, 164, 175, 168, 183, 166, 166, \n    182, 174, 167, 168, 176, 170, 169, 173, 177, 168, \n    172, 159, 173, 185, 161, 170, 170, 184, 171, 172\n])\n```\n\n可以使用`pyplot`模块的`hist`函数来绘制直方图，其中`bins`参数代表了我们使用的分箱方式（身高从150厘米到190厘米，每5厘米为一个分箱），代码如下所示。\n\n代码：\n\n```Python\nplt.figure(figsize=(6, 4), dpi=120)\n# 绘制直方图\nplt.hist(heights, bins=np.arange(145, 196, 5), color='darkcyan')\n# 定制横轴标签\nplt.xlabel('身高')\n# 定制纵轴标签\nplt.ylabel('概率密度')\nplt.show()\n```\n\n输出：\n\n<img class=\"lazy\" data-src=\"/res/hist_count.png\" style=\"zoom:50%;\">\n\n绘制直方图时，如果将`hist`函数的`density`参数修改为`True`，同时将`cumulative`参数也修改为`True`，那么一方面纵轴会显示为概率密度，而图表会绘制概率的累计分布，如下所示。\n\n代码：\n\n```python\nplt.figure(figsize=(6, 4), dpi=120)\n# 绘制直方图\nplt.hist(heights, bins=np.arange(145, 196, 5), color='darkcyan', density=True, cumulative=True)\n# 定制横轴标签\nplt.xlabel('身高')\n# 定制纵轴标签\nplt.ylabel('概率')\nplt.show()\n```\n\n输出：\n\n<img class=\"lazy\" data-src=\"/res/hist_cumulative.png\" style=\"zoom:50%;\">\n\n#### 箱线图\n\n箱线图又叫箱型图或盒须图，是一种用于展示一组数据分散情况的统计图表，如下所示。因图形如箱子，而且在上下四分位数之外有线条像胡须延伸出去而得名。在箱线图中，箱子的上边界是上四分位数（ $\\small{Q_{3}}$ ）的位置，箱子的下边界是下四分位数（ $\\small{Q_{1}}$ ）的位置，箱子中间的线条是中位数（ $\\small{Q_{2}}$ ）的位置，而箱子的长度就是四分位距离（IQR）。除此之外，箱子上方线条的边界是最大值，箱子下方线条的边界是最小值，这两条线之外的点就是离群值（outlier）。所谓离群值，是指数据小于 $\\small{Q_{1} - 1.5 \\times IQR}$ 或数据大于 $\\small{Q_{3} + 1.5 \\times IQR}$ 的值，公式中的`1.5`还可以替换为`3`来发现极端离群值（extreme outlier），而介于`1.5`到`3`之间的离群值通常称之为适度离群值（mild outlier）。\n\n可以使用`pyplot`模块的`boxplot`函数来绘制箱线图，代码如下所示。\n\n代码：\n\n```Python\n# 数组中有47个[0, 100)范围的随机数\ndata = np.random.randint(0, 100, 47)\n# 向数组中添加三个可能是离群点的数据\ndata = np.append(data, 160)\ndata = np.append(data, 200)\ndata = np.append(data, -50)\n\nplt.figure(figsize=(6, 4), dpi=120)\n# whis参数的默认值是1.5，将其设置为3可以检测极端离群值，showmeans=True表示在图中标记均值的位置\nplt.boxplot(data, whis=1.5, showmeans=True, notch=True)\n# 定制纵轴的取值范围\nplt.ylim([-100, 250])\n# 定制横轴的刻度\nplt.xticks([1], labels=['data'])\nplt.show()\n```\n\n输出：\n\n<img class=\"lazy\" data-src=\"/res/20220501172802.png\" style=\"zoom:50%;\" />\n\n> **说明**：由于数据是随机生成的，大家运行上面的代码生成的图表可能跟我这里并不相同，以实际运行结果为准。\n\n### 显示和保存图表\n\n可以使用`pyplot`模块的`show`函数来显示绘制的图表，我们在上面的代码中使用过这个函数。如果希望保存图表，可以使用`savefig`函数。需要注意的是，如果要同时显示和保存图表，应该先执行`savefig`函数，再执行`show`函数，因为在调用`show`函数时，图表已经被释放，位于`show`函数之后的`savefig`保存的只是一个空白的区域。\n\n```Python\nplt.savefig('chart.png')\nplt.show()\n```\n\n### 其他图表\n\n使用 matplotlib，我们还可以绘制出其他的统计图表（如：雷达图、玫瑰图、热力图等），但实际工作中，使用频率最高的几类图表我们在上面已经为大家完整的展示出来了。此外，matplotlib 还有很多对统计图表进行定制的细节，例如定制坐标轴、定制图表上的文字和标签等。如果想了解如何用 matplotlib 绘制和定制更多的统计图表，可以直接查看 matplotlib 官方网站上的[文档](https://matplotlib.org/stable/tutorials/index.html)和[示例](https://matplotlib.org/stable/gallery/index.html)，在下一个章节我们会为大家做一个简要的介绍。\n", "数据可视化-2": "## 数据可视化-2\n\n本章我们尝试用 matplotlib 来绘制一些高阶统计图表。正如前面所说的，大家可以通过 matplotlib 官方网站上提供的[文档](https://matplotlib.org/stable/tutorials/index.html)和[示例](https://matplotlib.org/stable/gallery/index.html)来学习如何使用 matplotlib 并绘制出更加高级的统计图表；尤其是在定制一些比较复杂的图表时，我们建议大家直接找到官网提供的示例，然后只需要做出相应的修改，就可以绘制出自己想要的图表。这种“拷贝+修改”的做法应该会大大提高你的工作效率，因为大多数时候，你的代码跟官网上的代码就仅仅是数据有差别而已，没有必要去做重复乏味的事情。\n\n### 气泡图\n\n气泡图可以用来了解三个变量之间的关系，通过比较气泡位置和大小来分析数据维度之间的相关性。例如在我们之前绘制的月收入和网购支出的散点图中，我们已经发现了二者的正相关关系，如果我们引入第三个变量网购次数，那么我们就需要使用气泡图来进行展示。\n\n代码：\n\n```python\nincome = np.array([5550, 7500, 10500, 15000, 20000, 25000, 30000, 40000])\noutcome = np.array([800, 1800, 1250, 2000, 1800, 2100, 2500, 3500])\nnums = np.array([5, 3, 10, 5, 12, 20, 8, 10])\n\n# 通过scatter函数的s参数和c参数分别控制面积和颜色\nplt.scatter(income, outcome, s=nums * 30, c=nums, cmap='Reds')\n# 显示颜色条\nplt.colorbar()\n# 显示图表\nplt.show()\n```\n\n输出：\n\n<img class=\"lazy\" data-src=\"/res/bubble_chart.png\" style=\"zoom:50%;\">\n\n### 面积图\n\n面积图又叫堆叠折线图，是在折线图的基础上，对折线以下的区域进行颜色填充（展示面积），用于在连续间隔或时间跨度上展示数值，一般用来显示趋势和对比数值，不同颜色的填充可以让多个面积块之间的对比和趋势更好的突显。下面的例子中，我们用面积图来展示从周一到周日花在睡觉、吃饭、工作和玩耍上的时间。\n\n代码：\n\n```python\nplt.figure(figsize=(8, 4))\ndays = np.arange(7)\nsleeping = [7, 8, 6, 6, 7, 8, 10]\neating = [2, 3, 2, 1, 2, 3, 2]\nworking = [7, 8, 7, 8, 6, 2, 3]\nplaying = [8, 5, 9, 9, 9, 11, 9]\n# 绘制堆叠折线图\nplt.stackplot(days, sleeping, eating, working, playing)\n# 定制横轴刻度\nplt.xticks(days, labels=[f'星期{x}' for x in '一二三四五六日'])\n# 定制图例\nplt.legend(['睡觉', '吃饭', '工作', '玩耍'], fontsize=10)\n# 显示图表\nplt.show()\n```\n\n输出：\n\n<img class=\"lazy\" data-src=\"/res/stacked_line_chart.png\" style=\"zoom:50%;\">\n\n### 雷达图\n\n雷达图通常用来比较多个定量数据，用于查看哪些变量具有相似的值。 雷达图也可用于查看数据集中哪些变量的值比较低，哪些变量的值比较高，是显示性能或表现的理想选择。经常观看篮球、足球比赛的读者应该对雷达图非常熟悉，例如在 NBA 的转播中就经常使用雷达图来展示球员的各项数据。雷达图的本质折线图，只不过将折线图映射到了极坐标系。在绘制雷达图时，需要让折线闭合，简单的说就是首尾相连，下面是绘制雷达图的代码。\n\n代码：\n\n```python\nlabels = np.array(['速度', '力量', '经验', '防守', '发球', '技术'])\n# 马龙和水谷隼的数据\nmalong_values = np.array([93, 95, 98, 92, 96, 97])\nshuigu_values = np.array([30, 40, 65, 80, 45, 60])\nangles = np.linspace(0, 2 * np.pi, labels.size, endpoint=False)\n# 多加一条数据让图形闭合\nmalong_values = np.append(malong_values, malong_values[0])\nshuigu_values = np.append(shuigu_values, shuigu_values[0])\nangles = np.append(angles, angles[0])\n# 创建画布\nplt.figure(figsize=(4, 4), dpi=120)\n# 创建坐标系\nax = plt.subplot(projection='polar')\n# 绘图和填充\nplt.plot(angles, malong_values, color='r', linewidth=2, label='马龙')\nplt.fill(angles, malong_values, color='r', alpha=0.3)\nplt.plot(angles, shuigu_values, color='g', linewidth=2, label='水谷隼')\nplt.fill(angles, shuigu_values, color='g', alpha=0.2)\n# 显示图例\nax.legend()\n# 显示图表\nplt.show()\n```\n\n输出：\n\n<img class=\"lazy\" data-src=\"/res/radar_chart.png\" style=\"zoom:50%;\">\n\n### 玫瑰图\n\n玫瑰图是映射在极坐标下的柱状图，由弗罗伦斯·南丁格尔（Florence Nightingale）所发明，当年是南丁格尔用来呈现战地医院季节性死亡率的一种图表。由于半径和面积的关系是平方的关系，南丁格尔玫瑰图会将数据的比例大小夸大，尤其适合对比大小相近的数值，同时由于圆形有周期的特性，所以南丁格尔玫瑰图也适用于表示一个周期内的时间概念，比如星期、月份。\n\n代码：\n\n```python\ngroup1 = np.random.randint(20, 50, 4)\ngroup2 = np.random.randint(10, 60, 4)\nx = np.array([f'A组-Q{i}' for i in range(1, 5)] + [f'B组-Q{i}' for i in range(1, 5)])\ny = np.array(group1.tolist() + group2.tolist())\n# 玫瑰花瓣的角度和宽度\ntheta = np.linspace(0, 2 * np.pi, x.size, endpoint=False)\nwidth = 2 * np.pi / x.size\n# 生成8种随机颜色\ncolors = np.random.rand(8, 3)\n# 将柱状图投影到极坐标\nax = plt.subplot(projection='polar')\n# 绘制柱状图\nplt.bar(theta, y, width=width, color=colors, bottom=0)\n# 设置网格\nax.set_thetagrids(theta * 180 / np.pi, x, fontsize=10)\n# 显示图表\nplt.show()\n```\n\n输出：\n\n<img class=\"lazy\" data-src=\"/res/rose_chart.png\" style=\"zoom:50%;\">\n\n### 3D图表\n\nmatplotlib 还可以用于绘制3D图，具体的内容大家可以参考官方文档，下面我们用一段简单的代码为大家展示如何绘制3D图表。\n\n代码：\n\n```python\nfrom mpl_toolkits.mplot3d import Axes3D\n\nfig = plt.figure(figsize=(8, 4), dpi=120)\n# 创建3D坐标系并添加到画布上\nax = Axes3D(fig, auto_add_to_figure=False)\nfig.add_axes(ax)\nx = np.arange(-2, 2, 0.1)\ny = np.arange(-2, 2, 0.1)\nx, y = np.meshgrid(x, y)\nz = (1 - y ** 5 + x ** 5) * np.exp(-x ** 2 - y ** 2)\n# 绘制3D曲面\nax.plot_surface(x, y, z)\n# 显示图表\nplt.show()\n```\n\n输出：\n\n<img class=\"lazy\" data-src=\"/res/3d_surface_chart.png\" style=\"zoom:60%;\">\n\n需要指出的是， JupyterLab 中渲染的3D图并不是真正的3D图，因为你没有办法调整观察者的视角，也没有办法旋转或者缩放。如果想要看到真正的3D效果，需要在将图表渲染到 Qt 窗口中，为此我们可以先安装名为 PyQt6 的三方库，如下所示。\n\n```\n%pip install PyQt6\n```\n\n然后，我们使用魔法指令让 JupyterLab 将图表渲染到 Qt 窗口中。\n\n```\n%matplotlib qt\n```\n\n在完成上面的操作后，我们可以重新运行刚才绘制3D图的代码，看到如下所示的窗口。在这个窗口中，我们可以通过鼠标对3D进行旋转、缩放，我们有可以选中图表的一部分数据进行观测，是不是非常的酷。\n\n<img class=\"lazy\" data-src=\"/res/3d_surface_chart_qt.png\" style=\"zoom:50%;\">\n", "数据可视化-3": "## 数据可视化-3\n\n通过前面的学习，我们已经对数据可视化工具 matplotlib 有一个初步的认知。大家可能也会发现了，matplotlib 提供的函数虽然强大，但是参数太多，要想对图表进行深度的定制就需要修改一系列的参数，这一点对新手并不友好。另一方面，使用 matplotlib 定制的统计图是静态图表，可能在某些需要交互效果的场景下并不合适。为了解决这两个问题，我们为大家介绍两个新的可视化工具，一个是 seaborn，一个是 pyecharts。\n\n### Seaborn\n\nSeaborn 是建立在 matplotlib 之上的数据可视化工具，它相当于是对 matplotlib 进行了更高级的封装，而且 seaborn 也能跟 pandas 无缝整合，让我们可以用更少的代码构建出更好的统计图表，帮助我们探索和理解数据。Seaborn 包含但不局限于以下描述的功能：\n\n1. 面向数据集的 API，可用于检查多个变量之间的关系。\n1. 支持使用分类变量来显示观察结果或汇总统计数据。\n1. 能够可视化单变量或双变量分布以及在数据子集之间进行比较的选项\n1. 各类因变量线性回归模型的自动估计与作图。\n1. 集成调色板和主题，轻松定制统计图表的视觉效果。\n\n可以使用 Python 的包管理工具 pip 来安装 seaborn。\n\n```Bash\npip install seaborn\n```\n\n在 Jupyter 中，可以直接使用魔法指令进行安装，如下所示。\n\n```Bash\n%pip install seaborn\n```\n\n下面，我们用 seaborn 自带的数据集为例，为大家简单的展示 seaborn 的用法和强大之处，想要深入研究 seaborn 的读者可以自行阅读官方[文档](https://seaborn.pydata.org/tutorial.html)和并查看官方作品集中的[示例。](https://seaborn.pydata.org/examples/index.html)根据官方示例来编写自己的代码是一个不错的选择，简单的说就是保留官方代码，将数据换成自己的数据即可。下图展示了 seaborn 绘制图表的函数，可以看出，seaborn 的这些函数主要支持我们通过绘制图表来探索数据的关系、分布和分类。\n\n<img class=\"lazy\" data-src=\"/res/20220502115005.png\" style=\"zoom:75%;\">\n\n使用 seaborn，首先需要导入该库并设置主题，代码如下所示。\n\n```Python\nimport seaborn as sns\n\nsns.set_theme()\n```\n\n如果需要在图表上显示中文，还需要用之前讲过的方法修改 matplotlib 的配置参数，代码如下所示。\n\n```Python\nimport matplotlib.pyplot as plt\n\nplt.rcParams['font.sans-serif'].insert(0, 'SimHei')\nplt.rcParams['axes.unicode_minus'] = False\n```\n\n> **注意**：上面的代码必须放在调用 set_theme 函数之后，否则调用 set_theme 函数时又会重新修改 matplotlib 配置参数中的字体设置。\n\n加载官方的 Tips 数据集（就餐小费数据）。\n\n```Python\ntips_df = sns.load_dataset('tips')\ntips_df.info()\n```\n\n运行结果如下所示，其中 total_bill 表示账单总金额，tip 表示小费的金额，sex 是顾客的性别，smoker 表示顾客是否抽样，day 代表星期几，time 代表是午餐还是晚餐，size 是就餐人数。\n\n```\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 244 entries, 0 to 243\nData columns (total 7 columns):\n #   Column      Non-Null Count  Dtype   \n---  ------      --------------  -----   \n 0   total_bill  244 non-null    float64 \n 1   tip         244 non-null    float64 \n 2   sex         244 non-null    category\n 3   smoker      244 non-null    category\n 4   day         244 non-null    category\n 5   time        244 non-null    category\n 6   size        244 non-null    int64   \ndtypes: category(4), float64(2), int64(1)\nmemory usage: 7.4 KB\n```\n\n由于数据集是联网加载的，上述代码可能因为 SSL 的原因无法获取到数据，可以尝试先运行下面的代码，然后再加载数据集。\n\n```Python\nimport ssl\n\nssl._create_default_https_context = ssl._create_unverified_context\n```\n\n如果我们希望了解账单金额的分布，可以使用下面的代码来绘制分布图。\n\n```Python\nsns.histplot(data=tips_df, x='total_bill', kde=True)\n```\n\n<img class=\"lazy\" data-src=\"/res/20220502115531.png\" style=\"zoom:50%;\">\n\n如果想了解变量之间的两两关系，我们可以绘制点对图，代码和效果如下所示。\n\n```Python\nsns.pairplot(data=tips_df, hue='sex')\n```\n\n<img class=\"lazy\" data-src=\"/res/20220502120236.png\" style=\"zoom:42%;\">\n\n如果对上面图表的颜色不满意，还可以通过 palette 参数选择 seaborn 自带的“调色板”来修改颜色，这种方式相比于自行指定颜色或使用随机颜色方便和靠谱了很多，下图为大家展示了部分 seaborn 自带的“调色板”。\n\n<img class=\"lazy\" data-src=\"/res/20220502120749.png\" style=\"zoom:45%;\">\n\n我们可以将上面的代码稍作修改，看看运行结果有什么差别。\n\n```Python\nsns.pairplot(data=tips_df, hue='sex', palette='Dark2')\n```\n\n接下来，我们为 total_bill 和 tip 两组数据绘制联合分布图，代码如下所示。\n\n```Python\nsns.jointplot(data=tips_df, x='total_bill', y='tip', hue='sex')\n```\n\n<img class=\"lazy\" data-src=\"/res/20220502121226.png\" style=\"zoom:50%;\">\n\n上面清晰的展示了，total_bill 和 tip 之间存在正相关关系，这一点我们也可以通过 DataFrame 对象的 corr 方法进行验证。接下来，我们可以建立回归模型来拟合这些数据点，而 seaborn 的线性回归模型图已经帮我们实现了这项功能，代码如下所示。\n\n```Python\nsns.lmplot(data=tips_df, x='total_bill', y='tip', hue='sex')\n```\n\n<img class=\"lazy\" data-src=\"/res/20220502121656.png\" style=\"zoom:50%;\">\n\n如果我们希望了解账单金额的集中和离散趋势，可以绘制箱线图或小提琴图，代码如下所示，我们将数据按星期四、星期五、星期六和星期天分别进行展示。\n\n```Python\nsns.boxplot(data=tips_df, x='day', y='total_bill')\n```\n\n<img class=\"lazy\" data-src=\"/res/20220502122106.png\" style=\"zoom:50%;\">\n\n```Python\nsns.violinplot(data=tips_df, x='day', y='total_bill')\n```\n\n<img class=\"lazy\" data-src=\"/res/20220502122144.png\" style=\"zoom:50%;\">\n\n> **说明**：相较于箱线图，小提琴图没有标注异常点而是显示了数据的整个范围，另一方面，小提琴图很好的展示了数据的分布（密度轨迹）。\n\n### Pyecharts\n\nEcharts 原来是百度开发的一个前端图表库，2018年1月16日，ECharts 进入 Apache Incubator 进行孵化，目前已经是 Apache 软件基金会的顶级项目。凭借着良好的交互性和精巧的图表设计，ECharts 得到了众多开发者的认可，而 pyecharts 就是基于 Python 语言对 ECharts 进行了包装，让 Python 开发者也可以使用 ECharts 绘制外观精美且交互性强的统计图表。\n\n可以使用 Python 的包管理工具 pip 来安装 pyecharts。\n\n```Bash\npip install pyecharts\n```\n\n在 JupyterLab 中，可以直接使用魔法指令进行安装，如下所示。\n\n```Bash\n%pip install pyecharts\n```\n\n如果想在 JupyterLab 中使用 pyecharts 绘图，我们还需要做一些准备工作，主要是修改 pyecharts 的配置，代码如下所示。\n\n```python\nfrom pyecharts.globals import CurrentConfig, NotebookType\n\nCurrentConfig.NOTEBOOK_TYPE = NotebookType.JUPYTER_LAB\n```\n\n接下来，我们通过来自于 pyecharts 官方网站新手教程中的一个例子，来认识 pyecharts。当然，我们对官网的例子进行一些调整，代码如下所示。\n\n```Python\nfrom pyecharts.charts import Bar\nfrom pyecharts import options as opts\n\n# 创建柱状图对象并设置初始参数（宽度、高度）\nbar_chart = Bar(init_opts=opts.InitOpts(width='600px', height='450px'))\n# 设置横轴数据\nbar_chart.add_xaxis([\"衬衫\", \"羊毛衫\", \"雪纺衫\", \"裤子\", \"高跟鞋\", \"袜子\"])\n# 设置纵轴数据（第一组）\nbar_chart.add_yaxis(\"商家A\", [25, 20, 36, 10, 75, 90])\n# 设置纵轴数据（第二组）\nbar_chart.add_yaxis(\"商家B\", [15, 12, 30, 20, 45, 60])\n# 设置纵轴数据（第三组）\nbar_chart.add_yaxis(\"商家C\", [12, 32, 40, 52, 35, 26])\n# 添加全局配置参数\nbar_chart.set_global_opts(\n    # 横轴相关的参数\n    xaxis_opts=opts.AxisOpts(\n        axislabel_opts=opts.LabelOpts(color='navy')\n    ),\n    # 纵轴相关的参数（标签、最小值、最大值、间隔）\n    yaxis_opts=opts.AxisOpts(\n        axislabel_opts=opts.LabelOpts(color='navy'),\n        min_=0,\n        max_=100,\n        interval=10\n    ),\n    # 标题相关的参数（内容、链接、位置、文本样式）\n    title_opts=opts.TitleOpts(\n        title='2022年销售数据展示',\n        pos_left='2%',\n        title_textstyle_opts=opts.TextStyleOpts(\n            color='navy',\n            font_size=16,\n            font_family='苹方-简',\n            font_weight='bold'\n        )\n    ),\n    # 工具箱相关的参数\n    toolbox_opts=opts.ToolboxOpts(\n        orient='vertical',\n        pos_left='right'\n    )\n)\n# 加载绘图需要的JavaScript文件\nbar_chart.load_javascript()\n```\n\n在执行完上面的代码后，我们就可以通过调用`bar`对象的方法来完成对图表的渲染。如果直接使用`render`方法，那么绘制好的统计图表将保存到一个 HTML 文件中，打开该文件也能够看到绘制好的统计图表，而`render_notebook`方法则是将图表渲染到浏览器窗口中。\n\n```python\nbar_chart.render_notebook()\n```\n\n上面代码的运行效果如下图所示。值得一提的是，下图中的标题、图例、右侧的工具箱都是可以点击的，大家可以点击它们看看会有什么样的效果，ECharts 的魅力就在于它的交互效果，大家一定要试一试。\n\n<img class=\"lazy\" data-src=\"/res/pyecharts_bar_chart.png\" style=\"zoom:55%;\">\n\n接下来，我们也是通过一个官方示例，看看如何绘制饼图。\n\n```Python\nimport pyecharts.options as opts\nfrom pyecharts.charts import Pie\n\n# 准备饼图需要的数据\nx_data = [\"直接访问\", \"邮件营销\", \"联盟广告\", \"视频广告\", \"搜索引擎\"]\ny_data = [335, 310, 234, 135, 1548]\ndata = [(x, y) for x, y in zip(x_data, y_data)]\n\n# 创建饼图对象并设置初始化参数\npie_chart = Pie(init_opts=opts.InitOpts(width=\"800px\", height=\"400px\"))\n# 向饼图添加数据\npie_chart.add(\n    '', \n    data_pair=data,\n    radius=[\"50%\", \"75%\"],\n    label_opts=opts.LabelOpts(is_show=False),\n)\n# 设置全局配置项\npie_chart.set_global_opts(\n    # 配置图例相关的参数\n    legend_opts=opts.LegendOpts(\n        pos_left=\"legft\",\n        orient=\"vertical\"\n    )\n)\n# 设置数据系列配置参数\npie_chart.set_series_opts(\n    # 设置不显示工具提示\n    tooltip_opts=opts.TooltipOpts(is_show=False),\n    # 设置饼图标签的样式\n    label_opts=opts.LabelOpts(formatter=\"{b}({c}): {d}%\")\n)\npie_chart.load_javascript()\n```\n\n```python\npie_chart.render_notebook()\n```\n\n运行上面的代码，效果如下图所示。\n\n<img class=\"lazy\" data-src=\"/res/pyecharts_pie_chart.png\" style=\"zoom:50%;\">\n\n需要提醒大家注意的是，pyecharts 并不能直接使用 NumPy 的 ndarray 和 Pandas 的 Series、DataFrame 为其提供数据，它需要的是 Python 原生的数据类型。可能大家也注意到了，上面的代码中，我们使用的都是列表、元组这样的数据类型。\n\n最后，我们来看看如何绘制地图，绘制地图首先需要安装额外的依赖库来获取地图相关信息，命令如下所示。\n\n```Bash\npip install echarts-countries-pypkg echarts-china-provinces-pypkg echarts-china-cities-pypkg echarts-china-counties-pypkg\n```\n\n在 Jupyter 中，可以直接使用魔法指令进行安装，如下所示。\n\n```Bash\n%pip install echarts-countries-pypkg\n%pip install echarts-china-provinces-pypkg\n%pip install echarts-china-cities-pypkg\n%pip install echarts-china-counties-pypkg\n```\n\n> **说明**：上面的四个库分别包含了世界各国、中国省级行政区域、中国市级行政区域、中国区/县级行政区域的数据。\n\n然后，我们将全国各省的数据放在一个列表中，代码如下所示。\n\n```Python\ndata = [\n    ('广东', 594), ('浙江', 438), ('四川', 316), ('北京', 269), ('山东', 248),\n    ('江苏', 234), ('湖南', 196), ('福建', 166), ('河南', 153), ('辽宁', 152),\n    ('上海', 138), ('河北', 86), ('安徽', 79), ('湖北', 75), ('黑龙江', 70), \n    ('陕西', 63), ('吉林', 59), ('江西', 56), ('重庆', 46), ('贵州', 39),\n    ('山西', 37), ('云南', 33), ('广西', 24), ('天津', 22), ('新疆', 21),\n    ('海南', 18), ('内蒙古', 14), ('台湾', 11), ('甘肃', 7), ('广西壮族自治区', 4),\n    ('香港', 4), ('青海', 3), ('新疆维吾尔自治区', 3), ('内蒙古自治区', 3), ('宁夏', 1)\n]\n```\n\n接下来，我们使用 pyecharts 在地图上标记各省抖音大V人数。\n\n```Python\nimport pyecharts.options as opts\nfrom pyecharts.charts import Map\n\nmap_chart = Map(init_opts=opts.InitOpts(width='1000px', height='1000px'))\nmap_chart.add('', data, 'china', is_roam=False)\nmap_chart.load_javascript()\n```\n\n```python\nmap_chart.render_notebook()\n```\n\n代码的运行效果如下图所示，将鼠标置于地图上时，会高亮对应的省并看到相关的信息。\n\n<img class=\"lazy\" data-src=\"/res/pyecharts_map_chart.png\" style=\"zoom:55%;\">\n\n和 seaborn 一样，我们建议大家参考官方提供的示例来使用 pyecharts，我们可以在 pyecharts [官方网站](https://pyecharts.org/#/zh-cn/)的左侧导航栏中找到“图表类型”选项，下面每种类型的图表都有对应的官方示例，很多代码是可以直接使用的，我们需要做的就是将数据换成自己的数据。", "浅谈机器学习": "## 浅谈机器学习\n\n人工智能无疑是最近几年热度极高的一个词，从2016年谷歌 DeepMind 团队开发的 AlphaGo 围棋程序战胜人类顶尖棋手，到2017年基于 Transformer 架构的 NLP 模型发布，再到2023年 OpenAI 推出基于 GPT-4 的 ChatGPT 以及人工智能在医疗、自动驾驶等领域的深度应用，人工智能的热潮到达了自1956年达特茅斯会议以来前所未有的高度，可以说几乎每个人的生活都或多或少的受到了人工智能的影响。人工智能是计算机科学的一个重要分支，涉及计算机模拟智能行为的能力以及机器模仿人类智能行为的能力。研究人工智能的主要目标是开发出能够独立做出决策的系统，从而在医疗、工程、金融、教育、科研、公共服务等诸多领域帮助人类更高效的工作。人工智能的英文是“*artificial intelligence*”，因此通常被简称为 *AI*，人工智能包含了诸多的内容，我们经常说到的机器学习、深度学习、自然语言处理、计算机视觉、强化学习、数据挖掘、专家系统、工业机器人、自动驾驶等都属于人工智能的范畴。狭义的人工智能通常只能执行特定的任务，会聊天的人工智能通常不会开车，会开车的人工智能通常不会下棋；广义的人工智能需要具备通用智能，能够执行任何人类智能可以执行的任务；而更进一步的能够超越人类智能的人工智能，我们称之为超人工智能。\n\n本课程我们主要探讨人工智能中的机器学习（Machine Learning）。机器学习是人工智能的一个子领域，关注如何通过数据和算法来使计算机系统从经验中学习并进行预测或决策。简单的说，机器学习是实现人工智能的一种方法，有很多 AI 系统都是通过机器学习技术开发的。在一些特定场景，人们也用数据挖掘（Data Mining）这个词来指代机器学习，所谓的数据挖掘就是从数据中提取有用的信息和知识，分析和解释数据中的模式和趋势，最终达成预测未来趋势和行为的目标。当然，我们在提到这两个词的时候，表达的侧重点还是有所区别，数据挖掘主要关注知识发现，而机器学习侧重于构建和优化预测模型。当下，还有一个非常热门的概念和研究领域叫深度学习（Deep Learning），它是机器学习的一个子领域，特别侧重于使用多层神经网络（深度神经网络）来进行数据处理和学习。深度学习在处理图像、语音和自然语言等复杂数据时表现出色，能够自动学习数据的层次化特征，从而降低人工干预的需求。当然，深度学习模型通常比传统的机器学习模型更复杂，且需要更多的数据和计算资源。\n\n### 人工智能发展史\n\n治学先治史，我们简单回顾一下人工智能发展史上的里程碑事件，对于比较久远的历史，我们只简单提一些重要的时间节点，我们把重点放在最近几年的重大事件上。\n\n![](/res/01_AI_history.jpg)\n\n> **说明**：上图来自于[AMiner网站](https://www.aminer.cn/ai-history)，按照该网站的要求，在引用上图需要引用下面的论文。需要高清原图的，也可以在该网站上获取。\n>\n> Jie Tang, Jing Zhang, Limin Yao, Juanzi Li, Li Zhang, and Zhong Su. [ArnetMiner: Extraction and Mining of Academic Social Networks.](https://www.aminer.cn/pub/53e9a5afb7602d9702edacce/arnetminer-extraction-and-mining-of-academic-social-networks) In Proceedings of the Fourteenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (SIGKDD'2008). pp.990-998.\n\n1. 1950年，艾伦·图灵发表了一篇划时代的论文，文中预言了创造出具有智能的机器的可能性并提出了著名的图灵测试。图灵测试旨在通过计算机与人类进行对话，如果计算机能够使人类无法区分回答问题的是机器还是人类，就认为该计算机具有智能。\n2. 1956年，达特茅斯会议召开，该会议被认为是人工智能的诞生标志。会议上约翰·麦卡锡、马文·明斯基、克劳德·香农等人提出了人工智能的研究议程。达特茅斯会议的几位主要参与者也被后人誉为“人工智能七侠”，包括约翰·麦卡锡、马文·明斯基、阿伦·纽厄尔、赫伯特·西蒙、克劳德·香农、奥利弗·塞尔弗里奇和内森·罗切斯特，他们为人工智能的发展奠定了基础，其中有五个人获得了图灵奖。\n3. 1957年，弗兰克·罗森布拉特提出了感知机模型，这是最早的神经网络模型之一，用于解决二分类问题。\n4. 1958年，约翰·麦卡锡开发了 LISP 编程语言，这种语言特别适合于符号处理，成为早期 AI 研究的主要编程语言。\n5. 1980年，卡内基梅隆大学为 DEC 公司设计了一个名为 XCON 的专家系统，每年为公司省下约四千万美元的开销。由于专家系统在 DEC 公司取得了巨大的成功，全世界有很多公司都开始研发和应用专家系统。\n6. 1982年，物理学家约翰·霍普菲尔德证明一种新型的神经网络（后被称为“Hopfield网络”）能够用一种全新的方式学习和处理信息。\n7. 1986年，杰弗里·辛顿及其团队提出了反向传播算法，解决了训练深层神经网络的难题，神经网络相关的方法论再次受到关注。这一突破使得神经网络在各类任务中表现优异，成为机器学习的重要工具。\n8. 1997年，IBM 开发的国际象棋程序 Deep Blue 战胜了国际象棋世界冠军传奇棋手卡斯帕罗夫。\n9. 2011年，IBM 开发的能够使用自然语言来回答问题的人工智能系统在综艺节目《危险边缘》中打败了最高奖金得主布拉德·鲁特尔和连胜纪录保持者肯·詹宁斯，赢得了100万美元的奖金。\n10. 2012年，杰弗里·辛顿和他的学生在 ImageNet 竞赛中使用深度卷积神经网络（CNN）获得了巨大成功，标志着深度学习的兴起。随后，深度学习在图像识别、语音识别、自然语言处理等领域取得了显著进展。\n11. 2016年，谷歌 DeepMind开发的 AlphaGo 战胜了围棋世界冠军李世乭，展示了深度学习和蒙特卡洛树搜索技术的强大能力。\n12. 2017年，谷歌的研究人员提出了 Transformer 模型，彻底改变了自然语言处理领域。Transformer 模型基于自注意力机制，大大提高了序列建模的效率和效果。后面的 BERT、GPT 等模型都是基于 Transformer 架构。\n13. 2018年，OpenAI 开发的 AI 系统 OpenAI Five 在多人在线战术竞技游戏《Dota 2》中击败了半专业和专业玩家团队。\n14. 2019年，OpenAI 发布了 GPT-2，一个具有15亿参数的语言模型，展示了生成高质量自然语言文本的能力。同年，DeepMind 开发的 AlphaStar 在实时战略游戏《星际争霸II》中击败了人类顶级选手。\n15. 2020年，OpenAI 发布了 GPT-3，一个具有1750亿参数的语言模型，是当时最大的语言模型，GPT-3 在生成自然语言文本、翻译、编写代码等任务中表现出色，推动了自然语言处理和生成模型的进一步发展。同年，DeepMind 的 AlphaFold 2 在蛋白质结构预测的 CASP 竞赛中取得了突破性成果，预测精度达到了实验级别，这一成就被认为是生物学领域的重大突破，有望推动药物研发和生物学研究的进步。\n16. 2021年，OpenAI 发布了 DALL-E，这个模型能够根据文本描述生成图像，展示了生成模型在多模态学习和图像生成中的潜力。同年，OpenAI 发布了 Codex，一个可以理解和生成代码的语言模型，是 Copilot 的核心技术。\n17. 2023年，OpenAI 推出了基于 GPT-4 的 ChatGPT，可以进行更自然、更流畅的对话。随后，国内外行业巨头纷纷入局大模型，各种各样的大模型应用遍地开花。\n18. 2024年，OpenAI 在 DALL-E 的基础上推出了 Sora，一个可以通过文本描述生成视频的人工智能模型。几天后，一家名为 Cognition AI 的初创公司推出了第一位 AI 软件工程师 Devin。 \n\n人工智能自图灵测试和达特茅斯会议以来，经历了多次的高潮和低谷。目前，受益于由于计算机运算和存储能力的飞速提升，从前很多难以实现的技术都成为了现实，而人工智能也又一次被推到了风口浪尖。从早期的专家系统到今天的大模型，AI 技术还在不断的演进和突破。无论是 AlphaGo 攻占了人类智慧的最后高地，还是自动驾驶技术的逐渐普及，又或是人工智能内容生成（AIGC）的广泛应用，你可以清楚的感受到，人工智能正在改变我们的生活。\n\n### 什么是机器学习\n\n人类通过记忆和归纳这两种方式进行学习，通过记忆可以积累单个事实，使用归纳可以从旧的事实推导出新的事实。机器学习是赋予机器从数据中学习知识的能力，这个过程并不需要人类的帮助（给出明确的规则），也就是说机器学习关注的是从数据中学习一种模式（pattern），即便数据本身存在问题（噪声），这也是机器学习算法和传统算法最根本的区别。传统的算法需要计算机被告知如何从复杂系统中找到答案，算法利用计算机的运算能力去寻找最佳结果。传统算法最大的缺点就是人类必须首先知道最佳的解决方案是什么，而机器学习算法并不需要人类告诉模型最佳解决方案，取而代之的是，我们提供和问题相关的示例数据。\n\n我们可以把需要计算机解决的问题分为四类，分类的依据一方面是输入是精确的还是模糊的，另一方面是输出是最优的还是满意的，我们可以制作出如下所示的表格。可以看出，传统算法擅长解决的只有第一类问题，而机器学习比较擅长解决第三类和第四类问题；第二类问题基本属于 NP 问题（非确定性多项式时间问题），包括旅行经销商问题、图着色问题、集合覆盖问题等，我们通常会采用启发式算法（如模拟退火算法、遗传算法等）或近似算法来解决这类问题，当然机器学习算法也可以为这类问题提供满意解。\n\n<img class=\"lazy\" data-src=\"/res/01_four_kinds_problems.png\" style=\"zoom:45%;\">\n\n当然，机器学习算法并非完美到无懈可击。在通过数据训练模型时，我们需要使用预处理和清洗后的数据，如果数据本身质量非常糟糕，我们也很难训练出一个好的模型，这也是我们经常说到的 GIGO（Garbage In Garbage Out）。如果要使用机器学习，我们还得确定变量之间是否存在某种关系，机器学习无法处理不存在任何关系的数据。大多数时候，机器学习模型输出的是一系列的数字和指标，需要人类解读这些数字和指标并做出决策，判定模型的好坏并决定模型如何在实际的业务场景中落地。通常，我们用来训练模型的数据会存在噪声数据（noisy data），很多机器学习模型对噪声都非常敏感，如果不能处理好这些噪声数据，我们就不太容易得到好的模型。\n\n### 机器学习的应用领域\n\n即使对于机器学习这个概念不那么熟悉，但是机器学习的成果已经广泛渗透到了生产生活的各个领域，下面的这些场景对于你来说一定不陌生。\n\n**场景1**：搜索引擎会根据搜索和使用习惯，优化下一次搜索的结果。\n\n**场景2**：电商网站会根据你的访问历史自动推荐你可能感兴趣的商品。\n\n**场景3**：金融类产品会通过你最近的金融活动信息综合评定你的贷款申请。\n\n**场景4**：视频和直播平台会自动识别图片和视频中有没有不和谐的内容。\n\n**场景5**：智能家电和智能汽车会根据你的语音指令做出相应的动作。\n\n简单的总结一下，机器学习可以应用到但不限于以下领域：\n\n#### 1. **图像识别与计算机视觉**\n\n计算机视觉（Computer Vision）是机器学习的一个重要应用领域，涉及到使机器能够理解和处理图像和视频数据。\n\n- **人脸识别**：通过深度学习模型识别图片中的人脸，如安全监控、手机解锁等。\n- **自动驾驶**：自动驾驶汽车使用计算机视觉来识别道路标志、行人、其他车辆、交通信号灯等，从而实现自主导航。\n- **医疗影像分析**：机器学习应用于X光片、MRI扫描和CT图像的分析，帮助医生发现疾病（如癌症、脑卒中等）。\n- **图像分类与标注**：自动为图像打标签，比如在社交媒体平台上自动识别图片中的物品和场景。\n\n#### 2. **自然语言处理（NLP）**\n\n自然语言处理是机器学习在文本和语音数据上的应用，目的是让计算机能够理解和生成自然语言。\n\n- **语音识别**：如智能助手（Siri、Google Assistant）通过语音识别技术将语音转换为文本。\n- **机器翻译**：Google翻译、百度翻译等应用，使用机器学习技术进行语言之间的自动翻译。\n- **情感分析**：分析社交媒体帖子、评论等文本数据的情感倾向（积极、消极、中立）。\n- **文本生成**：自动生成文章或新闻（如GPT系列），为用户提供文章自动写作、智能客服等功能。\n- **聊天机器人**：例如客服机器人，通过自然语言处理技术与用户进行对话。\n\n#### 3. **推荐系统**\n\n推荐系统利用用户行为数据来预测用户可能感兴趣的物品或服务。\n\n- **电子商务**：如亚马逊、淘宝等平台根据用户的浏览和购买记录推荐商品。\n- **影视推荐**：如Netflix、YouTube等根据用户观看历史推荐电影、视频和节目。\n- **社交网络推荐**：例如，Facebook和Twitter根据用户的兴趣推荐朋友、帖子或广告。\n\n#### 4. **金融领域**\n\n机器学习在金融领域的应用主要体现在风险管理、预测和自动化交易等方面。\n\n- **信用评分**：银行和金融机构利用机器学习模型评估借款人的信用风险。\n- **欺诈检测**：通过分析交易模式，机器学习模型能够检测到潜在的欺诈行为（如信用卡欺诈、洗钱行为）。\n- **算法交易**：利用机器学习算法进行股票和其他金融资产的自动化交易，实时根据市场数据进行决策。\n- **投资组合管理**：使用机器学习模型进行资产配置和投资组合优化。\n\n#### 5. **医疗健康**\n\n机器学习在医疗行业中被广泛应用，尤其是在疾病预测、个性化治疗和医疗图像分析等方面。\n\n- **疾病预测**：使用机器学习算法预测疾病的发生概率，例如糖尿病、心脏病等。\n- **个性化医疗**：基于患者的历史健康数据、基因数据等，机器学习可以帮助提供个性化的治疗方案。\n- **药物发现**：通过大数据分析，机器学习能够加速新药的发现过程，例如通过预测化合物的药效来筛选潜在药物。\n- **健康监测**：利用可穿戴设备（如智能手表、健康追踪器）收集的数据，机器学习可以监测健康状况并预测疾病风险。\n\n#### 6. **智能交通与自动驾驶**\n\n自动驾驶技术和智能交通系统都依赖于机器学习技术。\n\n- **自动驾驶汽车**：自动驾驶依赖于机器学习来识别周围环境（如行人、交通信号、其他车辆等），并作出决策。\n- **交通预测**：根据交通流量、天气、节假日等因素，机器学习可以预测路况、交通拥堵情况，优化路线规划。\n- **车联网（V2X）**：车与车、车与基础设施之间的通信系统，利用机器学习进行数据分析和决策。\n\n#### 7. **智能家居与物联网**\n\n物联网（IoT）设备可以通过机器学习实现自动化和智能化操作。\n\n- **智能家居**：如智能音响（Amazon Echo、Google Home）和智能家电（智能空调、智能冰箱等），通过语音和传感器数据自动调整设备设置。\n- **环境监控**：基于机器学习的传感器数据分析，可以监测室内空气质量、温度等参数，并自动调节环境条件。\n- **智能安防**：监控摄像头通过人脸识别和行为识别技术，识别潜在的安全威胁。\n\n#### 8. **体育分析**\n\n机器学习也在体育领域得到应用，特别是在数据分析和比赛策略优化方面。\n\n- **运动员表现分析**：通过分析运动员的训练数据、比赛数据等，机器学习可以帮助教练制定个性化的训练计划。\n- **比赛结果预测**：通过历史数据和实时数据，机器学习可以预测比赛的结果、球队表现等。\n- **虚拟体育教练**：利用机器学习技术为运动员提供数据驱动的训练建议和反馈。\n\n#### 9. **制造与工业自动化**\n\n机器学习在工业和制造领域主要用于优化生产流程、提高效率和减少故障。\n\n- **预测性维护**：机器学习模型通过分析设备的历史数据，预测设备可能发生故障的时间，从而提前进行维护。\n- **质量控制**：通过对生产数据进行分析，机器学习可以自动识别生产过程中出现的质量问题。\n- **自动化生产**：机器学习可以帮助机器人根据环境和任务自动调节生产流程，提高生产效率和质量。\n\n### 机器学习的分类\n\n机器学习模型可以按照不同的标准进行分类，主要包括以下几种：\n\n#### 按照学习方式分类\n\n<img class=\"lazy\" data-src=\"/res/01_machine_learning_category.png\" style=\"zoom:32%;\">\n\n1. 监督学习（Supervised Learning）\n   - 回归（Regression）：用于预测连续值的模型，例如线性回归、Ridge 回归、Lasso 回归等。\n   - 分类（Classification）：用于预测离散类别的模型，例如逻辑回归、支持向量机、决策树、随机森林、k近邻、朴素贝叶斯等。\n\n2. 无监督学习（Unsupervised Learning）\n   - 聚类（Clustering）：用于将数据分组的模型，例如K均值聚类、层次聚类、DBSCAN 等。\n   - 降维（Dimensionality Reduction）：用于减少特征数量的模型，例如主成分分析（PCA）、线性判别分析（LDA）、t分布随机近邻嵌入（t-SNE）等。\n   - 关联规则学习（Association Rule Learning）：用于发现数据集中项之间关系的模型，例如 Apriori 算法、Eclat 算法等。\n\n3. 半监督学习（Semi-Supervised Learning）\n   - 结合了监督学习和无监督学习的方法，使用大量未标记的数据和少量标记的数据来构建模型。\n\n4. 强化学习（Reinforcement Learning）\n   - 基于奖励机制的学习方法，例如Q-Learning、深度Q网络（DQN）、策略梯度方法等。\n\n#### 按照模型的复杂度分类\n\n1. 线性模型（Linear Models）：如线性回归、逻辑回归。\n2. 非线性模型（Non-linear Models）：如带核函数的支持向量机（SVM with Kernel）、神经网络。\n\n#### 按照模型的结构分类\n\n1. 生成模型（Generative Models）：可以生成新的数据点，如朴素贝叶斯、隐马尔可夫模型（HMM）。\n2. 判别模型（Discriminative Models）：仅用于分类或回归，如逻辑回归、支持向量机。\n\n如果不理解上面的分类也没有关系，后续的课程中我们会覆盖到上面说到的很多算法，我们会通过讲解算法的原理、适用场景、优缺点和代码实现来帮助大家掌握这些算法并将其应用于解决实际问题。\n\n### 机器学习的步骤\n\n机器学习的实施步骤通常分为多个阶段，从问题定义、数据准备到模型部署和维护，每个步骤都非常重要，具体如下所示。\n\n1. **定义问题**。首先我们需要做业务理解，明确问题的性质和类型，这个会直接影响到后续的数据收集、特征工程、选择算法以及评估指标的确定。\n\n2. **数据收集**。机器学习模型的训练需要大量的数据，这些数据可能包含结构化数据（数据库、Excel 电子表格等）、非结构化数据（文本、图像、音频、视频等）、其他类型的数据集。\n\n3. **数据清洗**。数据清洗要确保数据质量高且适合模型训练，具体包括：缺失值和异常值处理、数据标准化和归一化、特殊编码、特征工程等。\n\n4. **数据划分**。为了评估机器学习模型的泛化能力，需要将数据划分为训练集和测试集。除此以外，还可能使用交叉验证的方式将数据分成多个子集，每个子集轮流作为验证集，从而对模型的超参数进行调整。\n\n5. **模型选择**。针对分类问题、回归问题、聚类问题、深度学习，我们选择的机器学习算法或模型是不一样的。\n\n6. **模型训练**。使用训练集对模型进行训练，使模型能够学习到输入特征与目标之间的关系。此外，每个机器学习算法都有超参数，这些参数需要根据数据和任务来调优。\n\n7. **模型评估**。模型评估主要的目标是确定模型在新数据（测试集）上的表现，确保模型没有出现过拟合（overfitting）或欠拟合（underfitting），如下图所示。欠拟合会导致模型的预测效果糟糕，而过拟合会导致模型缺乏泛化能力，即在测试集和新数据上表现欠佳。当然，为了提高模型的性能或适应性，可能还要通过正则化、集成学习、算法调整等方式进行调优。\n\n    <img class=\"lazy\" data-src=\"/res/01_overfitting_vs_underfitting.png\" style=\"zoom:85%;\">\n\n8. **模型部署**。当你对模型的性能感到满意时，可以将模型部署到生产环境中，进行实时预测或批量预测。我们通过监控模型在实际应用中的表现，确保其持续保持较好的预测效果。如果模型性能下降，可能需要重新训练或调整。\n\n9. **模型维护**。机器学习模型不是一成不变的，随着时间的推移，模型可能需要通过重新训练、增量学习等方式来维持其性能。\n\n> **说明**：如果对上面出现的概念不是很理解，可以先跳过去，我们会在遇到这些问题的时候展开讲解。\n\n### 第一次机器学习\n\n下面，我们用一个极为简单的例子带大家开启第一次机器学习之旅。当然，作为本课的第一个案例，我们并没有严格执行上面提到的机器学习的实施步骤，我们只想通过这个例子对机器学习有一个感性的认知，消除机器学习在很多人心中的“神秘感”。为了研究某城市某类消费者每月收入和每月网购支出的关系，我们收集到了50条样本数据（后面我们统称为历史数据），分别保存在两个列表中，如下所示。\n\n```python\n# 每月收入\nx = [9558, 8835, 9313, 14990, 5564, 11227, 11806, 10242, 11999, 11630,\n     6906, 13850, 7483, 8090, 9465, 9938, 11414, 3200, 10731, 19880,\n     15500, 10343, 11100, 10020, 7587, 6120, 5386, 12038, 13360, 10885,\n     17010, 9247, 13050, 6691, 7890, 9070, 16899, 8975, 8650, 9100,\n     10990, 9184, 4811, 14890, 11313, 12547, 8300, 12400, 9853, 12890]\n# 每月网购支出\ny = [3171, 2183, 3091, 5928, 182, 4373, 5297, 3788, 5282, 4166,\n     1674, 5045, 1617, 1707, 3096, 3407, 4674, 361, 3599, 6584,\n     6356, 3859, 4519, 3352, 1634, 1032, 1106, 4951, 5309, 3800,\n     5672, 2901, 5439, 1478, 1424, 2777, 5682, 2554, 2117, 2845,\n     3867, 2962,  882, 5435, 4174, 4948, 2376, 4987, 3329, 5002]\n```\n\n我们假设月收入和月网购支出都来自于正态总体，接下来我们可以通过计算皮尔逊相关系数来判定两组数据是否存在相关性，代码如下所示。如果对相关性和相关系数不理解，可以移步到我的[《数据思维和统计思维》](https://www.zhihu.com/column/c_1620074540456964096)专栏看看。\n\n```python\nimport numpy as np\n\nnp.corrcoef(x, y)\n```\n\n输出：\n\n```\narray([[1.        , 0.94862936],\n       [0.94862936, 1.        ]])\n```\n\n可以看出该城市该类人群的月收入和月网购支出之间存在强正相关性（相关系数为`0.94862936`）。当然，计算皮尔逊相关系数也可以使用 scipy 中的`stats.pearsonr`函数，该函数在计算相关系数的同时，还会给出统计检验的 P 值，我们可以根据 P 值来判定相关性是否显著，代码如下所示。\n\n```python \nfrom scipy import stats\n\nstats.pearsonr(x, y)\n```\n\n输出：\n\n```\nPearsonRResult(statistic=0.9486293572644154, pvalue=1.2349851929268588e-25)\n```\n\n上面，我们已经确认了月收入和月网购支出之间存在强相关性，那么一个很自然的想法就是通过某人的月收入来预测他的月网购支出，反过来当然也是可以的。为了做到这一点，可以充分利用我们收集到的历史数据，让计算机通过对数据的“学习”获得相应的知识，从而实现对未知状况的预测。我们可以将上述数据中的 $\\small{X}$ 称为自变量或特征（*feature*），将 $\\small{y}$ 称为因变量或目标值（*target*），**机器学习的关键就是要通过历史数据掌握如何实现从特征到目标值的映射**。\n\n#### kNN算法\n\n要通过月收入预测月网购支出，一个最朴素的想法就是将历史数据做成一个字典，月收入作为字典中的键，月网购支出作为对应的值，这样就可以通过查字典的方式通过收入查到支出，如下所示。\n\n```python\nsample_data = {key: value for key, value in zip(x, y)}\n```\n\n但是，输入的月收入未必在字典中对应的键，没有键就无法获取对应的值，这个时候我们可以找到跟输入的月收入最为接近的 k 个键，对这 k 个键对应的值求平均，用这个平均值作为对月网购支出的预测。这里的方法就是机器学习中最为简单的 k 最近邻算法（kNN），它是一种用于分类和回归的非参数统计方法，下面我们用原生 Python 代码来实现 kNN 算法，暂时不使用 NumPy、SciPy、Scikit-Learn 这样的三方库，主要帮助大家理解算法的原理。\n\n```python\nimport heapq\nimport statistics\n\n\ndef predict_by_knn(history_data, param_in, k=5):\n    \"\"\"用kNN算法做预测\n    :param history_data: 历史数据\n    :param param_in: 模型的输入\n    :param k: 邻居数量（默认值为5）\n    :return: 模型的输出（预测值）\n    \"\"\"\n    neighbors = heapq.nsmallest(k, history_data, key=lambda x: (x - param_in) ** 2)\n    return statistics.mean([history_data[neighbor] for neighbor in neighbors])\n```\n\n上面的代码中，我们用 Python 中`heapq`模块的`nsmallest`来找到历史数据中最小的 k 个元素，通过该函数的`key`参数，我们界定了最小指的是跟输入的参数`param_in`误差最小，由于误差有正数和负数，所以通常都需要求平方或者取绝对值。对于算术平均值的计算，我们使用了 Python 中`statistics`模块的`mean`函数，对`heapq`和`statistics`模块不熟悉的可以看看 Python 的官方文档，此处不再赘述。接下来，我们用上面的函数来预测月网购支出，代码如下所示。\n\n```python\nincomes = [1800, 3500, 5200, 6600, 13400, 17800, 20000, 30000]\nfor income in incomes:\n    print(f'月收入: {income:>5d}元, 月网购支出: {predict_by_knn(sample_data, income):>6.1f}元')\n```\n\n输出：\n\n```\n月收入:  1800元, 月网购支出:  712.6元\n月收入:  3500元, 月网购支出:  712.6元\n月收入:  5200元, 月网购支出:  936.0元\n月收入:  6600元, 月网购支出: 1487.0元\n月收入: 13400元, 月网购支出: 5148.6元\n月收入: 17800元, 月网购支出: 6044.4元\n月收入: 20000元, 月网购支出: 6044.4元\n月收入: 30000元, 月网购支出: 6044.4元\n```\n\n通过上面的输出，我们可以看出 kNN 算法的一个弊端，样本数据的缺失或者不均衡情况会导致预测结果非常糟糕。上面月收入`17800`元、`20000`元、`30000`元的网购支出预测值都是`6044.4`元，那是因为历史数据中月收入的最大值是`19880`，所以跟它们最近的 k 个邻居是完全相同的，所以从历史数据预测出的网购支出也是相同的；同理，月收入`1800`元跟月收入`3500`元的网购支出预测值也是相同的，因为跟`1800`元最近的 k 个邻居和跟`3500`元最近的 k 个邻居也是完全相同的。当然，上面我们给出的 kNN 算法实现还有其他的问题，大家应该不难发现`predict_by_knn`函数中，我们每次找寻最近的 k 个邻居时，都要将整个历史数据遍历一次，如果数据集体量非常大，那么这个地方就会产生很大的开销。\n\n#### 回归模型\n\n我们换一种思路来预测网购支出，我们将月收入和月网购支出分别作为横纵坐标来绘制散点图。既然网购支出跟月收入之间存在强正相关，这就意味着可以找一条直线来拟合这些历史数据点，我们把这条直线的方程 $\\small{y = aX + b}$ 称为回归方程或回归模型，如下图所示。\n\n<img class=\"lazy\" data-src=\"/res/01_regression_model.png\" style=\"zoom:50%;\">\n\n现在，我们的问题就变成了如何利用收集到的历史数据计算出回归模型的斜率 $\\small{a}$ 和截距 $\\small{b}$ 。为了评价回归模型的好坏，也就是我们计算出的斜率和截距是否理想，我们可以先定义评判标准，一个简单且直观的评判标准就是我们将月收入 $\\small{X}$ 带入回归模型，计算出月网购支出的预测值 $\\small{\\hat{y}}$ ，预测值 $\\small{\\hat{y}}$ 和真实值 $\\small{y}$ 之间的误差越小，说明我们的回归模型越理想。之前我们提到过，计算误差的地方通常都需要取绝对值或者求平方，我们可以用误差平方的均值来作为评判标准，通常称之为均方误差（MSE），如下所示。\n\n$$\nMSE = \\frac{1}{n}{\\sum_{i=1}^{n}(y_{i} - \\hat{y_{i}})^{2}}\n$$\n\n根据上面的公式，我们可以写出计算均方误差的函数，通常称之为损失函数。\n\n```python\nimport statistics\n\n\ndef get_loss(X_, y_, a_, b_):\n    \"\"\"损失函数\n    :param X_: 回归模型的自变量\n    :param y_: 回归模型的因变量\n    :param a_: 回归模型的斜率\n    :param b_: 回归模型的截距\n    :return: MSE（均方误差）\n    \"\"\"\n    y_hat = [a_ * x + b_ for x in X_]\n    return statistics.mean([(v1 - v2) ** 2 for v1, v2 in zip(y_, y_hat)])\n```\n\n能让 MSE 达到最小的 $\\small{a}$ 和 $\\small{b}$ ，我们称之为回归方程的最小二乘解，接下来的工作就是要找到这个最小二乘解。简单的说，我们要将可能的 $\\small{a}$ 和 $\\small{b}$ 带入损失函数，看看什么样的 $\\small{a}$ 和 $\\small{b}$ 能让损失函数取到最小值。如果对 $\\small{a}$ 和 $\\small{b}$ 的取值一无所知，我们可以通过不断产生随机数的方式来寻找 $\\small{a}$ 和 $\\small{b}$ ，这种方法称为蒙特卡洛模拟，通俗点说就是随机瞎蒙，代码如下所示。\n\n```python\nimport random\n\n# 先将最小损失定义为一个很大的值\nmin_loss, a, b = 1e12, 0, 0\n\nfor _ in range(100000):\n    # 通过产生随机数的方式获得斜率和截距\n    _a, _b = random.random(), random.random() * 4000 - 2000\n    # 带入损失函数计算回归模型的MSE\n    curr_loss = get_loss(x, y, _a, _b)\n    if curr_loss < min_loss:\n        # 找到更小的MSE就记为最小损失\n        min_loss = curr_loss\n        # 记录下当前最小损失对应的a和b\n        a, b = _a, _b\n\nprint(f'MSE = {min_loss}')\nprint(f'{a = }, {b = }')\n```\n\n上面的代码进行了`100000`次的模拟， $\\small{a}$ 和 $\\small{b}$ 的值在 $\\small{[-2000, 2000)}$ 范围随机选择的，下面是在我的电脑上跑出来的结果。大家可以把自己蒙特卡罗模拟的结果分享到评论区，看看谁的运气更好，找到了让误差更小的 $\\small{a}$ 和 $\\small{b}$ 。\n\n```\nMSE = 270690.1419424315\na = 0.4824040159203802, b = -1515.0162977046068\n```\n\n对于数学知识比较丰富的小伙伴，我们可以将回归模型带入损失函数，由于 $\\small{X}$ 和 $\\small{y}$ 是已知的历史数据，那么损失函数其实是一个关于 $\\small{a}$ 和 $\\small{b}$ 的二元函数，如下所示。\n\n$$\nMSE = f(a, b) = \\frac{1}{n}{\\sum_{i=1}^{n}(y_{i} - (ax_{i} + b))^{2}}\n$$\n\n根据微积分的极值定理，我们可以对 $\\small{f(a, b)}$ 求偏导数，并令其等于0，这样我们就可以计算让 $\\small{f(a, b)}$ 取到最小值的 $\\small{a}$ 和 $\\small{b}$ 分别是多少，即：\n\n$$\n\\frac{\\partial{f(a, b)}}{\\partial{a}} = -\\frac{2}{n}\\sum_{i=1}^{n}x_{i}(y_{i} - x_{i}a - b) = 0\n$$\n\n$$\n\\frac{\\partial{f(a, b)}}{\\partial{b}} = -\\frac{2}{n}\\sum_{i=1}^{n}(y_i - x_{i}a - b) = 0\n$$\n\n求解上面的方程组可以得到：\n\n$$\na = \\frac{\\sum(x_{i} - \\bar{x})(y_{i} - \\bar{y})}{\\sum(x_{i} - \\bar{x})^{2}}\n$$\n\n$$\nb = \\bar{y} - a\\bar{x}\n$$\n\n需要说明的是，如果回归模型本身比较复杂，不像线性模型 $\\small{y = aX + b}$ 这么简单，可能没有办法像上面那样直接求解方程，而是要通过其他的方式来找寻极值点，这个我们会在后续的内容中会为大家讲解。回到刚才的问题，我们可以通过上面的公式计算出 $\\small{a}$ 和 $\\small{b}$ 的值，为了运算方便，下面直接使用了 NumPy 中的函数，因为 NumPy 中的运算都是矢量化的，通常不需要我们自己写循环结构，对 NumPy 不熟悉的小伙伴，可以移步到我的[《基于Python的数据分析》](https://www.zhihu.com/column/c_1217746527315496960)专栏。\n\n```python\nimport numpy as np\n\nx_bar, y_bar = np.mean(x), np.mean(y)\na = np.dot((x - x_bar), (y - y_bar)) / np.sum((x - x_bar) ** 2)\nb = y_bar - a * x_bar\nprint(f'{a = }, {b = }')\n```\n\n输出：\n\n```\na = 0.482084452824066, b = -1515.2028590756745\n```\n\n事实上，NumPy 库中还有封装好的函数可以帮我们完成参数拟合，你可以使用`linalg`模块的`lstsq`函数来计算最小二乘解，也可以使用`polyfit`函数或`Polynomial`类型的`fit`方法来获得最小二乘解，代码如下所示。大家可以看看，跟上面求偏导数找极值点获得的结果是否相同。\n\n```python\na, b = np.polyfit(x, y, deg=1)\nprint(f'{a = }, {b = }')\n```\n\n或\n\n```python\nfrom numpy.polynomial import Polynomial\n\nb, a = Polynomial.fit(x, y, deg=1).convert().coef\nprint(f'{a = }, {b = }')\n```\n\n> **说明**：上面代码中的`deg`参数代表多项式的最高次项是几次项，`deg=1`说明我们使用的是线性回归模型。\n\n### 小结\n\n首先，希望本篇内容能对大家了解机器学习有那么一点点帮助；其次，希望通过本章向大家传达一个理念，自己手撕机器学习的代码比直接调用三方库弄出一个结果来其实更有意思，它会让你对算法原理、应用场景、利弊情况等都有一个更好的认知。\n\n", "k最近邻算法": "## k最近邻算法\n\nk 最近邻算法（kNN）是一种用于分类和回归的非参数统计方法，由美国统计学家伊芙琳·费克斯和小约瑟夫·霍奇斯于 1951 年提出。kNN 算法的原理是从历史数据中找到 $\\small{k}$ 个跟新输入的实例最邻近的实例，根据它们中的多数所属的类别来对新实例进行分类或者输出新实例的目标值，这种算法我们在前面已经为大家做了简单的展示。与主流的机器学习算法不同，k 最近邻算法没有显式的学习训练过程，它用的是“近朱者赤，近墨者黑”这样一种简单朴素的思想来实现分类或回归。k 最近邻算法有两个关键问题，第一个是 $\\small{k}$ 值如何选择，即用多少个最近邻来判定新实例所属的类别或确定其目标值；第二个是如何判定两个实例是近还是远，这里就涉及到度量距离的问题。\n\n### 距离的度量\n\n我们可以用距离（distance）来衡量特征空间中两个实例之间的相似度，常用的距离度量包括闵氏距离、马氏距离、余弦距离、编辑距离等。闵氏距离全称闵可夫斯基距离（Minkowski Distance），对于两个 $\\small{n}$ 维向量 $\\small{\\mathbf{x}=(x_{1}, x_{2}, \\cdots, x_{n})}$ 和 $\\small{\\mathbf{y}=(y_{1}, y_{2}, \\cdots, y_{n})}$ ，它们之间的距离可以定义为：\n\n$$\nd(\\mathbf{x}, \\mathbf{y}) = (\\sum_{i=1}^{n}{\\vert x_{i} - y_{i} \\rvert}^{p})^{\\frac{1}{p}}\n$$\n\n其中， $\\small{p \\ge 1}$ ，虽然 $\\small{p \\lt 1}$ 可以计算，但不再严格满足距离的定义，通常不被视为真正的距离。\n\n当 $\\small{p = 1}$ 时，闵氏距离即**曼哈顿距离**：\n\n$$\nd(\\mathbf{x}, \\mathbf{y}) = \\sum_{i=1}^{n} \\lvert x_{i} - y_{i} \\rvert\n$$\n\n当 $\\small{p = 2}$ 时，闵氏距离即**欧几里得距离**：\n\n$$\nd(\\mathbf{x}, \\mathbf{y}) = \\sqrt{\\sum_{i=1}^{n}(x_{i} - y_{i})^{2}}\n$$\n\n当 $\\small{p \\to \\infty}$ 时，闵氏距离即**切比雪夫距离**：\n\n$$\nd(\\mathbf{x}, \\mathbf{y}) = \\underset{i}{max}(\\lvert x_{i} - y_{i} \\rvert)\n$$\n\n其他的距离度量方式我们等用到的时候再为大家介绍。在使用 k 最近邻算法做分类时，我们的数据集通常都是数值型数据，此时直接使用欧几里得距离是一个不错的选择。\n\n<img class=\"lazy\" data-src=\"/res/02_distance_measurement.jpeg\" style=\"zoom:38%;\">\n\n### 数据集介绍\n\n接下来为大家隆重介绍一下我们后续会使用到的一个重要的数据集——鸢尾花数据集（iris dataset）。鸢尾花数据集是机器学习领域中最著名、最经典的数据集之一，由植物学家 *Edgar S. Anderson* 在加拿大魁北克加斯帕半岛采集，由英国统计学家 *Ronald A. Fisher* 于 1936 年在他的论文*《The Use of Multiple Measurements in Taxonomic Problems》*中首次引入，被广泛用于机器学习算法的入门和实验。\n\n<img class=\"lazy\" data-src=\"/res/02_iris_dataset.png\" style=\"zoom:38%;\">\n\n鸢尾花数据集共有 150 条样本，其中包含 3 种类型的鸢尾花，分别是山鸢尾（Iris setosa）、多彩鸢尾（Iris versicolor）和为吉尼亚鸢尾（Iris virginica），如上图所示，每种各有50条样本。样本数据包含了 4 个特征（features）和 1 个类别标签（class label），4 个特征分别是花萼长度（Sepal length）、花萼宽度（Sepal width）、花瓣长度（Petal length）、花瓣宽度（Petal width），都是以厘米为单位的正数，数据集中的类别标签有 0、1、2 三个值，对应上面提到的三种鸢尾花类型。\n\n#### 数据集的加载\n\n我们可以通过著名的 Python 机器学习库 scikit-learn 来加载这个数据集，scikit-learn 包含了各种分类、回归、聚类算法，同时还提供了多层感知机、支持向量机、随机森林等模型，覆盖了从数据预处理、特征工程到模型训练、模型评估和参数调优等各项功能，如下图所示。我们推荐大家使用这个库来完成机器学习中的各种操作，scikit-learn 的[官方网站](https://scikit-learn.org/stable/)上面还提供了用户指南、API 文档和案例等内容，有兴趣的读者可以自行访问。\n\n<img class=\"lazy\" data-src=\"/res/02_scikit-learn_introduction.png\">\n\n由于我们后续的课程基本都会用到这个库，大家可以先通过下面的命令安装这个库。\n\n```\npip install scikit-learn\n```\n\n如果你已经打开了 IPython 或 Jupyter 但尚未安装 scikit-learn，可以通过下面的魔法指令来安装这个库。\n\n```\n%pip install scikit-learn\n```\n\n在安装完成之后，我们可以通过下面的代码加载鸢尾花数据集并查看该数据集的介绍。\n\n```Python\nfrom sklearn.datasets import load_iris\n\n# 加载鸢尾花数据集\niris = load_iris()\n# 查看数据集的介绍\nprint(iris.DESCR)\n```\n\n接下来，我们可以获得数据集中的特征和标签，代码如下所示。\n\n```python\n# 特征（150行4列的二维数组，分别是花萼长、花萼宽、花瓣长、花瓣宽）\nX = iris.data\n# 标签（150个元素的一维数组，包含0、1、2三个值分别代表三种鸢尾花）\ny = iris.target\n```\n\n如果希望更直观的查看鸢尾花数据集，我们可以用上面获得的特征和标签来创建一个 DataFrame 对象，有兴趣的读者可以自己试一试。\n\n#### 数据集的划分\n\n通常，我们需要将原始数据划分成训练集和测试集，其中训练集是为了训练模型选择的数据，而测试集则是为了测试模型训练效果保留的数据。对于上面的鸢尾花数据集，我们可以选择 80% 的数据（120 条）作为训练集，保留 20% 的数据（30 条）作为测试集，下面的代码用 NumPy 实现了对数据集的划分。\n\n```python\n# 将特征和标签堆叠到同一个数组中\ndata = np.hstack((X, y.reshape(-1, 1)))\n# 通过随机乱序函数将原始数据打乱\nnp.random.shuffle(data)\n# 选择80%的数据作为训练集\ntrain_size = int(y.size * 0.8)\ntrain, test = data[:train_size], data[train_size:]\nX_train, y_train = train[:, :-1], train[:, -1]\nX_test, y_test = test[:, :-1], test[:, -1]\n```\n\n当然，更简便的划分数据集的方式是使用 scikit-learn 封装好的函数`train_test_split`，我们只需要传入特征和标签，指定好`train_size`或`test_size`就可以实现同样的操作。`train_test_split`函数返回一个四元组，四个元素分别代表用于训练的特征、用于训练的标签、用于测试的特征和用于测试的标签。\n\n```python\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=3)\n```\n\n> **说明**：上面代码中`train_test_split`函数的`random_state`参数可以理解成随机数的种子，如果你使用跟我相同的随机数种子，那么我们划分的训练集和测试集也是完全相同的。\n\n### kNN分类的实现\n\n下面我们先不用 scikit-learn 而是用基础的数据科学库 NumPy 和 SciPy 来实现 kNN 算法，这样做的目的是帮助大家更好的理解算法原理，在此基础上我们再感受 scikit-learn 的强大并明白其中类、函数、参数等为什么要如此设定。\n\n#### 基于NumPy的实现\n\nk 最近邻算法需要计算距离，下面我们先设计计算两个数据点欧式距离的函数，代码如下所示。\n\n```python\nimport numpy as np\n\n\ndef euclidean_distance(u, v):\n    \"\"\"计算两个n维向量的欧式距离\"\"\"\n    return np.sqrt(np.sum(np.abs(u - v) ** 2))\n```\n\n接下来，我们设计根据邻居的标签为新数据生成标签的函数。\n\n```python\nfrom scipy import stats\n\n\ndef make_label(X_train, y_train, X_one, k):\n    \"\"\"\n    根据历史数据中k个最近邻为新数据生成标签\n    :param X_train: 训练集中的特征\n    :param y_train: 训练集中的标签\n    :param X_one: 待预测的样本（新数据）特征\n    :param k: 邻居的数量\n    :return: 为待预测样本生成的标签（邻居标签的众数）\n    \"\"\"\n    # 计算x跟每个训练样本的距离\n    distes = [euclidean_distance(X_one, X_i) for X_i in X_train]\n    # 通过一次划分找到k个最小距离对应的索引并获取到相应的标签\n    labels = y_train[np.argpartition(distes, k - 1)[:k]]\n    # 获取标签的众数\n    return stats.mode(labels).mode\n```\n\n> **说明**：`np.partition`函数可以对数组进行一次划分，将 k 个比较小的元素放在数组的左边，n - k 个比较大的元素放在数组的右边，跟快速排序算法中做一次划分操作的效果是一样的。上面代码中的`np.argpartition`函数是把 k 个较小元素的索引放在数组的左边，这样经过`[:k]`切片操作和对`y_train`的花式索引运算，就可以获得 k 个跟新数据距离较小的样本对应的标签。最后，我们通过 scipy 库的 stats 模块的`mode`函数可以获得标签的众数，并用它作为我们给新数据预测的类别标签。\n\n在完成上述准备工作后，用 k 最近邻做预测的函数就呼之欲出了，代码如下所示。\n\n```python\ndef predict_by_knn(X_train, y_train, X_new, k=5):\n    \"\"\"\n    KNN算法\n    :param X_train: 训练集中的特征\n    :param y_train: 训练集中的标签\n    :param X_new: 待预测的样本构成的数组\n    :param k: 邻居的数量（默认值为5）\n    :return: 保存预测结果（标签）的数组\n    \"\"\"\n    return np.array([make_label(X_train, y_train, X, k) for X in X_new])\n```\n\n我们用上面准备好的鸢尾花数据的训练集和测试集来做实验，看看我们的`predict_by_knn`函数能否很好的运转起来。下面代码中的`y_pred`是我们通过函数预测的30条鸢尾花的类型，我们跟`y_test`做一个比较，就可以看到我们的预测效果。\n\n```python\ny_pred = predict_by_knn(X_train, y_train, X_test)\ny_pred == y_test\n```\n\n我这里的输出是：\n\n```\narray([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True, False,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True])\n```\n\n输出的结果中有一个`False`，这表示预测的标签跟真实的标签并不相同，是一个错误的预测结果，也就是说我们预测的准确率为 $\\small{\\frac{29}{30}}$ ，即`96.67%`。当然，如果你划分训练集和测试集时跟我指定的`random_state`参数不相同，这里得到的结果可能会跟我不同。\n\n#### 基于scikit-learn的实现\n\n使用 scikit-learn 来实现 kNN 算法就要简单许多了，我们基本上只需要做三个动作就可以得到想要的结果，代码如下所示。\n\n```python\nfrom sklearn.neighbors import KNeighborsClassifier\n\n# 创建模型\nmodel = KNeighborsClassifier()\n# 训练模型\nmodel.fit(X_train, y_train)\n# 预测结果\ny_pred = model.predict(X_test)\n```\n\n我们来看看输出的结果，是不是跟我们自己手撕的代码完全一致。\n\n```python\ny_pred == y_test\n```\n\n输出：\n\n```\narray([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True, False,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True])\n```\n\n当然，scikit-learn 库考虑到的东西肯定比我们自己手撕的代码丰富得多，例如我们想知道模型预测的准确率（accuracy），可以使用下面的函数。\n\n```python\nmodel.score(X_test, y_test)\n```\n\n输出：\n\n```\n0.9666666666666667\n```\n\n### 模型评估\n\n当然，评价一个分类器的预测效果是否良好，不能只简单的看一下准确率，因为在类别不平衡的情况下，准确率很可能会误导你的判断。例如，我们的测试数据中维吉尼亚鸢尾花的样本数量非常小，那么即便我们的模型根本无法判断维吉尼亚鸢尾花，模型也会表现出很高的准确率。所以，我们还要考察查准率（精确率）、查全率（召回率）、F1 分数等指标，而**混淆矩阵**则是用于详细展示分类模型性能的工具，适用于二分类和多分类任务，二分类问题的混淆矩阵如下所示。\n\n|      | **预测为正类（Positive）** | **预测为负类（Negative）** |\n| ---- | ------------------------- | ------------------------- |\n| **实际为正类（Positive）** | True Positive（TP） | False Negative（FN） |\n| **实际为负类（Negative）** | False Positive（FP） | True Negative（TN） |\n\n我们举一个例子来说明如何使用混淆矩阵并计算出分类模型的评估指标。假设某种医学检测系统的目标预测是否患有某种疾病，类别“正类”表示“患病”，类别“负类”表示“未患病”，1000个样本的测试结果如下所示。\n\n|      | **预测为患病** | **预测为未患病** |\n| ---- | -------------- | ---------------- |\n| **实际为患病** | 80（TP） | 20（FN） |\n| **实际为未患病** | 30（FP） | 870（TN） |\n\n1. **准确率**（Accuracy）。\n\n$$\n\\text{Accuracy} = \\frac{\\text{TP} + \\text{TN}}{\\text{TP} + \\text{FP} + \\text{FN} + \\text{TN}}\n$$\n\n上面的例子，模型预测的准确率为： $\\frac{80 + 870}{80 + 30 + 20 + 870} = \\frac{950}{1000} = 0.95$ 。\n\n2. **精确率**（Precesion）。精确率用于衡量在所有被预测为正类的样本中，实际上属于正类的比例，通常也被称为查准率。\n\n$$\n\\text{Precesion} = \\frac{\\text{TP}}{\\text{TP} + \\text{FP}}\n$$\n\n上面的例子，模型预测的精确率为： $\\frac{80}{80 + 30} = \\frac{80}{110} = 0.73$ 。\n\n3. **召回率**（Recall）。召回率用于衡量在所有实际为正类的样本中，被模型正确预测为正类的比例，通常也被称为查全率或真正例率（True Positive Rate）。\n$$\n\\text{Recall} = \\frac{\\text{TP}}{\\text{TP} + \\text{FN}}\n$$\n\n上面的例子，模型预测的召回率为： $\\frac{80}{80 + 20} = \\frac{80}{100} = 0.8$ 。\n\n4. **F1 分数**（F1 Score）。F1 分数是精确率和召回率的调和平均数，它在精确率和召回率之间寻求一个平衡，尤其适用于在两者之间有权衡的情况。\n  \n$$\n\\text{F1 Score} = \\frac{2}{\\frac{1}{\\text{Precision}} + \\frac{1}{\\text{Recall}}} = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precesion} + \\text{Recall}}\n$$\n\n上面的例子，模型预测的F1 分数为： $2 \\times \\frac{0.7273 * 0.8}{0.7273 + 0.8} = 0.76$ 。\n\n5. **特异度**（Specificity）和**假正例率**（False Positive Rate，简称 FPR）。特异度用于衡量的是在所有实际为负类的样本中，被模型正确预测为负类的比例，类似于召回率，只不过针对的是负类样本。\n\n$$\n\\text{Specificity} = \\frac{\\text{TN}}{\\text{TN} + \\text{FP}} \\\\\\\\\n\\text{FPR} = 1 - \\text{Specificity}\n$$\n\n上面的例子，模型预测的特异度为： $\\frac{870}{870 + 30} = \\frac{870}{900} = 0.97$ 。\n\n6. **ROC** 和 **AUC**。\n\n    - **ROC**（Receiver Operating Characteristic Curve）绘制了召回率与假正例率的关系，如下图所示。\n\n        <img class=\"lazy\" data-src=\"/res/02_ROC_curve.png\" style=\"zoom:38%;\">\n\n    - **AUC**（Area Under the Curve）是 ROC 曲线下的面积，衡量模型区分正类和负类的能力。AUC 值的范围是 $\\small[0, 1]$ ，值越接近 1，表示模型区分正负类的能力越强。0.5 < AUC < 1，说明我们的模型优于随机猜测，只要这个分类器（模型）妥善设置阈值的话，就有预测价值。AUC = 0.5，说明我们的模型跟随机猜测一样，模型没有预测价值。AUC < 0.5，模型比随机猜测还差，但只要总能反向预测，它的实际效果就优于随机猜测。\n\n对于多分类问题，混淆矩阵的行数和列数都等于类别数，混淆矩阵是一个方阵，也就是说如果有 $\\small{n}$ 个类别，那么混淆矩阵就是一个 $\\small{n \\times n}$ 的方阵。根据上面我们得到的鸢尾花数据集的预测结果，我们先输出真实值和预测值，然后制作对应的混淆矩阵，如下所示。\n\n```python\nprint(y_test)\nprint(y_pred)\n```\n\n输出：\n\n```\n[0 0 0 0 0 2 1 0 2 1 1 0 1 1 2 0 1 2 2 0 2 2 2 1 0 2 2 1 1 1]\n[0 0 0 0 0 2 1 0 2 1 1 0 1 1 2 0 2 2 2 0 2 2 2 1 0 2 2 1 1 1]\n```\n\n|      | **预测为类别0（山鸢尾）** | **预测为类别1（多彩鸢尾）** | **预测为类别2（为吉尼亚鸢尾）** |\n| :---- | :---------------: | :---------------: | :---------------: |\n| **实际为类别0（山鸢尾）** | 10 | 0 | 0 |\n| **实际为类别1（多彩鸢尾）** | 0 | 9 | 1 |\n| **实际为类别2（吉尼亚鸢尾）** | 0 | 0 | 10 |\n\n\n我们可以用 scikit-learn 中的`confusion_matrix`和`classification_report`函数来输出混淆矩阵和评估报告，代码如下所示。\n\n```python\nfrom sklearn.metrics import classification_report, confusion_matrix\n\n# 输出分类模型混淆矩阵\nprint('混淆矩阵: ')\nprint(confusion_matrix(y_test, y_pred))\n# 输出分类模型评估报告\nprint('评估报告: ')\nprint(classification_report(y_test, y_pred))\n```\n\n输出：\n\n```\n混淆矩阵: \n[[10  0  0]\n [ 0  9  1]\n [ 0  0 10]]\n评估报告: \n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        10\n           1       1.00      0.90      0.95        10\n           2       0.91      1.00      0.95        10\n\n    accuracy                           0.97        30\n   macro avg       0.97      0.97      0.97        30\nweighted avg       0.97      0.97      0.97        30\n```\n\n如果希望用可视化的方式输出混淆矩阵，可以使用如下所示的代码。\n\n```python\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import ConfusionMatrixDisplay\n\n# 创建混淆矩阵显示对象\ncm_display_obj = ConfusionMatrixDisplay(confusion_matrix(y_test, y_pred), display_labels=iris.target_names)\n# 绘制并显示混淆矩阵\ncm_display_obj.plot(cmap=plt.cm.Reds)\nplt.show()\n```\n\n> **说明**：其中的`iris.target_names`就是类别标签`0`、`1`、`2`对应的三种鸢尾花的英文名。\n\n<img class=\"lazy\" data-src=\"/res/02_confusion_matrix.png\" style=\"zoom:85%;\">\n\n对于二分类问题，如果想要绘制出 ROC 曲线并显示 AUC 值，可以使用如下所示的代码。\n\n```python\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.metrics import RocCurveDisplay\n\n# 手动构造一组真实值和对应的预测值\ny_test_ex = np.array([0, 0, 0, 1, 1, 0, 1, 1, 1, 0])\ny_pred_ex = np.array([1, 0, 0, 1, 1, 0, 1, 1, 0, 1])\n# 通过roc_curve函数计算出FPR（假正例率）和TPR（真正例率）\nfpr, tpr, _ = roc_curve(y_test_ex, y_pred_ex)\n# 通过auc函数计算出AUC值并通过RocCurveDisplay类绘制图形\nRocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=auc(fpr, tpr)).plot()\nplt.show()\n```\n\n<img class=\"lazy\" data-src=\"/res/02_ROC_plot.png\" style=\"zoom:92%;\">\n\n### 参数调优\n\n之前我们说过，kNN 算法有两个关键问题，一是距离的度量，二是 k 值的选择。我们使用 scikit-learn 的`KNeighborsClassifier`创建分类器模型时，可以对模型的超参数进行设置，这里有几个比较重要的参数：\n\n1. `n_neighbors`：近邻的数量，就是 kNN 算法中 k 的值。\n2. `weights`：可以选择`uniform`或`distance`，前者表示所有样本的权重相同，后者表示距离越近权重越高，默认值是`uniform`。当然，我们也可以通过传入自定义的函数来确定每个样本的权重。\n3. `algorithm`：有`auto`、`ball_tree`、`kd_tree`、`brute`四个选项，默认值为`auto`。其中`ball_tree`是一种树形结构，基于球体划分的方法将数据点分配到层次化的树结构中，在高维数据和稀疏数据场景下有较好的性能；`kd_tree`也是一种树形结构，通过选择一个维度将空间划分为若干个子区域再进行搜索，从而避免跟所有的邻居进行比较，对于低维度和空间分布均匀的数据，后者有较好的效果，在高维空间中会遇到的维度灾难问题；`auto`选项是根据输入数据的维度自动选择`ball_tree`或`kd_tree`；`brute`选项则是使用暴力搜索算法（穷举法），再处理小数据集时，它是一个简单且有效的选择。\n4. `leaf_size`：使用`ball_tree`或`kd_tree`算法时，该参数用于限制树结构叶子节点最大样本数量，默认值为`30`，该参数会影响树的构建和节点查找的性能。\n5. `p`：闵可夫斯基距离公式中的`p`，默认值为2，计算欧氏距离。\n\n我们可以使用**网格搜索**（Grid Search）和**交叉验证**（Cross Validation）的方式对模型的超参数进行调整，评估模型的泛化能力，提升模型的预测效果。网格搜索就是通过穷举法遍历给定的超参数空间，找到最优的超参数组合；交叉验证则是将训练集分成多个子集，通过在不同的训练集和验证集上进行多次训练和评估，对模型的预测效果进行综合评判。K-Fold交叉验证是最常用的交叉验证方法，通过将数据集划分为 K 个子集，每次选取其中一个子集作为验证集，剩下的 K-1 个子集作为训练集，对每个子集重复这个过程，完成 K 次训练和评估并将平均值作为模型的最终性能评估，如下图所示。\n\n![](/res/02_k-fold_cross_validation.png)\n\n下面的代码了 scikit-learn 库中的`GridSearchCV`来做网格搜索和交叉验证，通过这种方式找到针对鸢尾花数据集实施 kNN 算法的最优参数。\n\n```python\nfrom sklearn.model_selection import GridSearchCV\n\n# 网格搜索交叉验证\ngs = GridSearchCV(\n    estimator=KNeighborsClassifier(),\n    param_grid={\n        'n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15],\n        'weights': ['uniform', 'distance'],\n        'p': [1, 2]\n    },\n    cv=5\n)\ngs.fit(X_train, y_train)\n```\n\n可以通过下面的代码获得最优参数及其评分。\n\n```python\nprint('最优参数:', gs.best_params_)\nprint('评分:', gs.best_score_)\n```\n\n输出：\n\n```\n最优参数: {'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}\n评分: 0.9666666666666666\n```\n\n如果需要使用训练好的最优模型进行预测，可以按照如下所示的代码进行操作。\n\n```python\ngs.predict(X_test)\n```\n\n### kNN回归\n\nkNN 算法通常用于解决分类问题，当然它也可以用于解决回归问题，其基本思想也是通过找出跟新实例最近的 k 个邻居，然后根据这 k 个邻居的标签（在回归问题中我们通常称之为目标值）来预测新实例的目标值。由于我们需要预测的不是类别标签而是一个数值，所以通常会使用平均或加权平均的方式来处理 k 个邻居的目标值，从而获得对新实例目标值的预测。让我们回到上一课用月收入预测网购支出的那个例子，然后使用 scikit-learn 中的`KNeighborsRegressor`来构建回归模型，我们先做一些准备工作，代码如下所示。\n\n```python\n# 每月收入\nincomes = np.array([\n    9558, 8835, 9313, 14990, 5564, 11227, 11806, 10242, 11999, 11630,\n    6906, 13850, 7483, 8090, 9465, 9938, 11414, 3200, 10731, 19880,\n    15500, 10343, 11100, 10020, 7587, 6120, 5386, 12038, 13360, 10885,\n    17010, 9247, 13050, 6691, 7890, 9070, 16899, 8975, 8650, 9100,\n    10990, 9184, 4811, 14890, 11313, 12547, 8300, 12400, 9853, 12890\n])\n# 每月网购支出\noutcomes = np.array([\n    3171, 2183, 3091, 5928, 182, 4373, 5297, 3788, 5282, 4166,\n    1674, 5045, 1617, 1707, 3096, 3407, 4674, 361, 3599, 6584,\n    6356, 3859, 4519, 3352, 1634, 1032, 1106, 4951, 5309, 3800,\n    5672, 2901, 5439, 1478, 1424, 2777, 5682, 2554, 2117, 2845,\n    3867, 2962,  882, 5435, 4174, 4948, 2376, 4987, 3329, 5002\n])\nX = np.sort(incomes).reshape(-1, 1)  # 将收入排序后处理成二维数组\ny = outcomes[np.argsort(incomes)]    # 将网购支出按照收入进行排序\n```\n\n> **说明**：即便只有一个特征，我们也需要将自变量处理二维数组的形式，因为我们训练模型时使用的`fit`方法并不能接受一维数组作为它的第一个参数。这里提前对 X 和 y 排序是为了待会绘制散点图和折线图的时候根据 X 的值从小到大依次绘制。\n\n接下来，我们创建 kNN 回归模型。\n\n```python\nfrom sklearn.neighbors import KNeighborsRegressor\n\n# 创建模型\nmodel = KNeighborsRegressor()\n# 训练模型\nmodel.fit(X, y)\n# 预测结果\ny_pred = model.predict(X)\n```\n\n上面我们直接用所有的历史数据进行模型训练，然后通过绘制下面的图形来看看预测效果到底如何。\n\n```python\n# 原始数据散点图\nplt.scatter(X, y, color='navy')\n# 预测结果折线图\nplt.plot(X, y_pred, color='coral')\nplt.show()\n```\n\n<img class=\"lazy\" data-src=\"/res/02_knn_regression_plot.png\" style=\"zoom:85%;\">\n\nkNN 回归模型计算复杂度较高，而且对噪声数据非常敏感，在很多时候它可能并不是一个很好的选择。当然，如何评估一个回归模型的效果，这个问题我们留到后续的章节再为大家进行讲解。\n\n### 总结\n\nkNN 算法是一种简单但不失强大的机器学习算法，适用于小数据集上的分类和回归任务，它的优点是简单易懂，没有显示的训练过程，不依赖于对数据分布的假设，可以适应复杂的数据模式。当然，kNN 算法的缺点也非常明显，最大的问题在于计算效率，所以在数据集较大时可能并不是最好的选择。除此以外，kNN 算法对噪声非常敏感，同时预测结果依赖于 k 的取值和样本是否均衡（各个类别的样本数量是否大致相等），k 值过小可能导致过拟合，k值过大又可能导致欠拟合，而不均衡的样本可能会导致类别偏倚（Class Imbalance Bias），也就是说，如果大部分训练样本都属于类别 A，而类别 B 样本较少，那么在分类时，KNN 更容易将测试样本预测为类别 A。\n", "决策树和随机森林": "## 决策树和随机森林\n\n**决策树**（Decision Tree）是一种基于树结构的监督学习算法，可用于**分类**和**回归**任务。它通过将数据集逐步分割成不同的子集，直到满足某些停止条件，以此实现预测目标。我们生活中做决策的时候也会用到类似的方法，例如某位女生约见相亲对象的决策方法就可以绘制成如下所示的决策树。\n\n<img class=\"lazy\" data-src=\"/res/03_decision_tree_in_life.png\" style=\"zoom:38%;\">\n\n> **说明**：上图仅用于帮助大家理解什么是决策树，无不良引导，也不代表本人的爱情观和婚姻观。\n\n如果具备一定的编程常识，你会发现用决策树做预测的过程相当于是执行了一系列的`if...else...`结构；如果你对概率论的知识更熟悉，那么决策树的构建也可以视为计算以特征空间为前提的条件概率的过程。决策树中的结点可以分为两类：内部结点（上图中蓝色的结点）和叶结点（上图中红色和绿色的结点），其中内部结点对应样本特征属性测试（特征分割条件），而叶结点代表决策的结果（分类标签或回归目标值）。决策树可以用于解决分类问题和回归问题，本章我们仍然把重点放在分类问题上。\n\n### 决策树的构建\n\n#### 特征选择\n\n训练决策树模型有三个核心的步骤：特征选择、决策树构建和决策树剪枝。特征选择决定了使用哪些特征来做判断，在训练数据集中，每个样本的属性可能有很多个，不同属性的作用有大有小。特征选择的作用就是筛选出跟分类结果相关性较高的特征，也就是分类能力较强的特征，这样的特征要出现在决策树靠上的位置。如果一个特征能够使得分类后的分支结点尽可能属于同一类别，即该结点有着较高的**纯度**（purity），那么该特征对数据集而言就具备较强的分类能力。这里就产生了第一个问题，我们应该按照什么样的标准来选择分类能力强的特征？在决策树模型中，我们有三种方式来选择分类能力强的特征，分别是：**信息增益**（information gain）、**信息增益比**（gain ratio）和**基尼指数**（Gini index）。\n\n要讲清楚信息增益，我们得先介绍**信息熵**（information entropy）这个概念。1948年，克劳德·香农（*Claude Shannon*）在他的著名论文《通信的数学原理》中提出了“信息熵”的概念，它解决了信息的度量问题，量化出了信息的价值。“熵”原本是热力学领域的概念，它反映的是系统的混乱程度，熵越大，系统的混乱程度就越高。在信息论中，熵可以看作随机变量（数据集）不确定性的度量，熵越大，变量（数据）的不确定性就越大，那么要确定它所需要获取的信息量也就越大；熵越低，数据的纯度就越高，不确定性就越小。\n\n例如，甲、乙两人参加一个射击比赛，如果从历史成绩来看，甲的胜率是100%，那么我们很容易接受甲会获胜这个结果；如果从历史成绩来看，甲的胜率是50%，那么我们就难以确定到底谁会获胜。克劳德·香农提出可以用下面的公式来描述这种不确定性：\n\n$$\nH(D) = -\\sum_{i = 1}^{k} P(x_i)log_2P(x_i)\n$$\n\n其中， $\\small{D}$ 代表数据集， $\\small{k}$ 代表类别的总数， $\\small{P(x_i)}$ 表示数据集中第 $\\small{i}$ 类样本的比例（概率）。我们用 $\\small{x_1}$ 和 $\\small{x_2}$ 来分别表示甲获胜和乙获胜，很显然，当 $\\small{P(x_1)=0.5}$ ， $\\small{P(x_2)=0.5}$ 时， $\\small{H=1}$ ，不确定性最大；当 $\\small{P(x_1)=1}$ ， $\\small{P(x_2)=0}$ 时， $\\small{H=0}$ ，不确定性最小；当 $\\small{P(x_1)=0.8}$ ， $\\small{P(x_2)=0.2}$ 时， $\\small{H \\approx 0.72}$ 。\n\n很显然，知道的信息越多，随机变量（数据集）的不确定性就越小。这些信息，可以是直接针对我们想了解的随机事件的信息，也可以是和我们关心的随机事件相关的其他事件的信息。在数学上可以严格的证明这些相关的信息也能够降低或消除不确定性，为此我们定义**条件熵**，它表示在给定特征 $\\small{A}$ 的条件下，数据集 $\\small{D}$ 的不确定性。条件熵的公式如下所示：\n\n$$\nH(D \\vert A) = \\sum_{v \\in A}\\frac{\\lvert D_{v} \\rvert}{\\lvert D \\rvert}H(D_{v})\n$$\n\n上面的公式中，我们让 $\\small{v}$ 取得特征 $\\small{A}$ 所有可能的取值，其中 $\\small{D_{v}}$ 代表特征 $\\small{A}$ 取值为 $\\small{v}$ 的样本子集， $\\small{\\frac{\\lvert D_{v} \\rvert}{\\lvert D \\rvert}}$ 代表权重，即特征取值为 $\\small{v}$ 的样本比例。可以证明 $\\small{H(D) \\ge H(D \\vert A)}$ ，也就是说多了特征 $\\small{A}$ 的信息之后，数据集 $\\small{D}$ 的不确定性下降了。当然，还要注意等号成立的情况，也就是说增加了特征 $\\small{A}$ 的信息，但是 $\\small{D}$ 的不确定没有下降，也就是说我们获取的信息与要研究的内容没有关系。\n\n有了上面的铺垫，接下来我们就可以给出**信息增益**的定义，它是在得到特征 $\\small{A}$ 的信息后，数据集 $\\small{D}$ 的不确定性减少的程度。换句话说，信息增益是一种描述数据集确定性增加的量，特征的信息增益越大，特征的分类能力就越强，在给定该特征后数据集的确定性就越大。信息增益可以通过下面的数学公式直观的描述：\n\n$$\ng(D, A) = E(D) - E(D \\vert A)\n$$\n\n计算信息熵和信息增益的函数如下所示：\n\n```python\nimport numpy as np\n\n\ndef entropy(y):\n    \"\"\"\n    计算信息熵\n    :param y: 数据集的目标值\n    :return: 信息熵\n    \"\"\"\n    _, counts = np.unique(y, return_counts=True)\n    prob = counts / y.size\n    return -np.sum(prob * np.log2(prob))\n\n\ndef info_gain(x, y):\n    \"\"\"\n    计算信息增益\n    :param x: 给定的特征\n    :param y: 数据集的目标值\n    :return: 信息增益\n    \"\"\"\n    values, counts = np.unique(x, return_counts=True)\n    new_entropy = 0\n    for i, value in enumerate(values):\n        prob = counts[i] / x.size\n        new_entropy += prob * entropy(y[x == value])\n    return entropy(y) - new_entropy\n```\n\n经典决策树算法中的 ID3 算法就是基于信息增益进行特征选择的，我们仍然以鸢尾花数据集为例，将数据集拆分为训练集和测试集，在训练集上计算出原始的信息熵以及引入四个特征（花萼长度、花萼宽度、花瓣长度、花瓣宽度）后的信息增益分别是多少，代码如下所示。\n\n```python\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\n\niris = load_iris()\nX, y = iris.data, iris.target\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=3)\nprint(f'H(D)    = {entropy(y_train)}')\nprint(f'g(D,A0) = {info_gain(X_train[:, 0], y_train)}')\nprint(f'g(D,A1) = {info_gain(X_train[:, 1], y_train)}')\nprint(f'g(D,A2) = {info_gain(X_train[:, 2], y_train)}')\nprint(f'g(D,A3) = {info_gain(X_train[:, 3], y_train)}')\n```\n\n输出：\n\n```\nH(D)    = 1.584962500721156\ng(D,A0) = 0.9430813063736728\ng(D,A1) = 0.5692093930591595\ng(D,A2) = 1.4475439590905472\ng(D,A3) = 1.4420095891994646\n```\n\n> **注意**：如果在划分训练集和测试集的时候，`train_test_split`函数的`random_state`参数跟我上面的代码不同，那么这里的运算结果可能会存在差异。\n\n根据上面的输出我们可以得知，花瓣长度（对应上面的`A2`）这个特征信息增益最高，也就是说使用花瓣长度这个特征分类能力最强，分类后的数据集纯度最高。需要注意的是，当某个特征取值较多时，该特征的信息增益计算结果就会比较大，所以使用信息增益选择特征时，会偏向于取值较多的特征。为了解决这个问题，我们可以计算**信息增益比**，它的定义如下所示：\n\n$$\nR(D, A) = \\frac{g(D, A)}{E_{A}(D)}\n$$\n\n其中， $\\small{E_{A}(D) = -\\sum_{i=1}^{n}{\\frac{\\lvert D_{i} \\rvert}{\\lvert D \\rvert}log_{2}\\frac{\\lvert D_{i} \\rvert}{\\lvert D \\rvert}}}$ ， $\\small{n}$ 表示特征 $\\small{A}$ 的取值个数，简单的说 $\\small{E_{A}(D)}$ 就是特征 $\\small{A}$ 的信息熵，而信息增益比就是特征 $\\small{A}$ 的信息增益和特征 $\\small{A}$ 的信息熵的比值。我们用下面的函数来计算信息增益比，调用该函数可以输出四个特征对应的信息增益比。\n\n```python\ndef info_gain_ratio(x, y):\n    \"\"\"\n    计算信息增益比\n    :param x: 给定的特征\n    :param y: 数据集的目标值\n    :return: 信息增益比\n    \"\"\"\n    return info_gain(x, y) / entropy(x)\n\n\nprint(f'R(D,A0) = {info_gain_ratio(X_train[:, 0], y_train)}')\nprint(f'R(D,A1) = {info_gain_ratio(X_train[:, 1], y_train)}')\nprint(f'R(D,A2) = {info_gain_ratio(X_train[:, 2], y_train)}')\nprint(f'R(D,A3) = {info_gain_ratio(X_train[:, 3], y_train)}')\n```\n\n输出：\n\n```\nR(D,A0) = 0.19687406476459068\nR(D,A1) = 0.14319788821311977\nR(D,A2) = 0.28837763858461984\nR(D,A3) = 0.35550822529855447\n```\n\n> **注意**：如果在划分训练集和测试集的时候，`train_test_split`函数的`random_state`参数跟我上面的代码不同，那么这里的运算结果可能会存在差异。\n\n根据上面的输出我们可以得知，花瓣宽度（对应上面的`A3`）这个特征信息增益比最高，也就是说这个特征能够完成一次良好的数据划分，可以作为我们构建决策树的根结点。当然，构建决策树不可能只做一次划分，我们可以在划分后的数据集上继续计算信息增益比来选择新的划分特征，重复这一过程直到满足一定的条件就可以构造出一棵完整的决策树模型。在经典决策树算法中，C4.5 算法就是基于信息增益比进行特征选择的。\n\n除了上面讲到的信息增益和信息增益比，**基尼指数**也是非常好的特征选择方法，它可以用于评价数据集的纯度。基尼指数也叫**基尼不纯度**（Gini impurity），它的取值在0到1之间，数据集纯度越高，基尼指数越靠近0，数据集纯度越低，基尼指数越靠近1。如果数据集有 $\\small{n}$ 个类别，样本属于第 $\\small{k}$ 个类别的概率为 $\\small{p_{k}}$ ，那么数据集的基尼指数可以通过下面的公式进行计算：\n\n$$\nG(D) = 1 - \\sum_{k=1}^{n}{p_{k}}^{2}\n$$\n\n例如鸢尾花数据集中，三种鸢尾花的样本数量都是50条，那么整个数据集的基尼指数为：\n\n$$\nG(D) = 1 - [(\\frac{1}{3})^{2} + (\\frac{1}{3})^{2} + (\\frac{1}{3})^{2}] = \\frac{2}{3}\n$$\n\n如果三种鸢尾花的样本数量分别为100条、25条、25条，那么整个数据集的基尼指数为：\n\n$$\nG(D) = 1 - [(\\frac{2}{3})^{2} + (\\frac{1}{6})^{2} + (\\frac{1}{6})^{2}] = \\frac{1}{2}\n$$\n\n如果三种鸢尾花的样本数量分别为140条、5条、5条，那么整个数据集的基尼指数为：\n\n$$\nG(D) = 1 - [(\\frac{14}{15})^{2} + (\\frac{1}{30})^{2} + (\\frac{1}{30})^{2}] = \\frac{19}{150}\n$$\n\n可以看出，随着数据集纯度越来越高，基尼指数的值越来越小。如果数据集 $\\small{D}$ 根据特征 $\\small{A}$ 划分为 $\\small{k}$ 个部分，那么在给定特征 $\\small{A}$ 的前提条件下，数据集的基尼指数可以定义为：\n\n$$\nG(D, A) = \\sum_{i=1}^{k}\\frac{\\lvert D_{i} \\rvert}{\\lvert D \\rvert}G(D_{i})\n$$\n\n根据上面的公式，我们可以设计出如下所示的计算基尼指数的函数，大家可以对照上面的公式看看是否能够理解下面的代码，或者通过调用下面的函数看看鸢尾花数据集的哪个特征可以对原始数据集或者训练集做出最好的划分。经典决策树算法中的 CART 算法就是基于基尼指数进行特征选择的。\n\n```python\ndef gini_index(y):\n    \"\"\"\n    计算基尼指数\n    :param y: 数据集的目标值\n    :return: 基尼指数\n    \"\"\"\n    _, counts = np.unique(y, return_counts=True)\n    return 1 - np.sum((counts / y.size) ** 2)\n\n\ndef gini_with_feature(x, y):\n    \"\"\"\n    计算给定特征后的基尼指数\n    :param x: 给定的特征\n    :param y: 数据集的目标值\n    :return: 给定特征后的基尼指数\n    \"\"\"\n    values, counts = np.unique(x, return_counts=True)\n    gini = 0\n    for value in values:\n        prob = x[x == value].size / x.size\n        gini += prob * gini_index(y[x == value]) \n    return gini\n\n\nprint(f'G(D)    = {gini_index(y_train)}')\nprint(f'G(D,A0) = {gini_with_feature(X_train[:, 0], y_train)}')\nprint(f'G(D,A1) = {gini_with_feature(X_train[:, 1], y_train)}')\nprint(f'G(D,A2) = {gini_with_feature(X_train[:, 2], y_train)}')\nprint(f'G(D,A3) = {gini_with_feature(X_train[:, 3], y_train)}')\n```\n\n输出：\n\n```\nG(D,A0) = 0.29187830687830685\nG(D,A1) = 0.44222582972582963\nG(D,A2) = 0.06081349206349207\nG(D,A3) = 0.06249999999999998\n```\n\n#### 数据分裂\n\n构建决策树的过程是一个递归的过程，通过上面介绍的方法选定特征后就要进行数据分裂，简单的说就是根据该特征将数据集分成两个或多个子集（两个子集对应二叉树，多个子集对应多叉树），每个子集对应于特征的不同取值。接下来，我们对每个子集重复特征选择和数据分裂的动作，直到满足停止条件。停止条件对于递归过程非常重要，同时可以避免生成过于复杂的树结构。常见的停止条件包括：\n\n1. 树达到预设的深度。\n2. 当前结点的样本数量少于预设的阈值。\n3. 结点上所有样本属于同一个类别。\n4. 信息增益或Gini指数的变动低于某个阈值。\n\n> **说明**：如果大家有编写树结构的经验，上面的过程应该很容易理解。当然，对递归（recursion）、二叉树（binary tree）、多叉树（multi-way tree）不熟悉的小伙伴也可以随便找本讲数据结构的书来看看，相关的知识并不复杂，我们这里就不进行赘述了。\n\n在数据分裂的过程中，还有一个值得关注的问题就是特征连续值和缺失值的处理。对于连续值，可以通过遍历特征所有可能的取值，找到切分点 $\\small{x}$ 让切分后的子集在信息增益比或基尼指数方面达到最优，在数据分裂时以 $\\small{x}$ 将数据划分为 $\\small{D_{1}}$ 和 $\\small{D_{2}}$ 两个子集，其中 $\\small{D_{1}}$ 包含特征值小于等于 $\\small{x}$ 的样本， $\\small{D_{2}}$ 包含特征值大于 $\\small{x}$ 的样本。对于缺失值，C4.5 算法采用了加权分配的方式进行处理，当选择一个特征进行分裂时，该特征存在缺失值的样本会被分配到每个子集，但是不同的子集中该样本被赋予的权重是不一样的，这个权重会根据该特征在各个类别中的比例进行计算。CART 算法在处理缺失值时，通常会为每个特征创建一个默认分支。对于存在缺失值的样本，CART 算法会将它们引导到默认分支进行处理，在计算基尼指数时，CART 算法可以选择是否将缺失值的样本纳入计算。\n\n#### 树的剪枝\n\n对于一棵较为复杂的决策树进行剪枝是很有必要的，剪枝可以减少树结构的复杂性，同时也避免了过拟合的风险。常用的剪枝策略包括：\n\n1. **后剪枝**（post-pruning）。后剪枝顾名思义是在决策树构建完成后，通过评估和移除一些不必要的分支来简化树结构。后剪枝的过程通常从叶结点开始，至底向上评估每个结点，看看将其替换为叶结点（将该结点及其子树剪掉）是否能提高模型的性能（在验证集上的预测效果）。这种方式在减少过拟合风险的同时，还能够较好的保留对数据的拟合能力，但是计算量较大，而且如果没有合适的验证集，剪枝效果就会受到影响。\n2. **预剪枝**（pre-pruning）。预剪枝顾名思义是在构建决策树的过程中动态决定是否停止分裂某个结点。通过在分裂前评估当前结点是否应该继续分裂，可以避免生成过于复杂的树，上面我们提到了几种常用的停止条件。预剪枝策略在决策树构建阶段就减少了不必要的分裂，从而降低了模型的复杂性，但是可能存在欠拟合的风险，因为过早停止分裂可能会遗漏潜在的重要决策规则。\n\n### 实现决策树模型\n\n我们可以使用 scikit-learn 中`tree`模块的`DecisionTreeClassifier`和`DecisionTreeRegressor`来实现用于分类和回归的决策树，这里我们重点讨论用于解决分类问题的决策树模型，有兴趣的读者可以自行研究用于解决回归问题的决策树模型。\n\n```python\nfrom sklearn.tree import DecisionTreeClassifier\n\n# 创建模型\nmodel = DecisionTreeClassifier()\n# 训练模型\nmodel.fit(X_train, y_train)\n# 预测结果\ny_pred = model.predict(X_test)\n```\n\n下面，我们对比一下预测值和真实值并看看模型的评估报告。\n\n```python\nfrom sklearn.metrics import classification_report\n\nprint(y_test)\nprint(y_pred)\nprint(classification_report(y_test, y_pred))\n```\n\n输出：\n\n```\n[0 0 0 0 0 2 1 0 2 1 1 0 1 1 2 0 1 2 2 0 2 2 2 1 0 2 2 1 1 1]\n[0 0 0 0 0 2 1 0 2 1 1 0 1 1 2 0 1 2 2 0 2 2 2 1 0 2 2 1 2 1]\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        10\n           1       1.00      0.90      0.95        10\n           2       0.91      1.00      0.95        10\n\n    accuracy                           0.97        30\n   macro avg       0.97      0.97      0.97        30\nweighted avg       0.97      0.97      0.97        30\n```\n\n> **说明**：大家运行上面的代码看到的输出可能跟我这里并不相同，因为在创建`DecisionTreeClassifier`时有一个控制随机性的参数`random_state`，如果为该参数提供一个确定的整数值，就可以确保你的运行结果是可重复的。\n\n我们可以通过下面的代码来可视化决策树，相信可视化的方式会帮助大家对决策树模型有一个更好的理解。\n\n```python\nimport matplotlib.pyplot as plt\nfrom sklearn.tree import plot_tree\n\nplt.figure(figsize=(12, 10))\nplot_tree(\n    decision_tree=model,               # 决策树模型\n    feature_names=iris.feature_names,  # 特征的名称\n    class_names=iris.target_names,     # 标签的名称\n    filled=True                        # 用颜色填充\n)\nplt.show()\n```\n\n输出：\n\n<img class=\"lazy\" data-src=\"/res/03_decision_tree_plot_1.png\" style=\"zoom:45%;\">\n\n> **注意**：上图中树的根结点的基尼指数跟我们之前计算的数据集的基尼指数完全一致。\n\n我们调整一下`DecisionTreeClassifier`的参数重新创建决策树并对模型进行可视化。\n\n```python\n# 创建模型\nmodel = DecisionTreeClassifier(\n    criterion='entropy',\n    ccp_alpha=0.01,\n    \n)\n# 训练模型\nmodel.fit(X_train, y_train)\n# 可视化\nplt.figure(figsize=(12, 10))\nplot_tree(\n    decision_tree=model,               # 决策树模型\n    feature_names=iris.feature_names,  # 特征的名称\n    class_names=iris.target_names,     # 标签的名称\n    filled=True                        # 用颜色填充\n)\nplt.show()\n```\n\n输出：\n\n<img class=\"lazy\" data-src=\"/res/03_decision_tree_plot_2.png\" style=\"zoom:38%;\">\n\n> **注意**：上图中树的根结点的信息熵跟我们之前计算的数据集的信息熵完全一致。\n\n由此可见，创建`DecisionTreeClassifier`对象时参数不同，生成的决策树也会存在差异。`DecisionTreeClassifier`构造函数的参数就是决策树模型的超参数，其中有几个非常重要的超参数：\n\n1. `criterion`：特征选择（数据分裂质量评估）的标准，可以选择`'gini'`或`'entropy'`，前者代表基尼指数，也是默认值，后者代表信息增益。\n2. `max_depth`：树的最大深度，默认值为`None`，如果不设置该参数，会存在过拟合风险。\n3. `min_samples_split`：一个内部结点再次分裂所需的最小样本数，默认值为`2`。这个参数可以设置为整数表示最小样本数，也可以设置为浮点数，表示占总样本数的比例。\n4. `min_samples_leaf`：叶结点所需的最小样本数，默认值为`1`。将该参数设置为较大的值可以平滑模型，降低过拟合风险。这个参数也可以设置为整数或浮点数，道理同上。\n5. `max_features`：用于最佳分裂的特征数，默认值为`None`。这个参数可以设置为整数，表示选择固定数量的特征；可以设置为浮点数，表示选择特征的比例；可以设置为字符串，`'auto'`和`'sqrt'`表示将总的特征数量求平方根，用平方根的值作为选择特征的数量，`'log2'`表示将总的特征数量求对数，用对数值作为选择特征的数量。\n6. `class_weight`：指定类别的权重，用于处理类别不平衡问题，默认值为`None`。可以用字典的方式手动设置每个类别的权重，也可以使用`'balanced'`让模型自动调整。\n7. `splitter`：选择分裂结点的策略，默认值为`'best'`，表示最佳分裂，还有一个取值是`'random'`，表示随机分裂。\n8. `max_leaf_nodes`：限制叶结点的最大数量，可以防止树结构过于复杂。\n9. `min_impurity_decrease`：结点分裂所需的最小不纯度降低值，任何结点只有在不纯度减少超过此值时才会进行分裂。\n10. `ccp_alpha`：成本复杂度剪枝中的$\\small{\\alpha}$参数值。这个参数用于控制后剪枝中成本复杂度计算公式中$\\small{\\alpha}$的值。较小的$\\small{\\alpha}$值允许更复杂的树，而较大的$\\small{\\alpha}$值倾向于选择更简单的树。通过调整$\\small{\\alpha}$，可以找到一个最佳的复杂度和误差之间的平衡点。\n\n我们可以通过之前讲到的网格搜索和交叉验证的方式来对超参数进行调优，有兴趣的读者可以参考下面的代码。\n\n```python\nfrom sklearn.model_selection import GridSearchCV\n\ngs = GridSearchCV(\n    estimator=DecisionTreeClassifier(),\n    param_grid={\n        'criterion': ['gini', 'entropy'],\n        'max_depth': np.arange(5, 10),\n        'max_features': [None, 'sqrt', 'log2'],\n        'min_samples_leaf': np.arange(1, 11),\n        'max_leaf_nodes': np.arange(5, 15)\n    },\n    cv=5\n)\ngs.fit(X_train, y_train)\n```\n\n### 随机森林概述\n\n随机森林是基于决策树的集成学习算法，所谓集成学习就是通过组合多个模型的预测结果来提高整体模型的性能，其核心思想就是多个模型的组合往往比单个模型更有效，通过不同的模型捕捉到数据的不同特征，从而降低模型的过拟合风险（提升模型的泛化能力）。随机森林通过构建多个决策树并将它们的预测结果进行投票（分类）或平均（回归），来提高模型的准确性和鲁棒性，如下图所示。\n\n<img class=\"lazy\" data-src=\"/res/03_random_forest.png\" style=\"zoom:45%;\">\n\n随机森林的基本工作流程如下：\n\n1. Bootstrap 抽样：从原始训练数据集中随机抽取若干个样本（有放回抽样），形成多个不同的子集，每个子集用于训练一棵决策树。\n2. 构建决策树：对于每棵树在进行结点分裂时，不必考虑所有特征，而是随机选择一部分特征实现数据分裂。通过这种方式，随机森林增加了模型的多样性，减少了树之间的相关性。\n3. 集成学习：对于分类任务，随机森林通过投票的方式（即多数表决）来决定最终分类的结果；对于回归任务，通常可以对每棵树的预测结果求均值作为最终的预测结果。\n\n随机森林的主要优点体现在：\n\n1. 通过集成多个决策树，能够有效提高模型的准确性。\n2. 由于引入了随机性，随机森林通常比单棵决策树更不容易过拟合。\n3. 随机森林可以提供特征的重要性评分，帮助理解模型。\n4. 能够处理大规模数据集和高维数据。\n\n当然，因为要构建多个决策树，随机森林模型通常比较复杂，在训练模型时对计算资源、内存资源和时间成本的消耗都是更大的。我们可以通过 scikit-learn 库`ensemble`模块的`RandomForestClassifier`类来构造随机森林模型，这里我们仍然使用网格搜索交叉验证的方式来对超参数进行调优，代码如下所示。\n\n```python\nfrom sklearn.ensemble import RandomForestClassifier\n\ngs = GridSearchCV(\n    estimator=RandomForestClassifier(n_jobs=-1),\n    param_grid={\n        'n_estimators': [50, 100, 150],\n        'criterion': ['gini', 'entropy'],\n        'max_depth': np.arange(5, 10),\n        'max_features': ['sqrt', 'log2'],\n        'min_samples_leaf': np.arange(1, 11),\n        'max_leaf_nodes': np.arange(5, 15)\n    },\n    cv=5\n)\ngs.fit(X_train, y_train)\n```\n\n> **提示**：上面的代码可能会运行非常长的时间。\n\n随机森林模型的超参数很多跟决策树类似，需要说明的有以下几个超参数：\n\n1. `estimator`：森林中树的数量，简单的说就是用多少个决策树来构造森林。更多的树通常会带来更好的预测效果，但也会增加计算成本。\n2. `boostrap`：是否使用 Bootstrap 抽样，默认值为`True`，表示在构建每棵树时使用有放回抽样。\n3. `n_jobs`：用于并行运行的任务数，默认值为`None`，表示使用单个处理器核心；设置为`-1`，则可以使用所有可用的处理器核心。\n\n### 总结\n\n决策树是简单有效且易于理解的预测模型，适用于分类和回归任务，但容易发生过拟合且对噪声数据敏感；随机森林通过集成多个决策树提高了泛化能力且对噪声数据不敏感，适合解决复杂问题。在解决实际问题时，可以根据具体场景选择合适的模型，通过调节相关超参数来获得最佳效果，二者的对比如下表所示：\n\n| **属性**         | **决策树**           | **随机森林**       |\n| ---------------- | -------------------- | ------------------ |\n| **模型复杂度**   | 简单                 | 较复杂             |\n| **抗过拟合能力** | 差                   | 强                 |\n| **计算效率**     | 高                   | 较低               |\n| **结果稳定性**   | 易受单一数据变化影响 | 稳定               |\n| **适用场景**     | 数据较少、简单问题   | 数据较多、复杂问题 |\n", "朴素贝叶斯算法": "## 朴素贝叶斯算法\n\n我们继续为大家介绍解决分类任务的算法，本章介绍一种概率模型贝叶斯分类器。贝叶斯分类器是一类分类算法的总称，这类算法均以贝叶斯定理为基础，因而统称为贝叶斯分类器。在介绍贝叶斯定理之前，我们先讲一个故事：从 2015 年到 2020 年期间，某位李姓女士凭借自己对航班是否会延误的分析，购买了大约 900 次飞机延误险并获得延误赔偿，累计获得理赔金高达 300 多万元，真可谓“航班延误，发家致富”。当然，这套骚操作本身不是我们探讨的重点，我们的问题是：李女士是怎么决定要不要购买延误险的呢？航班延误最主要的原因就是天气（包括起飞地和降落地的天气）、机场（起飞机场和降落机场）和航司，由于李女士有过航空服务类工作的经历，有获得机场和航司相关数据的途径（天气数据相对更容易获取），集齐相关的数据再利用贝叶斯定理，她可以能够计算出当前航班延误的概率并决定是否购买延误险。接下来，李女士通过虚构不同身份购票并大量投保（每个身份购买 30 到 40 份延误险），这样一旦航班延误，她就可以向保险公司进行索赔。那么，我们要探讨的就是贝叶斯定理是如何利用现有数据计算出航班延误的概率。\n\n### 贝叶斯定理\n\n贝叶斯定理是概率论中的一个重要定理，它描述了如何从主观经验或已知事实出发，通过收集到的样本数据（证据）来更新对事件发生概率的认知（信念）。贝叶斯定理的数学表达式为：\n\n$$\nP(A \\vert B) = \\frac{P(B \\vert A)}{P(B)} \\cdot P(A)\n$$\n\n其中， $\\small{P(A)}$ 是事件 $\\small{A}$ 发生的**先验概率**，我们可以理解为已知事实或主观经验（**主观概率**）； $\\small{P(B \\vert A)}$ 是在事件 $\\small{A}$ 发生的条件下事件 $\\small{B}$ 发生的 条件概率，通常也称之为**似然性**（likelihood）， $\\small{P(B)}$ 是事件 $\\small{B}$ 发生的（全）概率，这两个概率可以通过我们收集到的样本数据（证据）获得； $\\small{P(A \\vert B)}$ 是在事件 $\\small{B}$ 发生的条件下事件 $\\small{A}$ 发生的条件概率，即收集到样本数据后对事件 $\\small{A}$ 发生概率的重新认知，称之为**后验概率**。贝叶斯定理告诉我们一个重要的事实：可以从已知的事实或主观经验出发，通过收集到的证据来更新我们对某个事件发生概率的认知，简单的说就是**可以通过已知的事实和收集的证据来推断出未知的真相**。\n\n回到上面李女士购买飞机延误险的例子，假设本次航班是从成都双流国际机场飞往北京首都国际机场，执飞的航空公司是四川航空，起飞地天气为雨天（小雨），温度为8°C，东北风2级，降落地天气为晴天，温度4°C，西北风2级。为了更简单的让大家理解贝叶斯定理，我们对这里的条件稍作简化，只保留天气中的降水信息，暂不考虑温度和风速等其他因素，对应到上面的贝叶斯定理有：\n\n$$\nP(延误 \\vert 起飞机场=双流,到达机场=首都,起飞天气=小雨,降落天气=晴天,执飞航司=川航) = \\\\\\\\\n\\frac{P(起飞机场=双流,到达机场=首都,起飞天气=小雨,降落天气=晴天,执飞航司=川航 \\vert 延误)}{P(起飞机场=双流,到达机场=首都,起飞天气=小雨,降落天气=晴天,执飞航司=川航)} \\cdot P(延误)\n$$\n\n上面公式等号左边就是李女士想知道的当前航班延误的概率，等号右边的部分其实就是历史数据和当前信息，计算这个概率的关键在于计算出似然性，即 $\\small{P(起飞机场=双流,到达机场=首都,起飞天气=小雨,降落天气=晴天,执飞航司=川航 \\vert 延误)}$ 到底是多少，那么这个条件概率又该如何计算呢？\n\n### 朴素贝叶斯\n\n朴素贝叶斯算法是基于贝叶斯定理和特征条件独立性假设的分类算法，因其简单高效而受到广泛应用。朴素贝叶斯算法的关键在于“朴素”二字，就是刚才我们说到特征条件独立性假设，条件独立性假设是说用于分类的特征在类确定的条件下都是独立的，该假设使得朴素贝叶斯的学习成为可能。\n\n假设我们有一个特征集合 $\\small{X = \\{x_1, x_2, \\ldots, x_n\\}}$ 和一个类别 $\\small{C}$ ，朴素贝叶斯算法假设：\n\n$$\nP(X \\vert C) = P(x_1 \\vert C) \\cdot P(x_2 \\vert C) \\cdot \\ldots \\cdot P(x_n \\vert C)\n$$\n\n这个假设大大简化了计算复杂性，使得我们可以只计算每个特征在给定类别下的概率，而不需要考虑特征之间的相互作用，对应到上面购买飞机延误险的例子，我们可以用下面的方式来计算似然性：\n\n$$\nP(起飞机场=双流,到达机场=首都,起飞天气=小雨,降落天气=晴天,执飞航司=川航 \\vert 延误) = \\\\\\\\\nP(起飞机场=双流 \\vert 延误) \\times P(到达机场=首都 \\vert 延误) \\times P(起飞天气=小雨 \\vert 延误) \\times P(降落天气=晴天 \\vert 延误) \\times P(执飞航司=川航 \\vert 延误)\n$$\n\n### 算法原理\n\n#### 训练阶段\n\n在训练阶段，朴素贝叶斯算法首先需要计算每个类别的先验概率和每个特征在各个类别下的条件概率。\n\n1. **计算先验概率**：\n\n$$\nP(C_{i}) = \\frac{n_{i}}{n}\n$$\n\n其中， $\\small{C_{i}}$ 表示类别， $\\small{n_{i}}$ 是类别 $\\small{C_{i}}$ 的样本数量， $\\small{n}$ 是总的样本容量。\n\n2. **计算条件概率**：\n\n$$\nP(x_{j} \\vert C_{i}) = \\frac{n_{i,j}}{n_{i}}\n$$\n\n其中， $\\small{n_{i,j}}$ 是在类别 $\\small{C_{i}}$ 中，特征 $\\small{x_{j}}$ 出现的次数。\n\n#### 预测阶段\n\n在预测阶段，给定一个待分类样本 $\\small{X}$ ，朴素贝叶斯算法通过以下步骤来计算其属于每个类别的后验概率：\n\n$$\nP(C_{i} \\vert X) = \\frac{P(X \\vert C_{i})}{P(X)} \\cdot P(C_{i})\n$$\n\n上面的公式中， $\\small{P(X)}$ 对应到每个类别都是一个常量，可以忽略掉它，再结合独立性假设有：\n\n$$\nP(C_{i} \\vert X) \\propto P(C_{i}) \\cdot P(x_1 \\vert C_{i}) \\cdot P(x_2 \\vert C_{i}) \\cdot \\ldots \\cdot P(x_n \\vert C_{i})\n$$\n\n这样，我们可以选择具有最高后验概率的类别作为预测结果。\n\n#### 代码实现\n\n我们还是以鸢尾花数据集为例，按照上面的讲解的原理，用 NumPy 来实现一个朴素贝叶斯分类器，我们还是从加载数据开始，代码如下所示。\n\n```python\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\n\niris = load_iris()\nX, y = iris.data, iris.target\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=3)\n```\n\n训练阶段我们要获得类别标签和对应的先验概率，此外还要计算出似然性，似然性的计算用到了上面提到的“朴素”假设，我们对鸢尾花连续的特征值进行了简单的离散化处理（大家先不考虑这种处理方式是否合理），代码如下所示。\n\n```python\nimport numpy as np\nimport pandas as pd\n\n\ndef naive_bayes_fit(X, y):\n    \"\"\"\n    :param X: 样本特征\n    :param Y: 样本标签\n    :returns: 二元组 - (先验概率, 似然性)\n    \"\"\"\n    # 计算先验概率\n    clazz_labels, clazz_counts = np.unique(y, return_counts=True)\n    prior_probs = pd.Series({k: v / y.size for k, v in zip(clazz_labels, clazz_counts)})\n    # 拷贝数组创建副本\n    X = np.copy(X)\n    # 保存似然性计算结果的字典\n    likelihoods = {}\n    for j in range(X.shape[1]):  # 对特征的循环\n        # 对特征进行等宽分箱（离散化处理）\n        X[:, j] = pd.cut(X[:, j], bins=5, labels=np.arange(1, 6))\n        for i in prior_probs.index:\n            # 按标签类别拆分数据并统计每个特征值出现的频次\n            x_prime = X[y == i, j]\n            x_values, x_counts = np.unique(x_prime, return_counts=True)\n            for k, value in enumerate(x_values):  # 对不同特征值的循环\n                # 计算似然性并保存在字典中（字典的键是一个三元组 - (标签, 特征序号, 特征值)）\n                likelihoods[(i, j, value)] = x_counts[k] / x_prime.size\n    return prior_probs, likelihoods\n```\n\n调用上面的函数，我们可以得到一个二元组，解包之后分别是类别标签 $\\small{C_{i}}$ 对应的先验概率和在类别 $\\small{C_{i}}$ 中，第 $\\small{j}$ 个特征取到某个值`value`（上面的代码中，我们用 pandas 的`cut`函数对特征值分箱，`value`的取值为`1` 到`5`）的似然性，前者是一个`Series`对象，后者是一个`dict`对象，如下所示：\n\n```python\np_ci, p_x_ci = naive_bayes_fit(X_train, y_train)\nprint('先验概率: ', p_ci, sep='\\n')\nprint('似然性: ', p_x_ci, sep='\\n')\n```\n\n输出：\n\n```\n先验概率: \n0    0.333333\n1    0.333333\n2    0.333333\ndtype: float64\n似然性: \n{(0, 0, 1.0): 0.525, (0, 0, 2.0): 0.45, (0, 0, 3.0): 0.025, (1, 0, 1.0): 0.05, (1, 0, 2.0): 0.375, (1, 0, 3.0): 0.425, (1, 0, 4.0): 0.15, (2, 0, 1.0): 0.025, (2, 0, 2.0): 0.025, (2, 0, 3.0): 0.45, (2, 0, 4.0): 0.3, (2, 0, 5.0): 0.2, (0, 1, 1.0): 0.025, (0, 1, 3.0): 0.325, (0, 1, 4.0): 0.45, (0, 1, 5.0): 0.2, (1, 1, 1.0): 0.175, (1, 1, 2.0): 0.325, (1, 1, 3.0): 0.475, (1, 1, 4.0): 0.025, (2, 1, 1.0): 0.025, (2, 1, 2.0): 0.35, (2, 1, 3.0): 0.525, (2, 1, 4.0): 0.05, (2, 1, 5.0): 0.05, (0, 2, 1.0): 1.0, (1, 2, 2.0): 0.025, (1, 2, 3.0): 0.525, (1, 2, 4.0): 0.45, (2, 2, 4.0): 0.525, (2, 2, 5.0): 0.475, (0, 3, 1.0): 0.975, (0, 3, 2.0): 0.025, (1, 3, 2.0): 0.125, (1, 3, 3.0): 0.75, (1, 3, 4.0): 0.125, (2, 3, 3.0): 0.05, (2, 3, 4.0): 0.525, (2, 3, 5.0): 0.425}\n```\n\n> **说明**：字典中的第一个元素`(0, 0, 1.0): 0.525`表示标签为`0`，第`0`个特征（花萼长度）取值为`1.0`的似然性为`0.525`；最后一个元素`(2, 3, 5.0): 0.425`表示标签为`2`，第`3`个特征（花瓣宽度）取值为`5.0`的似然性为`0.425`。\n\n预测阶段我们利用上面函数得到的先验概率和似然性计算后验概率，然后根据后验概率的最大值为样本赋予预测的类别标签。\n\n```python\ndef naive_bayes_predict(X, p_ci, p_x_ci):\n    \"\"\"\n    朴素贝叶斯分类器预测\n    :param X: 样本特征\n    :param p_ci: 先验概率\n    :param p_x_ci: 似然性\n    :return: 预测的标签\n    \"\"\"\n    # 对特征进行等宽分箱（离散化处理）\n    X = np.copy(X)\n    for j in range(X.shape[1]):\n        X[:, j] = pd.cut(X[:, j], bins=5, labels=np.arange(1, 6))\n    # 保存每个样本对应每个类别后验概率的二维数组\n    results = np.zeros((X.shape[0], p_ci.size))\n    clazz_labels = p_ci.index.values\n    for k in range(X.shape[0]):\n        for i, label in enumerate(clazz_labels):\n            # 获得先验概率（训练的结果）\n            prob = p_ci.loc[label]\n            # 计算获得特征数据后的后验概率\n            for j in range(X.shape[1]):\n                # 如果没有对应的似然性就取值为0\n                prob *= p_x_ci.get((i, j, X[k, j]), 0)\n            results[k, i] = prob\n    # 根据每个样本对应类别最大的概率选择预测标签\n    return clazz_labels[results.argmax(axis=1)]\n```\n\n将上面的函数作用于测试集进行预测，比较预测值和真实值，如下所示。\n\n```python\ny_pred = naive_bayes_predict(X_test, p_ci, p_x_ci)\ny_pred == y_test\n```\n\n输出：\n\n```\narray([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n       False,  True,  True,  True,  True,  True,  True,  True, False,\n        True,  True,  True])\n```\n\n上面两个函数希望能帮助大家理解朴素贝叶斯的工作原理，实际工作中我们还是推荐大家使用 scikit-learn 库的`navie_bayes`模块封装的类来创建朴素贝叶斯模型，该模块下有五个朴素贝叶斯算法的变体，每种变体针对不同类型的数据和特征分布，对应的五种朴素贝叶斯分类器分别是：`BernoulliNB`、`CategoricalNB`、`ComplementNB`、`GaussianNB`和`MultinomialNB`，它们之间的差别如下表所示：\n\n| 分类器          | 特征类型 | 主要假设                               |\n| --------------- | -------- | ------------------------------------ |\n| `BernoulliNB`   | 二元特征 | 特征服从 Bernoulli 分布                |\n| `CategoricalNB` | 类别特征 | 特征服从多项式分布，常用于处理类别数据   | \n| `ComplementNB`  | 计数特征 | 利用补集概率，常用于处理不平衡数据集    |\n| `GaussianNB`    | 连续特征 | 特征服从高斯分布                      |\n| `MultinomialNB` | 计数特征 | 特征服从多项式分布，常用于文本分类      |\n\n对于鸢尾花数据集，由于其特征是连续值，我们可以用`GaussianNB`来创建模型，代码如下所示。\n\n```python\nfrom sklearn.naive_bayes import GaussianNB\n\nmodel = GaussianNB()\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\n```\n\n我们看看模型评估的结果。\n\n```python\nfrom sklearn.metrics import classification_report\n\nprint(classification_report(y_test, y_pred))\n```\n\n输出：\n\n```\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        10\n           1       0.91      1.00      0.95        10\n           2       1.00      0.90      0.95        10\n\n    accuracy                           0.97        30\n   macro avg       0.97      0.97      0.97        30\nweighted avg       0.97      0.97      0.97        30\n```\n\n如果想看看朴素贝叶斯模型给每个样本对应到每个标签给出的概率值，可以使用下面的代码。\n\n```python\nmodel.predict_proba(X_test).round(2)\n```\n\n输出：\n\n```\narray([[1.  , 0.  , 0.  ],\n       [1.  , 0.  , 0.  ],\n       [1.  , 0.  , 0.  ],\n       [1.  , 0.  , 0.  ],\n       [1.  , 0.  , 0.  ],\n       [0.  , 0.  , 1.  ],\n       [0.  , 1.  , 0.  ],\n       [1.  , 0.  , 0.  ],\n       [0.  , 0.  , 1.  ],\n       [0.  , 0.98, 0.02],\n       [0.  , 1.  , 0.  ],\n       [1.  , 0.  , 0.  ],\n       [0.  , 1.  , 0.  ],\n       [0.  , 1.  , 0.  ],\n       [0.  , 0.  , 1.  ],\n       [1.  , 0.  , 0.  ],\n       [0.  , 0.93, 0.07],\n       [0.  , 0.  , 1.  ],\n       [0.  , 0.02, 0.98],\n       [1.  , 0.  , 0.  ],\n       [0.  , 0.22, 0.78],\n       [0.  , 0.  , 1.  ],\n       [0.  , 0.  , 1.  ],\n       [0.  , 0.92, 0.08],\n       [1.  , 0.  , 0.  ],\n       [0.  , 0.  , 1.  ],\n       [0.  , 0.54, 0.46],\n       [0.  , 1.  , 0.  ],\n       [0.  , 1.  , 0.  ],\n       [0.  , 0.81, 0.19]])\n```\n\n### 算法优缺点\n\n朴素贝叶斯算法的优缺包括：\n\n1. **逻辑简单容易实现，适合大规模数据集**。\n2. **运算开销较小**。预测需要用到的概率在训练阶段都已经准好了，当新数据来了之后，只需要获取对应的概率值并进行简单的运算就能获得预测的结果。\n3. **受噪声和无关属性影响小**。\n\n当然，由于做了“特征相互独立”这个假设，朴素贝叶斯算法的缺点也相当明显，因为在实际应用中，特征之间很难做到完全独立，尤其是维度很高的数据，如果特征之间的相关性较大，那么分类的效果就会变得很差。为了解决这个问题，在朴素贝叶斯算法的基础上又衍生出了一些新的方法，包括：半朴素贝叶斯（One Dependent Estimator）、AODE（Averaged One Dependent Estimator）、K 依赖朴素贝叶斯、朴素贝叶斯网络、高斯混合朴素贝叶斯等，有兴趣的读者可以自行了解。\n\n### 总结\n\n朴素贝叶斯算法在多个领域有广泛应用，以下是一些常见的应用场景：\n\n- **文本分类**：如垃圾邮件检测、情感分析等。\n- **推荐系统**：根据用户行为和喜好进行个性化推荐。\n- **医药诊断**：根据症状预测疾病。\n", "回归模型": "## 回归模型\n\n回归模型是机器学习和统计学中的一种基本模型，用于预测连续型输出变量。简单的说，给定一组输入变量（自变量）和对应的输出变量（因变量），回归模型旨在找到输入变量和输出变量之间的映射关系。回归模型的形式可能比较简单，但它确包含了机器学习中最主要的建模思想。通常，我们建立回归模型主要有两个目标：\n\n1. **描述数据之间的关系**。我们之前讲过**机器学习的关键就是要通过历史数据掌握如何从特征映射到目标值**，这个过程不需要我们事先设置任何的规则，而是让机器通过对历史数据的学习来获得。回归模型可以帮助我们通过模型表达输入和输出之间的关系。\n2. **对未知数据做出预测**。通过学习到的映射关系，模型可以对新的输入数据进行预测。\n\n回归模型的应用非常广泛，我们为大家举几个具体的例子：\n\n1. **零售行业**。全球最大的电商平台亚马逊（Amazon）会根据历史销量、商品属性（价格、折扣、品牌、类别等）、时间特征（季节、工作日、节假日等）、外部因素（天气、社媒等）等特征创建回归模型预测未来一段时间内不同商品的需求量。在促销活动期间，会使用多元回归结合交互项来分析促销对销量的影响。\n2. **汽车行业**。为了优化电池的充电策略，延长电池的使用寿命，为电车用户提供更准确的电量预警，特斯拉（Tesla）使用回归模型，通过电池充放电次数、环境温度、放电深度、电池物理参数等建立回归模型，预测电池的剩余寿命。\n3. **房地产行业**。美国最大的在线房地产平台 Zillow 曾经使用回归模型帮助用户评估房屋的价值，通过房屋的面积、房龄、地理位置、房屋类型、社区安全等级、学校评分等对房屋的市场价格做出预测。\n\n### 回归模型的分类\n\n根据模型的复杂程度和假设，回归模型可以分为以下几类：\n\n1. **线性回归**（Linear Regression）：假设输入变量和输出变量之间是线性关系。\n\n一元线性回归：建立一个因变量与单个自变量之间线性关系的模型。\n\n$$\ny = \\beta_0 + \\beta_1 x + \\varepsilon\n$$\n\n其中， $\\small{y}$ 是目标变量（因变量）， $\\small{x}$ 是输入变量（自变量）， $\\small{\\beta_{0}}$ 是截距，表示 $\\small{x=0}$ 时的预测值， $\\small{\\beta_{1}}$ 是回归系数（斜率），表示输入变量对输出变量影响的大小， $\\small{\\varepsilon}$ 是误差项，用于表示数据中的随机噪声或无法解释的部分。\n\n多元线性回归：建立一个因变量与多个自变量之间线性关系的模型。\n\n$$\ny = \\beta_{0} + \\beta_{1} x_{1} + \\beta_{2} x_{2} + \\cdots + \\beta_{n} x_{n} + \\varepsilon\n$$\n\n上面的公式也可以用向量的形式简化表示为：\n\n$$\ny = \\mathbf{x}^{T} \\mathbf{\\beta} + \\varepsilon\n$$\n\n其中， $\\small{\\mathbf{x} = [1, x_{1}, x_{2}, \\dots, x_{n}]^{T}}$ 是包含截距的输入向量， $\\small{\\mathbf{\\beta} = [\\beta_{0}, \\beta_{1}, \\beta_{2}, \\dots, \\beta_{n}]^{T}}$ 是模型参数（包括截距 $\\small{\\beta_{0}}$ 和回归系数 $\\small{\\beta_{1}, \\beta_{2}, \\cdots, \\beta_{n}}$ ）， $\\small{\\varepsilon}$ 是误差项。\n\n2. **多项式回归**（Polynomial Regression）：引入高阶特征，使模型能拟合更复杂的非线性关系，属于线性模型的扩展，因为因为它对参数 $\\small{\\beta}$ 的求解仍然是线性形式，如下面所示的二次关系：\n\n$$\ny = \\beta_{0} + \\beta_{1} x + \\beta_{2} x^{2} + \\varepsilon\n$$\n\n3. **非线性回归**（Nonlinear Regression）：非线性回归完全放弃了线性假设，模型形式可以是任意非线性函数。\n\n4. **岭回归**（Ridge Regression）、**套索回归**（Lasso Regression）、**弹性网络回归**（Elastic Net Regression）：在线性回归基础上加入正则化项，用于处理过拟合、多重共线性和特征筛选问题。\n\n5. **逻辑回归**（Logistic Regression）：逻辑回归虽然名字中带“回归”，但实际上是用于分类问题的模型。它通过 Sigmoid 函数将线性组合的输入值映射到区间 $\\small{(0, 1)}$ ，表示分类概率，适用于二分类问题；也可以扩展为 Softmax 回归，解决多分类问题。\n\n$$\nP(y=1 \\vert x) = \\frac{1}{1 + e^{-(\\beta_{0} + \\beta_{1} x_{1} + \\cdots + \\beta_{n} x_{n})}}\n$$\n\n### 回归系数的计算\n\n建立回归模型的关键是找到最佳的回归系数 $\\small{\\mathbf{\\beta}}$ ，所谓最佳回归系数是指让模型对数据的拟合效果达到最好的模型参数，即能够最小化模型的预测值 $\\small{\\hat{y_{i}}}$ 与实际观测值 $\\small{y_{i}}$ 之间差异的模型参数。为此，我们先定义如下所示的损失函数。\n\n$$\nL(\\mathbf{\\beta}) = \\sum_{i=1}^{m}(y_{i} - \\hat{y_{i}})^{2}\n$$\n\n其中， $\\small{m}$ 表示样本容量，代入回归模型，有：\n\n$$\nL(\\mathbf{\\beta}) = \\sum_{i=1}^{m}(y_{i} - \\mathbf{x}_{i}^{T}\\mathbf{\\beta})^{2}\n$$\n\n如果用矩阵形式表示，有：\n\n$$\nL(\\mathbf{\\beta}) = (\\mathbf{y} - \\mathbf{X\\beta})^{T}(\\mathbf{y} - \\mathbf{X\\beta})\n$$\n\n其中， $\\mathbf{y}$ 是目标值的向量，大小为 $\\small{m \\times 1}$， $\\mathbf{X}$ 是特征矩阵，大小为 $\\small{m \\times n}$， $\\small{\\mathbf{\\beta}}$ 是回归系数的向量，大小为 $\\small{n \\times 1}$。\n\n通过最小化损失函数 $\\small{L(\\mathbf{\\beta})}$ ，我们可以得到线性回归模型的解析解。对 $\\small{L(\\mathbf{\\beta})}$ 求导并令其为 0，有：\n\n$$\n\\frac{\\partial{L(\\mathbf{\\beta})}}{\\partial{\\mathbf{\\beta}}} = -2\\mathbf{X}^{T}(\\mathbf{y} - \\mathbf{X\\beta}) = 0\n$$\n\n整理后得到：\n\n$$\n\\mathbf{\\beta} = (\\mathbf{X}^{T}\\mathbf{X})^{-1}\\mathbf{X}^{T}\\mathbf{y}\n$$\n\n对于矩阵 $\\small{\\mathbf{X}^{T}\\mathbf{X}}$ 不满秩的情况，可以通过添加正则化项的方式使得矩阵可逆，如下所示，这个就是线性回归的解析解。\n\n$$\n\\mathbf{\\beta} = (\\mathbf{X}^{T}\\mathbf{X} + \\mathbf{\\lambda \\mit{I}})^{-1}\\mathbf{X}^{T}\\mathbf{y}\n$$\n\n> **说明**：如果你对这里提到的正则化不理解可以先放放，后面我们再来讨论这个问题。\n\n上述方法适用于小规模数据集，当数据体量不大（样本和特征数量较少）时，计算效率是没有问题的。对于大规模数据集或更为复杂的优化问题，我们可以使用**梯度下降法**，通过迭代更新参数来逐步逼近最优解。梯度下降法的目标也是最小化损失函数，该方法通过计算梯度方向进行参数更新。梯度是一个向量，包含了目标函数在各个参数方向上的偏导数。对于上面的损失函数 $\\small{L(\\mathbf{\\beta})}$ ，梯度可以表示为：\n\n$$\n\\nabla L(\\mathbf{\\beta}) = \\left[ \\frac{\\partial{L}}{\\partial{\\beta_{1}}},  \\frac{\\partial{L}}{\\partial{\\beta_{2}}}, \\cdots,  \\frac{\\partial{L}}{\\partial{\\beta_{n}}} \\right]\n$$\n\n梯度下降法通过以下更新规则来更新参数 $\\small{\\mathbf{\\beta}}$ ：\n\n$$\n\\mathbf{\\beta}^{\\prime} = \\mathbf{\\beta} - \\alpha \\nabla L(\\mathbf{\\beta}) \\\\\\\\\n\\mathbf{\\beta} = \\mathbf{\\beta^{\\prime}}\n$$\n\n其中， $\\small{\\alpha}$ 是学习率（step size），通常是一个较小的正数，用于控制每次更新的幅度。如果学习率 $\\small{\\alpha}$ 选择得当，梯度下降法将收敛到目标函数的局部最小值。如果学习率过大，可能导致震荡不收敛；如果学习率过小，则收敛的速度缓慢，需要更多次的迭代。\n\n### 新数据集介绍\n\n之前介绍的鸢尾花数据集并不适合讲解回归模型，为此我们引入另一个经典的汽车 MPG 数据集。汽车 MPG 数据集最初由美国汽车协会提供，我们可以通过该数据集预测车辆的燃油效率，即每加仑燃料行驶的里程（Miles Per Gallon, MPG）。需要注意的是，scikit-learn 库没有内置该数据集，我们可以直接从 [UCI 机器学习仓库](https://archive.ics.uci.edu/dataset/9/auto+mpg) 网站下载数据集，也可以通过执行下面的代码联网加载该数据集。\n\n```python\nimport ssl\nimport pandas as pd\n\nssl._create_default_https_context = ssl._create_unverified_context\ndf = pd.read_csv('https://archive.ics.uci.edu/static/public/9/data.csv')\ndf.info()\n```\n\n输出：\n\n```\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 398 entries, 0 to 397\nData columns (total 9 columns):\n #   Column        Non-Null Count  Dtype  \n---  ------        --------------  -----  \n 0   car_name      398 non-null    object \n 1   cylinders     398 non-null    int64  \n 2   displacement  398 non-null    float64\n 3   horsepower    392 non-null    float64\n 4   weight        398 non-null    int64  \n 5   acceleration  398 non-null    float64\n 6   model_year    398 non-null    int64  \n 7   origin        398 non-null    int64  \n 8   mpg           398 non-null    float64\ndtypes: float64(4), int64(4), object(1)\nmemory usage: 28.1+ KB\n```\n\n根据上面的输出，我们简单介绍下数据集的九个属性，前面八个都是输入变量（第一个暂不使用），最后一个是输出变量，具体如下表所示。\n\n| 属性名称       | 描述                                                         |\n| -------------- | ------------------------------------------------------------ |\n| *car_name*     | 汽车的名称，字符串，这个属性对建模暂时没有帮助               |\n| *cylinders*    | 气缸数量，整数                                               |\n| *displacement* | 发动机排量（立方英寸），浮点数                               |\n| *horsepower*   | 马力，浮点数，有空值需要提前处理                             |\n| *weight*       | 汽车重量（磅），整数                                         |\n| *acceleration* | 加速（0 - 60 mph所需时间），浮点数                           |\n| *model_year*   | 模型年份（1970年 - 1982年），这里用的是两位的年份            |\n| *origin*       | 汽车来源（1 = 美国, 2 = 欧洲, 3 = 日本），这里的`1`、`2`、`3`应该视为三种类别而不是整数 |\n| *mpg*          | 车辆的燃油效率，每加仑行驶的里程（目标变量）                 |\n\n我们先删除`car_name`这个暂时用不上的属性，然后使用`DataFrame`对象的`corr`方法检查输入变量（特征）与输出变量（目标值）之间是否存在相关性。通过相关性分析我们可以选择相关性强的特征，剔除掉那些与目标值相关性较弱的特征，这有助于减少模型的复杂性和过拟合的风险。在多元回归中，多重共线性（即输入变量之间高度相关）可能会影响回归系数的估计，导致模型不稳定。可以通过计算特征之间的相关性和方差膨胀因子（VIF）等来检测共线性问题。\n\n```python\n# 删除指定的列\ndf.drop(columns=['car_name'], inplace=True)\n# 计算相关系数矩阵\ndf.corr()\n```\n\n> **说明**：`DataFrame`对象的`corr`方法默认计算皮尔逊相关系数，皮尔逊相关系数适合来自于正态总体的连续值，对于等级数据之间相关性的判定，可以通过修改`method`参数为`spearmean`或`kendall`来计算斯皮尔曼秩相关或肯德尔系数。当然，连续值也可以通过分箱操作处理成等级数据，然后再进行相关性的判定。\n\n在使用该数据集建模之前，我们需要做一些准备工作，首先处理掉`horsepower`字段的空值，然后将`origin`字段处理成**独热编码**（One-Hot Encoding）。独热编码是一种用于处理分类变量的常见编码方式，通常分类数据（如性别、颜色、季节等）无法直接输入机器学习模型进行训练，因为大多数算法只能处理数值数据。独热编码通过将每个分类变量转换为若干个新的二元特征（`0`或` 1`）来表示，从而使得这些变量可以输入到机器学习模型中。假设我们有一个叫“颜色”的特征列，可能的取值有`红色`、`绿色`和`蓝色`，我们可以将其通过独热编码转换成三个二元特征，如下表所示：\n\n| 红色  | 绿色 | 蓝色 |\n| :--: | :--: | :--: |\n| 1    | 0    | 0    |\n| 0    | 1    | 0    |\n| 0    | 0    | 1    |\n| 0    | 1    | 0    |\n| 1    | 0    | 0    |\n\n> **说明**：我们也可以只保留绿色和蓝色两个列，如果两个列的取值都为`0`，那么说明我们的颜色是红色。\n\n独热编码方法简单直观，容易理解和实现。对于无序类别独热编码是非常有效的，因为它不会引入任何虚假的顺序关系，处理后的数据类型是数值型的，很多机器学习算法都能很好的处理。当然，如果类别特征有大量不同的类别取值，独热编码会生成大量的新特征，可能导致数据的维度大幅增加，从而影响计算性能和存储效率，尤其是在数据中有很多稀疏类别时。\n\n下面的代码实现了对数据的预处理。\n\n```python\n# 删除有缺失值的样本\ndf.dropna(inplace=True)\n# 将origin字段处理为类别类型\ndf['origin'] = df['origin'].astype('category') \n# 将origin字段处理为独热编码\ndf = pd.get_dummies(df, columns=['origin'], drop_first=True)\ndf\n```\n\n输出：\n\n```\n     cylinders  displacement  horsepower  weight  ...  model_year   mpg  origin_2  origin_3\n0            8         307.0       130.0    3504  ...          70  18.0     False     False\n1            8         350.0       165.0    3693  ...          70  15.0     False     False\n2            8         318.0       150.0    3436  ...          70  18.0     False     False\n3            8         304.0       150.0    3433  ...          70  16.0     False     False\n4            8         302.0       140.0    3449  ...          70  17.0     False     False\n..         ...           ...         ...     ...  ...         ...   ...       ...       ...\n393          4         140.0        86.0    2790  ...          82  27.0     False     False\n394          4          97.0        52.0    2130  ...          82  44.0      True     False\n395          4         135.0        84.0    2295  ...          82  32.0     False     False\n396          4         120.0        79.0    2625  ...          82  28.0     False     False\n397          4         119.0        82.0    2720  ...          82  31.0     False     False\n\n[392 rows x 9 columns]\n```\n\n> **说明**：上面调用 pandas 的`get_dummies`函数将`origin`列处理成了独热编码，由于将`drop_first`参数设置为`True`，所以原来的取值`1`、`2`、`3`只保留了两个列，分别叫`origin_2`和`origin_3`。Scikit-learn 库中`preprocessing`模块的`OneHotEncoder`也支持将类别特征处理成独热编码。\n\n接下来，我们还是将数据集拆分为训练集和测试集，代码如下所示。\n\n```python\nfrom sklearn.model_selection import train_test_split\n\nX, y = df.drop(columns='mpg').values, df['mpg'].values\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=3)\n```\n\n### 线性回归代码实现\n\n我们首先使用 scikit-learn 库`linear_model`模块的`LinearRegression`来创建线性回归模型，`LinearRegression`使用最小二乘法计算回归模型的参数，代码如下所示。\n\n```python\nfrom sklearn.linear_model import LinearRegression\n\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\n```\n\n如果想查看线性回归模型的参数（回归系数和截距），可以通过下面的代码来实现。\n\n```python\nprint('回归系数:', model.coef_)\nprint('截距:', model.intercept_)\n```\n\n输出：\n\n```\n回归系数: [-0.70865621  0.03138774 -0.03034065 -0.0064137   0.06224274  0.82866534\n  3.20888265  3.68252848]\n截距: -21.685482718950933\n```\n\n### 回归模型的评估\n\n回归模型的预测效果到底如何，我们可以通过下面的指标对其进行评估。\n\n1. 均方误差（Mean Squared Error, MSE）。MSE 是回归模型最常用的评估指标之一，定义为预测值与真实值误差的平方平均值。\n\n$$\n\\text{MSE} = \\frac{1}{m} \\sum_{i=1}^{m}(y_{i} - \\hat{y_{i}})^{2}\n$$\n\n2. 均方根误差（Root Mean Squared Error, RMSE）。RMSE 是 MSE 的平方根形式，用于更直观地衡量误差的实际尺度（单位与目标变量一致）。\n\n$$\n\\text{RMSE} = \\sqrt{\\text{MSE}} = \\sqrt{\\frac{1}{m} \\sum_{i=1}^{m}(y_{i} - \\hat{y_{i}})^{2}}\n$$\n\n3. 平均绝对误差（Mean Absolute Error, MAE）。MAE 是另一个常用的误差度量指标，定义为预测值与真实值误差的绝对值平均值。\n\n$$\n\\text{MAE} = \\frac{1}{m} \\sum_{i=1}^{m} \\lvert y_{i} - \\hat{y_{i}} \\rvert\n$$\n\n4. 决定系数（R-Squared, $\\small{R^{2}}$）。 $\\small{R^{2}}$ 是一个相对指标，用于衡量模型对数据的拟合程度，其值越接近 1 越好。 $\\small{R^{2}}$ 的计算公式为：\n\n$$\nR^{2} = 1 - \\frac{SS_{res}}{{SS}_{tot}}\n$$\n\n其中，  $\\small{SS_{res} = \\sum_{i=1}^{m}(y_{i} - \\hat{y_{i}})^{2}}$ 为残差平方和； $\\small{SS_{tot} = \\sum_{i=1}^{m} (y_{i} - \\bar{y})^{2}}$ 为总平方和，如下图所示。\n\n<img class=\"lazy\" data-src=\"/res/05_regression_r2.png\" style=\"zoom:40%;\">\n\n上图左边红色正方形的面积之和就是总平方和，右边蓝色正方形的面积之和就是残差平方和，很显然，模型拟合的效果越好，残差平方和除以总平方和的值就越接近 0， $\\small{R^{2}}$ 的值就越接近 1。通常 $\\small{R^{2} \\ge 0.8}$ 时，我们认为模型的拟合效果已经很不错了。\n\n可以使用 scikit-learn 中封装好的函数计算出均方误差、平均绝对误差和 $\\small{R^{2}}$ 的值，代码如下所示。\n\n```python\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n\nmse = mean_squared_error(y_test, y_pred)\nmae = mean_absolute_error(y_test, y_pred)\nr2 = r2_score(y_test, y_pred)\n\nprint(f'均方误差: {mse:.4f}')\nprint(f'平均绝对误差: {mae:.4f}')\nprint(f'决定系数: {r2:.4f}')\n```\n\n输出：\n\n```\n均方误差: 13.1215\n平均绝对误差: 2.8571\n决定系数: 0.7848\n```\n\n### 引入正则化项\n\n岭回归是在线性回归的基础上引入 $\\small{L2}$ 正则化项，目的是防止模型过拟合，尤其是当特征数较多或特征之间存在共线性时。岭回归的损失函数如下所示：\n\n$$\nL(\\beta) = \\sum_{i=1}^{m}{(y_{i} - \\hat{y_{i}})^{2}} + \\lambda \\cdot \\sum_{j=1}^{n}{\\beta_{j}^{2}}\n$$\n\n其中， $\\small{L2}$ 正则化项 $\\small{\\lambda \\sum_{j=1}^{n} \\beta_{j}^{2}}$ 会惩罚较大的回归系数，相当于缩小了回归系数的大小，但不会使系数为 0（即不会进行特征选择）。可以通过 scikit-learn 库`linear_model`模块的`Ridge`类实现岭回归，代码如下所示。\n\n```python\nfrom sklearn.linear_model import Ridge\n\nmodel = Ridge()\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\nprint('回归系数:', model.coef_)\nprint('截距:', model.intercept_)\nmse = mean_squared_error(y_test, y_pred)\nr2 = r2_score(y_test, y_pred)\nprint(f'均方误差: {mse:.4f}')\nprint(f'决定系数: {r2:.4f}')\n```\n\n输出：\n\n```\n回归系数: [-0.68868217  0.03023126 -0.0291811  -0.00642523  0.06312298  0.82583962\n  3.04105754  3.49988826]\n截距: -21.390402697674855\n均方误差: 12.9604\n决定系数: 0.7874\n```\n\n套索回归引入 $\\small{L1}$ 正则化项，不仅防止过拟合，还具有特征选择的功，特别适用于高维数据。套索回归的损失函数如下所示：\n\n$$\nL(\\mathbf{\\beta}) = \\sum_{i=1}^{m}{(y_{i} - \\hat{y_i})^{2}} + \\lambda \\cdot \\sum_{j=1}^{n}{\\lvert \\beta_{j} \\rvert}\n$$\n\n其中， $\\small{L1}$ 正则化项 $\\small{\\lambda \\sum_{j=1}^{n} \\lvert \\beta_{j} \\rvert}$ 会将某些不重要的回归系数缩减为 0，从而实现特征选择。可以通过 scikit-learn 库`linear_model`模块的`Lasso`类实现套索回归，代码如下所示。\n\n```python\nfrom sklearn.linear_model import Lasso\n\nmodel = Lasso()\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\nprint('回归系数:', model.coef_)\nprint('截距:', model.intercept_)\nmse = mean_squared_error(y_test, y_pred)\nr2 = r2_score(y_test, y_pred)\nprint(f'均方误差: {mse:.4f}')\nprint(f'决定系数: {r2:.4f}')\n```\n\n输出：\n\n```\n回归系数: [-0.00000000e+00  4.46821248e-04 -1.22830326e-02 -6.29725191e-03\n  0.00000000e+00  6.91590631e-01  0.00000000e+00  0.00000000e+00]\n截距: -9.109888229245005\n均方误差: 11.1035\n决定系数: 0.8179\n```\n\n> **注意**：上面代码运行结果中的回归系数，有四个特征的回归系数被设置为 0，相当于从 8 个特征中选出了 4 个重要的特征。模型的拟合效果是优于之间的回归模型的，这一点从均方误差和决定系数可以看出。\n\n弹性网络回归结合了岭回归和套索回归的优点，通过同时引入 $\\small{L1}$ 和 $\\small{L2}$ 正则化项，适用于高维数据且特征之间存在相关的情况，其损失函数如下所示：\n\n$$\nL(\\mathbf{\\beta}) = \\sum_{i=1}^{m}{(y_{i} - \\hat{y_i})^{2}} + \\alpha \\cdot \\lambda \\sum_{j=1}^{n}{\\lvert \\beta_{j} \\rvert} + (1 - \\alpha) \\cdot \\lambda \\cdot \\sum_{j=1}^{n}{\\beta_{j}^{2}}\n$$\n\n其中， $\\small{\\alpha}$ 是控制 $\\small{L1}$ 和 $\\small{L2}$ 正则化的权重比例。\n\n### 线性回归另一种实现\n\n上面我们提到过，除了最小二乘法我们还可以使用梯度下降法来求解回归模型的参数，scikit-learn 库`linear_model`模块的`SGDRegressor`就使用了这种方法，SGD 就是 Stochastic Gradient Descent 的缩写。随机梯度下降每次迭代只使用一个随机样本来计算梯度，计算速度快，适合大规模数据集，而且可以跳出局部最优解。需要注意的是它的学习率，如果学习率设置得不合理，它的收敛性可能会发生波动，通常需要使用学习率衰减策略来促进收敛。此外，随机梯度下降对特征的尺度非常敏感，通常需要在训练之前对特征进行标准化或归一化处理，完整的代码如下所示。\n\n```python\nfrom sklearn.linear_model import SGDRegressor\nfrom sklearn.preprocessing import StandardScaler\n\n# 对特征进行选择和标准化处理\nscaler = StandardScaler()\nscaled_X = scaler.fit_transform(X[:, [1, 2, 3, 5]])\n# 重新拆分训练集和测试集\nX_train, X_test, y_train, y_test = train_test_split(scaled_X, y, train_size=0.8, random_state=3)\n\n# 模型的创建、训练和预测\nmodel = SGDRegressor()\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\nprint('回归系数:', model.coef_)\nprint('截距:', model.intercept_)\n\n# 模型评估\nmse = mean_squared_error(y_test, y_pred)\nr2 = r2_score(y_test, y_pred)\nprint(f'均方误差: {mse:.4f}')\nprint(f'决定系数: {r2:.4f}')\n```\n\n输出：\n\n```\n回归系数: [-0.25027084 -0.41349219 -4.9559786   2.83009217]\n截距: [23.48707219]\n均方误差: 11.3853\n决定系数: 0.8133\n```\n\n这里，我们还需要强调一下`SGDRegressor`构造函数几个重要的参数，也是回归模型比较重要的超参数，如下所示：\n\n1. `loss`：指定优化目标（损失函数），默认值为`'squared_error'`（最小二乘法），其他可以选择的值有：`'huber'`、`'epsilon_insensitive'` 和 `'squared_epsilon_insensitive'`，其中`'huber'`适用于对异常值更鲁棒的回归模型。\n\n2. `penalty`：指定正则化方法，用于防止过拟合，默认为`'l2'`（L2 正则化），其他可以选择的值有：`'l1'`（L1正则化）、`'elasticnet'`（弹性网络，L1 和 L2 的组合）、`None`（不使用正则化）。\n\n3. `alpha`：正则化强度的系数，控制正则化项的权重，默认值为`0.0001`。较大的 `alpha` 值会加重正则化的影响，从而限制模型复杂度；较小的值会让模型更关注训练数据的拟合。\n4. `l1_ratio`：当 `penalty='elasticnet'` 时，控制 L1 和 L2 正则化之间的权重，默认值为`0.15`，取值范围为`[0, 1]`（`0` 表示完全使用 L2，`1` 表示完全使用 L1）。\n5. `tol`：优化算法的容差，即判断收敛的阈值，默认值为`1e-3`。当目标函数的改变量小于 `tol` 时，训练会提前终止；如果希望训练更加精确，可以适当降低 `tol`。\n6. `learning_rate`：指定学习率的调节策略，默认值为`'constant'`，表示使用固定学习率，具体的值由 `eta0` 指定；其他可选项包括：\n    - `'optimal'`：基于公式`eta = 1.0 / (alpha * (t + t0))`自动调整。\n    - `'invscaling'`：按 `eta = eta0 / pow(t, power_t)` 缩放学习率。\n    - `'adaptive'`：动态调整，误差减少时保持当前学习率，否则减小学习率。\n\n7. `eta0`：初始学习率，默认值为`0.01`，当 `learning_rate='constant'` 或其他策略使用时，`eta0` 决定了初始更新步长。\n8. `power_t`：当 `learning_rate='invscaling'` 时，控制学习率衰减速度，默认值为`0.25`。较小的值会让学习率下降得更慢，从而更长时间地关注全局优化。\n9. `early_stopping`：是否启用早停机制，默认值为`False`。如果设置为 `True`，模型会根据验证集性能自动停止训练，防止过拟合。\n10. `validation_fraction`：指定用作验证集的训练数据比例，默认值为`0.1`。当 `early_stopping=True` 时，该参数会起作用。\n11. `max_iter`：训练的最大迭代次数，默认值为`1000`。当数据较大或学习率较小时，可能需要增加迭代次数以保证收敛。\n12. `shuffle`：是否在每个迭代轮次开始时打乱训练数据，默认值为`True`，表示打乱数据。打乱数据有助于提高模型的泛化能力。\n13. `warm_start`：是否使用上次训练的参数继续训练，默认值为`False`。当设置为 `True` 时，可以在已有模型的基础上进一步优化。\n14. `verbose`：控制训练过程的日志输出，默认值为`0`，可以设置为更高值以观察训练进度。\n\n### 多项式回归\n\n有的时候，我们关心的自变量和因变量之间并不是简单的线性关系，例如广告投入与销售额增长的关系、设备的使用时间与故障率之间的关系等。除此以外，如果数据中存在明显的拐点或者要通过简单的公式来近似某些复杂的现象，线性回归模型可能并不能满足这样的需求，这个时候我们就需要建立多项式回归模型。\n\n下面我们用一个简单的例子对多项式回归加以说明，我们先生成一组数据点并绘制出对应的散点图，代码如下所示。\n\n```python\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nx = np.linspace(0, 6, 150)\ny = x ** 2 - 4 * x + 3 + np.random.normal(1, 1, 150)\nplt.scatter(x, y)\nplt.show()\n```\n\n输出：\n\n<img class=\"lazy\" data-src=\"/res/05_polynomial_scatter.png\" style=\"zoom:50%;\">\n\n显然，这样的一组数据点是很难通过线性模型进行拟合的，下面的代码可以证明这一点。\n\n```Python\nx_ = x.reshape(-1, 1)\n\nmodel = LinearRegression()\nmodel.fit(x_, y)\na, b = model.coef_[0], model.intercept_\ny_pred = a * x + b\nplt.scatter(x, y)\nplt.plot(x, y_pred, color='r')\nplt.show()\n```\n\n输出：\n\n<img class=\"lazy\" data-src=\"/res/05_polynomial_line_fit.png\" style=\"zoom:50%;\">\n\n很显然，这是一个欠拟合的结果。我们再看看 $\\small{R^{2}}$ 的值：\n\n```python\nr2 = r2_score(y, y_pred)\nprint(f'决定系数: {r2:.4f}')\n```\n\n输出：\n\n```\n决定系数: 0.5933\n```\n\nScikit-learn 库`preprocessing`模块中的`PolynomialFeatures`类可以将原始特征扩展为多项式特征，从而将线性模型转换为具有高次项的模型。创建`PolynomialFeatures`对象时有几个重要的参数：\n\n1. `degree`：设置多项式的最高次项。例如，`degree=3` 会生成包含一次项、二次项和三次项的特征。\n2. `interaction_only`：默认值为`False`，如果设置为`True`，则只生成交互项（如 $\\small{x_{1}x_{2}}$ ），不生成单独的高次项（如 $\\small{x_{1}^{2}}$ 、 $\\small{x_{2}^{2}}$ ）。\n3. `include_bias`：默认值为`True`，表示包括常数项（通常为 1），设置为`False`则不包括常数项。\n\n下面我们通过代码来演示如何通过`PolynomialFeatures`类进行特征预处理，实现多项式回归。\n\n```python\nfrom sklearn.preprocessing import PolynomialFeatures\n\npoly = PolynomialFeatures(degree=2)\nx_ = poly.fit_transform(x_)\n\nmodel = LinearRegression()\nmodel.fit(x_, y)\ny_pred = model.predict(x_)\nr2 = r2_score(y, y_pred)\nprint(f'决定系数: {r2:.4f}')\n```\n\n输出：\n\n```\n决定系数: 0.9497\n```\n\n通过特征预处理引入了高次项之后，模型拟合的效果得到了明显的改善。如果希望只对一部分特征添加高次项，可以使用 scikit-learn 库`compose`模块的`ColumnTransformer`来定义处理规则，有兴趣的读者可以自行研究。需要注意的是，多项式回归时随着高次项的引入，模型发生过拟合的风险增加会大大增加，尤其在数据量较小时；另一方面，高次项的值可能会导致特征范围变得很大，要考虑对特征进行标准化处理。\n\n### 逻辑回归\n\n逻辑回归尽管名字中含有“回归”，但逻辑回归实际上是一种分类算法，用于处理二分类问题，例如电子邮件是不是垃圾邮件、用户是否会点击广告、信用卡客户是否存在违约风险等。逻辑回归的核心思想是通过 Sigmoid 函数将线性回归的输出映射到$\\small{(0, 1)}$区间，作为对分类概率的预测。Sigmoid 函数的曲线如下图所示。\n\n<img class=\"lazy\" data-src=\"/res/05_sigmoid_function.png\" style=\"zoom:58%;\">\n\n下面，我们用 scikit-learn 库`datasets`模块提供的`make_classification`函数生成一组模拟数据， 通过逻辑回归来构建分类预测模型，代码如下所示。\n\n```python\nfrom sklearn.datasets import make_classification\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report\n\n# 生成1000条样本数据，每个样本包含6个特征\nX, y = make_classification(n_samples=1000, n_features=6, random_state=3)\n# 将1000条样本数据拆分为训练集和测试集\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=3)\n\n# 创建和训练逻辑回归模型\nmodel = LogisticRegression()\nmodel.fit(X_train, y_train)\n\n# 对测试集进行预测并评估\ny_pred = model.predict(X_test)\nprint(classification_report(y_test, y_pred))\n```\n\n输出：\n\n```\n              precision    recall  f1-score   support\n\n           0       0.95      0.93      0.94       104\n           1       0.93      0.95      0.94        96\n\n    accuracy                           0.94       200\n   macro avg       0.94      0.94      0.94       200\nweighted avg       0.94      0.94      0.94       200\n```\n\n这里，我们再强调一下`LogisticRegression`构造函数几个重要的参数，也是逻辑回归模型比较重要的超参数，如下所示：\n\n1. `penalty`：指定正则化类型，用于控制模型复杂度，防止过拟合，默认值为`l2`。\n2. `C`：正则化强度的倒数，默认值为`1.0`。较小的 `C` 值会加强正则化（更多限制模型复杂度），较大的 `C` 值会减弱正则化（更注重拟合训练数据）。\n3. `solver`：指定优化算法，默认值为`lbfgs`，可选值包括：\n    - `'newton-cg'`、`'lbfgs'`、`'sag'`、`'saga'`：支持 L2 和无正则化。\n    - `'liblinear'`：支持 L1 和 L2 正则化，适用于小型数据集。\n    - `'saga'`：支持 L1、L2 和 ElasticNet，适用于大规模数据。\n4. `multi_class`：指定多分类问题的处理方式，默认值为`'auto'`，根据数据选择 `'ovr'` 或 `'multinomial'`，前者表示一对多策略，适合二分类或多分类的基础情况，后者表示多项式回归策略，适用于多分类问题，需与 `'lbfgs'`、`'sag'` 或 `'saga'` 搭配使用。\n5. `fit_intercept`：是否计算截距（偏置项），默认值为`True`。\n6. `class_weight`：类别权重，处理类别不平衡问题，默认值为`None`，设置为`'balanced'`可以根据类别频率自动调整权重。\n\n> **说明**：逻辑回归有些超参数跟我们之前讲的`SGDRegressor`是类似的，此处不再进行赘述。\n\n### 总结\n\n回归模型是一种统计分析方法，用于建立自变量与因变量之间的关系。它通过拟合数据来预测目标变量的值，在经济学、工程、医学等领域有着广泛的应用，可以帮助决策者进行数据驱动的预测和分析。\n\n", "K-Means聚类算法": "## K-Means聚类算法\n\n聚类（Clustering）是数据挖掘和机器学习中的一种重要技术，用于将数据集中的样本划分为多个相似的组或类别。这种方法在许多领域得到了广泛应用，例如：\n\n- **电商行业**：根据用户行为数据，将消费者分为不同的群体（高消费用户、高活跃用户、流失风险用户、价格敏感用户等）以制定有针对性的运营策略，实现更精准的广告投放，代表性的企业包括阿里巴巴、亚马逊（Amazon）等。\n- **金融行业**：各大银行通过聚类算法分析用户的信用记录、收入水平、消费行为等数据，将用户分为不同的风险群体，对于高风险群体需要更严格的信用审核，而低风险群体可以享受更优惠的贷款利率或信用额度。\n- **医疗行业**：通过分析患者的健康数据（如病史、基因数据、生活习惯等），将患者分为不同健康风险群体，提高疾病预测的准确性，推动了精准医疗的发展，代表性的公司如强生（Johnson & Johnson）、辉瑞（Pfizer）等。\n- **社交媒体**：通过分析用户的好友关系、兴趣爱好、社交互动等数据，将用户划分为不同的社交圈，用于推荐好友、定制个性化内容以及优化了平台上的信息流推荐系统。\n\n聚类是一种**无监督学习**，因为它不需要预先定义的标签，只是根据数据特征去学习，通过度量特征相似度或者距离，然后把已知的数据集划分成若干个不同的类别。与分类不同，聚类任务的目标是发现数据内在的结构。聚类算法大体上可以分为：**基于距离的聚类**、**基于密度的聚类**、**层次聚类**、**谱聚类**等。如果你还分不清楚聚类和分类到底有什么区别，相信下面的图可以帮到你。\n\n<img class=\"lazy\" data-src=\"/res/06_classification_vs_clustering.png\" style=\"zoom:38%;\">\n\n### 算法原理\n\n下面我们重点为大家介绍名为 K-Means 的聚类算法。K-Means 是一种基于原型的分区聚类方法，其目标是将数据集划分为K个簇，并使每个簇内的数据点尽可能相似。K-Means 算法的实施步骤如下所示：\n\n1. **初始化簇中心**：随机选择K个样本作为初始簇中心，簇中心通常也称为质心。\n2. **分配样本到最近的质心**：计算每个样本与所有质心的距离，将样本分配到最近的簇。\n3. **更新质心**：计算每个簇的所有样本的均值，并将其作为新的质心。\n4. **重复步骤2和步骤3**，直到质心收敛或达到预设的迭代次数。\n\n### 数学描述\n\n我们将上面的算法原理用数学语言进行描述。对于给定的数据集 ，K-Means 算法的目标是最小化目标函数（总误差平方和）。目标函数如下所示：\n\n$$\nJ = \\sum_{i=1}^{K} \\sum_{x \\in C_{i}} {\\lVert x - \\mu_{i} \\rVert}^{2}\n$$\n\n其中， $\\small{K}$ 是簇的数量， $\\small{C_{i}}$ 表示第 $\\small{i}$ 个簇中的样本集合， $\\small{\\mu_{i}}$ 是第 $\\small{i}$ 个簇的中心， $\\small{x}$ 是数据点。因为这个问题属于 NP 困难组合优化问题，所以在实际求解时我们会采用迭代的方式来寻求满意解。\n\n首先随机选择 $\\small{K}$ 个点作为初始质心 $\\small{\\mu_{1}, \\mu_{2}, \\cdots, \\mu_{K}}$ ，对于每个数据点 $\\small{x_{j}}$ ，计算到每个质心的距离，选择距离最近的质心，即：\n\n$$\nC_{i} = \\lbrace {x_{j} \\ \\vert \\ {\\lVert x_{j} - \\mu_{i} \\rVert}^{2} \\le {\\lVert x_{j} - \\mu_{k} \\rVert}^{2} \\ \\text{for all} \\ k \\ne i} \\rbrace\n$$\n\n更新质心为簇中所有点的均值，即：\n\n$$\n\\mu_{i} = \\frac{1}{\\lvert C_{i} \\rvert}\\sum_{x \\in C_{i}} x\n$$\n\n重复上面两个动作，直到质心不再变化或变化小于某个阈值，这就确保了算法的收敛性。\n\n### 代码实现\n\n下面我们用 Python 代码实现 K-Means 聚类，我们先暂时不使用 scikit-learn 库，主要帮助大家理解算法的工作原理。\n\n```python\nimport numpy as np\n\n\ndef distance(u, v, p=2):\n    \"\"\"计算两个向量的距离\"\"\"\n    return np.sum(np.abs(u - v) ** p) ** (1 / p)\n\n\ndef init_centroids(X, k):\n    \"\"\"随机选择k个质心\"\"\"\n    index = np.random.choice(np.arange(len(X)), k, replace=False)\n    return X[index]\n\n\ndef closest_centroid(sample, centroids):\n    \"\"\"找到跟样本最近的质心\"\"\"\n    distances = [distance(sample, centroid) for i, centroid in enumerate(centroids)]\n    return np.argmin(distances)\n\n\ndef build_clusters(X, centroids):\n    \"\"\"根据质心将数据分成簇\"\"\"\n    clusters = [[] for _ in range(len(centroids))]\n    for i, sample in enumerate(X):\n        centroid_index = closest_centroid(sample, centroids)\n        clusters[centroid_index].append(i)\n    return clusters\n\n\ndef update_centroids(X, clusters):\n    \"\"\"更新质心的位置\"\"\"\n    return np.array([np.mean(X[cluster], axis=0) for cluster in clusters])\n\n\ndef make_label(X, clusters):\n    \"\"\"生成标签\"\"\"\n    labels = np.zeros(len(X))\n    for i, cluster in enumerate(clusters):\n        for j in cluster:\n            labels[j] = i\n    return labels\n\n\ndef kmeans(X, *, k, max_iter=1000, tol=1e-4):\n    \"\"\"KMeans聚类\"\"\"\n    # 随机选择k个质心\n    centroids = init_centroids(X, k)\n    # 通过不断的迭代对数据进行划分\n    for _ in range(max_iter):\n        # 通过质心将数据划分到不同的簇\n        clusters = build_clusters(X, centroids)\n        # 重新计算新的质心的位置\n        new_centroids = update_centroids(X, clusters)\n        # 如果质心几乎没有变化就提前终止迭代\n        if np.allclose(new_centroids, centroids, rtol=tol):\n            break\n        # 记录新的质心的位置\n        centroids = new_centroids\n    # 给数据生成标签\n    return make_label(X, clusters), centroids\n```\n\n我们仍然以鸢尾花数据集为例，看看我们自己实现的`kmeans`函数能否为将三种鸢尾花划分为三个不同的类别。由于是无监督学习，这里我们直接把整个数据集带入`kmeans`函数，代码如下所示。\n\n```python\nfrom sklearn.datasets import load_iris\n\niris = load_iris()\nX, y = iris.data, iris.target\nlabels, centers = kmeans(X, k=3)\n```\n\n这里，千万不要直接拿`y_pred`和`y`进行比较，我们之前说过，聚类算法并不知道数据对应的标签，它只是根据特征将数据划分为不同的类别，这里输出的`0`、`1`、`2` 并不直接对应到山鸢尾、多彩鸢尾和为吉尼亚鸢尾。我们可以用可视化的方式来看看预测的结果，代码如下所示：\n\n```python\nimport matplotlib.pyplot as plt\n\ncolors = ['#FF6969', '#050C9C', '#365E32']\nmarkers = ['o', 'x', '^']\n\nplt.figure(dpi=200)\nfor i in range(len(centers)):\n    samples = X[labels == i]\n    print(markers[i])\n    plt.scatter(samples[:, 2], samples[:, 3], marker=markers[i], color=colors[i])\n    plt.scatter(centers[i, 2], centers[i, 3], marker='*', color='r', s=120)\n\nplt.xlabel('Petal length')\nplt.ylabel('Petal width')\nplt.show()\n```\n\n输出：\n\n<img class=\"lazy\" data-src=\"/res/06_kmeans_plot_1.png\" style=\"zoom:62%;\">\n\n我们用原始数据重新输出，跟上面的图做一个对比，代码如下所示。\n\n```python\nimport matplotlib.pyplot as plt\n\ncolors = ['#FF6969', '#050C9C', '#365E32']\nmarkers = ['o', 'x', '^']\n\nplt.figure(dpi=200)\nfor i in range(len(centers)):\n    samples = X[y == i]\n    plt.scatter(samples[:, 2], samples[:, 3], marker=markers[i], color=colors[i])\n\nplt.xlabel('Petal length')\nplt.ylabel('Petal width')\nplt.show()\n```\n\n输出：\n\n<img class=\"lazy\" data-src=\"/res/06_kmeans_plot_2.png\" style=\"zoom:62%;\">\n\n直接使用 scikit-learn 库`cluster`模块的`KMeans`类实现 K-Means 聚类是更好的选择，代码如下所示。\n\n```python\nfrom sklearn.cluster import KMeans\n\n# 创建KMeans对象\nkm_cluster = KMeans(\n    n_clusters=3,       # k值（簇的数量）\n    max_iter=30,        # 最大迭代次数\n    n_init=10,          # 初始质心选择尝试次数\n    init='k-means++',   # 初始质心选择算法\n    algorithm='elkan',  # 是否使用三角不等式优化\n    tol=1e-4,           # 质心变化容忍度\n    random_state=3      # 随机数种子\n)\n# 训练模型\nkm_cluster.fit(X)\nprint(km_cluster.labels_)           # 分簇的标签\nprint(km_cluster.cluster_centers_)  # 各个质心的位置\nprint(km_cluster.inertia_)          # 样本到质心的距离平方和\n```\n\n下面我们对`KMeans`类的几个超参数加以说明：\n\n1. `n_clusters`：指定聚类的簇数，即 $\\small{K}$ 值，默认值为`8`。\n2. `max_iter`：最大迭代次数，默认值为`300`，控制每次初始化中 K-Means 迭代的最大步数。\n3. `init`：初始化质心的方法，默认值为`'k-means++'`，表示从数据中多次随机选取 K 个质心，每次都计算这一次选中的中心点之间的距离，然后取距离最大的一组作为初始化中心点，推荐大家使用这个值；如果设置为`'random'`则随机选择初始质心。\n4. `n_init`：和上面的参数配合，指定算法运行的初始化次数，默认值为`10`。\n5. `algorithm`：K-Means 的计算算法，默认值为`'lloyd'`。还有一个可选的值为`'elkan'`，表示基于三角不等式的优化算法，适用于 K 值较大的情况，计算效率较高。\n6. `tol`：容忍度，控制算法的收敛精度，默认值为`1e-4`。如果数据集较大时，可适当增大此值以加快收敛速度。\n\n### 总结\n\nK-Means 是一种经典的聚类算法，它的优点包括实现简单，算法收敛速度快；缺点是结果不稳定（跟初始值设定有关系），无法解决样本不均衡的问题，容易收敛到局部最优解，受噪声数据影响较大。如果你想通过可视化的方式理解聚类的过程，我们给大家推荐一个名为 Naftali 的人的博客，该网站上提供了可视化的方式展示 K-Means 和 DBSCAN 聚类（一种基于密度的聚类算法），如下图所示。\n\n<img class=\"lazy\" data-src=\"/res/06_kmeans_visualization.png\" style=\"zoom:45%;\">\n\n<img class=\"lazy\" data-src=\"/res/06_dbscan_visualization.png\" style=\"zoom:45%;\">\n", "集成学习算法": "## 集成学习算法\n\n之前的章节，我们主要为大家介绍了机器学习中的单模型。事实上，将多个单模型组合成一个综合模型的方式早已成为现代机器学习模型采用的主流方法，这种方法被称为**集成学习**（ensemble learning）。集成学习的目标是通过多个弱学习器（分类效果略优于随机猜测的模型，如果太强容易导致过拟合）的组合来构建强学习器，从而克服单一模型可能存在的局限性，获得比单一模型**更好的泛化能力**，通常用于**需要高精度预测的场景**。\n\n### 算法分类\n\n集成学习算法主要分为以下几类：\n\n1. **Bagging**：通过从训练数据中随机抽样生成多个数据子集，在这些子集上训练多个模型，并将它们的结果进行结合。这种集成学习的原理如下图所示，最典型的例子就是我们之前讲过的随机森林。\n\n    <img class=\"lazy\" data-src=\"/res/07_ensemble_bagging.png\" style=\"zoom:50%;\">\n\n2. **Boosting**：通过迭代训练多个模型，在每一轮训练时，重点关注前一轮预测错误的样本。每个新模型的训练目标是弥补前一轮模型的不足。这种集成学习的原理如下图所示，经典的算法有 AdaBoost、Gradient Boosting 和 XGBoost。\n\n    <img class=\"lazy\" data-src=\"/res/07_ensemble_boosting.png\" style=\"zoom:50%;\">\n\n    Boosting的基本原理是：初始时对所有样本赋予相同的权重；训练第一个模型时，错误分类的样本权重会增加；训练下一个模型时，重点关注之前模型错误分类的样本；最终将所有模型的结果加权组合（表现好的模型会有更高的权重），得到最终的输出。简单的说，Boosting 就是串行的训练一系列弱分类器，使得被先前弱分类器分类错误的样本在后续得到更多关注，最后将这些分类器组合成最优强分类器的过程。\n\n3. **Stacking**：通过训练多个模型，将它们的预测结果作为新特征输入到另一个模型（通常称为“二级模型”）中，用“二级模型”来做最终的预测，原理如下图所示。\n\n    <img class=\"lazy\" data-src=\"/res/07_ensemble_stacking.png\" style=\"zoom:36%;\">\n\n### AdaBoost\n\nAdaBoost（Adaptive Boosting）由 Yoav Freund 和 Robert Schapire 于 1996 年提出，是一种经典的集成学习算法，通常将其翻译为自适应提升算法。AdaBoost 的做法非常朴素，一是**提高前一轮被弱分类器分类错误的样本的权重**，二是对多个弱分类器进行线性组合，**提高分类效果好的弱分类器的权重**；它的自适应体现在会根据前一轮模型的错误调整样本的权重。\n\nAdaBoost 算法的训练过程是逐步迭代的，关键步骤如下：\n\n1. **初始化样本权重**：给每个训练样本分配一个相等的初始权重。对于 $\\small{N}$ 个样本，初始权重为：\n\n$$\nw_{i}^{(1)} = \\frac{1}{N}, \\ i = 1, 2, \\cdots, N\n$$\n\n这里， $\\small{w_{i}^{(1)}}$ 表示第 $\\small{i}$ 个样本的权重，初始时权重相等。\n\n2. **训练弱学习器**：在每一轮迭代中，AdaBoost 会根据当前样本的权重训练一个弱分类器（例如决策树桩，即深度为 1 的决策树）。弱分类器的目标是最小化加权误差。对于第 $\\small{t}$ 轮训练得到的分类器模型（弱学习器） $\\small{h_t}$，计算其加权误差：\n\n$$\n\\varepsilon_{t} = \\sum_{i=1}^{N} w_{i}^{(t)} \\cdot I(y_{i} \\neq h_{t}(x_{i}))\n$$\n\n其中， $\\small{y_{i}}$ 是第 $\\small{i}$ 个样本的真实标签， $\\small{h_{t}(x_{i})}$ 是第 $\\small{t}$ 轮模型 $\\small{h_{t}}$ 对第 $\\small{i}$ 个样本 $\\small{x_{i}}$ 给出的预测结果（取值为 1 或 -1）， $\\small{I(y_{i} \\neq h_{t}(x_{i}))}$ 是指示函数，当样本 $\\small{x_{i}}$ 被错误分类时函数取值为 1，否则函数取值为 0。\n\n3. **更新分类器权重**：计算第 $\\small{t}$ 轮分类器模型的权重 $\\small{\\alpha_{t}}$，并用它来更新每个样本的权重。分类器权重 $\\small{\\alpha_{t}}$ 的计算公式为：\n\n$$\n\\alpha_{t} = \\frac{1}{2} ln \\left( \\frac{1 - \\varepsilon_{t}}{\\varepsilon_{t}} \\right)\n$$\n\n当分类器的误差较低时， $\\small{\\alpha_{t}}$ 的值较大，说明该分类器的权重较大。\n\n4. **更新样本权重**：根据当前分类器的表现，更新样本的权重。误分类样本的权重会增加，正确分类样本的权重会减少。样本权重的更新公式为：\n\n$$\nw_{i}^{(t + 1)} = w_{i}^{(t)} \\cdot e^{-\\alpha_{t} y_{i} h_{t}(x_{i})}\n$$\n\n5. **归一化权重**：对所有样本的权重进行归一化，使得所有样本的权重和为 1。\n\n6. **最终分类器**：AdaBoost 的最终分类器是所有弱学习器的加权组合，预测时通过加权投票来决定最终类别：\n\n$$\nH(x) = \\text{sign} \\left( \\sum_{t=1}^{T} \\alpha_{t} h_{t}(x) \\right)\n$$\n\n其中， $\\small{\\text{sign}}$ 是符号函数，其定义如下所示：\n\n$$\n\\text{sign}(z) = \\begin{cases} +1 \\ (z \\ge 0) \\\\\\\\ -1 \\ (z \\lt 0) \\end{cases}\n$$\n\n例如，有 3 个弱学习器 $\\small{h_{1}(x)}$、 $\\small{h_{2}(x)}$、 $\\small{h_{3}(x)}$，它们的输出分别是`+1`、`-1`和`+1`，对应的权重是 $\\small{\\alpha_{1} = 0.5}$、 $\\small{\\alpha_{2} = 0.3}$、 $\\small{\\alpha_{3} = 0.2}$ ，那么加权和为：\n\n$$\n\\sum_{t=1}^{3} \\alpha_{t} h_{t}(x) = 0.5 \\times 1 + 0.3 \\times -1 + 0.2 \\times 1 = 0.4\n$$\n\n由于加权和`0.4`为正，符号函数会输出`+1`，表示最终预测类别为正类。\n\n我们还是以鸢尾花数据集为例，应用 AdaBoost 集成学习算法来构建分类模型，完整的代码如下所示。\n\n```python\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.metrics import classification_report\n\n# 数据集的加载和划分\niris = load_iris()\nX, y = iris.data, iris.target\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=3)\n\n# 初始化弱分类器（决策树桩）\nbase_estimator = DecisionTreeClassifier(max_depth=1)\n# 初始化 AdaBoost 分类器\nmodel = AdaBoostClassifier(base_estimator, n_estimators=50)\n# 训练模型\nmodel.fit(X_train, y_train)\n# 预测结果\ny_pred = model.predict(X_test)\n\n# 输出评估报告\nprint(classification_report(y_test, y_pred))\n```\n\n输出：\n\n```\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        10\n           1       0.90      0.90      0.90        10\n           2       0.90      0.90      0.90        10\n\n    accuracy                           0.93        30\n   macro avg       0.93      0.93      0.93        30\nweighted avg       0.93      0.93      0.93        30\n```\n\n这里需要注意几个超参数的设置：\n\n1. `n_estimators`：指定要训练的基学习器（弱分类器）的数量，默认值为 50。\n2. `learning_rate`：控制每个基学习器在最终模型中的贡献大小，即学习率，默认值为 1.0。\n3. `algorithm`：决定 AdaBoost 的训练算法。AdaBoost 主要有两种训练模式：\n    - `'SAMME'`：用于多类分类问题的算法，采用加法模型。\n    - `'SAMME.R'`：基于 Real AdaBoost 的算法，用于加权的二分类和多分类问题，使用了一个加权的重新采样策略。\n4. `base_estimator`：基学习器，默认值为`None`，表示使用`max_depth=1`的`DecisionTreeClassifier`作为基学习器。所以，上面代码中创建`AdaBoostClassifier`对象的两个参数都可以省略，因为它们刚好都是默认值。\n\n增大 `n_estimators` 可以提高模型的性能，但可能会导致过拟合；增大 `learning_rate` 则可以加速训练，但可能会导致模型不稳定。通常需要通过交叉验证来找到最佳的 `n_estimators` 和 `learning_rate` 的组合。对于大多数问题，`DecisionTreeClassifier(max_depth=1)` 是常见的选择，但如果数据较为复杂，可以考虑其他基学习器，如`SVC`、`LogisticRegression`等。\n\n### GBDT\n\nGBDT（Gradient Boosting Decision Trees）也是一种强大的集成学习算法，相较于 AdaBoost，GBDT 系列的模型应用得更加广泛。GBDT 基于**梯度提升**（Gradient Boosting）的思想，结合了决策树的优势，通过一系列的弱分类器（决策树）逐步改进模型，每次训练时通过减少前一个模型的误差（拟合残差）来提高模型的预测性能。\n\nGBDT 使用梯度下降的方式来最小化损失函数。对于回归任务，损失函数通常是均方误差（MSE）；对于分类任务，常用的损失函数是对数损失（Log Loss）。下面我们以二分类任务为例，为大家讲解算法的原理。\n\n1. 损失函数。在分类任务中，通常使用对数似然损失函数，对于二分类问题，损失函数如下所示：\n\n$$\nL(y, F(x)) = -y\\log(p(x)) - (1 - y)\\log(1 - p(x))\n$$\n\n其中， $\\small{y}$ 是实际标签（ $\\small{y \\in \\lbrace 0, 1 \\rbrace}$ ，表示类别 0 或 1）， $\\small{p(x)}$ 是模型预测的样本 $\\small{x}$ 属于类别 1 的概率。由于 GBDT 是基于梯度提升算法的，因此在每一轮的更新中，我们将通过梯度下降法来优化这个损失函数。\n\n2. 梯度计算。为了使用梯度提升，我们需要计算损失函数关于当前模型预测的梯度。令当前模型的输出为 $\\small{F(x)}$，即预测函数。根据对数损失函数， $\\small{p(x)}$ 是通过模型输出 $\\small{F(x)}$ 转换得到的概率，通常使用 Sigmoid 函数，有：\n\n$$\np(x) = \\frac{1}{1 + e^{-F(x)}}\n$$\n\n计算损失函数对 $\\small{F(x)}$ 的梯度时，我们得到：\n\n$$\n\\frac{\\partial{L(y, F(x))}}{\\partial{F(x)}} = p(x) - y\n$$\n\n即梯度为 $\\small{p(x) - y}$ ，这个值告诉我们当前模型的预测 $\\small{F(x)}$ 与真实标签 $\\small{y}$ 之间的差距。\n\n3. 模型更新。每一轮的更新都包括两步：\n\n    - 计算残差：在每一轮迭代中，我们计算当前模型的残差，即 $\\small{\\delta_i = p(x_i) - y_i}$，表示每个样本的误差。\n    - 拟合残差：使用新的基学习器（通常是决策树）来拟合这些残差。在分类任务中，我们训练的决策树并不是拟合真实标签，而是拟合残差，即拟合当前模型的预测误差。\n\n更新规则为：\n\n$$\nF_{m + 1}(x) = F_{m}(x) + \\eta h_{m}(x)\n$$\n\n其中， $\\small{F_{m}(x)}$ 是第 $\\small{m}$ 轮模型的输出； $\\small{h_{m}(x)}$ 是第 $\\small{m}$ 轮训练出的弱学习器（通常是决策树），它预测当前模型的残差； $\\small{\\eta}$ 是学习率，控制每棵树的贡献大小。通过这样逐步拟合残差，最终生成的模型 $\\small{F(x)}$ 就是一个由多棵决策树组成的强学习器。\n\n对于多分类任务，我们需要将损失函数和梯度计算做相应的扩展。常用的多分类损失函数是多项式对数损失，对于每个类别 $\\small{k}$ ，损失函数可以表示为：\n\n$$\nL(y, F(x)) = -\\sum_{k=1}^{K} y_{k} \\log(p_{k}(x))\n$$\n\n其中， $\\small{K}$ 是类别总数， $\\small{y_{k}}$ 是目标类别 $\\small{k}$ 的指示函数， $\\small{p_k(x)}$ 是样本 $\\small{x}$ 属于类别 $\\small{k}$ 的预测概率。\n\n我们还是以鸢尾花数据集为例，应用 AdaBoost 集成学习算法来构建分类模型，完整的代码如下所示。\n\n```python\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.metrics import classification_report\n\n# 数据集的加载和划分\niris = load_iris()\nX, y = iris.data, iris.target\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=3)\n\n# 初始化 GBDT 分类器\nmodel = GradientBoostingClassifier(n_estimators=32)\n# 训练模型\nmodel.fit(X_train, y_train)\n# 预测结果\ny_pred = model.predict(X_test)\n\n# 输出评估报告\nprint(classification_report(y_test, y_pred))\n```\n\n输出：\n\n```\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        10\n           1       1.00      1.00      1.00        10\n           2       1.00      1.00      1.00        10\n\n    accuracy                           1.00        30\n   macro avg       1.00      1.00      1.00        30\nweighted avg       1.00      1.00      1.00        30\n```\n\n我们还是讲一讲`GradientBoostingClassifier`几个重要的超参数：\n\n1. `loss`：指定用于分类任务的损失函数，默认值为 `deviance`，表示使用对数损失函数。也可以选择 `exponential`，表示使用指数损失函数（AdaBoost 的损失函数）。\n2. `learning_rate`：控制每棵树对最终预测结果的影响程度，默认值为 0.1。较小的学习率通常会带来更好的泛化能力，但需要更多的弱分类器（即更多的树）来拟合训练数据；如果学习率设置得太大，则可能会导致模型欠拟合。\n3. `n_estimators`：指定要训练的基学习器（通常是决策树）的数量，默认值为 100。\n4. `subsample`：控制每棵树训练时使用的数据比例，默认值为 1.0（即使用所有数据）。通过设置小于 1 的值，可以在训练每棵树时随机选择部分样本，从而增加模型的随机性减少过拟合。通常情况下，0.8 或 0.9 是不错的选择。\n5. `criterion`：用于控制分裂时的分裂标准，默认值为`'friedman_mse'`。该参数决定了如何选择每个节点的最佳划分方式，可选的值有：\n    - `'friedman_mse'`：这个准则是基于均方误差（MSE）的一个改进版本，旨在减小对不平衡数据的敏感性，并且在一些实际任务中，能够比传统的 MSE 产生更好的结果。\n    - `'mse'`：使用传统的均方误差（MSE）来评估每个分裂点的质量，MSE 越小，说明当前节点的分裂越好。在分类任务中，使用 `'friedman_mse'` 往往能取得更好的效果。\n    - `'mae'`：使用平均绝对误差（MAE）来评估分裂的质量，MAE 对异常值不那么敏感，但在实际应用中通常较少使用。\n6. `validation_fraction`：用于指定训练过程中的验证集比例，用于执行早期停止（early stopping），避免过拟合。该参数可与 `n_iter_no_change` 配合使用，在验证集上评估性能，当连续若干轮没有改进时，提前停止训练。\n\n除了上面提到的超参数外，还有一些跟决策树类似的超参数，此处就不再进行赘述了。需要注意的是，增加 `n_estimators`（树的数量）时，通常需要减小 `learning_rate`以防过拟合；调整决策树的`max_depth`和`min_samples_split`也可以减小树的复杂度来防止过拟合；用好`subsample`和`early_stopping`参数也可以达成类似的效果。建议大家通过网格搜索交叉验证的方式，结合模型的训练误差和验证误差来寻找最佳参数组合。\n\n### XGBoost\n\n从算法精度、速度和泛化能力等性能指标来看GBDT，仍然有较大的优化空间。XGBoost（eXtreme Gradient Boosting）正是一种基于 GBDT 的顶级梯度提升模型，由陈天奇在其论文[《*XGBoost: A Scalable Tree Boosting System*》](https://arxiv.org/pdf/1603.02754)中提出。相较于 GBDT，从算法精度上看，XGBoost 通过将损失函数展开到二阶导数，使得梯度提升树模型更能逼近其真实损失；从算法速度上看，XGBoost 使用了加权分位数 sketch 和稀疏感知算法这两个技巧，通过缓存优化和模型并行来提高算法速度；从算法泛化能力上来看，通过对损失函数加入正则化项、加性模型中设置缩减率和列抽样等方法，来防止模型过拟合。因为上述原因，XGBoost 不论在学术界、工业界和竞赛圈都很受欢迎，有着广泛的应用。关于 XGBoost 的细节，有兴趣的读者可以阅读陈天奇的论文，此处不进行展开介绍。\n\n我们可以下面的方式来使用 XGBoost，首先安装依赖项。\n\n```bash\npip install xgboost\n```\n\n下面的代码为大家展示了如何使用 XGBoost。\n\n```python\nimport matplotlib.pyplot as plt\nimport xgboost as xgb\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\n\n# 数据集的加载和划分\niris = load_iris()\nX, y = iris.data, iris.target\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=3)\n\n# 将数据处理成数据集格式DMatrix格式\ndm_train = xgb.DMatrix(X_train, y_train)\ndm_test = xgb.DMatrix(X_test)\n\n# 设置模型参数\nparams = {\n    'booster': 'gbtree',           # 用于训练的基学习器类型\n    'objective': 'multi:softmax',  # 指定模型的损失函数\n    'num_class': 3,                # 类别的数量\n    'gamma': 0.1,                  # 控制每次分裂的最小损失函数减少量\n    'max_depth': 6,                # 决策树最大深度\n    'lambda': 2,                   # L2正则化权重\n    'subsample': 0.8,              # 控制每棵树训练时随机选取的样本比例\n    'colsample_bytree': 0.8,       # 用于控制每棵树或每个节点的特征选择比例\n    'eta': 0.001,                  # 学习率\n    'seed': 10,                    # 设置随机数生成器的种子\n    'nthread': 16,                 # 指定了训练时并行使用的线程数\n}\n\n# 训练模型\nmodel = xgb.train(params, dm_train, num_boost_round=200)\n# 预测结果\ny_pred = model.predict(dm_test)\n\n# 输出模型评估报告\nprint(classification_report(y_test, y_pred))\n\n# 绘制特征重要性评分\nxgb.plot_importance(model)\nplt.grid(False)\nplt.show()\n```\n\n输出的特征重要性如下图所示。\n\n<img class=\"lazy\" data-src=\"/res/07_features_importance.png\" style=\"zoom:45%;\">\n\n我们再说说这个 XGBoost 的模型参数， 先看看上面代码中的`param`字典，有几个参数需要详细说明一下。\n\n1. `booster`：指定用于训练的基学习器类型，默认值为 `'gbtree'`，表示使用传统的决策树作为基学习器；其他的选项包括 `'gblinear'`和`'dart'`，前者表示使用线性回归或逻辑回归，后者也是基于决策树的模型，但具有丢弃树的机制，降低过拟合风险。通常`'gbtree'`适用于大多数问题，尤其涉及到非线性关系；`'dart'`适用于复杂数据集，尤其是在出现过拟合时。如果数据集较小或线性关系较强，可以尝试使用 `'gblinear'`。\n2. `objective`：指定模型的损失函数（优化目标），常见的选项包括：\n    - `'reg:squarederror'`：回归任务中的均方误差（MSE），用于回归任务。\n    - `'reg:logistic'`：回归任务中的逻辑回归，通常用于二分类任务。\n    - `'binary:logistic'`：二分类任务中的逻辑回归，输出概率值。\n    - `'binary:logitraw'`：二分类任务中的逻辑回归，输出未经过 Sigmoid 处理的原始值。\n    - `'multi:softmax'`：多分类任务，输出为每个类别的最大概率。\n    - `'multi:softprob'`：多分类任务，输出为每个类别的概率分布。\n3. `eta`/`learning_rate`：XGBoost 中的学习率，默认值为 0.3，推荐将初始值设置为 0.01 到 0.1。\n4. `alpha`和`lambda`：前者控制 L1 正则化项（Lasso）的强度，默认为 `0`；后者控制 L2 正则化项（Ridge）的强度，默认为 `1`。\n5. `scale_pos_weight`：用于处理类别不平衡问题，尤其是二分类问题。在类别严重不平衡的情况下，通过调整这个参数来加大少数类的权重，使得模型更关注少数类样本，默认值为 1。\n6. `gamma`：用来控制每次分裂的最小损失函数减少量，该参数控制树的生长，越大的 `gamma` 会使得树更小，减小过拟合的风险，默认值为 0，意味着模型不会受到分裂的限制，树会尽可能深，直到节点中没有足够的样本。\n7. `num_class`：用于多分类任务的参数，表示类别的数量。对于二分类任务，无需设置该参数。\n8. `colsample_bytree` / `colsample_bylevel` / `colsample_bynode`：控制在每棵树、每一层、每个节点上采样特征的比例。这些参数用于控制模型的复杂度。较小的值会增加模型的随机性，从而防止过拟合；较大的值则意味着每棵树使用更多的特征，可能导致过拟合。\n    - `colsample_bytree`：每棵树使用的特征比例（默认为 1.0）。\n    - `colsample_bylevel`：每一层使用的特征比例（默认为 1.0）。\n    - `colsample_bynode`：每个节点使用的特征比例（默认为 1.0）。\n\n除了`param`字典提供的模型参数外，`train`函数还有几个参数也值得注意，它们也是模型的超参数。\n\n1. `num_boost_round`：树的训练轮数，设置较小的`learning_rate`并增加训练轮数可以提高模型的稳定性。\n2. `early_stopping_rounds`：用于实现早期停止机制。当指定轮次的训练中，验证集上的损失函数不再减少时，训练会自动停止，避免过拟合。\n3. `feval`：设置用户自定义的评估函数，这种方式允许用户灵活地使用任何适合特定任务的评估指标，需要注意的是评估函数有两个参数，一个表示模型预测值（NumPy 的`ndarray`对象），一个是训练数据（XGBoost 的`DMatrix`对象）；函数返回一个二元组`(name, value)`，其中 `name` 是评估指标的名称，`value` 是指标的值。\n4. `obj`：设置用户自定义的目标函数，目标函数用于计算每一步的梯度和二阶导数，从而指导模型的优化过程，有兴趣的读者可以自行研究。\n5. `evals`：用于指定一个或多个验证集，其值是包含一个或多个`(data, label)` 元组的列表，每个元组代表一个评估数据集，数据集需要是`DMatrix`对象。在训练过程中，XGBoost 会在每一轮迭代后评估验证集上的性能，通常用于监控训练过程中的过拟合或调整超参数。\n6. `eval_results`：存储在训练过程中计算的所有评估结果，通常传入一个字典。\n7. `verbose_eval`：控制训练过程中评估结果的输出频率，可以设置为一个整数，表示多少轮迭代输出一次评估结果，也可以设置为`True`或`False`，表示每轮都输出或不输出任何评估结果。\n8. `xgb_model`：用于加载之前训练好的模型，以便从中断点继续训练。你可以指定一个 `xgb_model` 文件或者传入一个 `Booster` 对象。\n9. `callbacks`：在训练过程中添加自定义的回调函数，回调函数可以在每一轮迭代时提供额外的控制，如自动停止训练、调整学习。\n\n### LightGBM\n\nLightGBM（Light Gradient Boosting Machine）是微软于2017年开源的一款顶级 Boosting 算法框架，虽然本质仍然是 GBDT 算法，但被设计用于大规模数据集的处理，特别是在需要高效率和低内存消耗的场景下。就 GBDT 系列算法性能而言，XGBoost 已经非常高效了，但并非没有缺陷。LightGBM 就是一种针对 XGBoost 缺陷的改进版本，通过直方图算法（通过将连续特征分箱）、单边梯度抽样（GOSS，通过采样方法在训练过程中保留梯度较大的样本，减少计算量）、互斥特征捆绑（EFB，将一些互斥特征做组合，减少特征空间的维度）和 leaf-wise 生长策略（优先对当前叶子节点进行分裂来扩展树的深度）四个方法，使得 GBDT 算法系统更轻便、更高效，能够做到又快又准。当然，在较小的数据集上，LightGBM 的优势并不明显，而且不管是 XGBoost 还是 LightGBM，模型的可解释性都是一个问题，超参数调优的难度也是比较大的。\n\n这里，我们不再使用更多的篇幅去讲解 LightGBM 的细节，感兴趣的小伙伴可以直接访问 LightGBM 的[官方文档](https://lightgbm.readthedocs.io/en/stable/index.html)。我们直接通过代码带大家简单感受一下如何使用 LightGBM，首先还是需要通过下面的命令完成安装。\n\n```bash\npip install lightgbm\n```\n\n我们仍然使用鸢尾花数据集来训练模型，代码如下所示。\n\n```python\nimport lightgbm as lgb\nimport numpy as np\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\n\n# 加载和划分数据集\niris = load_iris()\nX, y = iris.data, iris.target\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=3)\n\n# 将数据转化为 LightGBM 的数据格式\ntrain_data = lgb.Dataset(X_train, label=y_train)\ntest_data = lgb.Dataset(X_test, label=y_test, reference=train_data)\n\n# 设置模型参数\nparams = {\n    'objective': 'multiclass',   # 多分类问题\n    'num_class': 3,              # 类别数量\n    'metric': 'multi_logloss',   # 多分类对数损失函数\n    'boosting_type': 'gbdt',     # 使用梯度提升树算法\n    'num_leaves': 31,            # 叶子节点数\n    'learning_rate': 0.05,       # 学习率\n    'feature_fraction': 0.75,    # 每次训练时随机选择特征的比例\n    'early_stopping_rounds': 10  # 连续多少论没有性能提升就停止迭代\n}\n# 模型训练\nmodel = lgb.train(params=params, train_set=train_data, num_boost_round=200, valid_sets=[test_data])\n# 模型预测\ny_pred = model.predict(X_test, num_iteration=model.best_iteration)\n# 将预测结果处理成标签\ny_pred_max = np.argmax(y_pred, axis=1)\n\n# 查看模型评估报告\nprint(classification_report(y_test, y_pred_max))\n```\n\n这里还是简单为大家讲讲模型的超参数，更多的细节大家可以参考官方文档。\n\n1. `objective`：设置优化目标函数（损失函数），可选值有：\n    - `'regression'`：回归任务。\n    - `'binary'`：二分类任务。\n    - `'multiclass'`：多分类任务。\n    - `'multiclassova'`：多分类任务，使用一对多的策略。\n    - `'rank_xendcg'`、`'lambdarank'`：排名任务。\n2. `metric`：评估模型性能的指标，可选值有：\n    - `'l2'`、`'mean_squared_error'`：回归任务中的均方误差。\n    - `'binary_error'`：二分类错误率。\n    - `'multi_logloss'`：多分类对数损失。\n    - `'auc'`：二分类任务中的 AUC。\n    - `'precision'`、`'recall'`、`'f1'`：精度、召回率、F1分数。\n3. `boosting_type`：设置提升类型，可选值有：\n    - `'gbdt'`：传统的梯度提升树。\n    - `'dart'`：具有随机丢弃树机制来防止过拟合的决策树。\n    - `'goss'`：通过单边梯度抽样来加速训练。\n    - `'rf'`：随机森林。\n4. `num_leaves`/`max_depth`：决策树的叶子节点数 / 决策树的最大深度，控制树的复杂度。\n5. `lambda_l1`/`lambda_l2`：L1 和 L2 正则化参数，用于控制模型的复杂度，防止过拟合。\n6. `max_bin`： 用于分割连续特征（数据分箱）的最大箱子数。\n7. `feature_fraction`：每次训练时随机选择特征的比例。\n8. `early_stopping_rounds`： 设置评估指标在连续多少轮迭代中没有改进时，训练会提前停止。\n\n### 总结\n\n集成学习通过结合多个模型来减少模型的偏差和方差，通常能获得比单一模型更好的预测效果。由于集成学习通常结合多个基础模型，它能够有效降低单一模型可能存在的过拟合问题，也能够处理异常数据和噪声数据，比单一模型更加稳定。当然，集成学习也存在计算开销大、模型可解释性差、超参数调优复杂等问题。除了 XGBoost 和 LightGBM 之外，还有一个因处理类别特征而闻名的 Boosting 算法叫做 CatBoost，三者都是 GBDT 系列算法的佼佼者。虽然目前“大力出奇迹”的深度学习大行其道，但是以 XGBoost、LightGBM 和 CatBoost 为代表的 Boosting 算法仍然有广阔的应用场景，即便是在非结构化数据（文本、语音、图像、视频）的建模上也是有用武之地的。\n\n\n\n", "神经网络模型": "## 神经网络模型\n\n在人类的大脑中，神经元（neuron）是负责信息传递和处理的单元，神经元通过化学信号和电信号进行交流，这是人类记忆、感觉、运动等功能的基础。神经元包含了轴突（axon）和树突（dendrite），树突负责接收信号，轴突负责发送信号，此外细胞体也是神经元的重要部分，起到整合和传递信息的作用。神经元之间的连接通过突触（synapse）传递化学信号或电信号来实现，一个神经元可能会与成千上万个神经元连接，构成错综复杂的神经网络。人在刚出生时，大脑中有约 860 亿神经元，大部分神经元是不会再生的，所以这个数字会随着年龄的增长而略为减少。新生儿的大脑拥有数量极其庞大的突触连接，为未来的学习和适应奠定基础。\n\n很多科普文章都宣传神经网络模型是模拟人脑神经元的计算模型，通过多层神经元连接来完成复杂的非线性映射，但是没有证据表明大脑的学习机制与神经网络模型机制相同。虽然神经网络这个术语来自于神经生物学，深度学习中的一些概念也是从人类对大脑的理解中汲取灵感而形成的，但是对新手来说，如果认为神经网络与神经生物学存在某种联系，只会让人变得更加困惑。\n\n### 基本构成\n\n神经网络一般由多个层组成，通常包括输入层、隐藏层和输出层。每层中的神经元与前一层的神经元相连接，通过权重调整和激活函数的作用，逐层传递和处理数据，最终完成复杂数据的特征提取和学习。\n\n1. **输入层**：输入层神经元接收输入数据，每个神经元通常对应一个输入特征。输入层的任务是将输入数据传递给下一层的神经元。\n2. **隐藏层**：隐藏层是网络的核心部分，负责对数据进行特征提取和处理。隐藏层可以有一层或多层，每层的神经元通过权重和激活函数来进行数据处理。深度神经网络通常会包含多层隐藏层，这样能够提取数据中的高阶特征。\n3. **输出层**：输出层负责将隐藏层的结果转换为最终输出。输出层的激活函数通常与问题类型有关，例如二分类任务可能用 Sigmoid 函数以获得概率，而回归任务则可能直接输出数值。\n4. **神经元**：每个神经元都接收来自前一层神经元的输入，进行加权求和，再通过激活函数计算输出。\n\n<img class=\"lazy\" data-src=\"/res/08_neural-network-diagram.webp\" style=\"zoom:80%;\">\n\n神经网络的训练过程通常通过反向传播算法（Backpropagation）和梯度下降法来优化权重，以减少预测误差。深度神经网络通过多层非线性转换能够学习到更加复杂的特征表示，因此在许多任务中表现优异。\n\n### 工作原理\n\n我们先设计一个最简单的神经网络模型，它只有一层输入和一层输出，该模型会根据输入（ $\\small{X}$ ）去预测输出（ $\\small{y}$ ），而输出又满足下面的公式：\n\n$$\ny = aX_{1} + bX_{2} + cX_{3} + d\n$$\n\n其中， $\\small{a, b, c, d}$ 都是模型的参数（权重和偏置），那么我们的神经网络模型应该是如下图所示的结构。\n\n<img class=\"lazy\" data-src=\"/res/08_one_layer_nn.png\" style=\"zoom:55%;\">\n\n大家可能已经发现，这个最简单的神经网络模型跟线性回归根本没有区别，但是我们在输入层和输出层中间再加上一个隐藏层又会怎样呢？看看下面的图，是不是已经有一点“网络”的味道了，加入的隐藏层可以处理非线性关系，而且隐藏层可以有多个，层与层之间连接的方式可以是全连接或部分连接，甚至可以出现环形结构。上面我们也说过，引入非线性能够让模型学习到更加复杂的特征表示，这也是神经网络模型在很多任务中表现优异的原因。\n\n<img class=\"lazy\" data-src=\"/res/08_multi_layer_nn.png\" style=\"zoom:58%;\">\n\n接下来，我们看看神经网络的工作原理。每个神经元的计算过程可以表示为：\n\n$$\ny = f \\left( \\sum_{i=1}^{n}w_{i}x_{i} + b \\right)\n$$\n\n其中， $\\small{x_{1}, x_{2}, \\dots, x_{n}}$ 是输入特征， $\\small{w_1, w_2, \\dots, w_n}$ 是与输入对应的权重； $\\small{b}$ 是偏置项； $\\small{f}$ 是激活函数，通常是非线性函数，如 Sigmoid、ReLU、Tanh 等。激活函数一个方面是引入非线性变换，增加了神经网络的表达能力，使得它可以模拟任意复杂的函数关系；另一方面，在训练神经网络时会使用反向传播来更新权重，激活函数的非线性属性使得梯度传递更有效，让神经网络收敛得更快，提高训练效率。下面我们对常用的激活函数做一个简要的介绍。\n\n1. Sigmoid 函数\n  \n$$\nf(x) = \\frac{1}{1 + e^{-x}}\n$$\n\n<img class=\"lazy\" data-src=\"/res/08_sigmoid_function.png\" style=\"zoom:62%;\">\n    \n- **特点**：Sigmoid 函数将输入值映射到 $\\small{(0, 1)}$ 的范围内，呈现出平滑的 S 型曲线。\n- **优点**：特别适用于概率预测，因为输出在 $\\small{(0, 1)}$ 之间，可以理解为概率值。\n- **缺点**：对于较大的正值或负值，梯度会变得很小，导致梯度消失问题，从而影响深层网络的训练。除此以外，由于输出非零中心，这会导致梯度更新不对称，可能使得收敛变慢。\n\n2. Tanh 函数（双曲正切函数）\n\n$$\nf(x) = tanh(x) = \\frac{e^{x} - e^{-x}}{e^{x} + e^{-x}}\n$$\n\n<img class=\"lazy\" data-src=\"/res/08_tanh_function.png\" style=\"zoom:62%;\" />\n    \n- **特点**：Tanh 函数将输入映射到 $\\small{(-1, 1)}$ 的范围内，也是 S 型曲线，但中心对称。\n- **优点**：与 Sigmoid 类似，但输出在 $\\small{(-1, 1)}$ 之间，这样的零中心输出使得梯度更新更对称，更适合用于深层网络。\n- **缺点**：在极值附近，梯度仍会趋向于零，导致梯度消失问题。\n\n3. ReLU 函数（Rectified Linear Unit）\n\n$$\nf(x) = max(0, x)\n$$\n\n- **特点**：ReLU 将输入小于零的部分设为零，而大于零的部分保持不变，因此其输出范围是 $\\small{[0, +\\infty]}$ 。\n- **优点**：计算简单，有效避免了梯度消失问题，因此被广泛应用于深层网络。能够保持稀疏性，许多神经元的输出为零，有利于网络简化计算。\n- **缺点**：当输入为负数时，ReLU 的梯度为零。若输入长期为负数，神经元可能“死亡”并停止更新。\n\n4. Leaky ReLU 函数\n\n$$\nf(x) = \\begin{cases} x & (x \\gt 0) \\\\\\\\ {\\alpha}x & (x \\le 0)\\end{cases}\n$$\n\n- **特点**：Leaky ReLU 是对 ReLU 的改进，它为输入小于零的部分引入了一个小的负斜率（通常取值 $\\small{\\alpha = 0.01}$ ），使得梯度不为零。\n- **优点**：通过允许负值的输出，避免了死神经元问题，使得网络更健壮。\n- **缺点**：虽然 Leaky ReLU 能缓解死神经元问题，但其负值斜率的选择对网络性能会有一些影响，且对模型的非线性表示能力没有显著提升。\n\n在一个包含多个层的神经网络中，信息会一层一层的进行传递。假设第 $\\small{l}$ 层的输出是 $\\small{\\mathbf{a}^{[l]}}$  ，按照上面神经元计算公式，有：\n\n$$\n\\mathbf{a}^{[l]} = f \\left( \\mathbf{W}^{[l]} \\mathbf{a}^{[l-1]} + \\mathbf{b}^{[l]} \\right)\n$$\n\n其中， $\\small{\\mathbf{W}^{[l]}}$ 是第 $\\small{l}$ 层的权重矩阵， $\\small{\\mathbf{a}^{[l-1]}}$ 是是第 $\\small{l - 1}$ 层的输出， $\\small{\\mathbf{b}^{[l]}}$ 是第 $\\small{l}$ 层的偏置项， $\\small{f}$ 是激活函数。神经网络最终的输出是通过最后一层的激活函数得到的，这个过程叫做前向传播（forward-propagation）。\n\n对于神经网络模型来说，还有一个极其重要的操作就是通过计算损失函数相对于每个权重和偏置的梯度来更新神经网络的参数（权重和偏置），这一过程通常称为反向传播（back-propagation）。反向传播有两个要点，一个是损失函数，一个是梯度下降法，前者用于衡量预测值与真实值之间的差距，常用的损失函数有均方误差（回归任务）和交叉熵损失函数（分类任务），后者通过更新参数 $\\small{\\theta}$（权重和偏置)，使得损失函数最小化，即：\n\n$$\n\\theta^{\\prime} = \\theta - \\eta \\nabla L(\\theta) \\\\\\\\\n\\theta = \\theta^{\\prime}\n$$\n\n其中， $\\small{\\eta}$ 是学习率， $\\small{\\nabla L(\\theta)}$ 是损失函数相对于参数的梯度，跟我们讲解回归模型时使用的方法是一致的。\n\n### 代码实现\n\n根据上面讲到的神经网络模型的原理，要自己写一个简单的神经网络模型也并不困难。当然，我们也可以用 scikit-learn 库`neural_network` 模块来构建神经网络模型。下面，我们仍然以鸢尾花数据集为例，为大家展示神经网络模型的构建和预测效果。\n\n```python\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.metrics import classification_report\n\n# 加载和划分数据集\niris = load_iris()\nX, y = iris.data, iris.target\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=3)\n\n# 创建多层感知机分类器模型\nmodel = MLPClassifier(\n    solver='lbfgs',            # 优化模型参数的求解器\n    learning_rate='adaptive',  # 学习率的调节方式为自适应 \n    activation='relu',         # 隐藏层中神经元的激活函数 \n    hidden_layer_sizes=(1, )   # 每一层神经元的数量\n)\n# 训练和预测\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\n\n# 查看模型评估报告\nprint(classification_report(y_test, y_pred))\n```\n\n输出：\n\n```\n              precision    recall  f1-score   support\n\n           0       1.00      0.10      0.18        10\n           1       0.00      0.00      0.00        10\n           2       0.34      1.00      0.51        10\n\n    accuracy                           0.37        30\n   macro avg       0.45      0.37      0.23        30\nweighted avg       0.45      0.37      0.23        30\n```\n\n> **注意**：由于创建`MLPClassifier`时没有指定`random_state`参数，所以代码每次执行的结果可能并不相同。\n\n模型的预测准确率只有`0.37`，大家对这个结果是不是感觉到非常失望，我们煞费苦心构建的模型预测效果竟然如此拉胯。别紧张，上面代码中我们创建神经网络模型时，`hidden_layer_sizes`参数设置的是`(1, )`，它表示我们的网络只有 1 个隐藏层，而且隐藏层只有 1 个神经元，这个神经元承受了太多（它真的，我哭死）。接下俩，我们需要增加隐藏层和神经元的数量，让模型可以更好的学习特征和目标之间的映射关系，这样预测的效果就会好起来。下面，我们将`hidden_layer_sizes`参数调整为`(32, 32, 32)`，即模型有三个隐藏层，每层有 32 个神经元，再来看看代码执行的结果。\n\n```python\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.metrics import classification_report\n\n# 加载和划分数据集\niris = load_iris()\nX, y = iris.data, iris.target\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=3)\n\n# 创建多层感知机分类器模型\nmodel = MLPClassifier(\n    solver='lbfgs',                  # 优化模型参数的求解器\n    learning_rate='adaptive',        # 学习率的调节方式为自适应 \n    activation='relu',               # 隐藏层中神经元的激活函数 \n    hidden_layer_sizes=(32, 32, 32)  # 每一层神经元的数量\n)\n# 训练和预测\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\n\n# 查看模型评估报告\nprint(classification_report(y_test, y_pred))\n```\n\n> **说明**：大家可以试着运行上面的代码，看看有没有获得更好的结果。当然，模型准确率为 1 也未必就值得高兴，因为你可能训练了一个过拟合的模型。无论如何，大家可以试着重新设置`hidden_layer_sizes`参数，看看会得到怎样的结果。\n\n下面，我们还是对`MLPClassifier`几个比较重要的超参数做一个说明。\n\n1. `hidden_layer_sizes`：指定神经网络中每一层的神经元数目，元组类型，默认值为`(100, )`，表示只有一个隐藏层，包含 100 个神经元。该超参数可以改变网络的结构和容量，层数越多，神经元数目越多，模型的表示能力就越强，但也存在过拟合风险。\n2. `activation`：隐藏层中神经元的激活函数，默认值为`relu`，表示使用 ReLU 激活函数。激活函数决定了网络每一层的输出形态，一般来说，`'relu'` 是训练深度网络时的首选，因为它能够缓解梯度消失问题，并且训练速度较快，可选值包括：\n    - `'identity'`：线性激活函数，即 $\\small{f(x) = x}$ ，通常不推荐使用。\n    - `'logistic'` / `'tanh'` / `'relu'`：Sigmoid / 双曲正切 / ReLU 激活函数。\n3. `solver`：用来优化模型参数的求解器（优化算法）。常用的优化算法有：\n    - `'lbfgs'`：拟牛顿法（Limited-memory Broyden-Fletcher-Goldfarb-Shanno），这种方法计算复杂度较高，但对小数据集表现较好。\n    - `'sgd'`：随机梯度下降（Stochastic Gradient Descent），适用于大规模数据集，在训练时会随机选取小批量数据进行更新。\n    - `'adam'`：自适应矩估计（Adaptive Moment Estimation），默认值，适用于大多数情况且计算效率较高。\n4. `alpha`：L2 正则化项（也称为权重衰减），控制神经网络的复杂度，默认值为`0.0001`。\n5. `batch_size`：每次迭代所用的样本批量大小，默认值为`'auto'`，根据样本数量自动决定批量大小。较小的批量会使训练更加不稳定，但有助于避免陷入局部最优解；较大的批量则可以加速训练，但可能导致内存不足。\n6. `learning_rate`：学习率的调节方式，影响模型在每次迭代时调整权重的步长，默认值为`'constant'`，表示学习率保持不变。其他可选的值有`'invscaling'`和`'adaptive'`，前者表示学习率随着迭代次数的增加而逐步减小，后者表示学习率会根据当前梯度变化自动调整，当梯度更新较小时学习率会增加，当梯度较大时学习率会减小。\n7. `learning_rate_init`：初始学习率，默认值为`0.001`。\n8. `max_iter`：最大迭代次数，控制训练过程中优化算法的最大迭代次数，默认值为`200`。若达到最大迭代次数后模型仍未收敛，训练将停止。这对于防止过长时间训练是有用的，但过小的值可能会导致训练中止太早，导致欠拟合。\n9. `tol`：训练过程中的优化容忍度，决定了当目标函数变化小于该值时训练停止，默认值为`0.0001`。较小的 `tol` 会导致更长的训练时间，较大的 `tol` 可能会提前停止训练。\n\n除了 scikit-learn 库，我们还可以使用 TensorFlow、PyTorch、MXNet 等三方库来实现神经网络模型，这些库很多都支持 GPU（图形处理单元） 或 TPU（张量处理单元） 加速，而且内置很多深度网络模型（如卷积神经网络、循环神经网络、生成对抗网络等）以及相应的优化器，相较于 scikit-learn，这些库可能是更好的选择。对此感兴趣的小伙伴，可以看看下面的代码，我们用 PyTorch 构建了神经网络模型来解决鸢尾花分类问题。\n\n```python\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom sklearn import datasets\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# 加载鸢尾花数据集\niris = datasets.load_iris()\nX, y = iris.data, iris.target\n\n# 数据预处理（标准化）\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n# 划分训练集和测试集\nX_train, X_test, y_train, y_test = train_test_split(X_scaled, y, train_size=0.8, random_state=3)\n# 将数组转换为PyTorch张量\nX_train_tensor, X_test_tensor, y_train_tensor, y_test_tensor = (\n    torch.tensor(X_train, dtype=torch.float32),\n    torch.tensor(X_test, dtype=torch.float32),\n    torch.tensor(y_train, dtype=torch.long),\n    torch.tensor(y_test, dtype=torch.long)\n)\n\n\nclass IrisNN(nn.Module):\n    \"\"\"鸢尾花神经网络模型\"\"\"\n\n    def __init__(self):\n        \"\"\"初始化方法\"\"\"\n        # 调用父类构造器\n        super(IrisNN, self).__init__()\n        # 输入层到隐藏层（4个特征到32个神经元全连接）\n        self.fc1 = nn.Linear(4, 32)\n        # 隐藏层到输出层（32个神经元到3个输出全连接）\n        self.fc2 = nn.Linear(32, 3)\n\n    def forward(self, x):\n        \"\"\"前向传播\"\"\"\n        # 隐藏层使用ReLU激活函数\n        x = torch.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x\n\n\n# 创建模型实例\nmodel = IrisNN()\n# 定义损失函数（交叉熵损失函数）\nloss_function = nn.CrossEntropyLoss()\n# 使用Adam优化器（大多数任务表现较好）\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\n# 训练模型（迭代256个轮次）\nfor _ in range(256):\n    model.train()\n    # 清除上一次的梯度\n    optimizer.zero_grad()\n    # 计算输出\n    output = model(X_train_tensor)\n    # 计算损失\n    loss = loss_function(output, y_train_tensor)\n    # 反向传播\n    loss.backward()\n    # 更新权重\n    optimizer.step()\n\n# 评估模型\nmodel.eval()\nwith torch.no_grad():\n    output = model(X_test_tensor)\n    # 获取预测得分最大值的索引（预测标签）\n    _, y_pred_tensor = torch.max(output, 1)\n    # 计算并输出预测准确率\n    print(f'Accuracy: {accuracy_score(y_test_tensor, y_pred_tensor):.2%}')\n    # 输出分类模型评估报告\n    print(classification_report(y_test_tensor, y_pred_tensor))\n```\n\n> **说明**：如果还没有安装 PyTorch 库，可以使用命令`pip install torch`进行安装。\n\n我们也可以通过神经网络模型来处理回归任务，这里仍然以之前讲回归模型时使用过的“汽车 MPG 数据集”为例，演示如何通过构造神经网络模型解决回归任务，完整的代码如下所示。\n\n```python\nimport ssl\n\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\nssl._create_default_https_context = ssl._create_unverified_context\n\n\ndef load_prep_data():\n    \"\"\"加载准备数据\"\"\"\n    df = pd.read_csv('https://archive.ics.uci.edu/static/public/9/data.csv')\n    # 对特征进行清洗\n    df.drop(columns=['car_name'], inplace=True)\n    df.dropna(inplace=True)\n    df['origin'] = df['origin'].astype('category')\n    df = pd.get_dummies(df, columns=['origin'], drop_first=True).astype('f8')\n    # 对特征进行缩放\n    scaler = StandardScaler()\n    return scaler.fit_transform(df.drop(columns='mpg').values), df['mpg'].values\n\n\nclass MLPRegressor(nn.Module):\n    \"\"\"神经网络模型\"\"\"\n\n    def __init__(self, n):\n        super(MLPRegressor, self).__init__()\n        self.fc1 = nn.Linear(n, 64)\n        self.fc2 = nn.Linear(64, 64)\n        self.fc3 = nn.Linear(64, 1)\n\n    def forward(self, x):\n        x = torch.relu(self.fc1(x))\n        x = torch.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n\n\ndef main():\n    # 加载和准备数据集\n    X, y = load_prep_data()\n    # 划分训练集和测试集\n    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=3)\n    # 将数据转为PyTorch的Tensor\n    X_train_tensor, X_test_tensor, y_train_tensor, y_test_tensor = (\n        torch.tensor(X_train, dtype=torch.float32),\n        torch.tensor(X_test, dtype=torch.float32),\n        torch.tensor(y_train, dtype=torch.float32).view(-1, 1),\n        torch.tensor(y_test, dtype=torch.float32).view(-1, 1)\n    )\n\n    # 实例化神经网络模型\n    model = MLPRegressor(X_train.shape[1])\n    # 指定损失函数（均方误差）\n    criterion = nn.MSELoss()\n    # 指定优化器（Adam优化器）\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    # 模型训练\n    epochs = 256\n    for epoch in range(epochs):\n        # 前向传播\n        y_pred_tensor = model(X_train_tensor)\n        loss = criterion(y_pred_tensor, y_train_tensor)\n        # 反向传播\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        if (epoch + 1) % 16 == 0:\n            print(f'Epoch [{epoch + 1} / {epochs}], Loss: {loss.item():.4f}')\n\n    # 模型评估\n    model.eval()\n    with torch.no_grad():\n        y_pred = model(X_test_tensor)\n        test_loss = mean_squared_error(y_test, y_pred.numpy())\n        r2 = r2_score(y_test, y_pred.numpy())\n    print(f'Test MSE: {test_loss:.4f}')\n    print(f'Test R2: {r2:.4f}')\n\n\nif __name__ == '__main__':\n    main()\n```\n\n输出：\n\n```\nEpoch [16 / 256], Loss: 588.2971\nEpoch [32 / 256], Loss: 530.0340\nEpoch [48 / 256], Loss: 429.9081\nEpoch [64 / 256], Loss: 286.5121\nEpoch [80 / 256], Loss: 133.6717\nEpoch [96 / 256], Loss: 44.3843\nEpoch [112 / 256], Loss: 30.3168\nEpoch [128 / 256], Loss: 24.0182\nEpoch [144 / 256], Loss: 19.5326\nEpoch [160 / 256], Loss: 16.4941\nEpoch [176 / 256], Loss: 14.2642\nEpoch [192 / 256], Loss: 12.5515\nEpoch [208 / 256], Loss: 11.2248\nEpoch [224 / 256], Loss: 10.1825\nEpoch [240 / 256], Loss: 9.3600\nEpoch [256 / 256], Loss: 8.7116\nTest MSE: 8.7226\nTest R2: 0.8569\n```\n\n通过上面的输出可以看到，随着神经网络模型不断的前向传播和反向传播，损失变得越来越小，模型的拟合变得越来越好。在预测的时候，我们利用训练得到的模型参数进行一次正向传播，就完成了从特征到目标值的映射，评估回归模型的两个指标 MSE 和 $\\small{R^{2}}$ 看起来还不错哟。目前，神经网络被广泛应用于模式识别、图像处理、语音识别等领域，是深度学习中最核心的技术。对深度学习有兴趣的读者，可以关注我的另一个项目[“深度学习就是大力出奇迹”](https://github.com/jackfrued/Deep-Learning-Is-Nothing)，目前该项目仍然在创作更新中。\n\n### 模型优缺点\n\n神经网络模型最可爱的一点就是可以像搭积木一样不断的扩展模型边界，对于模型内部具体的运行则不需要加以太多的干涉。神经网络能够学习和拟合非常复杂的映射关系，能够根据输入数据自动调整其结构和参数，因此具有较强的适应性。当面临不同类型的数据或任务时，神经网络可以通过调整网络的结构（层数、节点数等）来适应不同的需求，只要数据量足够大、算力足够强，最终都会得到一个不错的结果，表现常常优于传统的机器学习算法，这就是我们常说的“大力出奇迹”。此外，大家耳熟能详的深度学习一词中的“深度”二字，指的就是神经网络模型的层次具备了足够的深度，我们也通常把这样的神经网络称为深度神经网络（DNN）。\n\n神经网络模型就像一个黑盒子，你给它数据它告诉你结果，至于为什么会出现这样的结果却缺乏可解释性。所以，在很多对模型的解释性要求非常高的场景（如信用评级、金融风控等），我们可能没有办法使用神经网络模型。再者，神经网络特别是深度神经网络需要大量的计算资源来训练，尤其是在处理高维数据时，训练时间和所需的计算资源可能非常庞大，需要强大的硬件支持，如高性能的图形处理单元（GPU）或专用硬件（TPU）。最后，也是我个人觉得神经网络模型最坑的一点是超参数调优过于困难，网络的层数、每层神经元的数量、学习率、激活函数的选择等都可能影响模型的性能，如果没有强大的计算资源作为支撑，很难完成超参数的调优，个人和小公司基本就被劝退了。\n\n### 总结\n\n神经网络模型使用了与传统机器学习算法不同的方式从海量数据中学习知识，尽管模型缺乏可解释性，但不能否认它在图像、语音和自然语言处理等多个领域已经取得了显著的成绩。当然，训练神经网络模型需要消耗大量的资源，在应用神经网络模型时建议权衡其优缺点，并根据具体的任务需求选择合适的模型和训练方法。对于那些数据量较小、需要可解释性或计算资源有限的场景，我们建议考虑使用传统的机器学习算法或者其他更轻量级的模型。\n", "自然语言处理入门": "## 自然语言处理入门\n\n自然语言处理（Natural Language Processing，NLP）是计算机科学和人工智能领域中的一个重要分支，旨在使计算机能够理解、生成和与人类语言进行交互。NLP 的应用场景广泛，包括文本分类、情感分析、机器翻译、语音识别、聊天机器人等。随着深度学习的迅猛发展，NLP 的研究也逐渐由传统的机器学习方法转向深度学习方法。经典的 NLP 方法依赖于特征工程和模型设计，而现代的深度学习方法则更多地依赖于数据驱动和自动特征学习。\n\n### 词袋模型\n\n词袋模型（Bag of Words）是 NLP 中最简单的文本表示方法之一，它将文本中的每个单词看作一个“词袋”，忽略了单词的顺序和语法，只考虑每个单词出现的频率。简单来说，词袋模型通过将文本转换为词频向量（TF）来表示文本。构造词袋模型有两个非常简单的步骤：\n\n1. **构建词汇表**：首先扫描所有文档，列出文本中所有的单词（重复的单词只保留一项），形成一个词汇表。\n2. **文本向量化**：将每个文档中的单词映射到词汇表中，并统计每个单词的出现次数，形成文档的向量表示。\n\n例如，有三个文档分别是：\n\n1. `I love programming.`\n2. `I love machine learning.`\n3. `I love apple.`\n\n那么，构造词汇表将得到：`['I', 'love', 'programming', 'machine', 'learning', 'apple']`。然后，将每个文档转换为词频向量，分别是：\n\n1. `[1, 1, 1, 0, 0, 0]`\n2. `[1, 1, 0, 1, 1, 0]`\n3. `[1, 1, 0, 0, 0, 1]`\n\nScikit-learn 库提供了构建词词袋模型的类`CountVectorizer`，使用的方法如下所示。\n\n```python\nfrom sklearn.feature_extraction.text import CountVectorizer\n\n# 文档列表\ndocuments = [\n    'I love programming.',\n    'I love machine learning.',\n    'I love apple.'\n]\n\n# 创建词袋模型\ncv = CountVectorizer()\nX = cv.fit_transform(documents)\n\n# 输出词汇表和词频向量\nprint('词汇表:\\n', cv.get_feature_names_out())\nprint('词频向量:\\n', X.toarray())\n```\n\n输出：\n\n```\n词汇表:  ['apple' 'learning' 'love' 'machine' 'programming']\n词频向量:\n[[0 0 1 0 1]\n [0 1 1 1 0]\n [1 0 1 0 0]]\n```\n\n> **注意**：上面的词汇表中没有单词`'I'`，因为这个单词被认为是停用词而忽略不计了。所谓停用词通常是指特定语言中高频出现但对文本分析任务贡献较小的词语。\n\n对于中文文档，需要利用三方库`jieba`进行中文分词处理，先将句子拆分为词，然后再构造词频向量，代码如下所示。\n\n```python\nimport jieba\nfrom sklearn.feature_extraction.text import CountVectorizer\n\n# 文档列表\ndocuments = [\n    '我在四川大学读书',\n    '四川大学是四川最好的大学',\n    '大学校园里面有很多学生',\n]\n\n# 创建词袋模型并指定分词函数\ncv = CountVectorizer(\n    tokenizer=lambda x: jieba.cut(x),\n    token_pattern=None\n)\nX = cv.fit_transform(documents)\n\n# 输出词汇表和词频向量\nprint('词汇表:\\n', cv.get_feature_names_out())\nprint('词频向量:\\n', X.toarray())\n```\n\n> **说明**：如果尚未安装中文分词库，可以通过命令`pip install jieba`进行安装。\n\n输出：\n\n```\n词汇表:\n ['四川' '四川大学' '在' '大学' '大学校园' '学生' '很多' '我' '是' '最好' '有' '的' '读书' '里面']\n词频向量:\n [[0 1 1 0 0 0 0 1 0 0 0 0 1 0]\n  [1 1 0 1 0 0 0 0 1 1 0 1 0 0]\n  [0 0 0 0 1 1 1 0 0 0 1 0 0 1]]\n```\n\n如果想去掉中文中常见的停用词，可以在创建`CountVectorizer`对象时指定`stop_words`参数，我们可以从中文停用词文件中加载停用词清单，代码如下所示。\n\n```python\nimport jieba\nfrom sklearn.feature_extraction.text import CountVectorizer\n\nwith open('哈工大停用词表.txt') as file_obj:\n    stop_words_list = file_obj.read().split('\\n')\n\n# 文档列表\ndocuments = [\n    '我在四川大学读书',\n    '四川大学是四川最好的大学',\n    '大学校园里面有很多学生',\n]\n\n# 创建词袋模型并指定分词函数\ncv = CountVectorizer(\n    tokenizer=lambda x: jieba.lcut(x),\n    token_pattern=None,\n    stop_words=stop_words_list\n)\nX = cv.fit_transform(documents)\n\n# 输出词汇表和词频向量\nprint('词汇表:\\n', cv.get_feature_names_out())\nprint('词频向量:\\n', X.toarray())\n```\n\n> **说明**：上面用到的中文停用词文件可以点击[传送门](https://github.com/goto456/stopwords)获得。\n\n输出：\n\n```\n词汇表:\n ['四川' '四川大学' '大学' '大学校园' '学生' '很多' '最好' '读书' '里面']\n词频向量:\n [[0 1 0 0 0 0 0 1 0]\n  [1 1 1 0 0 0 1 0 0]\n  [0 0 0 1 1 1 0 0 1]]\n```\n\n### 词向量\n\n与词袋模型不同，词向量（Word Embedding）将每个单词映射到一个稠密的向量空间中，从而使计算机能够理解和处理文本数据。这些向量通过捕捉单词之间的语义和上下文关系，可以让模型更好地进行词义匹配和语义分析。例如，单词`'king'`和`'queen'`之间的关系、单词`'cat'`和`'dog'`之间的关系等在向量空间中应当有所体现。\n\n常见的词向量模型有：\n\n1. **Word2Vec**：通过浅层神经网络训练来学习词向量，分为两种架构：CBOW （Continuous Bag Of Words）和 Skip-Gram。\n    - CBOW 模型的核心思想是：给定一个上下文词汇，预测中心词，即通过上下文中的词汇来预测目标词汇，上下文的顺序不重要，因为词袋是一个集合，而集合没有顺序的概念。假设你有一个句子\"The cat sits on the mat.\"，如果目标是预测 \"sits\" 这个词，那么 CBOW 会使用上下文词汇\"The\"、\"cat\"、\"on\"、\"the\"、\"mat\"来预测\"sits\"。在训练过程中，CBOW 会根据上下文中的词来调整 \"sits\" 的词向量，使得在上下文环境下该词能够更准确地表示语义。通过这种方式，CBOW 学习到的是一个词汇的上下文相关的表示。\n    - 与 CBOW 相反，Skip-Gram 模型的核心思想是：给定一个目标词，预测该词的上下文词汇。即通过一个中心词来预测其周围的词汇。假设我们还是以句子\"The cat sits on the mat.\"为例，目标词是\"sits\"。在 Skip-Gram 模型中，系统会用\"sits\"来预测它的上下文词汇，即\"The\"、\"cat\"、\"on\"、\"the\"、\"mat\"。Skip-Gram 模型会通过训练，使得\"sits\"的词向量能最大化其在训练数据中与上下文词的关联度。\n2. **GloVe**：基于词频矩阵的分解，能够捕捉到词汇的全局统计信息，由斯坦福大学的研究团队在2014年提出。GloVe 的词向量可以用于多种自然语言处理任务，如文本分类、情感分析、机器翻译等。它为后续的深度学习模型提供了有效的输入特征。\n\n下面，我们简单讲一下词向量学习的基本思路，主要有三个核心要素：\n\n1. **输入和目标**：假设我们使用 Word2Vec 模型（CBOW 或 Skip-Gram），目标是通过一个单词（中心词）或上下文词来学习词向量。在 Skip-Gram 中，给定一个单词，目标是预测其上下文中的单词；在 CBOW 中，给定上下文单词，目标是预测中心词。\n\n2. **神经网络模型**：Word2Vec 通过一个简单的神经网络来学习词向量，输入层是每个单词对应的独热编码；隐藏层是一个低维的稠密向量（即词向量），它在训练过程中通过反向传播逐渐优化；输出层是目标单词的概率分布，如下图所示。\n\n    <img class=\"lazy\" data-src=\"/res/09_word2vec.png\" style=\"zoom:45%;\">\n\n3. **训练过程**：通过上下文和目标单词的共现信息，模型根据每个单词的上下文调整词向量，使得语义上相似的词向量距离更近。训练过程中，神经网络通过最小化误差（即预测的词与实际词之间的差距）来调整词向量，使得能够准确预测词汇之间的联系。\n\n词向量的维度通常是一个超参数，需要根据实际情况来选择。通常，常见的维度范围为 50 到 300 之间，但有时可以更高或更低。较低的维度可能无法捕捉到词汇的丰富语义信息，但会减少计算复杂度，适用于训练数据比较少或对精度要求不高的场景；较高的维度可以捕捉更多的语义特征，适用于大规模数据集，但计算成本也会增加。\n\n一旦词向量被训练出来，它们就能捕捉到词汇之间的多种关系。最常见的方式是通过计算词向量之间的距离或相似度来理解它们的关系。计算两个词向量之间的余弦相似度是最常用的方式，余弦相似度的公式我们之前提到过，如下所示。\n\n$$\n\\text{Cosine Similarity}(\\mathbf{A}, \\mathbf{B}) = \\frac{\\mathbf{A} \\cdot \\mathbf{B}}{\\lVert \\mathbf{A} \\rVert \\lVert \\mathbf{B} \\rVert}\n$$\n\n其中， $\\small{\\mathbf{A}}$ 和 $\\small{\\mathbf{B}}$ 是两个词的词向量， $\\small{\\cdot}$ 是向量的点积运算， $\\small{\\lVert \\mathbf{A} \\rVert}$ 和 $\\small{\\lVert \\mathbf{B} \\rVert}$ 是它们的模长。余弦相似度的值介于 -1 到 1 之间，值越大表示两个词越相似，越小则表示越不相似。\n\n另一方面，我们可以研究词向量的空间关系并完成一些有趣的运算。例如，如果我们想知道`'king'`（国王）和`'queen'`（王后）之间的关系，可以通过这样的方式来探索：\n\n$$\n\\text{king} − \\text{man} + \\text{woman} \\approx \\text{queen}\n$$\n\n这个式子表示，`'king'`去掉`'man'`（男人）的部分，再加上`'woman'`（女人）的部分，得到的结果约等于`'queen'`。这样的运算可以捕捉到性别上的相似性。此外，利用词向量我们还可以进行聚类分析、词义消歧（通过上下文和相似度判断词在特定场景中的意思）、文本分类、情感分析等操作。\n\n我们用下面的代码为大家展示词向量的构建以及词与词相似性的度量，这里需要安装一个名为`gensim`的三方库。\n\n```bash\npip install gensim\n```\n\n此外，我们还需要提前加载训练模型的语料库，这里我用的是 Hugging Face 提供了的 `datasets` 库，通过它能够加载多种公开数据集，包括一些常用的语料库。当然，你也可以选择像`nltk`这样专门用于自然语言处理的工具包来下载语料库。如果还没有安装`datasets`库，需要使用下面的命令进行安装。\n\n```bash\npip install datasets\n```\n\n我们先加载 IMDB 数据集，它是一个广泛使用的文本分类数据集，尤其在情感分析和自然语言处理领域中。IMDB 数据集包含大量电影评论，标注了每条评论的情感倾向（这里我们暂时用不到）。IMDB 数据集通常包含 50000 条评论，其中 25000 条用于训练，25000 条用于测试。每条评论都是观众对电影的评价，内容有长有短，我们就用它来作为训练模型的语料库。\n\n```python\nimport re\n\nfrom datasets import load_dataset\nfrom gensim.models import Word2Vec\nfrom sklearn.metrics.pairwise import cosine_similarity\n\n# 加载 IMDB 数据集\nimdb = load_dataset('imdb')\n# 直接将 50000 条评论用作语料\ntemp = [imdb['unsupervised'][i]['text'] for i in range(50000)]\n# 用正则表达式对评论文本进行简单处理\ncorpus = [re.sub(r'[^\\w\\s]', '', x) for x in temp]\n\n# 预处理语料库（英文分词）\nsentences = [sentence.lower().split() for sentence in corpus]\n# 训练 Word2Vec 模型\n# sentences - 输入语料库（句子构成的列表，每个句子是一个或多个单词的列表）\n# vector_size - 词向量的维度（维度越高能够表示的信息越多）\n# windows - 上下文窗口大小（模型在训练时使用的上下文单词的范围）\n# min_count - 忽略频率低于此值的单词（过滤掉在语料库中出现次数较少的单词）\n# workers - 训练时使用的 CPU 核心数量\n# seed - 随机数种子（用于初始化模型的权重）\nmodel = Word2Vec(sentences, vector_size=100, window=10, min_count=2, workers=4, seed=3)\n\n# 通过模型获取 king 和 queen 的词向量\nking_vec, queen_vec = model.wv['king'], model.wv['queen']\n\n# 计算两个词向量的余弦相似度\ncos_similarity = cosine_similarity([king_vec], [queen_vec])\nprint(f'king 和 queen 的余弦相似度: {cos_similarity[0, 0]:.2f}')\n\n# 通过词向量进行推理（king - man + woman ≈ queen）\nman_vec, woman_vec = model.wv['man'], model.wv['woman']\nresult_vec = king_vec - man_vec + woman_vec\n# 查找与计算结果最相似的三个词\nsimilar_words = model.wv.similar_by_vector(result_vec, topn=3)\nprint(f'跟 king - man + woman 最相似的词:\\n {similar_words}')\n\n# 查找与 dog 最相似的五个词\ndog_similar_words = model.wv.most_similar('dog', topn=5)\nprint(f'跟 dog 最相似的词:\\n {dog_similar_words}')\n```\n\n输出：\n\n```\nking 和 queen 的余弦相似度: 0.43\n跟 king - man + woman 最相似的词:\n [('queen', 0.7126370668411255), ('princess', 0.6760246753692627), ('mary', 0.5891180038452148)]\n跟 dog 最相似的词:\n [('cat', 0.7801533937454224), ('sheep', 0.6783771514892578), ('pet', 0.6658452749252319), \n  ('doll', 0.655034065246582), ('dude', 0.6548768877983093)]\n```\n\n从代码的输出可以看出，跟`'king' - 'man' + 'woman'`最相似的词就是`'queen'`和`'princess'`（公主、王妃），另外一个单词是女孩子的名字。跟`'dog'`（狗）最相似的单词有：`'cat'`（猫）、`'sheep'`（绵羊）、`'pet'`（宠物）、`'doll'`（玩偶）和`'dude'`（家伙）。\n\n### NPLM和RNN\n\nWord2Vec 虽然已经帮助我们掌握了词与词之间的联系，但是由于无法捕捉长距离依赖（超出上下文窗口的词汇）和无法处理未知词（训练中没有出现的词汇）等问题，无法让 NLP 在具体的下游任务中实现突破和应用落地。随着对 Word2Vec 局限性的认识，研究者提出了 **NPLM**（神经网络语言模型），采用神经网络结构来预测单词序列中的下一个词。与传统的语言模型不同，NPLM 通过神经网络（通常是前馈神经网络）来处理整个单词序列，而不仅仅是局部的上下文信息，从而能够建模更为复杂的语言结构，其结构如下图所示。\n\n<img class=\"lazy\" data-src=\"/res/09_nplm_model.png\" style=\"zoom:85%;\">\n\n当然，NPLM 模型也存在无法有效捕捉长期依赖关系的问题，为此，研究者又提出了 **RNN**（循环神经网络）模型。RNN 是一种能够处理序列数据的神经网络，它的关键特性是能够将前一时刻的隐藏状态传递到下一时刻，从而在时间维度上建立联系。RNN 在训练时能够捕捉文本中的时序依赖关系，并且不局限于固定长度的上下文窗口。RNN 在每个时间步依赖于当前输入和上一时刻的隐藏状态，能够有效捕捉序列数据中的时间依赖性，通过反向传播算法更新权重，如下图所示。\n\n<img class=\"lazy\" data-src=\"/res/09_rnn_model.png\" style=\"zoom:50%;\">\n\n为了解决传统 RNN 中的梯度消失和梯度爆炸问题，研究人员又提出了**长短期记忆**（LSTM） 和**门控循环单元**（GRU）等改进算法。LSTM 和 GRU 都引入了门控机制，允许模型控制信息的流动和遗忘，从而有效防止了梯度消失问题，可以捕捉长时间序列的依赖关系。但是，LSTM 和 GRU 仍然存在计算效率低、训练速度慢的问题，且无法进行并行化训练的问题。\n\n### Seq2Seq\n\n起初，研究人员尝试用一个独立的 RNN 来解决机器翻译、文本摘要、语音识别等 NLP 任务，但是发现效果并不理想。主要原因是 RNN 在同时处理输入和输出序列时，既要负责编码又要负责解码，所以很容易出现信息损失。后来，谷歌提出了 Seq2Seq 模型，核心思想是通过学习输入与输出序列之间的映射关系，从而实现序列到序列的转换。Seq2Seq 模型通常包含一个**编码器**和一个**解码器**，编码器通常由 RNN 或其变体构成（LSTM、GRU等）构成，其主要任务是读取输入序列并将其转换成上下文向量，上下文向量包含了整个输入序列的语义信息，并作为解码器生成输出的基础；解码器通常也是由 RNN 或其变体构成，其主要任务是根据上下文向量生成目标序列。Seq2Seq 模型的结构如下图所示。\n\n<img class=\"lazy\" data-src=\"/res/09_seq2seq_model.png\" style=\"zoom:62%;\">\n\n简单的 Seq2Seq 模型将整个输入序列的信息压缩到一个固定大小的上下文向量中，这可能导致信息丢失，尤其是在处理长序列时。**注意力机制**是 Seq2Seq 模型的一个重要扩展，通过在每个解码步骤中动态的对编码器输出的不同部分进行加权求和，允许解码器在生成每个词时能够关注输入序列中的相关部分。这样，模型能够根据当前的解码需求自动“聚焦”在输入的某个子部分，而不是依赖于一个固定大小的上下文向量。\n\n### Transformer\n\n为了进一步克服 LSTM、GRU 等模型在长序列建模中的局限，2017 年谷歌大脑（Google Brain）团队的 Vaswani 等人在其论文 [*Attention Is All You Need*](https://arxiv.org/pdf/1706.03762) 中提出了 **Transformer** 架构，这个架构迅速成为 NLP 领域的主流方法，彻底改变了这个领域的生态，大名鼎鼎的 GPT 和 BERT 都是基于 Transformer 架构的。Transformer 的核心是**自注意力机制**（Self-Attention），它能够为输入序列中的每个元素分配不同的权重，从而更好的捕捉序列内部的依赖关系。此外，Transformer 摒弃了 RNN 和 LSTM 中的循环结构，采用了全新的编码器-解码器架构，这种设计使得模型可以并行处理输入数据，进一步加速训练的过程。除了 NLP 领域，Transformer 在计算机视觉、语音识别等领域也取得了显著的成果。\n\n<img class=\"lazy\" data-src=\"/res/09_transformer_arch.png\" style=\"zoom:45%;\">\n\nTransformer 架构如上图所示，它也是一个编码器-解码器结构，图左边部分红框中是堆叠的 N 组编码器，右边部分蓝框中是堆叠的 N 组解码器。编码器负责处理输入序列并将其转化为一个上下文相关的表示，解码器则根据编码器的输出生成目标序列（例如翻译任务中的目标语言）。下面，我们先简单说一下编码器和解码器的构成。\n\n1. 编码器：每个编码器都包括多头注意力机制、前馈神经网络、残差连接和层归一化。\n2. 解码器：解码器结构类似编码器，但在自注意力层和编码器-解码器注意力层之间引入了额外的层，以便处理编码器输出的上下文信息。\n\n我们再来展开说说 Transformer 的核心组件，如下所示。\n\n1. 嵌入层（输入嵌入和输出嵌入）：与传统的词向量方法（如 Word2Vec 或 GloVe）类似，Transformer 的输入首先需要通过词嵌入层将离散的单词映射为稠密的向量。\n\n2. 位置编码：由于 Transformer 不像 RNN 或 LSTM 那样处理序列中的时序信息，因此需要通过位置编码（Positional Encoding）来注入词序信息。位置编码的形式通常是一个与词嵌入大小相同的向量，每个维度编码了该词在序列中的位置信息。常见的做法是使用正弦和余弦函数来构造这些位置编码。\n\n3. 自注意力机制：允许模型在每个时间步根据输入序列中的所有其他词来计算每个词的表示。这样每个词都能关注到序列中其他位置的信息，而不依赖于输入的顺序。自注意力机制的原理是：对每个输入的词，通过嵌入层计算三个向量，分别是：**查询向量**（Q）、**键向量**（K）、**值向量**（V）。\n\n- 查询向量：用来查询其他词信息的向量，它代表我们关注的内容，每个输入词都会有一个对应的查询向量。\n\n- 键向量：根据输入序列中每个元素生成的一个向量，它与查询向量进行对比，计算每个词与其他词的注意力分数，这个分数决定了当前词和其他词的相关性，计算公式如下，其中， $\\small{d_{k}}$ 是键向量的维度，这里除以 $\\small{\\sqrt{d_k}}$ 的操作是为了防止点积值过大。\n\n$$\n\\text{Attention Score}(Q, K) = \\frac{Q \\cdot K^{T}}{\\sqrt{d_{k}}}\n$$\n\n- 值向量：实际的信息载体。在计算出注意力分数后，通过加权和运算得到的就是每个词的最终表示，这个最终表示是该词的上下文相关的向量，反映了该词在上下文中的重要性。\n\n$$\n\\text{Output} = \\sum_{i} \\text{softmax} \\left( \\frac{Q \\cdot K^{T}}{\\sqrt{d_{k}}} \\right) \\cdot V_{i}\n$$\n\n这里，我们得到的某个词的最终表示，不仅仅是它自身的语义，还包含了它与其他词的关系和上下文信息。\n\n4. 多头注意力：在标准的自注意力机制中，Q、K、V 向量都是通过同一个线性变换得到的，但这可能会限制信息的捕获。多头注意力通过使用多个并行的注意力头来解决这个问题，每个头使用不同的线性变换来捕捉不同的特征或关系。\n\n5. 前馈神经网络：为每个词提供非线性的变换，提取更高级别的特征，增强模型的能力。\n\n6. 残差连接和层归一化：Transformer 中广泛使用了残差连接（将输入直接加到输出上）和层归一化（对每个样本的各个特征进行标准化），这些技术有助于避免训练过程中梯度消失并加速训练。\n\n### 总结\n\n从传统的基于规则、基于统计的方法到深度学习和 Transformer 架构，研究人员一直没有停下对 NLP 探索的脚本，即便经历了人工智能的几次寒冬。随着 GPT 和 BERT 的出现，再到今天各种大模型在不同领域得到广泛应用，计算机已经能够理解和生成几乎所有语言的精髓并顺利的通过“图灵测试”。这一切不仅改变了我们与机器的互动方式，更为信息的获取、理解和交流开辟了崭新的天地，语言的力量永不止步！\n\n\n\n", "机器学习实战": "## 机器学习实战\n\n本章我们通过经典的“泰坦尼克号生存预测”项目为大家讲解机器学习的完整应用，该项目来自于全球知名的数据科学竞赛平台[Kaggle](https://www.kaggle.com/)。该平台是数据科学、机器学习、人工智能领域的重要社区之一，为数据科学家和算法工程师提供了一个实践、分享和竞争的空间。无论是新手还是经验丰富的专家，Kaggle 都能为其提供丰富的资源和挑战，通过平台提供的数据集、竞赛、课程等资源，用户可以根据自身的需求提升相关的数据科学技能并与全球的数据科学家互动。\n\n泰坦尼克号生存预测项目是 Kaggle 上最著名的入门级机器学习项目之一。该项目要求你根据乘客的基本信息（如年龄、性别、舱位、登船地等）预测他们是否能够在泰坦尼克号沉船事件中幸存下来，属于典型的分类任务。我们可以在 Kaggle 网站的 Competitions 搜索到名为“[*Titanic - Machine Learning from Disaster*](https://www.kaggle.com/competitions/titanic/)”的项目，点击进入可以看到项目的背景介绍并找到下载数据文件`train.csv`和`test.csv`的链接，显然前者是训练集（包含特征和标签）而后者是测试集（只有特征）。我们可以下载数据文件到本地并训练模型，然后再提交自己的预测结果；当然，如果愿意也可以在线创建 Notebook 文件并编写和运行代码。\n\n### 数据探索\n\n我们首先加载训练模型的数据，假设数据文件保存在当面路径下名为`data`的目录中，代码如下所示。\n\n```python\nimport numpy as np\nimport pandas as pd\n\ndf = pd.read_csv('data/train.csv', index_col='PassengerId')\ndf.head(5)\n```\n\n输出：\n\n```\n\t\t\tSurvived Pclass\tName\t\t\tSex\t\tAge\t\tSibSp\tParch\tTicket\t\tFare\tCabin\tEmbarked\nPassengerId\t\t\t\t\t\t\t\t\t\t\t\n1\t\t\t0\t\t 3\t\tBraund, ...\t    male\t22.0\t1\t\t0\t\tA/5 ...\t\t7.2500\tNaN\t\tS\n2\t\t\t1\t\t 1\t\tCumings, ...\tfemale\t38.0\t1\t\t0\t\tPC ...\t\t71.2833\tC85\t\tC\n3\t\t\t1\t\t 3\t\tHeikkinen, ...  female\t26.0\t0\t\t0\t\tSTON/O2 ...\t7.9250\tNaN\t\tS\n4\t\t\t1\t\t 1\t\tFutrelle, ...   female\t35.0\t1\t\t0\t\t113803 ...\t53.1000\tC123\tS\n5\t\t\t0\t\t 3\t\tAllen, ...\t    male\t35.0\t0\t\t0\t\t373450 ...\t8.0500\tNaN\t\tS\n```\n\n> **注意**：加载数据的时候，我们直接将 PassengerID （乘客编号）列处理成了行索引。\n\n下面的数据字典对`DataFrame`每个列的含义进行了说明。\n\n| 列名       | 含义             | 说明                                                |\n| ---------- | ---------------- | --------------------------------------------------- |\n| `Survived` | 是否幸存         | 目标类别（`1`表示幸存，`0`表示遇难）                |\n| `Pclass`   | 舱位等级         | 整数，取值为`1`、`2`、`3`，表示三种不同的等级       |\n| `Name`     | 乘客姓名         | 字符串                                              |\n| `Sex`      | 性别             | 字符串，`male`为男性，`female`为女性                |\n| `Age`      | 年龄             | 浮点数                                              |\n| `SibSp`    | 平辈亲属登船人数 | 整数，包括兄弟、姐妹、配偶总共登船的人数            |\n| `Parch`    | 父母小孩登船人数 | 整数                                                |\n| `Ticket`   | 船票号           | 字符串                                              |\n| `Fare`     | 船票价格         | 浮点数                                              |\n| `Cabin`    | 客舱号           | 字符串                                              |\n| `Embarked` | 登船港口         | 字符串，`C`表示瑟堡，`Q`表示皇后镇、`S`表示南安普顿 |\n\n我们对数据进行可视化操，通过统计图表实训对数据的初步探索，代码如下所示。\n\n```python\nimport matplotlib.pyplot as plt\n\n# 修改配置添加中文字体\nplt.rcParams['font.sans-serif'].insert(0, 'SimHei')\nplt.rcParams['axes.unicode_minus'] = False\n\n# 定制画布\nplt.figure(figsize=(16, 12), dpi=200)\n\n# 遇难和获救人数分布\nplt.subplot(3, 4, 1)\nser = df.Survived.value_counts()\nser.plot(kind='bar', color=['#BE3144', '#3A7D44'])\nplt.xticks(rotation=0)\nplt.title('图1.获救情况分布')\nplt.ylabel('人数')\nplt.xlabel('')\nfor i, v in enumerate(ser):\n    plt.text(i, v, v, ha='center')\n\n# 客舱等级人数分布\nplt.subplot(3, 4, 2)\nser = df.Pclass.value_counts().sort_index()\nser.plot(kind='bar', color=['#FA4032', '#FA812F', '#FAB12F'])\nplt.xticks(rotation=0)\nplt.ylabel('人数')\nplt.xlabel('')\nplt.title('图2.客舱等级分布')\nfor i, v in enumerate(ser):\n    plt.text(i, v, v, ha='center')\n\n# 性别人数分布\nplt.subplot(3, 4, 3)\nser = df.Sex.value_counts()\nser.plot(kind='bar', color=['#16404D', '#D84040'])\nplt.xticks(rotation=0)\nplt.ylabel('人数')\nplt.xlabel('')\nplt.title('图3.性别分布')\nfor i, v in enumerate(ser):\n    plt.text(i, v, v, ha='center')\n\n# 登船港口人数分布\nplt.subplot(3, 4, 4)\nser = df.Embarked.value_counts()\nser.plot(kind='bar', color=['#FA4032', '#FA812F', '#FAB12F'])\nplt.xticks(rotation=0)\nplt.ylabel('人数')\nplt.xlabel('')\nplt.title('图4.登船港口分布')\nfor i, v in enumerate(ser):\n    plt.text(i, v, v, ha='center')\n\n# 乘客年龄箱线图\nplt.subplot(3, 4, 5)\ndf.Age.plot(kind='box', showmeans=True, notch=True)\nplt.title('图5.乘客年龄情况')\n\n# 船票价格箱线图\nplt.subplot(3, 4, 6)\ndf.Fare.plot(kind='box', showmeans=True, notch=True)\nplt.title('图6.船票价格情况')\n\n# 不同客舱等级遇难和幸存人数分布\nplt.subplot(3, 4, (7, 8))\ns0 = df[df.Survived == 0].Pclass.value_counts()\ns1 = df[df.Survived == 1].Pclass.value_counts()\ntemp = pd.DataFrame({'遇难': s0, '幸存': s1})\npcts = temp.div(temp.sum(axis=1), axis=0)\ntemp.plot(ax=plt.gca(), kind='bar', stacked=True, color=['#BE3144', '#3A7D44'])\nfor i, idx in enumerate(temp.index):\n    plt.text(i, temp.at[idx, '遇难'] // 2, f'{pcts.at[idx, \"遇难\"]:.2%}', ha='center', va='center')\n    plt.text(i, temp.at[idx, '遇难'] + temp.at[idx, '幸存'] // 2, f'{pcts.at[idx, \"幸存\"]:.2%}', ha='center', va='center')\nplt.xticks(rotation=0)\nplt.xlabel('')\nplt.title('图7.不同客舱等级幸存情况')\n\n# 不同性别遇难和幸存人数分布\nplt.subplot(3, 4, (9, 10))\ns0 = df[df.Survived == 0].Sex.value_counts()\ns1 = df[df.Survived == 1].Sex.value_counts()\ntemp = pd.DataFrame({'遇难': s0, '幸存': s1})\npcts = temp.div(temp.sum(axis=1), axis=0)\ntemp.plot(ax=plt.gca(), kind='bar', stacked=True, color=['#BE3144', '#3A7D44'])\nfor i, idx in enumerate(temp.index):\n    plt.text(i, temp.at[idx, '遇难'] // 2, f'{pcts.at[idx, \"遇难\"]:.2%}', ha='center', va='center')\n    plt.text(i, temp.at[idx, '遇难'] + temp.at[idx, '幸存'] // 2, f'{pcts.at[idx, \"幸存\"]:.2%}', ha='center', va='center')\nplt.xticks(rotation=0)\nplt.xlabel('')\nplt.title('图8.不同性别幸存情况')\n\n# 不同登船港口遇难和幸存人数分布\nplt.subplot(3, 4, (11, 12))\ns0 = df[df.Survived == 0].Embarked.value_counts()\ns1 = df[df.Survived == 1].Embarked.value_counts()\ntemp = pd.DataFrame({'遇难': s0, '幸存': s1})\npcts = temp.div(temp.sum(axis=1), axis=0)\ntemp.plot(ax=plt.gca(), kind='bar', stacked=True, color=['#BE3144', '#3A7D44'])\nfor i, idx in enumerate(temp.index):\n    plt.text(i, temp.at[idx, '遇难'] // 2, f'{pcts.at[idx, \"遇难\"]:.2%}', ha='center', va='center')\n    plt.text(i, temp.at[idx, '遇难'] + temp.at[idx, '幸存'] // 2, f'{pcts.at[idx, \"幸存\"]:.2%}', ha='center', va='center')\nplt.xticks(rotation=0)\nplt.xlabel('')\nplt.title('图9.不同登船港口幸存情况')\n\nplt.show()\n```\n\n输出：\n\n<img class=\"lazy\" data-src=\"/res/10_dataset_visualization.png\" style=\"zoom:85%;\">\n\n从上面的统计图表可以看出，一等舱的乘客有更高的存活率，女性乘客相较于男性乘客也有更高的存活率，在瑟堡登船的用户存活率较其他两地更高。如果愿意，我们还可以尝试对性别、舱位、年龄等维度进行交叉组合并绘制出对应的统计图表，甚至还可以探索乘客姓名中的称谓（`Mr`、`Miss`、`Mrs`、`Dr`、`Master`、`Major`等）跟乘客能否幸存是否存在某种关系，有兴趣的读者可以自行研究。\n\n我们进一步查看`DataFrame`对象相关信息。\n\n```python\ndf.info()\n```\n\n输出：\n\n```\n<class 'pandas.core.frame.DataFrame'>\nIndex: 891 entries, 1 to 891\nData columns (total 11 columns):\n #   Column    Non-Null Count  Dtype  \n---  ------    --------------  -----  \n 0   Survived  891 non-null    int64  \n 1   Pclass    891 non-null    int64  \n 2   Name      891 non-null    object \n 3   Sex       891 non-null    object \n 4   Age       714 non-null    float64\n 5   SibSp     891 non-null    int64  \n 6   Parch     891 non-null    int64  \n 7   Ticket    891 non-null    object \n 8   Fare      891 non-null    float64\n 9   Cabin     204 non-null    object \n 10  Embarked  889 non-null    object \ndtypes: float64(2), int64(4), object(5)\nmemory usage: 83.5+ KB\n```\n\n可以看出，训练集一共`891`条数据，其中年龄、客舱号、登船港口等列存在缺失值，乘客姓名、登船港口等是字符串类型没有办法直接用于模型训练，所以我们需要做一些准备工作。\n\n### 特征工程\n\n特征工程（Feature Engineering）是机器学习中的一个重要环节，通过对原始数据的处理、转换与选择，提取出能够帮助模型更好理解数据的特征，最终提升模型的预测性能。特征工程的主要步骤包括：\n\n1. **数据清洗**：处理数据中的缺失值、重复值、异常值等。\n\n2. **特征转换**：将原始数据转化为更适合模型输入的形式。常见的特征转换方法有：\n\n    - 标准化和归一化：标准化将数据转换为均值为`0`、标准差为`1`的分布；归一化将数据缩放到特定的范围（如：$\\small{[0, 1]}$），确保各特征在同一数量级，对应的公式如下所示：\n        $$\n        X^{\\prime} = \\frac{X - \\mu}{\\sigma}\n        $$\n\n        $$\n        X^{\\prime} = \\frac{X - X_{min}}{X_{max} - X_{min}}\n        $$\n\n        其中，$\\small{\\mu}$表示数据的均值，$\\small{\\sigma}$表示数据的标准差，$\\small{X_{min}}$表示数据中的最小值，$\\small{X_{max}}$表示数据中的最大值。Scikit-learn 库`preprocessing`模块中的`StandardScaler`和`MinMaxScaler`可以实现数据的标准化和归一化。\n\n    - 类别编码：对于类别变量（如：性别、职业、地区等），常用的编码方式有独热编码（One-Hot Encoding）和标签编码（Label Encoding）。Scikit-learn 库`preprocessing`模块中的`OneHotEncoder`和`LabelEncoder`可以实现数据的独热编码和标签编码，当然也可以通过 pandas 库的`get_dummies`函数来处理`DataFrame`中的类别变量。\n\n    - 对数变换：对数变换可以帮助处理具有偏态分布的特征，使其更接近正态分布。\n\n3. **特征选择**：从大量的特征中筛选出对模型预测有用的特征，去除冗余或无关的特征，减少维度并提高模型的性能。常用的方法有：\n\n    - **过滤法**：基于统计检验方法（如：卡方检验、皮尔逊相关系数等）选择最具区分度的特征。\n    - **包裹法**：通过模型的性能来评估特征子集的效果（如：递归特征消除法）。\n    - **嵌入法**：通过训练模型并从模型中提取特征的重要性（如：决策树、L1正则化等），从而进行特征选择。\n\n4. **特征降维**：通过某种数学变换将数据从高维空间映射到低维空间，以便保留数据的主要信息，简化模型，降维后的新特征是原始特征的某种组合。降维可以减少模型训练的运算量，减少不必要的噪声和冗余特征来降低复杂性，从而提高模型的泛化能力。特征降维常用的方法有：\n\n    - **PCA**（主成分分析）：PCA 的目标是找出数据中最重要的特征（主成分），这些主成分能够保留数据的大部分方差。PCA 通过线性变换将数据投影到新的坐标轴上，使得投影后的数据方差最大化。换句话说，PCA通过对数据的特征进行“旋转”，将其转换为一个新的坐标系，新坐标系的每个轴（即主成分）按数据的方差大小排列，前几个主成分通常就能够解释数据的大部分变异。Scikit-learn 库`decomposition`模块的`PCA`类可以帮助我们完成主成分分析。\n    - **LDA**（线性判别分析）：LDA 的主要目标是通过寻找最佳的投影方向来最大化不同类别之间的可分性，并同时最小化同一类别内数据点的散布。LDA在特征空间中找到一个低维的空间，使得类别之间的差异尽可能大，而同一类别内的数据尽量聚集。简单的说，LDA 的核心思想是**最大化类间散度，最小化类内散度**。Scikit-learn 库`discriminant_analysis`模块的`LinearDiscriminantAnalysis`类可以帮助我们完成线性判别分析。\n    - **t-SNE**（t分布随机邻居嵌入）：t-SNE 是一种非线性的降维方法，主要用于数据可视化，特别适用于高维数据（如图像、文本等）的降维。t-SNE的目标是将高维空间中的相似点（邻近点）映射到低维空间中的相近位置，同时尽量避免不同类别之间的重叠。Scikit-learn 库`manifold`模块的`TSNE`类可以帮助我们完成t分布随机邻居嵌入。\n\n5. **特征构造**：通过原始特征组合、变换或派生出新的特征。\n\n特征工程不仅是提高模型准确性的关键因素，也是机器学习中一个需要持续优化的过程。通过对数据进行精心的清洗、转换、选择和构造，可以为模型提供更有价值的信息，提高模型的表现。尽管特征工程看似复杂，但它的效果在很多情况下超出了模型本身的改进，因此在实际应用中，我们应投入足够的精力和时间来进行特征工程的优化。\n\n对于我们加载的数据集，我们可以将年龄字段的缺失值处理为中位数，将登船港口的缺失值处理为众数，客舱号字段的缺失值比较多，一种处理方式是直接删除这个列，另一种处理方式是二值化，有客舱号的记为`1`，没有客舱号的记为`0`，代码如下所示。\n\n```python\ndf['Age'] = df.Age.fillna(df.Age.median())\ndf['Embarked'] = df.Embarked.fillna(df.Embarked.mode()[0])\ndf['Cabin'] = df.Cabin.replace(r'.+', '1', regex=True).replace(np.nan, 0).astype('i8')\n```\n\n处理完缺失值后，我们对年龄和船票价格两个字段进行特征缩放，通过`StandardScaler`实现标准化，代码如下所示。\n\n```python\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\ndf[['Fare', 'Age']] = scaler.fit_transform(df[['Fare', 'Age']])\n```\n\n接下来，还需要对性别和登船港口两个字段进行独热编码处理，可以使用 pandas 库中的`get_dummies`函数或 scikit-learn 库的`OneHotEncoder`处理，两者处理的结果类似，代码如下所示。\n\n```python\ndf = pd.get_dummies(df, columns=['Sex', 'Embarked'], drop_first=True)\n```\n\n我们继续处理乘客姓名字段，根据姓名中的称谓衍生出一个新的特征；此外，对于`SibSp`和`Parch`两个字段，我们可以将其衍生为家庭成员数量的新特征，代码如下所示。\n\n```python\ntitle_mapping = {\n    'Mr': 0, 'Miss': 1, 'Mrs': 2, 'Master': 3, 'Dr': 4, 'Rev': 5, 'Col': 6, 'Major': 7, \n    'Mlle': 8, 'Ms': 9, 'Lady': 10, 'Sir': 11, 'Jonkheer': 12, 'Don': 13, 'Dona': 14, 'Countess': 15\n}\ndf['Title'] = df['Name'].map(\n    lambda x: x.split(',')[1].split('.')[0].strip()\n).map(title_mapping).fillna(-1)\ndf['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n```\n\n> **说明**：我们将每个称谓映射到一个数字，这里不必过于纠结称谓跟数字的对应关系，而且有些称谓在我们的训练集中并没有出现。对于那些未知的称谓，我们统一处理为`-1`。\n\n完成上面的操作之后，我们可以把不必要的字段全部删除掉，数据的准备工作就基本完成了。\n\n```python\ndf.drop(columns=['Name', 'SibSp', 'Parch', 'Ticket'], inplace=True)\n```\n\n### 模型训练\n\n首先我们将数据集划分为训练集和验证集，注意这里不是划分训练集和测试集，因为我们最终的测试集是官方提供的`test.csv`文件，这里我们把`train.csv`中 90% 的数据划分出来训练模型，用剩下的 10% 对模型进行验证。下面的代码中我们将验证集的特征和标签分别命名为`X_valid`和`y_valid`。\n\n```python\nfrom sklearn.model_selection import train_test_split\n\nX, y = df.drop(columns='Survived'), df.Survived\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.9, random_state=3)\n```\n\n我们先尝试逻辑回归模型，代码如下所示。\n\n```python\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report\n\nmodel = LogisticRegression(penalty='l1', tol=1e-6, solver='liblinear')\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_valid)\nprint(classification_report(y_valid, y_pred))\n```\n\n输出：\n\n```\n              precision    recall  f1-score   support\n\n           0       0.88      0.80      0.84        56\n           1       0.72      0.82      0.77        34\n\n    accuracy                           0.81        90\n   macro avg       0.80      0.81      0.80        90\nweighted avg       0.82      0.81      0.81        90\n```\n\n我们再试一试大杀器 XGBoost，代码如下所示。\n\n```python\nimport xgboost as xgb\n\n# 将数据处理成数据集格式DMatrix格式\ndm_train = xgb.DMatrix(X_train, y_train)\ndm_valid = xgb.DMatrix(X_valid)\n\n# 设置模型参数\nparams = {\n    'booster': 'gbtree',             # 用于训练的基学习器类型\n    'objective': 'binary:logistic',  # 指定模型的损失函数\n    'gamma': 0.1,                    # 控制每次分裂的最小损失函数减少量\n    'max_depth': 10,                 # 决策树最大深度\n    'lambda': 0.5,                   # L2正则化权重\n    'subsample': 0.8,                # 控制每棵树训练时随机选取的样本比例\n    'colsample_bytree': 0.8,         # 用于控制每棵树或每个节点的特征选择比例\n    'eta': 0.05,                     # 学习率\n    'seed': 3,                       # 设置随机数生成器的种子\n    'nthread': 16,                   # 指定了训练时并行使用的线程数\n}\n\nmodel = xgb.train(params, dm_train, num_boost_round=200)\ny_pred = model.predict(dm_valid)\n# 将预测的概率转换为类别标签\ny_pred_label = (y_pred > 0.5).astype('i8')\nprint(classification_report(y_valid, y_pred_label))\n```\n\n输出：\n\n```\n              precision    recall  f1-score   support\n\n           0       0.89      0.91      0.90        56\n           1       0.85      0.82      0.84        34\n\n    accuracy                           0.88        90\n   macro avg       0.87      0.87      0.87        90\nweighted avg       0.88      0.88      0.88        90\n```\n\n当然，在条件允许的情况下，**强烈建议**大家通过网格搜索交叉验证的方式对模型的超参数进行调优，同时我们还可以绘制**学习曲线**（learning curve）来辅助判定是否存在过拟合和欠拟合问题。学习曲线包含两条曲线，一条反映训练误差，一条反映验证误差。欠拟合通常表现为模型在训练集和验证集上的误差都较大，并且随着训练数据增加，训练误差和验证误差的差距较小，说明我们的模型过于简单，无法捕捉到数据中的模式。过拟合通常表现为模型在训练集上表现得很好（训练误差较低），但在验证集上表现较差（验证误差较高），且随着训练数据增加，训练误差持续降低而验证误差开始上升时，说明我们的模型过于复杂。Scikit-learn 库`model_selection`模块的`learning_curve`函数可以帮助我们绘制学习曲线，有兴趣的读者可以自行研究。\n\n### 模型评估\n\n接下来我们加载真正的测试数据`test.csv`，通过前面训练好的模型来做出预测。我们可以将预测的结果保存成一个 CSV 文件，该文件共有两列，一列是 PassengerID，一列是我们预测的结果。我们将该文件提交到 Kaggle 平台，可以获得最终模型的准确率评分。\n\n```python\ntest = pd.read_csv('data/test.csv', index_col='PassengerId')\n# 处理缺失值\ntest['Age'] = test.Age.fillna(test.Age.median())\ntest['Fare'] = test.Fare.fillna(test.Fare.median())\ntest['Embarked'] = test.Embarked.fillna(test.Embarked.mode()[0])\ntest['Cabin'] = test.Cabin.replace(r'.+', '1', regex=True).replace(np.nan, 0).astype('i8')\n# 特征缩放\ntest[['Fare', 'Age']] = scaler.fit_transform(test[['Fare', 'Age']])\n# 处理类别\ntest = pd.get_dummies(test, columns=['Sex', 'Embarked'], drop_first=True)\n# 特征构造\ntest['Title'] = test['Name'].apply(lambda x: x.split(',')[1].split('.')[0].strip()).map(title_mapping).fillna(-1)\ntest['FamilySize'] = test['SibSp'] + test['Parch'] + 1\n# 删除多余特征\ntest.drop(columns=['Name', 'Ticket', 'SibSp', 'Parch'], inplace=True)\n\n# 使用逻辑回归模型\npassenger_id, X_test = test.index, test\n# 使用XGBoost模型\n# passenger_id, X_test = test.index, xgb.DMatrix(test)\n\ny_test_pred = model.predict(X_test)\n# XGoost模型 - 将预测的概率转换成类别标签\n# y_test_pred = (model.predict(X_test) > 0.5).astype('i8')\n\n# 生成提交文件\nresult = pd.DataFrame({\n    'PassengerId': passenger_id,\n    'Survived': y_test_pred\n})\nresult.to_csv('submission.csv', index=False)\n```\n\n大家可以试一试，不同的模型预测结果是否存在较大的差异，哪个是你心目中最理想的模型，然后大家可以通过实验验证我们之前提到的一个观点，看看特征工程是不是对预测的结果有重要的影响。下面是我对特征工程的一些小建议（仅供参考），大家可以自行实践，看看能否通过这些操作提升模型的性能。\n\n1. 对年龄（Age）字段进行离散化（分箱），将年龄特别小的（儿童）单独处理（如增加一个布尔字段）。\n2. 对客舱号（Cabin）字段进行更细致的处理，提取前缀字母和后续数字作为特征，而不是简单的二值化。\n3. 对比较重要的两个特征舱位等级（Pclass）和性别（Sex）进行特征组合。\n4. 对名字（Name）中有 Mrs 且父母小孩登船人数大于1的（可能是一位母亲）单独处理（如增加一个布尔字段）。\n5. 删除掉登船港口（Embarked）字段。\n\n### 模型部署\n\n我们可以将训练好的模型部署到工程化项目中，首先需要对模型进行序列化处理，代码如下所示。\n\n```python\nimport joblib\n\njoblib.dump(model, 'model.pkl')\n```\n\n> **说明**：此处我们默认上面代码中的`model`对象是之前通过 XGBoost 训练的模型。 \n\n`joblib`模块的`dump`函数对模型进行了 Pickle 序列化（Python私有序列化协议），在需要使用模型的地方，我们可以通过`load`函数实现反序列化，这样就可以将模型加载到应用程序中并完成预测，代码如下所示。\n\n```python\nimport joblib\n\nmodel = joblib.load('model.pkl')\nmodel.predict(X_test)\n```\n\n> **说明**：此处我们默认上面代码中的`X_test`已经处理为 XGBoost 中`DMatrix`对象。\n\n如果我们希望将模型部署成 Web 服务，可以利用 Flask、FastAPI 这样的 Web 框架来创建 API 接口。下面，我们以 Flask 框架为例，用简单的代码为大家演示这个过程。\n\n```python\nfrom flask import Flask\nfrom flask import jsonify\nfrom flask import request\n\nimport joblib\nimport pandas as pd\nimport xgboost as xgb\n\napp = Flask(__name__)\n\n\n@app.route('/predict', methods=['POST'])\ndef predict():\n    query_df = pd.DataFrame(request.json)\n    model = joblib.load('model.pkl')\n    y_pred = (model.predict(xgb.DMatrix(query_df)) > 0.5).tolist()\n    return jsonify({'message': 'OK', 'result': y_pred})\n\n\nif __name__ == '__main__':\n    app.run(debug=True)\n```\n\n> **说明**：作为工程化的项目，肯定不能在请求到来时才加载模型，因为这样会严重影响 Web 服务的性能。可以在项目启动之后的适当时机提前加载需要的模型，与此同时还要根据实际需求做好模型资源占用的监控。\n\n运行上面的代码，默认会在本机 5000 端口运行一个 Web 服务器，下面我们通过 API 测试工具模拟发送一个 HTTP 请求给服务器，看看我们的模型能否运转起来给出预测的结果。\n\n<img class=\"lazy\" data-src=\"/res/10_test_web_api.png\" style=\"zoom:40%;\">\n\n除了把模型部署成 Web 服务之外，我们还可以将模型部署到定时任务中，通过时间自动激发对模型的调用。此外，一些边缘设备支持我们将训练好的模型以某种特殊的格式嵌入进去，有兴趣的读者可以自行探索。\n", "补充内容": "## 补充内容\n\n之前没有来得及安排，准备后面补充的内容：\n\n1. **面试**相关资源请移步到[“Python面试宝典”](https://github.com/jackfrued/Python-Interview-Bible)项目。\n    - Python 面试宝典\n    - 商业分析面试宝典\n    - 数据分析师 SQL 面试宝典\n    - 机器学习面试宝典\n2. **数学基础**相关资源请移步到[“机器学习数学基础知识”](https://github.com/jackfrued/Math_for_ML)项目。\n    - 线性代数\n    - 概率论和统计学\n    - 高等数学\n    - 信息论\n3. **深度学习**相关内容请移步到[“深度学习就是大力出奇迹”](https://github.com/jackfrued/Deep-Learning-Is-Nothing)项目。\n", "团队项目开发的问题和解决方案": "## 团队项目开发的问题和解决方案\n\n个人开发和团队开发这两个词相信对大家来说并不陌生。所谓个人开发就是一个人把控产品的所有内容；而团队开发则是由多个人组团并完成产品的开发。要实施团队开发以下几点是不可或缺的：\n\n1. 对开发过程中的各种事件（例如：谁到什么时间完成了什么事情）进行管理和共享。\n2. 在团队内部共享各类工作成果以及新的知识技巧等。\n3. 管理工作成果的变更，既要防止成果被破坏，又要保证各个成员利用现有成果并行作业。\n4. 证明团队开发出的软件在任何时候都是可以正常运行的。\n5. 使用自动化的工作流程，让团队成员能够正确的实施开发、测试和部署。\n\n### 团队项目开发常见问题\n\n团队开发相较于个人开发，容易遇到以下几个方面的问题。\n\n#### 问题1：传统的沟通方式无法确定处理的优先级\n\n例如：使用邮件进行沟通可能出现邮件数量太多导致重要的邮件被埋没，无法管理状态，不知道哪些问题已经解决，哪些问题尚未处理，如果用全文检索邮件的方式来查询相关问题效率过于低下。\n\n解决方案：使用缺陷管理工具。\n\n#### 问题2：没有能够用于验证的环境\n\n例如：收到项目正式环境中发生的故障报告后，需要还原正式环境需要花费很长的时间。\n\n解决方法：实施持续交付。\n\n#### 问题3：用别名目录管理项目分支\n\n解决方法：实施版本控制。\n\n#### 问题4：重新制作数据库非常困难\n\n例如：正式环境和开发环境中数据库表结构不一致或者某个表列的顺序不一致。\n\n解决方法：实施版本控制。\n\n#### 问题5：不运行系统就无法察觉问题\n\n例如：解决一个bug可能引入其他的bug或者造成系统退化，不正确的使用版本系统覆盖了其他人的修改，修改的内容相互发生了干扰，如果问题不能尽早发现，那么等过去几个月后再想追溯问题就非常麻烦了。\n\n解决方法：实施持续集成，将团队成员的工作成果经常、持续的进行构建和测试。\n\n#### 问题6：覆盖了其他成员修正的代码\n\n解决方法：实施版本控制。\n\n#### 问题7：无法实施代码重构\n\n例如：在实施代码重构（在不影响代码产生的结果的前提下对代码内部的构造进行调整）时可能引发退化。\n\n解决方法：大量的可重用的测试并实施持续集成。\n\n#### 问题8：不知道bug的修正日期无法追踪退化\n\n解决方法：版本控制系统、缺陷管理系统和持续集成之间需要交互，最好能够和自动化部署工具集成到一起来使用。\n\n#### 问题9：发布过程太复杂\n\n解决方法：实施持续交付。\n\n基于对上述问题的阐述和分析，我们基本上可以得到以下的结论，在团队开发中版本控制、缺陷管理和持续集成都是非常重要且不可或缺的。\n\n### 版本控制\n\n针对上面提到的一系列问题，我们可以得出一个简单的结论，版本控制是实施团队开发的首要前提，必须通过版本控制对产品研发过程中产生的各种信息进行管理，这些内容包括：\n\n1. 代码。\n2. 需求和设计的相关文档。\n3. 数据库模式和初始数据。\n4. 配置文件。\n5. 库的依赖关系定义。\n\n#### Git简介\n\n![](/res/git-logo.png)\n\nGit是诞生于2005年的一个开源分布式版本控制系统，最初是Linus Torvalds（Linux之父） 为了帮助管理Linux内核开发而开发的一个版本控制软件。Git与常用的版本控制工具Subversion等不同，它采用了分布式版本控制的方式，在没有中央服务器支持的环境下也能够实施版本控制。\n\n对于有使用Subversion（以下简称为SVN）经验的人来说，Git和SVN的共同点是摒弃了传统的基于锁定模式的版本控制（早期的CVS和VSS使用了锁定模式，当一个开发者编辑一个文件时会锁定该文件，其他开发者在此期间无法编辑该文件），采用了更有效率的基于合并模式的版本控制，而二者的区别在于：\n\n1. Git是分布式的，SVN是集中式的，SVN需要中央服务器的支持才能工作。\n2. Git把内容按元数据方式存储，而SVN是按文件，即把文件的元信息隐藏在一个.svn文件夹里。\n3. Git分支和SVN的分支不同，SVN对分支的处理是相当“狗血”的。\n4. Git没有一个全局版本号，但是可以自己维护一个版本标签。\n5. Git的内容完整性要优于SVN，Git的内容存储使用的是SHA-1哈希算法。这能确保代码内容的完整性，确保在遇到磁盘故障和网络问题时降低对版本库的破坏。  \n\n总而言之，**Git真的非常棒！！！**\n\n#### 安装Git\n\n可以在[Git官方网站](http://git-scm.com/)找到适合自己系统的Git下载链接并进行安装，macOS和Windows平台下安装Git都非常简单，Linux下如果要安装官方最新的版本，建议通过官方提供的Git源代码进行构建安装，步骤如下所示（以CentOS为例）。\n\n下载Git源代码压缩文件。\n\n```Shell\nwget https://mirrors.edge.kernel.org/pub/software/scm/git/git-2.23.0.tar.xz\n```\n\n解压缩和解归档。\n\n```Shell\nxz -d git-2.23.0.tar.xz\ntar -xvf git-2.23.0.tar\n```\n\n安装底层依赖库。\n\n```Shell\nyum -y install libcurl-devel\n```\n\n> 说明：没有这个依赖库，git的网络功能将无法执行。\n\n安装前的配置。\n\n```Shell\ncd git-2.23.0\n./configure --prefix=/usr/local\n```\n\n构建和安装。\n\n```Shell\nmake && make install\n```\n\n安装成功后可以在终端中键入下面的命令检查自己的Git版本。\n\n```Shell\ngit --version\n```\n\n如果之前完全没有接触过Git，可以先阅读[《git - 简易指南》](http://www.bootcss.com/p/git-guide/)来对Git有一个大致的了解。\n\n#### Git本地操作\n\n可以使用下面的命令将一个文件夹变成Git仓库。\n```Shell\ngit init \n```\n\n当你完成了上述操作后，本地目录就变成了下面的样子，下图左边是你的工作区（正在操作的工作目录），而右边是你的本地仓库，中间是工作区和本地仓库之间的暂存区（也称为缓存区）。\n\n![](./res/git_repository.png)\n\n> **提示**：用`ls -la`查看所有文件会发现在执行完上面的命令后，文件夹下多了一个名为`.git`的隐藏文件夹，这个就是本地的Git版本仓库。\n\n通过`git add`可以将指定的文件或所有文件添加到暂存区。\n\n```Shell\ngit add <file>\ngit add .\n```\n\n这个时候使用下面的命令可以查看工作区、暂存区和本地仓库的状态。\n\n```Shell\ngit status\n```\n\n> **提示**：如果不希望将文件添加到暂存区，可以按照提示，使用`git rm --cached <file>`命令将文件从暂存区放回到工作区。\n\n如果这个时候对工作区的文件又进行了修改使得工作区和暂存区的内容并不相同了，再次执行`git status`可以看到哪个或哪些文件被修改了，如果希望用暂存区的内容恢复工作区，可以使用下面的命令。\n\n```Shell\ngit restore <file>\ngit restore .\n```\n\n> **注意**：上面的命令目前仍然处于试验性阶段，在Git较早的版本中对应的命令是`git checkout -- <file>`。由于`git checkout`这个命令还可以用于切换分支，容易引起混淆，所以Git最新版本中将这个命令的两项功能分别赋予两个新的命令，一个就是上面的`git restore`，另一个是`git switch`。\n\n如果第一次使用Git，需要配置用户名和邮箱，然后才能将代码提交到仓库。\n\n```Shell\ngit config --global user.name \"jackfrued\"\ngit config --global user.email \"jackfrued@126.com\"\n```\n\n> **提示**：可以用`git config --list`来查看Git的配置信息。\n\n通过下面的命令可以将暂存区的内容纳入本地仓库，\n\n```Shell\ngit commit -m '本次提交的说明'\n```\n\n可以通过`git log`查看每次提交对应的日志。\n\n```Shell\ngit log\ngit log --graph --oneline --abbrev-commit\n```\n\n#### Git服务器概述\n\nGit不像SVN那样一定需要中央服务器才能工作，上面我们演示的版本控制操作都是在本地执行的，但是对于企业开发多人协作这样的场景还是需要中央服务器的支持。通常，企业可以选择使用代码托管平台（如[GitHub](https://github.com)）或自己搭建Git私服的方式来建立中央服务器（版本仓库），当然大多数的企业更倾向于后者。Github创办于2008年4月，目前是全世界最大的代码托管平台，支持企业用户（可以创建私有仓库，私有仓库内容不对外界公开）和普通用户（受限的使用私有仓库，不受限的使用公开仓库，公开仓库内容对他人可见）。Github上面代码库惊人的增长速度证明了它是非常成功的，在2018年6月被微软以75亿美元的天价收购。\n\n国内也有不少类似Github的代码托管平台，最有名的当属[码云](https://gitee.com/)和[CODING](https://coding.net/)，目前码云和CODING对注册用户都提供了受限的使用私有仓库的功能，支持**Pull Request**（一种对话机制，可以在提交你的工作成果时让相关人员或团队注意到这件事情），同时还提供了对**缺陷管理**、**Webhook**等功能支持，这些使得版本控制系统还具备了缺陷管理和持续集成的能力。当然，很多公司都不愿意将自己的商业代码托管于别人的平台，这样的公司可以用[Gitlab](<https://about.gitlab.com/>)来搭建公司内部的Git私服，具体的做法在下一章为大家介绍。\n\n![](./res/gitlab-about.png)\n\n这里我们直接以码云为例来说明使用Git服务器的一些注意事项。首先需要在码云上注册账号，当然也可以使用第三方登录（github账号、微信账号、新浪微博账号、CSDN账号等），登录成功后就可以创建项目，创建项目几乎是“傻瓜式”的，无需赘述，我们只对几个地方加以说明。\n\n1. 创建项目时不建议勾选如下图所示的这些选项，编程语言可以暂时不做选择，而`.gitignore`模板也可以稍后自己编写或者通过更专业的工具（如：<http://gitignore.io/>网站）自动生成。\n\n   ![](./res/gitee-create-project.png)\n\n2. 添加项目成员。创建项目后，可以在项目的“设置”或“管理”中找到“成员管理”功能，这样就可以将其他开发者设置为项目团队的成员，项目成员通常分为“所有者”、“管理者”、“普通成员”和“受限成员”几种角色。\n\n   ![](./res/gitee-add-members.png)\n\n3. 项目的分支。创建项目后，项目只有一个默认的**master**分支，应该将该分支设置为“保护分支”来避免项目管理者之外的成员修改该分支（不可直接提交）。当然，如果需要我们也可以在线创建新的代码分支。\n\n4. 设置公钥实现免密访问。在项目的“设置”或“管理”中我们还可以找到“部署公钥管理”的选项，通过添加部署公钥，可以通过SSH（安全远程连接）的方式访问服务器而不用每次输入用户名和口令。可以使用`ssh-keygen`命令来创建密钥对。\n\n   ```Shell\n   ssh-keygen -t rsa -b 2048 -C \"your_email@example.com\"\n   ```\n\n   > **说明**：上面命令生成的密钥对在`~/.ssh`目录下，公钥文件默认的名字为`id_rsa.pub`，可以通过`cat id_rsa.pub`来查看自己的公钥。Windows用户在安装Git工具后，可以通过**Git Bash**来输入上面的命令。\n\n#### Git远程操作\n\n拥有了Git服务器之后，我们就可以通过Git的远程操作将自己的工作成果推到服务器的仓库中，也可以将他人的工作成果从服务器仓库更新到本地。我们以刚才在码云上创建的仓库（仓库名为`python`）为例来说明如何进行远程操作。可以在如下所示的页面上找到仓库的地址（URL），如果配置了**SSH Key**就使用SSH方式访问仓库，否则就用HTTPS方式，后者需要在进行远程操作时提供用户名和口令。\n\n![](./res/gitee-project-index.png)\n\n1. 添加远程仓库（Git服务器）。\n\n   ```Shell\n   git remote add origin git@gitee.com:jackfrued/python.git\n   ```\n\n   其中`git@gitee.com:jackfrued/python.git`是上图中显示的仓库的URL，而前面的`origin`是替代这个冗长的URL的字符串，简单的说`origin`就是服务器上仓库的别名（如果有多个Git服务器，这个简短的名字也会有多个）。可以用`git remote -v`来查看已经指定的Git服务，也可以用`git remote remove`来删除指定的Git服务器。\n\n2. 将本地代码（工作成果）推送到远程仓库。\n\n   ```Shell\n   git push -u origin master:master\n   ```\n\n   其中，`-u`是`--set-upstream`的缩写，用来指定推送的服务器仓库，后面的`origin`就是刚才给仓库起的简短的别名，冒号前面的`master`是本地分支名，冒号后面的`master`是远程分支名，如果本地分支`master`已经和远程分支`master`建立过关联，则冒号以及后面的部分可以省略。\n\n3. 从远程仓库取回代码。\n\n   ```Shell\n   git pull origin master\n   ```\n\n#### Git分支操作\n\n1. **创建**和**切换**分支。下面的命令创建了名为`dev` 的分支并切换到该分支。\n\n   ```Shell\n   git branch <branch-name>\n   git switch <branch-name>\n   ```\n\n   或\n\n   ```Shell\n   git switch -c <branch-name>\n   ```\n\n   > **注意**：在之前的Git版本中，切换分支使用`git checkout <branch-name>`命令，也可以通过`git checkout -b <branch-name>`来创建并切换分支。`git switch`命令目前仍然处于试验性阶段，但很明显这个命令更加清晰的表达了它要做的事情。\n\n2. **关联远程**分支。例如：如果当前所在的分支还没有关联到远程分支，可以使用下面的命令为它们建立关联。\n\n   ```Shell\n   git branch --set-upstream-to origin/develop\n   ```\n\n   如果需要为指定的分支关联远程分支，可以如下操作。\n\n   ```Shell\n   git branch --set-upstream-to origin/develop <branch-name>\n   ```\n\n   > 提示：上面的操作假设Git服务器上存在名为`develop`的分支，`--set-upstream-to`可以缩写为`-u`。\n\n   当然，在创建分支时，如果使用了`--track`参数，也可以直接指定与本地分支关联的远程分支，如下所示。\n\n   ```Shell\n   git branch --track <branch-name> origin/develop\n   ```\n\n   如果需要解除本地分支与远程分支的关联，可以使用下面的命令。\n\n   ```Shell\n   git branch --unset-upstream <branch-name>\n   ```\n\n3. 分支**合并**。例如在`dev`分支上完成开发任务之后，如果希望将`dev`分支上的成果合并到`master`，可以先切回到`master`分支然后使用`git merge`来做分支合并，合并的结果如下图右上方所示。\n\n   ```Shell\n   git switch master\n   git merge --no-ff dev\n   ```\n\n   使用`git merge`合并分支时，默认使用`Fast Forward`合并，这意味着如果删除了分支，分支上的信息就全都丢掉了，如果希望将分支上的历史版本保留下来，可以使用`--no-ff`参数来禁用`Fast Forward`。\n\n   在合并分支时，没有冲突的部分Git会做自动合并。如果发生了冲突（如`dev`和`master`分支上都修改了同一个文件），会看到`CONFLICT (content): Merge conflict in <filename>. Automatic merge failed; fix conflicts and then commit the result`（自动合并失败，修复冲突之后再次提交）的提示，这个时候我们可以用`git diff`来查看产生冲突的内容。解决冲突通常需要当事人当面沟通之后才能决定保留谁的版本，冲突解决后需要重新提交代码。\n\n4. 分支**变基**。分支合并操作可以将多个分支上的工作成果最终合并到一个分支上，但是再多次合并操作之后，分支可能会变得非常的混乱和复杂，为了解决这个问题，可以使用`git rebase`操作来实现分支变基。如下图所示，当我们希望将`master`和`dev`上的工作成果统一到一起的时候，也可以使用变基操作。\n\n   ![](./res/git-rebase.png)\n\n   ```Shell\n   git rebase master\n   git switch master\n   git merge dev\n   ```\n\n   当我们在`dev`分支执行`git rebase`命令时，将首先计算`dev`分支和`master`分支的差集，然后应用该差集到`dev`分支，最后我们切回到`master`分支并执行操作合并，这样就看到了如上图右下方所示的干净的分支。\n\n5. **删除**分支。删除分支可以使用`git branch`加上`-d`参数，如果分支上的工作成果还没有合并，那么在删除分支时会看到`error: The branch '<branch-name>' is not fully merged.`这样的错误提示。如果希望强行删除分支，可以使用`-D`参数。删除分支的操作如下所示。\n\n   ```Shell\n   git branch -d <branch-name>\n   error: The branch '<branch-name>' is not fully merged.\n   If you are sure you want to delete it, run 'git branch -D <branch-name>'.\n   git branch -D <branch-name>\n   ```\n\n   如果要删除远程分支，可以使用下面的命令，但是请慎重的操作。\n\n   ```Shell\n   git branch -r -d origin/develop\n   git push origin :develop\n   ```\n\n   或者\n\n   ```Shell\n   git push origin --delete develop\n   ```\n\n#### Git其他操作\n\n1. `git fetch`：下载远程仓库的所有变动，可以将远程仓库下载到一个临时分支，然后再根据需要进行合并操作，`git fetch`命令和`git merge`命令可以看作是之前讲的`git pull`命令的分解动作。\n\n   ```Shell\n   git fetch origin master:temp\n   git merge temp\n   ```\n\n2. `git diff`：常用于比较工作区和仓库、暂存区与仓库、两个分支之间有什么差别。\n\n3. `git stash`：将当前工作区和暂存区发生的变动放到一个临时的区域，让工作区变干净。这个命令适用于手头工作还没有提交，但是突然有一个更为紧急的任务（如线上bug需要修正）需要去处理的场景。\n\n   ```Shell\n   git stash\n   git stash list\n   git stash pop\n   ```\n\n4. `git reset`：回退到指定的版本。该命令主要有三个参数，如下图所示。\n\n   ![](./res/git-reset.png)\n\n5. `git cherry-pick`：挑选某个分支的单次提交并作为一个新的提交引入到你当前分支上。\n\n6. `git revert`：撤回提交信息。\n\n7. `git tag`：经常用于查看或新增一个标签。\n\n#### Git工作流程（分支管理策略）\n\n既然Git是团队开发必备的工具，那么在团队协作时就必须有一个规范的工作流程，这样才能让团队高效的工作，让项目顺利的进展下去，否则工具再厉害但团队成员各自为战，冲突就会无处不在，协作更加无从谈起。我们仍然以刚才码云上创建的`python`项目为例，来说明Git的分支管理策略。\n\n##### Github-flow\n\n1. 克隆服务器上的代码到本地。\n\n   ```Shell\n   git clone git@gitee.com:jackfrued/python.git\n   ```\n\n2. 创建并切换到自己的分支。\n\n   ```Shell\n   git switch -c <branch-name>\n   ```\n\n   或\n\n   ```Shell\n   git checkout -b <branch-name>\n   ```\n\n3. 在自己的分支上开发并在本地做版本控制。\n\n4. 将自己的分支（工作成果）推到服务器。\n\n   ```Shell\n   git push origin <branch-name>\n   ```\n\n5. 在线发起一次合并请求（通常称之为**Pull Request**，有的地方称为**Merge Request**），请求将自己的工作成果合并到`master`分支，合并之后可以删除该分支。\n\n   ![](./res/gitee-pull-request.png)\n\n上面这种分支管理策略就是被称为**github-flow**或**PR**的流程，它非常简单容易理解，只需要注意以下几点：\n\n1. `master`的内容都是可以进行发布的内容（不能直接在`master`上进行修改）。\n2. 开发时应该以`master`为基础建立新分支（日常开发任务在自己的分支上进行）。\n3. 分支先在本地实施版本控制，然后以同名分支定期向服务器进行push操作。\n4. 开发任务完成后向`master`发送合并请求。\n5. 合并请求通过审查之后合并到`master`，并从`master`向正式环境发布。\n\n当然，github-flow的缺点也很明显，`master`分支默认就是当前的线上代码，但是有的时候工作成果合并到`master`分支，并不代表它就能立刻发布，这样就会导致线上版本落后于`master`分支。\n\n##### Git-flow\n\n除了上述的github-flow分支管理策略外，还有一种名为git-flow的分支管理策略，它也是大多数公司愿意使用的一套流程。Git-flow借鉴了中央集权型版本控制系统的长处，为团队内部统一建立、合并和关闭分支的方法，如下图所示。\n\n![](./res/git-flow.png)\n\n在这种模式下，项目有两个长线分支，分别是`master`和`develop`，其他都是临时的的辅助分支，包括`feature`（开发特定功能的分支，开发结束后合并到`develop`）、`release`（从`develop`分离出来的为发布做准备的分支，发布结束后合并到`master`和`develop`）和`hotfix`（产品发布后出现问题时紧急建立的分支，直接从`master`分离，问题修复后合并到`master`并打上标签，同时还要合并到`develop`来避免将来的版本遗漏了这个修复工作，如果此时有正在发布中的`release`分支，还要合并到`release`分支）。具体的实施过程如下所示：\n\n![](./res/git-flow-detail.png)\n\n1. 最开始的时候只有`master`和`develop`分支，如上图左侧所示。\n\n2. 从`develop`分支创建`feature`分支（上图右上），工作完成后将工作成果合并到`develop`分支（上图右中）。\n\n   创建`feature`分支：\n\n   ```Shell\n   git switch -c feature/user develop\n   ```\n\n   或\n\n   ```Shell\n   git checkout -b feature/user develop\n   ```\n\n   接下来就是在`feature`分支上进行开发并实施版本控制，这一段如何操作我们就不再赘述了。工作完成后，将`feature`分支合并到`develop`分支：\n\n   ```Shell\n   git checkout develop\n   git merge --no-ff feature/user\n   git branch -d feature/user\n   git push origin develop\n   ```\n\n3. 从`develop`分支创建`release`分支，发布结束后合并回`master`和`develop`分支。\n\n   创建`release`分支：\n\n   ```Shell\n   git checkout -b release-0.1 develop\n   git push -u origin release-0.1\n   ... ... ...\n   git pull\n   git commit -a -m \"............\"\n   ```\n\n   将`release`分支合并回`master`和`develop`分支：\n\n   ```Shell\n   git checkout master\n   git merge --no-ff release-0.1\n   git push\n   \n   git checkout develop\n   git merge --no-ff release-0.1\n   git push\n   \n   git branch -d release-0.1\n   git push --delete release-0.1\n   git tag v0.1 master\n   git push --tags\n   ```\n\n4. 从`master`分支创建`hotfix`分支，在修复bug后合并到`develop`和`master`分支（上图右下）。\n\n   创建`hotfix`分支：\n\n   ```Shell\n   git checkout -b hotfix-0.1.1 master\n   git push -u origin hotfix-0.1.1\n   ... ... ...\n   git pull\n   git commit -a -m \"............\"\n   ```\n\n   将`hotfix`分支合并回`develop`和`master`分支。\n\n   ```Shell\n   git checkout master\n   git merge --no-ff hotfix-0.1.1\n   git push\n   \n   git checkout develop\n   git merge --no-ff hotfix-0.1.1\n   git push\n   \n   git branch -d hotfix-0.1.1\n   git push --delete hotfix-0.1.1\n   git tag v0.1.1 master\n   git push --tags\n   ```\n\nGit-flow流程比较容易控制各个分支的状况，但是在运用上github-flow要复杂得多，因此实际使用的时候通常会安装名为`gitflow`的命令行工具（Windows环境的Git自带了该工具）或者使用图形化的Git工具（如：SmartGit、SourceTree等）来简化操作，具体的可以参考[《git-flow 的工作流程》](<https://www.git-tower.com/learn/git/ebook/cn/command-line/advanced-topics/git-flow>)一文，因为这篇文章写得已经很好了，本文不再进行赘述。\n\n### 缺陷管理\n\n没有好的团队管理工具必然导致项目进展不顺利，任务管理困难，而引入缺陷管理系统正好可以解决这些问题，通常一个缺陷管理系统都包含了以下的功能：\n\n1. 任务管理（包括必须做什么、谁来做、什么时候完成、现在处于什么状态等）。\n2. 直观而且可以检索过去发生的各种问题。\n3. 能够对信息进行统一的管理和共享。\n4. 能够生成各类报表。\n5. 能够关联到其他系统，具有可扩展性。\n\n#### 禅道\n\n[禅道](<https://www.zentao.net/>)是国产的专业项目管理软件，它不仅仅是缺陷管理工具，它提供了完整软件生命周期管理功能，支持[Scrum敏捷开发](<http://www.scrumcn.com/agile/scrum-knowledge-library/scrum.html>)，能够实现需求管理、缺陷管理、任务管理等一系列的功能，而且拥有强大的扩展机制和丰富的功能插件。可以从禅道的官方网站提供的[下载链接](<https://www.zentao.net/download.html>)来下载禅道，推荐使用一键安装包。\n\n下面仍然以CentOS Linux为例，讲解如何利用官方提供的一键安装包来安装禅道。\n\n```Shell\ncd /opt\nwget http://dl.cnezsoft.com/zentao/pro8.5.2/ZenTaoPMS.pro8.5.2.zbox_64.tar.gz\ngunzip ZenTaoPMS.pro8.5.2.zbox_64.tar.gz\ntar -xvf ZenTaoPMS.pro8.5.2.zbox_64.tar\n```\n\n我们在`/opt`目录下（官方推荐使用这个目录）下载了禅道的归档压缩文件，并进行了解压缩和解归档的操作，完成上述步骤后，会看到一个名为`zbox`的文件夹。一键安装包中内置了Apache、MySQL、PHP等应用，也就是说这些都不需要单独安装部署了，接下来我们通过下面的命令来启动禅道。\n\n```Shell\n/opt/zbox/zbox -ap 8080 -mp 3307\n/opt/zbox/zbox start\n```\n\n> 说明：上面使用`zbox`文件夹下的`zbox`命令，其中`-ap`是为了指定Apache服务器使用的端口，`-mp`是为了指定MySQL数据库使用的端口，这里使用3307端口是为了避开服务器上可能已经存在的MySQL服务的3306端口；`start`表示启动服务，`stop`可以用来停止服务。此外，需要打开防火墙8080端口以便访问禅道，注意**数据库的端口决不能暴露给公网**。\n\n打开浏览器，输入服务器的公网IP地址就可以访问禅道，如果愿意，也可以通过DNS解析绑定一个域名来进行访问，禅道的首页如下图所示，默认的管理员是`admin`，口令是`123456`。\n\n![](./res/zentao-login.png)\n\n第一次使用禅道时，建议通过点击用户名，然后通过“帮助”菜单的“新手教程”来迅速了解禅道。官方网站的文档链接中提供了[视频教程](<https://www.zentao.net/video/c1454.html>)，初学者也可以通过视频教程来上手。\n\n![](./res/zentao-index.png)\n\n对敏捷开发以及敏捷闭环工具不是特别了解的，可以参考[《基于JIRA的Scrum敏捷开发的项目管理》](<https://blog.51cto.com/newthink/1775427>)一文。\n\n#### GitLab\n\n常用的代码托管平台和之前提到的Git私服Gitlab都提供了缺陷管理的功能，当我们要报告一个bug时，可以在如下图所示的界面创建一个新的问题票（issue ticket）。填写的内容包括：\n\n1. **[必填]**出现问题的软件版本号、具体的使用环境（如操作系统）等相关信息。\n2. **[必填]**能够稳定重现该问题的相关步骤。\n3. **[必填]**描述此处期待的行为和实际的行为。\n4. **[可选]**你对这个bug的看法（产生bug的原因是什么）。\n\n![](./res/gitlab-new-issue.png)\n\n如上图所示，我们在创建问题票时，还需要将问题指派给处理问题的人，如果不清楚应该由谁来修复这个bug，就指派给项目管理者，除此之外还要指定问题的优先级（十分紧急、紧急、普通、不紧急等）、问题的标签（功能缺陷、新特性、改进增强、前瞻研究等）、里程碑（通过里程碑可以将问题与某些特定的项目节点关联起来，之后可以查看每一个里程碑的进展，可以基于软件版本号来建立里程碑，也可以基于迭代周期来建立里程碑）以及需要在哪个时间点以前修复等信息。\n\n有些敏捷团队使用问题票来管理产品的需求，称之为“问题驱动开发”（TiDD），也就是说新功能的开发是通过创建问题票来驱动的，具体的步骤包括：建立问题票、指定责任人、开发、提交、Push到代码库。如果要创建一个和需求相关的问题票，应该要填写以下的内容：\n\n1. **[必填]**简短的描述需求，并用它作为标题。\n2. **[必填]**这个需求是解决什么问题的。\n3. **[必填]**这个需求对软件现有功能会造成什么影响。\n4. **[必填]**这个需求应该实现什么样的功能。\n5. **[必填]**这个需求是否依赖其他模块提供相关支持。\n6. **[可选]**这个需求有哪些实现方式。\n7. **[可选]**这些可选的实现方式分别有哪些优缺点。\n\n#### 其他产品\n\n除了禅道和GitLab之外，[JIRA](<https://www.atlassian.com/zh/software/jira>)、[Redmine](<https://www.redmine.org/>)、Backlog等也是不错的缺陷管理系统。目前，这些系统大都不仅仅提供了缺陷管理的功能，更多的时候它们可以作为敏捷闭环工具来使用，关于敏捷闭环工具这个话题，请大家参考[《基于JIRA的Scrum敏捷开发的项目管理》](<https://blog.51cto.com/newthink/1775427>)一文。\n\n\n### 持续集成\n\n为了快速的产出高质量的软件，在团队开发中持续集成（CI）是一个非常重要的环节。所谓CI，就是一种让计算机自动任意次重复编译、测试、汇报等工作的方法，通过CI可以帮助开发者提早发现问题，降低各种人为失误给项目带来的风险。按照经典的软件过程模型（瀑布模型），集成的工作一般要等到所有的开发工作都结束后才能开始，但这个时候如果发现了问题，修复问题的代价是非常具体的。基本上，集成实施得越晚，代码量越大，解决问题就越困难。持续集成将版本控制、自动化构建、代码测试融入到一起，让这些工作变得自动化和可协作。由于其频繁重复整个开发流程（在指定时间内多次pull源代码并运行测试代码），所以能帮助开发者提早发现问题。\n\n在所有的CI工具中，Jenkins和[TravisCI](<https://www.travis-ci.org/>)是最具有代表性的，前者是基于 Java的开源CI工具，后者是新晋的在线CI工具，下图是Jenkins的工作面板。\n\n![](./res/jenkins_new_project.png)\n\n持续集成对于编译型语言的意义更大，对于Python这样的解释型语言，更多的时候是用于对接版本控制系统触发自动化测试并产生相应的报告，类似的功能也可以通过配置**Webhook**来完成。如果要通过Docker这样的虚拟化容器进行项目打包部署或者通过K8S进行容器管理，可以在持续集成平台安装对应的插件来支持这些功能。码云甚至可以直接对接[钉钉开放平台](<https://ding-doc.dingtalk.com/>)使用钉钉机器人来向项目相关人员发送即时消息。GitLab也对CI和CD（持续交付）提供了支持，具体内容请大家参考[《GitLab CI/CD基础教程》](<https://blog.stdioa.com/2018/06/gitlab-cicd-fundmental/>)。\n\n> **说明**：\n>\n> 1. 关于敏捷开发的相关内容，有兴趣的读者可以阅读知乎上的[《这才是敏捷开发》](<https://zhuanlan.zhihu.com/p/33472102>)一文。\n>\n> 2. 本章中的部分插图来自于网易云课堂[《人人都会用Git》](<https://study.163.com/course/introduction/1003268008.htm>)课程（免费哟），在此表示感谢。\n\n", "Docker容器技术详解": "## Docker容器技术详解\n\nDocker是基于Go语言开发的开源应用容器引擎，遵从Apache Licence 2.0协议，可以让开发者打包应用以及应用的依赖包到一个可移植的容器中，然后发布到各种发行版本的Linux系统上。\n\n### Docker简介\n\n软件开发中最为麻烦的事情可能就是配置环境了。由于用户使用的操作系统具有多样性，即便使用跨平台的开发语言（如Java和Python）都不能保证代码能够在各种平台下都可以正常的运转，而且在不同的环境下我们安装的软件需要依赖的软件包也是不一样的。\n\n那么问题来了，我们安装软件的时候可不可以把软件运行的环境一并安装？我们是不是可以把原始环境一模一样地复制过来呢？\n\n虚拟机（virtual machine）就是带环境安装的一种解决方案，它可以在一种操作系统里面运行另一种操作系统，比如在Windows系统里面运行Linux系统，在macOS上运行Windows，而应用程序对此毫无感知。使用过虚拟机的人都知道，虚拟机用起来跟真实系统一模一样，而对于虚拟机的宿主系统来说，虚拟机就是一个普通文件，不需要了就删掉，对宿主系统或者其他的程序并没有影响。但是虚拟机通常会占用较多的系统资源，启动和关闭也非常的缓慢，总之用户体验并没有想象中的那么好。\n\nDocker属于对Linux容器技术（LXC）的一种封装（利用了Linux的namespace和cgroup技术），它提供了简单易用的容器使用接口，是目前最流行的 Linux 容器解决方案。Docker将应用程序与该程序的依赖打包在一个文件里面，运行这个文件，就会生成一个虚拟容器。程序在这个虚拟容器里运行，就好像在真实的物理机上运行一样。下图是虚拟机和容器的对比，左边是传统的虚拟机，右边是Docker。\n\n![](./res/docker_vs_vm.png)\n\n目前，Docker主要用于几下几个方面：\n\n1. 提供一次性的环境。\n2. 提供弹性的云服务（利用Docker很容易实现扩容和收缩）。\n3. 实践微服务架构（隔离真实环境在容器中运行多个服务）。\n\n### 安装Docker\n\n下面以CentOS为例讲解如何安装Docker，使用[Ubuntu](https://docs.docker.com/install/linux/docker-ce/ubuntu/)、[macOS](https://docs.docker.com/docker-for-mac/install/)或[Windows](https://docs.docker.com/docker-for-windows/install/)的用户可以通过点击对应的链接了解这些平台下如何进行安装。\n\n1. 确定操作系统内核版本（CentOS 7要求64位，内核版本3.10+；CentOS 6要求64位，内核版本2.6+）。\n\n   ```Bash\n   uname -r\n   ```\n\n2. 更新系统底层的库文件（建议一定要执行，否则在使用Docker时可能会出现莫名其妙的问题）。\n\n   ```Bash\n   yum update\n   ```\n\n3. 移除可能存在的旧的Docker版本。\n\n   ```Bash\n   yum list installed | grep docker\n   yum erase -y docker docker-common docker-engine\n   ```\n\n4. 安装yum工具包和依赖项。\n\n   ```Bash\n   yum install -y yum-utils device-mapper-persistent-data lvm2\n   ```\n\n5. 通过yum工具包添加yum源（安装Docker-ce的源）。\n\n   ```Bash\n   yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo\n   ```\n\n6. 在CentOS下使用yum安装Docker-ce并启动。\n\n   ```Bash\n   yum -y install docker-ce\n   systemctl start docker\n   ```\n\n7. 查看Docker的信息和版本。\n\n   ```Shell\n   docker version\n   docker info\n   ```\n\n接下来可以通过下载镜像和创建容器来看看Docker是否可以运转起来。可以使用下面的命令从Docker的镜像仓库下载名为hello-world的镜像文件。\n\n ```Shell\ndocker pull hello-world\n ```\n\n查看所有镜像文件。\n\n```Shell\ndocker images\n```\n\n```\nREPOSITORY               TAG        IMAGE ID            CREATED             SIZE\ndocker.io/hello-world    latest     fce289e99eb9        7 months ago        1.84 kB\n```\n\n通过镜像文件创建并运行容器。\n\n```Shell\ndocker container run --name mycontainer hello-world\n```\n\n> 说明：其中`mycontainer`是我们给容器起的名字，跟在`--name`参数之后；`hello-world`就是我们刚才下载的镜像文件。\n\n```\nHello from Docker!\nThis message shows that your installation appears to be working correctly.\n\nTo generate this message, Docker took the following steps:\n 1. The Docker client contacted the Docker daemon.\n 2. The Docker daemon pulled the \"hello-world\" image from the Docker Hub.\n    (amd64)\n 3. The Docker daemon created a new container from that image which runs the\n    executable that produces the output you are currently reading.\n 4. The Docker daemon streamed that output to the Docker client, which sent it\n    to your terminal.\n\nTo try something more ambitious, you can run an Ubuntu container with:\n $ docker run -it ubuntu bash\n\nShare images, automate workflows, and more with a free Docker ID:\n https://hub.docker.com/\n\nFor more examples and ideas, visit:\n https://docs.docker.com/get-started/\n```\n\n如果要删除这个容器，可以使用下面的命令。\n\n```Shell\ndocker container rm mycontainer\n```\n\n在删除容器之后，我们还可以删除刚才下载的镜像文件。\n\n```Shell\ndocker rmi hello-world\n```\n\n> 说明：如果要在Ubuntu（内核版本3.10+）下面安装和启动Docker，可以按照如下的步骤进行。\n>\n> ```Shell\n> apt update\n> apt install docker-ce\n> service docker start\n> ```\n>\n> 国内用户可以通过更换Ubuntu软件下载源来提升下载速度，具体请参照清华大学开源软件镜像站上的[《Ubuntu镜像使用帮助》](<https://mirrors.tuna.tsinghua.edu.cn/help/ubuntu/>)。\n\n安装Docker后，由于直接访问[dockerhub](https://hub.docker.com/)下载镜像会非常缓慢，建议将服务器更换为国内镜像，可以通过修改 `/etc/docker/daemon.json` 文件来做到。一般的云服务器会有自己专属的镜像，就不需要手动修改了。\n\n```JavaScript\n{\n\t\"registry-mirrors\": [\n        \"http://hub-mirror.c.163.com\",\n        \"https://registry.docker-cn.com\"\n    ]\n}\n```\n\n### 使用Docker\n\n想要玩转Docker，最简单的办法就是马上用Docker创建一些自己学习和工作中需要用到的容器，下面我们带着大家一起来创建这些容器。\n\n#### 运行Nginx\n\nNginx是高性能的Web服务器，同时也是做反向代理服务器的上佳选择。使用Docker可以非常简单的创建一个运行Nginx的容器，命令如下所示。\n\n```Shell\ndocker container run -d -p 80:80 --rm --name mynginx nginx\n```\n\n> 说明：上面的参数`-d`表示容器在后台运行（不产生输出到Shell）并显示容器的ID；`-p`是用来映射容器的端口到宿主机的端口，冒号前面是宿主机的端口，冒号后面是容器内部使用的端口；`--rm`表示容器停止后自动删除容器，例如执行命令`docker container stop mynginx`后，容器就不复存在了；`--name`后面的mynginx是自定义的容器名字；在创建容器的过程中，需要用到nginx的镜像文件，镜像文件的下载是自动完成的，如果没有指定版本号，默认是最新版本（latest）。\n\n如果需要将自己的Web项目（页面）部署到Nginx上，可以使用容器拷贝命令将指定路径下所有的文件和文件夹拷贝到容器的指定目录中。\n\n```Shell\ndocker container cp /root/web/index.html mynginx:/usr/share/nginx/html\n```\n\n如果不愿意拷贝文件也可以在创建容器时通过数据卷操作`--volume`将指定的文件夹映射到容器的某个目录中，例如将Web项目的文件夹直接映射到`/usr/share/nginx/html`目录。我们先通过下面的命令让刚才创建的容器停止运行。\n\n```Shell\ndocker container stop mynginx\n```\n\n然后用下面的命令重新创建容器。\n\n```Shell\ndocker container run -d -p 80:80 --rm --name mynginx --volume /root/docker/nginx/html:/usr/share/nginx/html nginx\n```\n\n> 说明：上面创建容器和拷贝文件的命令中，`container`是可以省略的，也就是说`docker container run`和`docker run`是一样的，而`docker container cp`和`docker cp`是一样的。此外，命令中的`--volume`也可以缩写为`-v`，就如同`-d`是`--detach`的缩写，`-p`是`--publish`的缩写。`$PWD`代表宿主系统当前文件夹，这些对于使用过Unix或者Linux系统的人来说，应该是很容易理解的。\n\n要查看运行中的容器，可以使用下面的命令。\n\n```Shell\ndocker ps\n```\n\n```\nCONTAINER ID    IMAGE    COMMAND                  CREATED            STATUS             PORTS                 NAMES\n3c38d2476384    nginx    \"nginx -g 'daemon ...\"   4 seconds ago      Up 4 seconds       0.0.0.0:80->80/tcp    mynginx\n```\n\n要启动和停止容器，可以使用下面的命令。\n\n```Shell\ndocker start mynginx\ndocker stop mynginx\n```\n\n由于在创建容器时使用了`--rm`选项，容器在停止时会被移除，当我们使用下面的命令查看所有容器时，应该已经看不到刚才的`mynginx`容器了。\n\n```Shell\ndocker container ls -a\n```\n\n如果在创建容器时没有指定`--rm`选项，那么也可以使用下面的命令来删除容器。\n\n```Shell\ndocker rm mynginx\n```\n\n要删除正在运行中的容器，需要使用`-f`选项。\n\n```Shell\ndocker rm -f mynginx\n```\n\n#### 运行MySQL\n\n我们再来尝试用Docker安装一台MySQL服务器，首先可以先检查一下有没有MySQL的镜像文件。\n\n```Shell\ndocker search mysql\n```\n\n```\nINDEX        NAME            DESCRIPTION        STARS        OFFICIAL        AUTOMATED\ndocker.io    docker.io/mysql MySQL is a ...     8486         [OK]\n...\n```\n\n> 说明：上面查询结果的列依次代表索引、镜像名、镜像描述、用户评价、是否官方镜像、自动构建。\n\n下载MySQL镜像并指定镜像的版本号。\n\n```Shell\ndocker pull mysql:5.7\n```\n\n如果需要查看已经下载的镜像文件，可以使用下面的命令。\n\n```Shell\ndocker images\n```\n\n```\nREPOSITORY          TAG                 IMAGE ID            CREATED             SIZE\ndocker.io/nginx     latest              e445ab08b2be        2 weeks ago         126 MB\ndocker.io/mysql     5.7                 f6509bac4980        3 weeks ago         373 MB\n```\n\n创建并运行MySQL容器。\n\n```Shell\ndocker run -d -p 3306:3306 --name mysql57 -v /root/docker/mysql/conf:/etc/mysql/mysql.conf.d -v /root/docker/mysql/data:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=123456 mysql:5.7\n```\n\n> **注意**：上面创建容器时我们又一次使用了数据卷操作，那是因为通常容器是随时创建随时删除的，而数据库中的数据却是需要保留下来的。\n\n上面的两个数据卷操作一个是映射了MySQL配置文件所在的文件夹，一个是映射了MySQL数据所在的文件夹，这两个数据卷操作非常重要。我们可以将MySQL的配置文件放在`$PWD/mysql/conf`目录下，配置文件的具体内容如下所示：\n\n```INI\n[mysqld]\npid-file=/var/run/mysqld/mysqld.pid\nsocket=/var/run/mysqld/mysqld.sock\ndatadir=/var/lib/mysql\nlog-error=/var/log/mysql/error.log\nserver-id=1\nlog-bin=/var/log/mysql/mysql-bin.log\nexpire_logs_days=30\nmax_binlog_size=256M\nsymbolic-links=0\n```\n\n如果安装了MySQL 8.x版本（目前的最新版本），在使用客户端工具连接服务器时可能会遇到`error 2059: Authentication plugin 'caching_sha2_password' cannot be loaded`的问题，这是因为MySQL 8.x默认使用了名为“caching_sha2_password”的机制对用户口令进行了更好的保护，但是如果客户端工具不支持新的认证方式，连接就会失败。解决这个问题有两种方式：一是升级客户端工具来支持MySQL 8.x的认证方式；二是进入容器，修改MySQL的用户口令认证方式。下面是具体的步骤，我们先用`docker exec`命令进入容器的交互式环境，假设运行MySQL 8.x的容器名字叫`mysql8x`。\n\n```Shell\ndocker exec -it mysql8x /bin/bash\n```\n\n进入容器的交互式Shell之后，可以首先利用MySQL的客户端工具连接MySQL服务器。\n\n```Shell\nmysql -u root -p\nEnter password:\nYour MySQL connection id is 16\nServer version: 8.0.12 MySQL Community Server - GPL\nCopyright (c) 2000, 2018, Oracle and/or its affiliates. All rights reserved.\nOracle is a registered trademark of Oracle Corporation and/or its\naffiliates. Other names may be trademarks of their respective\nowners.\nType 'help;' or '\\h' for help. Type '\\c' to clear the current input statement.\nmysql>\n```\n\n接下来通过SQL来修改用户口令就可以了。\n\n```SQL\nalter user 'root'@'%' identified with mysql_native_password by '123456' password expire never;\n```\n\n当然，如果愿意你也可以查看一下用户表检查是否修改成功。\n\n```SQL\nuse mysql;\nselect user, host, plugin, authentication_string from user where user='root';\n+------+-----------+-----------------------+-------------------------------------------+\n| user | host      | plugin                | authentication_string                     |\n+------+-----------+-----------------------+-------------------------------------------+\n| root | %         | mysql_native_password | *6BB4837EB74329105EE4568DDA7DC67ED2CA2AD9 |\n| root | localhost | mysql_native_password | *6BB4837EB74329105EE4568DDA7DC67ED2CA2AD9 |\n+------+-----------+-----------------------+-------------------------------------------+\n2 rows in set (0.00 sec)\n```\n\n在完成上面的步骤后，现在即便不更新客户端工具也可以连接MySQL 8.x了。\n\n#### 运行Redis\n\n接下来我们试一试运行多个容器并让多个容器之间通过网络通信。我们创建4个Redis容器来实现一主三从的主从复制结构。\n\n```Shell\ndocker run -d -p 6379:6379 --name redis-master redis\ndocker run -d -p 6380:6379 --name redis-slave-1 --link redis-master:redis-master redis redis-server --replicaof redis-master 6379\ndocker run -d -p 6381:6379 --name redis-slave-2 --link redis-master:redis-master redis redis-server --replicaof redis-master 6379\ndocker run -d -p 6382:6379 --name redis-slave-3 --link redis-master:redis-master redis redis-server --replicaof redis-master 6379\n```\n\n上面的命令中，`--link`参数用于给容器创建网络别名，因为三台从机（slave）需要通过网络连接自己的主机（master）。虽然，我们可以通过`docker inspect --format '{{ .NetworkSettings.IPAddress }}' <container-ID>`命令来查看到容器的IP地址，但是由于容器的即装即用性，容器的IP地址有可能会发生变化，如果直接使用IP地址，在容器重启后就可能会因为IP地址的变化导致从机无法连接到主机。使用`--link`参数创建网络别名就是为了在启动Redis服务器时在`redis-server`后面的`--replicaof`参数后使用这个别名而不是IP地址。\n\n接下来我们进入名为`redis-master`的容器，看看主从复制的配置是否成功。\n\n```Shell\ndocker exec -it redis-master /bin/bash\n```\n\n通过`redis-cli`启动命令行工具。\n\n```Shell\nredis-cli\n127.0.0.1:6379> info replication\n# Replication\nrole:master\nconnected_slaves:3\nslave0:ip=172.17.0.4,port=6379,state=online,offset=1988,lag=0\nslave1:ip=172.17.0.5,port=6379,state=online,offset=1988,lag=1\nslave2:ip=172.17.0.6,port=6379,state=online,offset=1988,lag=1\nmaster_replid:94703cfa03c3ddc7decc74ca5b8dd13cb8b113ea\nmaster_replid2:0000000000000000000000000000000000000000\nmaster_repl_offset:1988\nsecond_repl_offset:-1\nrepl_backlog_active:1\nrepl_backlog_size:1048576\nrepl_backlog_first_byte_offset:1\nrepl_backlog_histlen:1988\n```\n\n#### 运行GitLab\n\nGitLab是由GitLab Inc.开发的Git仓库管理工具，具有wiki、问题跟踪、持续集成等一系列的功能，分为社区版和企业版。通过Docker提供的虚拟化容器，我们可以安装社区版的Docker。因为GitLab需要使用SSH协议进行安全连接，我们要暴露容器的22端口，所以可以先将宿主机SSH连接的22端口修改为其他端口（如：12345），然后再进行后续的操作。\n\n```Shell\nvim /etc/ssh/sshd_config\n```\n\n将其中定义端口的那行代码去掉注释并将端口修改为12345。\n\n```\nPort 12345\n```\n\n重新启动`sshd`服务。 \n\n```Shell\nsystemctl restart sshd\n```\n\n> **提示**：修改端口后应该确保防火墙上也开启对应的端口，否则无法使用SSH连接到Linux服务器。\n\n创建需要用于数据卷映射操作的文件夹。\n\n```Shell\nmkdir -p /root/gitlab/{config,logs,data}\n```\n\n基于`gitlab/gitlab-ce`镜像创建容器，并暴露80端口（HTTP连接）和22端口（SSH连接）。\n\n```Shell\ndocker run -d -p 80:80 -p 22:22 --name gitlab -v /root/gitlab/config:/etc/gitlab -v /root/gitlab/logs:/var/log/gitlab -v /root/gitlab/data:/var/opt/gitlab gitlab/gitlab-ce\n```\n\n> 说明：GitLab的启动比较缓慢，创建好容器后可能需要等待一段时间才能通过浏览器来进行访问。\n\n首次进入GitLab访问界面会提示我们修改管理员密码，设置好管理员密码后就可以在登录界面输入用户名`root`和刚才设置的密码登录到管理员控制台，在使用上还是非常简单和人性化的。\n\n### 构建镜像\n\n通过上面的讲解，我们已经掌握了如何通过官方提供的镜像来创建容器。当然如果愿意，我们也可以用配置好的容器来生成镜像。简而言之，**Docker镜像是由文件系统叠加而成的，系统的最底层是bootfs，相当于就是Linux内核的引导文件系统；接下来第二层是rootfs，这一层可以是一种或多种操作系统（如Debian或Ubuntu文件系统），Docker中的rootfs是只读状态的；Docker利用联合挂载技术将各层文件系统叠加到一起，最终的文件系统会包含有底层的文件和目录，这样的文件系统就是一个镜像**。\n\n之前我们讲过了如何查找、列出镜像和拉取（下载）镜像，接下来看看构建镜像的两种方式：\n\n1. 使用`docker commit`命令。（不推荐）\n2. 使用`docker build`命令和Dockerfile文件。\n\n#### 使用commit命令构建镜像\n\n为了演示如何构建镜像，我们先使用Ubuntu镜像来定制一个容器，命令如下所示。\n\n```Shell\ndocker run --name myubuntu -it ubuntu /bin/bash\n```\n\n在容器中执行下面的命令来安装Apache服务器并退出容器。\n\n```Shell\napt -y upgrade\napt -y install apache2\nexit\n```\n\n我们将这个容器作为一个定制的Web服务器保存起来，当需要这样一台Web服务器的时候，就没有必要重新创建容器并安装Apache了。\n\n首先我们通过下面的命令查看容器的ID。\n\n```Shell\ndocker container ls -a\n```\n\n```\ndocker container ls -a\nCONTAINER ID    IMAGE    COMMAND        CREATED        STATUS        PORTS    NAMES\n014bdb321612    ubuntu   \"/bin/bash\"    5 minutes ago  Exited (0)             myubuntu\n```\n\n提交定制的容器。\n\n```Shell\ndocker commit 014bdb321612 jackfrued/mywebserver\n```\n\n查看镜像文件。\n\n```Shell\ndocker images\n```\n\n```\nREPOSITORY              TAG       IMAGE ID        CREATED             SIZE\njackfrued/mywebserver   latest    795b294d265a    14 seconds ago      189 MB\n```\n\n生成镜像文件以后，后面就可以利用刚才创建的镜像文件来创建新的容器。\n\n#### 使用Dockerfile构建镜像\n\nDockerfile使用DSL（Domain Specific Language）来构建一个Docker镜像，只要编辑好了Dockerfile文件，就可以使用`docker build`命令来构建一个新的镜像。\n\n我们先创建一个名为myapp的文件夹来保存项目代码和Dockerfile的文件，如下所示：\n\n```Shell\n[ECS-root temp]# tree myapp\nmyapp\n├── api\n│   ├── app.py\n│   ├── requirements.txt\n│   └── start.sh\n└── Dockerfile\n```\n\n其中api是Flask项目的文件夹，其中包括了项目代码、依赖项以及启动脚本等文件，具体内容如下所示：\n\n`app.py`文件：\n\n```Python\nfrom flask import Flask\nfrom flask_restful import Resource, Api\nfrom flask_cors import CORS\n\napp = Flask(__name__)\nCORS(app, resources={r'/api/*': {'origins': '*'}})\napi = Api(app)\n\n\nclass Product(Resource):\n\n    def get(self):\n        products = ['Ice Cream', 'Chocolate', 'Coca Cola', 'Hamburger']\n        return {'products': products}\n\n\napi.add_resource(Product, '/api/products')\n```\n\n`requirements.txt`文件：\n\n```INI\nflask\nflask-restful\nflask-cors\ngunicorn\n```\n\n`start.sh`文件：\n\n```Shell\n#!/bin/bash\nexec gunicorn -w 4 -b 0.0.0.0:8000 app:app\n```\n\n> **提示**：需要给start.sh文件以执行权限，可以使用`chmod 755 start.sh`命令来做到。\n\nDockerfile文件：\n\n```Dockerfile\n# 指定基础镜像\nFROM python:3.7\n# 指定镜像的维护者\nMAINTAINER jackfrued \"jackfrued@126.com\"\n# 将指定文件添加到容器中指定的位置\nADD api/* /root/api/\n# 设置工作目录\nWORKDIR /root/api\n# 执行命令(安装Flask项目的依赖项)\nRUN pip install -r requirements.txt -i https://pypi.doubanio.com/simple/\n# 容器启动时要执行的命令\nENTRYPOINT [\"./start.sh\"]\n# 暴露端口\nEXPOSE 8000\n```\n\n我们来解释一下上面的Dockerfile文件。Dockerfile文件通过特殊的指令来指定基础镜像（FROM指令）、创建容器后需要指定的命令（RUN指令）以及需要暴露的端口（EXPOSE）等信息。我们稍后会专门为大家介绍这些Dockfile中的指令。\n\n接下来我们可以使用`docker build`命令来创建镜像，如下所示。\n\n```Shell\ndocker build -t \"jackfrued/myapp\" .\n```\n\n> 提示：上面的命令最后面的`.` 千万不要漏掉了哦，它表示从当前路径下寻找Dockerfile。\n\n通过下面的命令可以查看创建好的镜像。\n\n```Shell\ndocker images\n```\n\n```\nREPOSITORY                   TAG                 IMAGE ID            CREATED             SIZE\njackfrued/myapp              latest              6d6f026a7896        5 seconds ago       930 MB\n```\n\n如果想知道镜像文件是如何创建出来的，可以使用下面的命令。\n\n```Shell\ndocker history jackfrued/myapp\n```\n\n```\nIMAGE               CREATED             CREATED BY                                      SIZE                COMMENT\n6d6f026a7896        31 seconds ago      /bin/sh -c #(nop)  EXPOSE 8000/tcp              0 B                 \n3f7739173a79        31 seconds ago      /bin/sh -c #(nop)  ENTRYPOINT [\"./start.sh\"]    0 B                 \n321e6bf09bf1        32 seconds ago      /bin/sh -c pip install -r requirements.txt...   13 MB               \n2f9bf2c89ac7        37 seconds ago      /bin/sh -c #(nop) WORKDIR /root/api             0 B                 \n86119afbe1f8        37 seconds ago      /bin/sh -c #(nop) ADD multi:4b76f9c9dfaee8...   870 B               \n08d465e90d4d        3 hours ago         /bin/sh -c #(nop)  MAINTAINER jackfrued \"j...   0 B                 \nfbf9f709ca9f        12 days ago         /bin/sh -c #(nop)  CMD [\"python3\"]              0 B \n```\n\n使用该镜像来创建容器运行Web服务器。\n\n```Shell\ndocker run -d -p 8000:8000 --name myapp jackfrued/myapp\n```\n\n如果希望将上面创建的镜像文件放到dockerhub仓库中，可以按照如下所示的步骤进行操作。\n\n通过下面的命令登录到dockerhub。\n\n```Shell\ndocker login\n```\n\n输入用户名和口令进行登录。\n\n```\nLogin with your Docker ID to push and pull images from Docker Hub. If you don't have a Docker ID, head over to https://hub.docker.com to create one.\nUsername: jackfrued\nPassword: \nLogin Succeeded\n```\n\n通过下面的命令将镜像推到仓库中。\n\n```Shell\ndocker push jackfrued/webserver\n```\n\n![](./res/dockerhub-repo.png)\n\n#### Dockerfile指令\n\n想了解Dockerfile的指令可以查看官方提供的[参考手册](<https://docs.docker.com/engine/reference/builder/>)，下面我们为大家介绍一些常用的指令。\n\n1. **FROM**：设置基础镜像，必须是Dockerfile中的第一条指令。\n\n   ```Dockerfile\n   FROM <镜像名> [AS <别名>]\n   ```\n\n   或\n\n   ```Dockerfile\n   FROM <镜像名>[:<标签>] [AS <别名>]\n   ```\n\n2. **RUN**：指定构建镜像时要执行的命令。\n\n   ```Dockerfile\n   RUN <命令> [参数1], [参数2], ... \n   ```\n\n   或\n\n   ```Dockerfile\n   RUN [\"可执行文件\", \"参数1\", \"参数2\", ...]\n   ```\n\n3. **CMD**：指定构建镜像后要执行的命令。\n\n   ```Dockerfile\n   CMD <命令> [参数1], [参数2], ...\n   ```\n\n   或\n\n   ```Dockerfile\n   CMD [\"可执行文件\", \"参数1\", \"参数2\", ...]\n   ```\n\n   > 说明：Docker不同于虚拟机，容器本身就是一个进程，容器中的应用应该位于前台运行。CMD命令相当于就是用来指定容器主进程（创建容器后要在前台执行的程序）的，如果主进程结束了，容器也就停止运行了。所以在容器中启动Nginx不能使用`service nginx start`或是`systemctl start nginx`而是要通过`CMD [\"nginx\", \"-g\", \"daemon off;\"]`让它在前台运行。\n\n4. **ENTRYPOINT**：和CMD类似，也可以执行命令，但`docker run`命令行中指定的任何参数都会被当做参数再次传给ENTRYPOINT指令中的命令，这就使得我们可以构建一个镜像，它既可以运行一个默认的命令，也支持通过`docker run`命令行为该命令指定可覆盖的参数选项。\n\n   ```Dockerfile\n   ENTRYPOINT <命令> [参数1], [参数2], ...\n   ```\n\n   或\n\n   ```Dockerfile\n   ENTRYPOINT [\"可执行文件\", \"参数1\", \"参数2\", ...]\n   ```\n\n5. **WORKDIR**：在通过镜像创建新容器时，在容器内部创建一个工作目录，ENTRYPOINT和CMD指定的程序会在这个目录下执行。在使用`docker run`命令时可以通过`-w`参数来覆盖由WORKDIR指定的工作目录。例如：\n\n   ```Dockerfile\n   WORKDIR /opt/webapp\n   ```\n\n   ```Shell\n   docker run -w /usr/share/webapp ...\n   ```\n\n6. **ENV**：在创建镜像时设置环境变量。在使用`docker run`命令时，可以通过`-e`参数来修改环境变量的设置。例如：\n\n   ```Dockerfile\n   ENV DEFAULT_PORT=8080\n   ```\n\n   ```Shell\n   docker run -e \"DEFAULT_PORT=8000\" ...\n   ```\n\n7. **USER**：指定镜像会以什么用户身份去运行。例如：\n\n   ```Dockerfile\n   USER nginx\n   ```\n\n8. **VOLUME**：在创建容器时添加一个数据卷的挂载点。通过数据卷操作可以实现容器间数据的共享和重用，对卷所作的修改可以马上生效而不需要重新启动容器，我们之前创建容器时使用`--volume`参数就是为了实现数据卷的映射操作。\n\n   ```Dockerfile\n   VOLUME [\"/路径1\", \"/路径2/子路径2.1/\", ...]\n   ```\n\n9. **ADD**：将构建目录下的文件和文件夹复制到镜像中，如果是压缩文件和归档文件，ADD命令会对这些文件进行解压缩解归档的操作。\n\n   ```Dockerfile\n   ADD [--chown=<用户>:<用户组>] <源文件> <目标文件>\n   ```\n\n10. **COPY**：非常类似于ADD，但不会主动对文件进行提取操作。\n\n11. **LABEL**：为Docker镜像添加一些元数据，在使用`docker inspect`命令时会看到这些元数据。\n\n    ```Dockerfile\n    LABEL version=\"1.0.0\" location=\"Chengdu\"\n    ```\n\n12. **ONBUILD**：为镜像添加触发器，当一个镜像被用作其他镜像的基础镜像，触发器将会被执行。例如：\n\n    ```Dockerfile\n    ONBUILD ADD . /app/src\n    ONBUILD RUN cd /app/src && make\n    ```\n\n### 多容器管理\n\n我们的项目可能会使用了多个容器，容器多了之后管理容器的工作就会变得麻烦。如果要对多个容器进行自动配置使得容器可以相互协作甚至实现复杂的调度，这就需要进行容器编排。Docker原生对容器编排的支持非常弱，但是可以通过社区提供的工具来实现容器编排。\n\n#### Docker Compose\n\n可以通过安装Docker Compose工具来实现基于YAML文件的容器编排，YAML文件会定义一系列的容器以及容器运行时的属性，Docker Compose会根据这些配置来管理容器。\n\n1. 安装Docker Compose。\n\n   ```Shell\n   curl -L \"https://github.com/docker/compose/releases/download/1.25.4/docker-compose-$(uname -s)-$(uname -m)\" -o /usr/local/bin/docker-compose\n   chmod +x /usr/local/bin/docker-compose\n   ```\n\n   > 说明：如果没有curl工具，在CentOS下可以先通过包管理工具yum安装curl再执行上面的命令。\n\n   当然我们也可以使用Python的包管理工具pip来安装Docker Compose，命令如下所示。\n\n   ```Shell\n   pip3 install -U docker-compose\n   ```\n\n2. 使用Docker Compose。\n\n   我们在刚才的Flask项目中引入缓存，然后再利用Flask提供的数据接口为前端页面提供数据，使用Vue.js进行页面渲染并将静态页面部署在Nginx服务器上。项目文件夹结构如下所示：\n\n   ```Shell\n   [ECS-root ~]# tree temp\n   temp\n   ├── docker-compose.yml\n   ├── html\n   │   └── index.html\n   └── myapp\n       ├── api\n       │   ├── app.py\n       │   ├── requirements.txt\n       │   └── start.sh\n       └── Dockerfile\n   ```\n\n   修改后的app.py文件代码如下所示：\n\n   ```Python\n   from pickle import dumps, loads\n   \n   from flask import Flask\n   from flask_restful import Resource, Api\n   from flask_cors import CORS\n   from redis import Redis\n   \n   app = Flask(__name__)\n   CORS(app, resources={r'/api/*': {'origins': '*'}})\n   api = Api(app)\n   redis = Redis(host='redis-master', port=6379)\n   \n   \n   class Product(Resource):\n   \n       def get(self):\n           data = redis.get('products')\n           if data:\n               products = loads(data)\n           else:\n               products = ['Ice Cream', 'Chocolate', 'Coca Cola', 'Hamburger']\n               redis.set('products', dumps(products))\n           return {'products': products}\n   \n   \n   api.add_resource(Product, '/api/products')\n   ```\n\n   html文件夹用来保存静态页面，稍后我们会通一个运行Nginx的容器来向浏览器提供静态页面。index.html文件的内容如下所示：\n\n   ```HTML\n   <!DOCTYPE html>\n   <html lang=\"en\">\n   <head>\n       <meta charset=\"utf-8\">\n       <title>首页</title>\n   </head>\n   <body>\n       <div id=\"app\">\n           <h2>产品列表</h2>\n           <ul>\n               <li v-for=\"product in products\">{{ product }}</li>\n           </ul>\n       </div>\n       <script src=\"https://cdn.bootcss.com/vue/2.6.10/vue.min.js\"></script>\n       <script>\n           new Vue({\n               el: '#app', \n               data: {\n                   products: []\n               },\n               created() {\n                   fetch('http://1.2.3.4:8000/api/products')\n                       .then(resp => resp.json())\n                       .then(json => {this.products = json.products})\n               }\n           })\n       </script>\n   </body>\n   </html>\n   ```\n\n   接下来，我们要通过docker-compose.yml文件来创建三个容器并指明容器之间的依赖关系。\n\n   ```YAML\n   version: '3'\n   services:\n     api-server:\n       build: ./myapp\n       ports:\n         - '8000:8000'\n       links:\n         - redis-master\n     web-server:\n       image: nginx\n       ports:\n         - '80:80'\n       volumes:\n         - ./html:/usr/share/nginx/html\n     redis-master:\n       image: redis\n       expose:\n         - '6379'\n   ```\n\n   有了这个YAML文件，我们就可以使用`docker-compose`命令来创建容器运行项目，其命令如下所示：\n\n   ```Shell\n   [ECS-root temp]# docker-compose up\n   Creating network \"temp_default\" with the default driver\n   Creating temp_web-server_1   ... done\n   Creating temp_redis-master_1 ... done\n   Creating temp_api-server_1   ... done\n   Attaching to temp_redis-master_1, temp_web-server_1, temp_api-server_1\n   redis-master_1  | 1:C 05 Dec 2019 11:57:26.828 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo\n   redis-master_1  | 1:C 05 Dec 2019 11:57:26.828 # Redis version=5.0.6, bits=64, commit=00000000, modified=0, pid=1, just started\n   redis-master_1  | 1:C 05 Dec 2019 11:57:26.828 # Warning: no config file specified, using the default config. In order to specify a config file use redis-server /path/to/redis.conf\n   redis-master_1  | 1:M 05 Dec 2019 11:57:26.830 * Running mode=standalone, port=6379.\n   redis-master_1  | 1:M 05 Dec 2019 11:57:26.831 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n   redis-master_1  | 1:M 05 Dec 2019 11:57:26.831 # Server initialized\n   redis-master_1  | 1:M 05 Dec 2019 11:57:26.831 # WARNING overcommit_memory is set to 0! Background save may fail under low memory condition. To fix this issue add 'vm.overcommit_memory = 1' to /etc/sysctl.conf and then reboot or run the command 'sysctl vm.overcommit_memory=1' for this to take effect.\n   redis-master_1  | 1:M 05 Dec 2019 11:57:26.831 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n   redis-master_1  | 1:M 05 Dec 2019 11:57:26.831 * Ready to accept connections\n   api-server_1    | [2019-12-05 11:57:27 +0000] [1] [INFO] Starting gunicorn 20.0.4\n   api-server_1    | [2019-12-05 11:57:27 +0000] [1] [INFO] Listening at: http://0.0.0.0:8000 (1)\n   api-server_1    | [2019-12-05 11:57:27 +0000] [1] [INFO] Using worker: sync\n   api-server_1    | [2019-12-05 11:57:27 +0000] [8] [INFO] Booting worker with pid: 8\n   api-server_1    | [2019-12-05 11:57:27 +0000] [9] [INFO] Booting worker with pid: 9\n   api-server_1    | [2019-12-05 11:57:27 +0000] [10] [INFO] Booting worker with pid: 10\n   api-server_1    | [2019-12-05 11:57:27 +0000] [11] [INFO] Booting worker with pid: 11\n   ```\n\n    要停止容器的运行，可以使用下面的命令。\n\n   ```Shell\n   docker-compose down\n   ```\n\n#### Kubernetes（K8S）\n\n实际的生产环境中常常需要部署和管理多个协同工作的容器，docker compose解决了多容器创建和管理的问题，但是实际项目中，我们还需要Kubernetes（以下都简称为K8S）来提供一个跨主机集群的容器调度平台。K8S可以进行自动化容器的部署、扩展和操作，从而提供以容器为中心的基础架构。该项目是谷歌在2014年启动的项目，建立在谷歌公司十余年运维经验的基础之上，而且谷歌自己的应用也是运行在容器上的。\n\n", "MySQL性能优化": "## MySQL性能优化\n\n### 基本原则\n\n想要发挥 MySQL 的最佳性能，需要遵循 3 个基本使用原则。\n\n1. 让MySQL回归存储的基本职能：MySQL 数据库只用于数据的存储，不进行数据的复杂计算，不承载业务逻辑，确保存储和计算分离；\n2. 查询数据时，尽量单表查询，减少跨库查询和多表关联；\n3. 杜绝大事务、大 SQL、大批量、大字段等一系列性能杀手。\n    - 大事务：运行步骤较多，涉及的表和字段较多，容易造成资源的争抢，甚至形成死锁。一旦事务回滚，会导致资源占用时间过长。\n    - 大 SQL：复杂的SQL意味着过多的表的关联，MySQL 数据库处理关联超过3张表以上的SQL时，占用资源多，性能低下。\n    - 大批量：多条SQL一次性执行完成，可以减少一条条执行SQL产生的额外开销，但必须确保进行充分的测试，并且在业务低峰时段或者非业务时段执行。\n    - 大字段：blob、text类型的大字段要尽量少用，必须要用时，尽量与主业务表分离，减少对这类字段的检索和更新。\n\n### 建库建表\n\n1. 必须指定默认存储引擎为 InnoDB，并且禁用 MyISAM 存储引擎，随着 MySQL 8.0 版本的发布，所有的数据字典表都已经转换成了 InnoDB，MyISAM 存储引擎已成为了历史。\n2. 默认字符集 UTF8mb4，以前版本的 UTF8 是 UTF8mb3，未包含个别特殊字符，新版本的 UTF8mb4 包含所有字符，官方强烈建议使用此字符集。\n3. 关闭区分大小写功能。设置参数`lower_case_table_names`的值为`1`，即可关闭区分大小写功能，即大写字母 T 和小写字母 t 一样。\n4. 存储过程、触发器、视图、event等功能尽量在程序中实现，一方面是为了存储和计算分离，另一方面是因为这些功能非常不完整，调试、排错、监控都非常困难，相关数据字典也不完善，存在潜在的风险。一般在生产数据库中，禁止使用。\n5. 单个数据库实例表数量控制在2000个以内。\n\n#### InnoDB表的注意事项\n\n1. 主键列使用`unsigned`整数，可以使用`auto_increment`，但是要禁止手动更新主键。\n2. 每个列都必须添加`comment`注释。\n3. 在建表时必须显示指定`engine`。\n4. 表必备三字段：`xxx_id`、 `xxx_create`、 `xxx_modified`。其中`xxx_id`为主键，类型`unsigned`整数类型（例如：`int unsigned`）；`xxx_create`、`xxx_modified`的类型均为`datetime`类型，分别记录该条数据的创建时间、修改时间。\n5. 所有字段必须指定`not null`，为空值指定`default`值，因为MySQL难以优化`null`值，含`null`值的复合索引会失效，最终导致查询效率低。\n6. 单张表的字段数尽量空值在50个字段以内，如果字段过多可以考虑垂直拆分。\n7. 禁用`enum`和`set`类型，因为这样的类型兼容性不好且性能较差。\n8. 大文件不应该使用`blob`类型而是保存它们的路径，`blob`和`text`这样的类型会导致处理性能下降，全表扫描代价大大增加。\n9. 对货币等对精度敏感的数据，应该使用定点数（`decimal`）而不是浮点数（`float`）。\n10. 保存IP地址不要用`char(15)`，应该使用`int unsigned`，可以使用`inet_aton`和`inet_ntoa`函数实现整数和IP地址的转换。\n\n### 使用索引\n\n在前面[《关系型数据库MySQL》](../Day36-40/36-38.关系型数据库MySQL.md)一文中，我们已经讲到过索引的相关知识，这里我们做一个简单的回顾。\n\n#### 索引的设计原则\n\n1. 创建索引的列并不一定是`select`操作中要查询的列，最适合做索引的列是出现在`where`子句中经常用作筛选条件或连表子句中作为表连接条件的列。\n2. 具有唯一性的列，索引效果好；重复值较多的列，索引效果差。\n3. 如果为字符串类型创建索引，最好指定一个前缀长度，创建短索引。短索引可以减少磁盘I/O而且在做比较时性能也更好，更重要的是MySQL底层的高速索引缓存能够缓存更多的键值。\n4. 创建一个包含N列的复合索引（多列索引）时，相当于是创建了N个索引，此时应该利用最左前缀进行匹配。\n5. 不要过度使用索引。索引并不是越多越好，索引需要占用额外的存储空间而且会影响写操作的性能（插入、删除、更新数据时索引也需要更新）。MySQL在生成执行计划时，要考虑各个索引的使用，这个也是需要耗费时间的。\n6. 要注意可能使索引失效的场景，例如：模糊查询使用了前置通配符、使用负向条件进行查询等。\n\n### 使用过程\n\n过程，通常也称之为存储过程，它是事先编译好存储在数据库中的一组SQL的集合。调用存储过程可以简化应用程序开发人员的工作，减少与数据库服务器之间的通信，对于提升数据操作的性能是有帮助的，这些我们在之前的[《关系型数据库MySQL》](../Day36-40/36-38.关系型数据库MySQL.md)一文中已经提到过。\n\n### 数据分区\n\nMySQL支持做数据分区，通过分区可以存储更多的数据、优化查询，获得更大的吞吐量并快速删除过期的数据。关于这个知识点建议大家看看MySQL的[官方文档](https://dev.mysql.com/doc/refman/5.7/en/partitioning-overview.html)。数据分区有以下几种类型：\n\n1. RANGE分区：基于连续区间范围，把数据分配到不同的分区。\n\n   ```SQL\n   CREATE TABLE tb_emp (\n       eno INT NOT NULL,\n       ename VARCHAR(20) NOT NULL,\n       job VARCHAR(10) NOT NULL,\n       hiredate DATE NOT NULL,\n       dno INT NOT NULL\n   )\n   PARTITION BY RANGE( YEAR(hiredate) ) (\n       PARTITION p0 VALUES LESS THAN (1960),\n       PARTITION p1 VALUES LESS THAN (1970),\n       PARTITION p2 VALUES LESS THAN (1980),\n       PARTITION p3 VALUES LESS THAN (1990),\n       PARTITION p4 VALUES LESS THAN MAXVALUE\n   );\n   ```\n\n2. LIST分区：基于枚举值的范围，把数据分配到不同的分区。\n\n3. HASH分区 / KEY分区：基于分区个数，把数据分配到不同的分区。\n\n   ```SQL\n   CREATE TABLE tb_emp (\n       eno INT NOT NULL,\n       ename VARCHAR(20) NOT NULL,\n       job VARCHAR(10) NOT NULL,\n       hiredate DATE NOT NULL,\n       dno INT NOT NULL\n   )\n   PARTITION BY HASH(dno)\n   PARTITIONS 4;\n   ```\n\n### SQL优化\n\n1. 定位低效率的SQL语句 - 慢查询日志。\n\n   - 查看慢查询日志相关配置\n\n      ```SQL\n      mysql> show variables like 'slow_query%';\n      +---------------------------+----------------------------------+\n      | Variable_name             | Value                            |\n      +---------------------------+----------------------------------+\n      | slow_query_log            | OFF                              |\n      | slow_query_log_file       | /mysql/data/localhost-slow.log   |\n      +---------------------------+----------------------------------+\n\n      mysql> show variables like 'long_query_time';\n      +-----------------+-----------+\n      | Variable_name   | Value     |\n      +-----------------+-----------+\n      | long_query_time | 10.000000 |\n      +-----------------+-----------+\n      ```\n\n   - 创建慢查询日志文件并修改所有者。\n\n      ```Bash\n      touch /var/log/mysqld-slow.log\n      chown mysql /var/log/mysqld-slow.log\n      ```\n\n   - 修改全局慢查询日志配置。\n\n      ```SQL\n      mysql> set global slow_query_log_file='/var/log/mysqld-slow.log'\n      mysql> set global slow_query_log='ON'; \n      mysql> set global long_query_time=1;\n      ```\n      \n   - 或者直接修改MySQL配置文件启用慢查询日志。\n     \n      ```INI\n      [mysqld]\n      slow_query_log=ON\n      slow_query_log_file=/var/log/mysqld-slow.log\n      long_query_time=1\n      ```\n\n   > **注意**：修改了配置文件需要重启MySQL，CentOS上对应的命令是`systemctl restart mysqld`。\n\n2. 通过`explain`了解SQL的执行计划。例如：\n\n   ```SQL\n   explain select ename, job, sal from tb_emp where dno=20\\G\n   *************************** 1. row ***************************\n              id: 1\n     select_type: SIMPLE\n           table: tb_emp\n            type: ref\n   possible_keys: fk_emp_dno\n             key: fk_emp_dno\n         key_len: 5\n             ref: const\n            rows: 7\n           Extra: NULL\n   1 row in set (0.00 sec)\n   ```\n\n   - `select_type`：查询类型（SIMPLE - 简单查询、PRIMARY - 主查询、UNION - 并集、SUBQUERY - 子查询）。\n   - `table`：输出结果集的表。\n   - `type`：访问类型（ALL - 全表查询性能最差、index、range、ref、eq_ref、const、NULL）。\n   - `possible_keys`：查询时可能用到的索引。\n   - `key`：实际使用的索引。\n   - `key_len`：索引字段的长度。\n   - `rows`：扫描的行数，行数越少肯定性能越好。\n   - `extra`：额外信息。\n\n3. 通过`show profiles`和`show profile for query`分析SQL。\n\n   MySQL从5.0.37开始支持剖面系统来帮助用户了解SQL执行性能的细节，可以通过下面的方式来查看MySQL是否支持和开启了剖面系统。\n\n   ```SQL\n   select @@have_profiling;\n   select @@profiling;\n   ```\n\n   如果没有开启剖面系统，可以通过下面的SQL来打开它。\n\n   ```SQL\n   set profiling=1;\n   ```\n\n   接下来就可以通过剖面系统来了解SQL的执行性能，例如：\n\n   ```SQL\n   mysql> select count(*) from tb_emp;\n   +----------+\n   | count(*) |\n   +----------+\n   |       14 |\n   +----------+\n   1 row in set (0.00 sec)\n   \n   mysql> show profiles;\n   +----------+------------+-----------------------------+\n   | Query_ID | Duration   | Query                       |\n   +----------+------------+-----------------------------+\n   |        1 | 0.00029600 | select count(*) from tb_emp |\n   +----------+------------+-----------------------------+\n   1 row in set, 1 warning (0.00 sec)\n   \n   mysql> show profile for query 1;\n   +----------------------+----------+\n   | Status               | Duration |\n   +----------------------+----------+\n   | starting             | 0.000076 |\n   | checking permissions | 0.000007 |\n   | Opening tables       | 0.000016 |\n   | init                 | 0.000013 |\n   | System lock          | 0.000007 |\n   | optimizing           | 0.000005 |\n   | statistics           | 0.000012 |\n   | preparing            | 0.000010 |\n   | executing            | 0.000003 |\n   | Sending data         | 0.000070 |\n   | end                  | 0.000012 |\n   | query end            | 0.000008 |\n   | closing tables       | 0.000012 |\n   | freeing items        | 0.000032 |\n   | cleaning up          | 0.000013 |\n   +----------------------+----------+\n   15 rows in set, 1 warning (0.00 sec)\n   ```\n\n4. 优化CRUD操作。\n\n   - 优化`insert`语句\n     - 在`insert`语句后面跟上多组值进行插入在性能上优于分开`insert`。\n     - 如果有多个连接向同一个表插入数据，使用`insert delayed`可以获得更好的性能。\n     - 如果要从一个文本文件装载数据到表时，使用`load data infile`比`insert`性能好得多。\n\n   - 优化`order by`语句\n\n     - 如果`where`子句的条件和`order by`子句的条件相同，而且排序的顺序与索引的顺序相同，如果还同时满足排序字段都是升序或者降序，那么只靠索引就能完成排序。\n\n   - 优化`group by`语句\n\n     - 在使用`group by`子句分组时，如果希望避免排序带来的开销，可以用`order by null`禁用排序。\n\n   - 优化嵌套查询\n\n     - MySQL从4.1开始支持嵌套查询（子查询），这使得可以将一个查询的结果当做另一个查询的一部分来使用。在某些情况下，子查询可以被更有效率的连接查询取代，因为在连接查询时MySQL不需要在内存中创建临时表来完成这个逻辑上需要多个步骤才能完成的查询。\n\n   - 优化or条件\n\n     - 如果条件之间是`or`关系，则只有在所有条件都用到索引的情况下索引才会生效。\n\n   - 优化分页查询\n\n     - 分页查询时，一个比较头疼的事情是如同`limit 1000, 20`，此时MySQL已经排序出前1020条记录但是仅仅返回第1001到1020条记录，前1000条实际都用不上，查询和排序的代价非常高。一种常见的优化思路是在索引上完成排序和分页的操作，然后根据返回的结果做表连接操作来得到最终的结果，这样可以避免出现全表查询，也避免了外部排序。\n\n       ```SQL\n       select * from tb_emp order by ename limit 10000, 20;\n       select * from tb_emp t1 inner join (select eno from tb_emp order by ename limit 10000, 20) t2 on t1.eno=t2.eno;\n       ```\n\n       上面的代码中，第2行SQL是优于第1行SQL的，当然我们的前提是已经在`ename`字段上创建了索引。\n\n   - 使用SQL提示\n     - USE INDEX：建议MySQL使用指定的索引。\n     - IGNORE INDEX：建议MySQL忽略掉指定的索引。\n     - FORCE INDEX：强制MySQL使用指定的索引。\n\n### 配置优化\n\n可以使用下面的命令来查看MySQL服务器配置参数的默认值。\n\n```SQL\nshow variables;\nshow variables like 'key_%';\nshow variables like '%cache%';\nshow variables like 'innodb_buffer_pool_size';\n```\n\n通过下面的命令可以了解MySQL服务器运行状态值。\n\n```SQL\nshow status;\nshow status like 'com_%';\nshow status like 'innodb_%';\nshow status like 'connections';\nshow status like 'slow_queries';\n```\n\n1. 调整`max_connections`：MySQL最大连接数量，默认151。在Linux系统上，如果内存足够且不考虑用户等待响应时间这些问题，MySQL理论上可以支持到万级连接，但是通常情况下，这个值建议控制在1000以内。\n2. 调整`back_log`：TCP连接的积压请求队列大小，通常是max_connections的五分之一，最大不能超过900。\n3. 调整`table_open_cache`：这个值应该设置为max_connections的N倍，其中N代表每个连接在查询时打开的表的最大个数。\n4. 调整`innodb_lock_wait_timeout`：该参数可以控制InnoDB事务等待行锁的时间，默认值是50ms，对于反馈响应要求较高的应用，可以将这个值调小避免事务长时间挂起；对于后台任务，可以将这个值调大来避免发生大的回滚操作。\n5. 调整`innodb_buffer_pool_size`：InnoDB数据和索引的内存缓冲区大小，以字节为单位，这个值设置得越高，访问表数据需要进行的磁盘I/O操作就越少，如果可能甚至可以将该值设置为物理内存大小的80%。\n\n### 架构优化\n\n1. 通过拆分提高表的访问效率。\n   - 垂直拆分\n   - 水平拆分\n\n2. 逆范式理论。数据表设计的规范程度称之为范式（Normal Form），要提升表的规范程度通常需要将大表拆分为更小的表，范式级别越高数据冗余越小，而且在插入、删除、更新数据时出问题的可能性会大幅度降低，但是节省了空间就意味着查询数据时可能花费更多的时间，原来的单表查询可能会变成连表查询。为此，项目实践中我们通常会进行逆范式操作，故意降低范式级别增加冗余来减少查询的时间开销。\n   - 1NF：列不能再拆分\n   - 2NF：所有的属性都依赖于主键\n   - 3NF：所有的属性都直接依赖于主键（消除传递依赖）\n   - BCNF：消除非平凡多值依赖\n\n3. 使用中间表提高统计查询速度。\n\n   使用`insert into 中间表 select ... where ...`这样的语句先将需要的数据筛选出来放到中间表中，然后再对中间表进行统计，避免不必要的运算和处理。\n\n4. 主从复制和读写分离，具体内容请参考[《项目部署上线和性能调优》](./98.项目部署上线和性能调优.md)。\n\n5. 配置MySQL集群。\n\n> **说明**：本章内容参考了网易出品的《深入浅出MySQL》一书，该书和《高性能MySQL》一样，都对MySQL进行了深入细致的讲解，虽然总体感觉后者更加高屋建瓴，但是前者也算得上是提升MySQL技能的佳作（作者的文字功底稍显粗糙，深度也不及后者），建议有兴趣的读者可以阅读这两本书。\n\n", "网络API接口设计": "## 网络API接口设计\n\n目前许多的Web应用和移动应用都使用了前后端分离的开发模式，前后端分离简单的说就是前端或移动端通过网络API接口和后台进行交互，获得接口中提供的数据并负责用户界面的渲染。API是应用程序的编程接口的缩写，网络API通常指的是基于一个URL（统一资源定位符）可以访问到的资源，也就是说通过这个URL我们就可以请求服务器对某个资源进行操作并返回操作的结果。大家可以想想，网络API接口不也是一种封装吗，简单的说就是将复杂的业务逻辑隐藏在简单的API接口中。\n\nURL的通用格式如下所示：\n\n```\n协议://用户名:口令@主机:端口/路径1/.../路径N/资源名\n```\n\n> **说明**：URL中的用户名（有可能不需要提供用户名）、口令（有可能不需要提供口令）、端口（有可能使用默认端口）、路径（资源有可能直接位于根路径`/`下）并不是必需的部分，可以根据需要进行设置。\n\n网络API通常基于HTTP或HTTPS进行访问，基于HTTP/HTTPS最大的好处就在于访问起来非常的简单方便，而且可以跨语言、跨应用进行访问和互操作。\n\n### 设计原则\n\n#### 关键问题\n\n为移动端或者PC端设计网络API接口一个非常重要的原则是：**根据业务实体而不是用户界面或操作来设计API接口**。如果API接口的设计是根据用户的操作或者界面上的功能设置来设计，随着需求的变更，用户界面也会进行调整，需要的数据也在发生变化，那么后端开发者就要不停的调整API，或者给一个API设计出多个版本，这些都会使项目的开发和维护成本增加。我们可以将业务实体理解为服务器提供的资源，而URL就是资源的定位符（标识符），这种方式是最为简单自然的。对于相对复杂的用户操作，我们可以提供一个“门面”（设计模式中的“门面模式”），通过该“门面”把多个接口的功能组装起来即可。\n\n下面是某个网站开放API的接口，可以看出API的设计是围绕业务实体来进行的，而且都做到了“见名知意”。\n\n| 评论              |                        |\n| ----------------- | ---------------------- |\n| comments/show     | 获取某条微博的评论列表 |\n| comments/by_me    | 自己的评论列表         |\n| comments/to_me    | 收到的评论列表         |\n| comments/mentions | @了自己的评论列表      |\n| comments/create   | 创建一条评论           |\n| comments/destroy  | 删除一条评论           |\n| comments/reply    | 回复一条评论           |\n\n需要说明的是，**上面的API接口并不是REST风格的**。REST是一种网络应用架构风格，被认为最适合分布式的网络应用。关于REST的知识，可以阅读阮一峰的[《理解RESTful架构》](http://www.ruanyifeng.com/blog/2011/09/restful.html)以及[《RESTful API设计指南》](http://www.ruanyifeng.com/blog/2014/05/restful_api.html)，当然这两篇文章大家也要批判的阅读，因为上面阐述的观点并不完全正确，有些内容甚至是自相矛盾的。\n\nAPI接口返回的数据通常都是**JSON**或**XML**格式，XML这种数据格式目前基本已经被弃用了。对于JSON格式的数据，我们需要做到不要返回null这的值，因为这样的值一旦处置失当，会给前端和移动端开发带来不必要的麻烦（因为开发者有可能会使用强类型语言）。要解决这个问题可以从源头入手，在设计数据库的时候，尽量给每个字段都加上“not null”约束或者设置合理的默认值约束。\n\n#### 其他问题\n\n1. 更新提示问题：设计一个每次使用系统首先要访问的API，该API会向移动端返回系统更新的相关信息，这样就可以提升用户更新App了。\n2. 版本升级问题：API版本升级时应该考虑对低版本的兼容，同时要让新版本和旧版本都能够被访问，可以在URL中包含版本信息或者在将版本号放在HTTP(S)协议头部，关于这个问题有很多的争论，有兴趣的可以看看[stack overflow](https://stackoverflow.com/questions/972226/how-to-version-rest-uris)上面对这个问题的讨论。\n3. 图片尺寸问题：移动端对于一张图片可能需要不同的尺寸，可以在获取图片时传入尺寸参数并获取对应的资源；更好的做法是直接使用云存储或CDN（直接提供了图片缩放的功能），这样可以加速对资源的访问。\n\n### 文档撰写\n\n下面以设计评论接口为例，简单说明接口文档应该如何撰写。\n\n首先，我们可以定义全局返回状态码。\n\n| 返回码 | 返回信息     | 说明                               |\n| ------ | ------------ | ---------------------------------- |\n| 10000  | 获取评论成功 |  |\n| 10001 | 创建评论成功 |  |\n| 10002  | 无法创建评论 | 创建评论时因违反审核机制而无法创建 |\n| 10003 | 评论已被删除     | 查看评论时评论因不和谐因素已被删除                |\n| 10004 | …… | …… |\n\n1. 获取文章评论。\n\n   **GET** `/articles/{article-id}/comments/`\n\n   开发者：王大锤\n\n   最后更新时间：2018年8月10日\n\n   标签：v 1.0\n\n   接口说明：获取指定文章的所有评论\n\n   使用帮助：默认返回20条数据，需要在请求头中设置身份标识（key）\n\n   请求参数：\n\n   | 参数名 | 类型   | 是否必填 | 参数位置 | 说明                                 |\n   | ------ | ------ | -------- | -------- | ------------------------------------ |\n   | page   | 整数   | 否       | 查询参数 | 页码，默认值1                        |\n   | size   | 整数   | 否       | 查询参数 | 每次获取评论数量（10~100），默认值20 |\n   | key    | 字符串 | 是       | 请求头   | 用户的身份标识                       |\n\n   响应信息：\n\n   ```JSON\n   {\n       \"code\": 10000,\n       \"message\": \"获取评论成功\",\n       \"page\": 1,\n       \"size\": 10,\n       \"totalPage\": 35,\n       \"contents\": [\n           {\n               \"userId\": 1700095,\n               \"nickname\": \"王大锤\",\n               \"pubDate\": \"2018年7月31日\",\n               \"content\": \"小编是不是有病呀\",\n               /* ... */\n           },\n           {\n           \t\"userId\", 1995322,\n               \"nickname\": \"白元芳\",\n               \"pubDate\": \"2018年8月2日\",\n               \"content\": \"楼上说得好\",\n               /* ... */\n           }\n       ]\n       /* ... */\n   }\n   ```\n\n2. 新增文章评论。\n\n   **POST** `/articles/{article-id}/comments`\n\n   开发者：王大锤\n\n   最后更新时间：2018年8月10日\n\n   标签：v 1.0\n\n   接口说明：为指定的文章创建评论\n\n   使用帮助：暂无\n\n   请求参数：\n\n   | 参数名  | 类型   | 是否必填 | 参数位置 | 说明       |\n   | ------- | ------ | -------- | -------- | ---------- |\n   | userId  | 字符串 | 是       | 消息体   | 用户ID     |\n   | key     | 字符串 | 是       | 请求头   | 用户的令牌 |\n   | content | 字符串 | 是       | 消息体   | 评论的内容 |\n\n   响应信息：\n\n   ```JSON\n   {\n       \"code\": 10001,\n       \"message\": \"创建评论成功\",\n       \"comment\": {\n           \"pubDate\": \"2018年7月31日\",\n           \"content\": \"小编是不是有病呀\"\n           /* ... */\n       }\n       /* ... */\n   }\n   ```\n\n\n\n> **提示**：如果没有接口文档撰写经验，可以使用在线接口文档编辑平台[RAP2](<http://rap2.taobao.org/>)或[YAPI](<http://yapi.demo.qunar.com/>)来进行接口文档撰写。\n\n", "使用Django开发商业项目": "## 使用Django开发商业项目\n\n> **说明**：本文的部分插图来自于《Python项目开发实战》和《精通Django》，这两本书中都包含了对Django框架精彩的讲解，有兴趣的读者可以自行购买阅读。\n\n### Web应用\n\n问题1：描述一个Web应用的工作流程。\n\n![](./res/web-application.png)\n\n问题2：描述项目的物理架构。（上图中补充负载均衡（反向代理）服务器、数据库服务器、文件服务器、邮件服务器、缓存服务器、防火墙等，而且每个节点都有可能是多节点构成的集群。当然，架构都是根据业务的需要一步步演进而不是一蹴而就的。）\n\n问题3：描述Django项目的工作流程。（如下图所示）\n\n![](./res/django_request_response_cycle.png)\n\n### MVC架构模式\n\n问题1：为什么要使用MVC架构模式？（模型和视图解耦合）\n\n问题2：MVC架构中每个部分的作用？（如下图所示）\n\n![](./res/mvc.png)\n\n### HTTP请求和响应\n\n#### HTTP请求 = 请求行+请求头+空行+[消息体]\n\n![](./res/http-request.png)\n\n#### HTTP响应 = 响应行+响应头+空行+消息体\n\n![](./res/http-response.png)\n\n1. `HTTPRequest`对象的属性和方法：\n\n   - `method` - 获取请求方法\n   - `path` / `get_full_path()` - 获取请求路径/带查询字符串的路径\n   - `scheme` / `is_secure()` / `get_host()` / `get_port()` - 获取请求的协议/主机/端口\n   - `META` / `COOKIES` - 获取请求头/Cookie信息\n   - `GET` / `POST` / `FILES` - 获取GET或POST请求参数/上传的文件\n   - `get_signed_cookie()` - 获取带签名的Cookie\n   - `is_ajax()` - 是不是Ajax异步请求\n   - `body` / `content_type` / `encoding` - 获取请求的消息体（bytes流）/MIME类型/编码\n2. 中间件添加的属性：\n\n   - `session` / `user` / `site`\n3. `HttpResponse`对象的属性和方法：\n\n   - `set_cookie()` / `set_signed_cookie()` / `delete_cookie()` - 添加/删除Cookie\n   - `__setitem__` / `__getitem__` / `__delitem__` - 添加/获取/删除响应头\n   - `charset` / `content` / `status_code` - 响应的字符集/消息体（bytes流）/状态码\n     - 1xx：请求已经收到，继续处理\n     - 2xx（成功）：请求已经成功收到、理解和接收。\n     - 3xx（重定向）：为完成请求要继续执行后续的操作。\n     - 4xx（客户端错误）：请求不正确或不能够被受理。\n     - 5xx（服务器错误）：服务器处理请求失败。\n4. `JsonResponse`（`HttpResponse`的子类型）对象\n\n    ```Python\n    >>> from django.http import HttpResponse, JsonResponse\n    >>>\n    >>> response = JsonResponse({'foo': 'bar'})\n    >>> response.content\n    >>>\n    >>> response = JsonResponse([1, 2, 3], safe=False)\n    >>> response.content\n    >>>\n    >>> response = HttpResponse(b'...')\n    >>> response['cotent-type'] = 'application/pdf';\n    >>> response['content-disposition'] = 'inline; filename=\"xyz.pdf\"'\n    >>> response['content-disposition'] = 'attachment; filename=\"xyz.pdf\"'\n    >>>\n    >>> response.set_signed_cookie('foo', 'bar', salt='')\n    >>> response.status_code = 200\n    ```\n\n### 数据模型(Model)\n\n问题1：关系型数据库表的设计应该注意哪些问题（范式理论和逆范式）？如何通过表来创建模型类（反向工程）？如何通过模型类来创建表（正向工程）？\n\n```Shell\npython manage.py makemigrations <appname>\npython manage.py migrate\n\npython manage.py inspectdb > <appname>/models.py\n```\n\n问题2：关系型数据库中数据完整性指的是什么？什么时候需要牺牲数据完整性？（实体完整性/参照完整性/域完整性）\n\n问题3：ORM是什么以及解决了什么问题？（对象模型-关系模型双向转换）\n\n1. `Field`及其子类的属性：\n\n   - 通用选项：\n     - `db_column` / `db_tablespace`\n     - `null` / `blank` / `default`\n     - `primary_key`\n     - `db_index` / `unqiue`\n     - `choices` / `help_text` / `error_message` / `editable` / `hidden`\n   - 其他选项：\n     - `CharField`: `max_length`\n     - `DateField`: `auto_now` / `auto_now_add`\n     - `DecimalField`: `max_digits` / `decimal_places`\n     - `FileField`: `storage` / `upload_to`\n     - `ImageField`: `height_field` / `width_field`\n\n2. `ForeignKey`的属性：\n\n   - 重要属性：\n     - `db_constraint`（提升性能或者数据分片的情况可能需要设置为`False`）\n\n     - `on_delete`\n\n       * `CASCADE`：级联删除。\n\n       - `PROTECT`：抛出`ProtectedError`异常，阻止删除引用的对象。\n       - `SET_NULL`：把外键设置为`null`，当`null`属性被设置为`True`时才能这么做。\n       - `SET_DEFAULT`：把外键设置为默认值，提供了默认值才能这么做。\n\n     - `related_name`\n\n       ```Python\n       class Dept(models.Model):\n           pass\n       \n       \n       class Emp(models.Model):\n           dept = models.ForeignKey(related_name='+', ...)\n           \n        \n       Dept.objects.get(no=10).emp_set.all()\n       Emp.objects.filter(dept__no=10)\n       ```\n\n       > 说明：`related_name`设置为`'+'`，可以防止一对多外键关联从“一”的一方查询“多”的一方。\n\n   - 其他属性：\n\n     - `to_field` / `limit_choices_to` / `swappable`\n\n3. `Model`的属性和方法\n\n   - `objects` / `pk`\n\n   - `save()` / `delete()` \n\n   - `clean()` / `validate_unique()` / `full_clean()`\n\n4. `QuerySet`的方法\n\n   - `get()` / `all()` / `values()`\n\n     > 说明：`values()`返回的`QuerySet`中不是模型对象而是字典\n\n   - `count()` / `order_by()` / `exists()` / `reverse()`\n\n   - `filter()` / `exclude()`\n\n     - `exact` / `iexact`：精确匹配/忽略大小写的精确匹配查询\n     - `contains` / `icontains` / `startswith / istartswith / endswith / iendswith`：基于`like`的模糊查询\n     - `in`：集合运算\n     - `gt` / `gte` / `lt` / `lte`：大于/大于等于/小于/小于等于关系运算\n     - `range`：指定范围查询（SQL中的`between…and…`）\n     - `year` / `month` / `day` / `week_day` / `hour` / `minute` / `second`：查询时间日期\n     - `isnull`：查询空值（`True`）或非空值（`False`）\n     - `search`：基于全文索引的全文检索\n     - `regex` / `iregex`：基于正则表达式的模糊匹配查询\n     - `aggregate()` / `annotate()`\n\n     - `Avg` / `Count` / `Sum` / `Max` / `Min`\n\n       ```Python\n       >>> from django.db.models import Avg\n       >>> Emp.objects.aggregate(avg_sal=Avg('sal'))\n       (0.001) SELECT AVG(`TbEmp`.`sal`) AS `avg_sal` FROM `TbEmp`; args=()\n       {'avg_sal': 3521.4286}\n       ```\n\n       ```Python\n       >>> Emp.objects.values('dept').annotate(total=Count('dept'))\n       (0.001) SELECT `TbEmp`.`dno`, COUNT(`TbEmp`.`dno`) AS `total` FROM `TbEmp` GROUP BY `TbEmp`.`dno` ORDER BY NULL LIMIT 21; args=()\n       <QuerySet [{'dept': 10, 'total': 4}, {'dept': 20, 'total': 7}, {'dept': 30, 'total': 3}]\n       ```\n\n   - `first()` / `last()`\n\n     > 说明：调用`first()`方法相当于用`[0]`对`QuerySet`进行切片。\n\n   - `only()` / `defer()`\n\n     ```Python\n     >>> Emp.objects.filter(pk=7800).only('name', 'sal')\n     (0.001) SELECT `TbEmp`.`empno`, `TbEmp`.`ename`, `TbEmp`.`sal` FROM `TbEmp` WHERE `TbEmp`.`empno` = 7800 LIMIT 21; args=(7800,)\n     <QuerySet [<Emp: Emp object (7800)>]>\n     >>> Emp.objects.filter(pk=7800).defer('name', 'sal')\n     (0.001) SELECT `TbEmp`.`empno`, `TbEmp`.`job`, `TbEmp`.`mgr`, `TbEmp`.`comm`, `TbEmp`.`dno` FROM `TbEmp` WHERE `TbEmp`.`empno` = 7800 LIMIT 21; args=(7800,)\n     <QuerySet [<Emp: Emp object (7800)>]>\n     ```\n\n   - `create()` / `update()` / `raw()` \n\n     ```Python\n     >>> Emp.objects.filter(dept__no=20).update(sal=F('sal') + 100)\n     (0.011) UPDATE `TbEmp` SET `sal` = (`TbEmp`.`sal` + 100) WHERE `TbEmp`.`dno` = 20; args=(100, 20)\n     >>>\n     >>> Emp.objects.raw('select empno, ename, job from TbEmp where dno=10')\n     <RawQuerySet: select empno, ename, job from TbEmp where dno=10>\n     ```\n\n5. `Q`对象和`F`对象\n\n   > 说明：Q对象主要用来解决多条件组合的复杂查询；F对象主要用于更新数据。\n\n   ```Python\n   >>> from django.db.models import Q\n   >>> Emp.objects.filter(\n   ...     Q(name__startswith='张'),\n   ...     Q(sal__lte=5000) | Q(comm__gte=1000)\n   ... ) # 查询名字以“张”开头且工资小于等于5000或补贴大于等于1000的员工\n   <QuerySet [<Emp: 张三丰>]>\n   ```\n\n   ```Python\n   >>> from backend.models import Emp, Dept\n   >>> emps = Emp.objects.filter(dept__no=20)\n   >>> from django.db.models import F\n   >>> emps.update(sal=F('sal') + 100)\n   ```\n\n6. 原生SQL查询\n\n   ```Python\n   from django.db import connections\n   \n   \n   with connections['...'].cursor() as cursor:\n       cursor.execute(\"UPDATE TbEmp SET sal=sal+10 WHERE dno=30\")\n       cursor.execute(\"SELECT ename, job FROM TbEmp WHERE dno=10\")\n       row = cursor.fetchall()\n   ```\n\n7. 模型管理器\n\n   ```Python\n   class BookManager(models.Manager):\n       \n       def title_count(self, keyword):\n           return self.filter(title__icontains=keyword).count()\n   \n   class Book(models.Model):\n       \n       objects = BookManager()\n   ```\n\n### 视图函数(Controller)\n\n#### 如何设计视图函数\n\n1. 用户的每个请求（用户故事）对应一个视图函数，当然也可以将用户要执行的业务逻辑封装到独立的函数中，也就是有专门的模块处理程序中的业务逻辑。\n\n2. 用户的请求可能会包含多个（持久化）操作，这些操作有可能需要设计成不可分割的原子性操作，那么这里就形成了事务的边界。\n\n   - 事务的ACID特性。\n\n     - 原子性（Atomicity）：事务中各项的操作要么全做要么全不做；\n     - 一致性（Consistentcy）：事务前后系统的状态是一致的；\n     - 隔离性（Isolation）：并发执行的事务无法看到彼此的中间状态；\n     - 持久性（Duration）：事务完成后所做的改动都会被持久化。\n\n   - 事务隔离级别 - 设置事务隔离级别是为了数据库底层依据事务隔离级别为数据加上适当的锁。如果需要保证数据的强一致性，那么关系型数据库仍然是唯一的也是最好的选择，因为关系型数据库可以通过锁机制来保护数据。事务隔离级别从低到高依次是：Read Uncommitted（读未提交）、Read Committed（读提交）、Repeatable Read（可重复读）、Serializable（串行化）。事务隔离级别越高，数据并发访问的问题越少，但是性能越差；事务隔离级别越低，数据并发访问的问题越多，但是性能越好。\n\n   - 数据并发访问会产生5种问题（请参考我的[《Java面试题全集（上）》](https://blog.csdn.net/jackfrued/article/details/44921941)第80题对该问题的讲解）：\n\n     - 第1类丢失更新（A事务撤销覆盖B事务更新的数据）和第2类丢失更新（A事务提交覆盖B事务更新的数据）。\n     - 脏读（读脏数据）：一个事务读取到其他尚未提交的事务的数据。\n     - 不可重复读： 一个事务在读取它的查询结果时，被另一个事务更新了它的查询记录导致无法读到数据。\n     - 幻读：一个事务在读取它的查询结果时，发现读到了被另一个事务提交的新数据。\n\n     ```SQL\n     -- 设置全局默认的事务隔离级别\n     set global transaction isolation level repeatable read;\n     -- 设置当前会话的事务隔离级别\n     set session transaction isolation level read committed;\n     -- 查询当前会话的事务隔离级别\n     select @@tx_isolation;\n     ```\n\n   - Django中的事务控制。\n\n     - 给每个请求绑定事务环境（反模式）。\n\n       ```Python\n       ATOMIC_REQUESTS = True\n       ```\n\n     - 使用事务装饰器（简单易用） - 粗粒度（控制不够精细）。\n\n       ```Python\n       @transaction.non_atomic_requests\n       @transaction.atomic\n       ```\n\n     - 使用上下文语法（细粒度 - 事务控制的范围更加精准）。\n\n       ```Python\n       with transaction.atomic():\n           pass\n       ```\n\n     - 关闭自动提交使用手动提交。\n\n       ```Python\n       AUTOCOMMIT = False\n       ```\n\n       ```Python\n       transaction.commit()\n       transaction.rollback()\n       ```\n\n#### URL配置\n\n1. 可以让部分URL只在调试模式下生效。\n\n   ```Python\n   from django.conf import settings\n   \n   urlpatterns = [\n       ...\n   ]\n   \n   if settings.DEBUG:\n       urlpatterns += [ ... ]\n   ```\n\n2. 可以使用命名捕获组捕获路径参数。\n\n   ```Python\n   url(r'api/code/(?P<mobile>1[3-9]\\d{9})'),\n   path('api/code/<str:mobile>'),\n   ```\n\n3. URL配置不关心请求使用的方法（一个视图函数可以处理不同的请求方式）。\n\n4. 如果使用`url`函数捕获的路径参数都是字符串，`path`函数可以指定路径参数类型。\n\n5. 可以使用`include`函数引入其他URL配置并指定`namespace`来解决命名冲突，捕获的参数会向下传递。\n\n6. 在`url`和`path`函数甚至是`include`函数中都可以用字典向视图传入额外的参数，如果参数与捕获的参数同名，则使用字典中的参数。\n\n7. 可以用`reverse`函数实现URL的逆向解析（从名字解析出URL），在模板中也可以用`{% url %}`实现同样的操作。\n\n   ```Python\n   path('', views.index, name='index')\n   \n   return redirect(reverse('index'))\n   return redirect('index')\n   ```\n\n\n### 模板(View)\n\n#### 后端渲染\n\n1. 模板的配置和渲染函数。\n\n   ```Python\n   TEMPLATES = [\n       {\n           'BACKEND': 'django.template.backends.django.DjangoTemplates',\n           'DIRS': [os.path.join(BASE_DIR, 'templates'), ],\n           'APP_DIRS': True,\n           'OPTIONS': {\n               'context_processors': [\n                   'django.template.context_processors.debug',\n                   'django.template.context_processors.request',\n                   'django.contrib.auth.context_processors.auth',\n                   'django.contrib.messages.context_processors.messages',\n               ],\n           },\n       },\n   ]\n   ```\n\n   ```Python\n   resp = render(request, 'index.html', {'foo': ...})\n   ```\n\n2. 模板遇到变量名的查找顺序。\n\n   - 字典查找（如：`foo['bar']`）\n   - 属性查找（如：`foo.bar`）\n   - 方法调用（如：`foo.bar()`）\n     - 方法不能有必须传值的参数\n     - 在模板中不能够给方法传参\n     - 如果方法的`alters_data`被设置为`True`则不能调用该方法（避免误操作的风险），模型对象动态生成的`delete()`和`save()`方法都设定了`alters_data = True`。\n   - 列表索引查找（如：`foo[0]`）\n\n3. 模板标签的使用。\n\n   - `{% if %}` / `{% else %}` / `{% endif %}`\n   - `{% for %}` / `{% endfor %}`\n   - `{% ifequal %}` / `{% endifequal %}` / `{% ifnotequal %}` / `{% endifnotequal %}`\n   - `{# comment #}` / `{% comment %}` / `{% endcomment %}`\n\n4. 过滤器的使用。\n\n   - `lower` / `upper` / `first` / `last` / `truncatewords` / `date `/ `time` / `length` / `pluralize` / `center` / `ljust` / `rjust` / `cut` / `urlencode` / `default_if_none` / `filesizeformat` / `join` / `slice` / `slugify`\n\n5. 模板的包含和继承。\n\n   - `{% include %}` / `{% block %}`\n   - `{% extends %}`\n\n6. 模板加载器（后面优化部分会讲到）。\n\n   - 文件系统加载器\n\n     ```Python\n     TEMPLATES = [{\n         'BACKEND': 'django.template.backends.django.DjangoTemplates',\n         'DIRS': [os.path.join(BASE_DIR, 'templates')],\n     }]\n     ```\n\n   - 应用目录加载器\n\n     ```Python\n     TEMPLATES = [{\n         'BACKEND': 'django.template.backends.django.DjangoTemplates',\n         'APP_DIRS': True,\n     }]\n     ```\n\n\n#### 前端渲染\n\n1. 前端模板引擎：Handlebars / Mustache。\n2. 前端MV\\*框架。\n   - MVC - AngularJS\n   - MVVM(Model-View-ViewModel) - Vue.js\n\n#### 其他视图\n\n1. MIME（多用途Internet邮件扩展）类型 - 告知浏览器传输的数据类型。\n\n   | Content-Type     | 说明                                                         |\n   | ---------------- | ------------------------------------------------------------ |\n   | application/json | [JSON](https://zh.wikipedia.org/wiki/JSON)（JavaScript Object Notation） |\n   | application/pdf  | [PDF](https://zh.wikipedia.org/wiki/PDF)（Portable Document Format） |\n   | audio/mpeg       | [MP3](https://zh.wikipedia.org/wiki/MP3)或其他[MPEG](https://zh.wikipedia.org/wiki/MPEG)音频文件 |\n   | audio/vnd.wave   | [WAV](https://zh.wikipedia.org/wiki/WAV)音频文件             |\n   | image/gif        | [GIF](https://zh.wikipedia.org/wiki/GIF)图像文件             |\n   | image/jpeg       | [JPEG](https://zh.wikipedia.org/wiki/JPEG)图像文件           |\n   | image/png        | [PNG](https://zh.wikipedia.org/wiki/PNG)图像文件             |\n   | text/html        | [HTML](https://zh.wikipedia.org/wiki/HTML)文件               |\n   | text/xml         | [XML](https://zh.wikipedia.org/wiki/XML)                     |\n   | video/mp4        | [MP4](https://zh.wikipedia.org/wiki/MP4)视频文件             |\n   | video/quicktime  | [QuickTime](https://zh.wikipedia.org/wiki/QuickTime)视频文件 |\n\n2. 如何处置生成的内容（inline / attachment）。\n\n   ```Python\n   >>> from urllib.parse import quote\n   >>>\n   >>> response['content-type'] = 'application/pdf'\n   >>> filename = quote('Python语言规范.pdf')\n   >>> filename\n   'Python%E8%AF%AD%E8%A8%80%E8%A7%84%E8%8C%83.pdf'\n   >>> response['content-disposition'] = f'attachment; filename=\"{filename}\"'\n   ```\n   > 提醒：URL以及请求和响应头中的中文都应该处理成[百分号编码](https://zh.wikipedia.org/zh-hans/%E7%99%BE%E5%88%86%E5%8F%B7%E7%BC%96%E7%A0%81)。\n\n3. 生成CSV / Excel / PDF / 统计报表。\n\n   - 向浏览器传输二进制数据。\n\n     ```Python\n     from io import BytesIO\n     \n     buffer = BytesIO()\n     \n     resp = HttpResponse(content_type='...')\n     resp['Content-Disposition'] = 'attachment; filename=\"...\"'\n     resp.write(buffer.getvalue())\n     ```\n\n     ```Python\n     from io import BytesIO\n     \n     import xlwt\n     \n     \n     def get_style(name, color=0, bold=False, italic=False):\n         font = xlwt.Font()\n         font.name, font.colour_index, font.bold, font.italic = \\\n         \tname, color, bold, italic\n         style = xlwt.XFStyle()\n         style.font = font\n         return style\n     \n     \n     def export_emp_excel(request):\n         # 创建Excel工作簿(使用三方库xlwt)\n         workbook = xlwt.Workbook()\n         # 向工作簿中添加工作表\n         sheet = workbook.add_sheet('员工详细信息')\n         # 设置表头\n         titles = ['编号', '姓名', '主管', '职位', '工资', '部门名称']\n         for col, title in enumerate(titles):\n             sheet.write(0, col, title, get_style('HanziPenSC-W3', 2, True))\n         # 使用Django的ORM框架查询员工数据\n         emps = Emp.objects.all().select_related('dept').select_related('mgr')\n         cols = ['no', 'name', 'mgr', 'job', 'sal', 'dept']\n         # 通过嵌套的循环将员工表的数据写入Excel工作表的单元格\n         for row, emp in enumerate(emps):\n             for col, prop in enumerate(cols):\n                 val = getattr(emp, prop, '')\n                 if isinstance(val, (Dept, Emp)):\n                     val = val.name\n                 sheet.write(row + 1, col, val)\n         # 将Excel文件的二进制数据写入内存\n         buffer = BytesIO()\n         workbook.save(buffer)\n         # 通过HttpResponse对象向浏览器输出Excel文件\n         resp = HttpResponse(buffer.getvalue())\n         resp['content-type'] = 'application/msexcel'\n         # 如果文件名有中文需要处理成百分号编码\n         resp['content-disposition'] = 'attachment; filename=\"detail.xls\"'\n         return resp\n     ```\n\n   - 大文件的流式处理：`StreamingHttpResponse`。\n\n     ```Python\n     def download_file(request):\n         file_stream = open('...', 'rb')\n         # 如果文件的二进制数据较大则最好用迭代器进行处理避免过多的占用服务器内存\n         file_iter = iter(lambda: file_stream.read(4096), b'')\n         resp = StreamingHttpResponse(file_iter)\n         # 中文文件名要处理成百分号编码\n         filename = quote('...', 'utf-8')\n         resp['Content-Type'] = '...'\n         resp['Content-Disposition'] = f'attachment; filename=\"{filename}\"'\n         return resp\n     ```\n\n     > 说明：如果需要生成PDF文件，可以需要安装`reportlab`。另外，使用StreamingHttpResponse只能减少内存的开销，但是如果下载一个大文件会导致一个请求长时间占用服务器资源，比较好的做法还是把报表提前生成好（可以考虑使用定时任务），放在静态资源服务器或者是云存储服务器上以访问静态资源的方式访问。\n\n   - [ECharts](http://echarts.baidu.com/)或[Chart.js](https://www.chartjs.org/)。\n\n     - 思路：后端只提供JSON格式的数据，前端JavaScript渲染生成图表。\n\n     ```Python\n     def get_charts_data(request):\n         \"\"\"获取统计图表JSON数据\"\"\"\n         names = []\n         totals = []\n         # 通过connections获取指定数据库连接并创建游标对象\n         with connections['backend'].cursor() as cursor:\n             # 在使用ORM框架时可以使用对象管理器的aggregate()和annotate()方法实现分组和聚合函数查询\n             # 执行原生SQL查询(如果ORM框架不能满足业务或性能需求)\n             cursor.execute('select dname, total from vw_dept_emp')\n             for row in cursor.fetchall():\n                 names.append(row[0])\n                 totals.append(row[1])\n         return JsonResponse({'names': names, 'totals': totals})\n     ```\n\n     ```HTML\n     <!DOCTYPE html>\n     <html lang=\"en\">\n     <head>\n         <meta charset=\"UTF-8\">\n         <title>统计图表</title>\n         <style>\n             #main {\n                 width: 600px;\n                 height: 400px;\n             }\n         </style>\n     </head>\n     <body>\n         <div id=\"main\"></div>\n         <script src=\"https://cdn.bootcss.com/echarts/4.2.0-rc.2/echarts.min.js\"></script>\n         <script src=\"https://cdn.bootcss.com/jquery/3.3.1/jquery.min.js\"></script>\n         <script>\n             var myChart = echarts.init($('#main')[0]);\n             $.ajax({\n                 'url': 'charts_data',\n                 'type': 'get',\n                 'data': {},\n                 'dataType': 'json',\n                 'success': function(json) {\n                     var option = {\n                         title: {\n                             text: '员工分布统计图'\n                         },\n                         tooltip: {},\n                         legend: {\n                             data:['人数']\n                         },\n                         xAxis: {\n                             data: json.names\n                         },\n                         yAxis: {},\n                         series: [{\n                             name: '人数',\n                             type: 'bar',\n                             data: json.totals\n                         }]\n                     };\n                     myChart.setOption(option);\n                 },\n                 'error': function() {}\n             });\n         </script>\n     </body>\n     </html>\n     ```\n\n\n### 中间件\n\n问题1：中间件背后的设计理念是什么？（分离横切关注功能/拦截过滤器模式）\n\n问题2：中间件有哪些不同的实现方式？（参考下面的代码）\n\n问题3：描述Django内置的中间件及其执行顺序。（推荐阅读：[Django官方文档 - 中间件 - 中间件顺序](https://docs.djangoproject.com/zh-hans/2.0/ref/middleware/#middleware-ordering)）\n\n#### 激活中间件\n\n```Python\nMIDDLEWARE = [\n    'django.middleware.security.SecurityMiddleware',\n    'django.contrib.sessions.middleware.SessionMiddleware',\n    'django.middleware.common.CommonMiddleware',\n    'django.middleware.csrf.CsrfViewMiddleware',\n    'django.contrib.auth.middleware.AuthenticationMiddleware',\n    'django.contrib.messages.middleware.MessageMiddleware',\n    'django.middleware.clickjacking.XFrameOptionsMiddleware',\n    'common.middlewares.block_sms_middleware',\n]\n```\n\n#### 自定义中间件\n\n\n```Python\ndef simple_middleware(get_response):\n    \n    def middleware(request, *args, **kwargs):\n        \n\t\tresponse = get_response(request, *args, **kwargs)\n        \n\t\treturn response\n    \n    return middleware\n```\n\n```Python\nclass MyMiddleware:\n        \n    def __init__(self, get_response):\n        self.get_response = get_response\n        \n    def __call__(self, request):\n        \n        response = self.get_response(request)\n       \n        return response\n```\n\n```Python\nclass MyMiddleware(MiddlewareMixin):\n    \n    def __init__(self):\n        pass\n    \n    def process_request(request):\n        pass\n    \n    def process_view(request, view_func, view_args, view_kwargs):\n        pass\n    \n    def process_template_response(request, response):\n        pass\n    \n    def process_response(request, response):\n        pass\n    \n    def process_exception(request, exception):\n        pass\n```\n\n\n#### 内置中间件\n\n1. CommonMiddleware - 基础设置中间件\n   - DISALLOWED_USER_AGENTS - 不被允许的用户代理（浏览器）\n   - APPEND_SLASH - 是否追加`/`\n   - USE_ETAG - 浏览器缓存相关\n\n2. SecurityMiddleware - 安全相关中间件\n   - SECURE_HSTS_SECONDS - 强制使用HTTPS的时间\n   - SECURE_HSTS_INCLUDE_SUBDOMAINS - HTTPS是否覆盖子域名\n   - SECURE_CONTENT_TYPE_NOSNIFF - 是否允许浏览器推断内容类型\n   - SECURE_BROWSER_XSS_FILTER - 是否启用跨站脚本攻击过滤器\n   - SECURE_SSL_REDIRECT - 是否重定向到HTTPS连接\n   - SECURE_REDIRECT_EXEMPT - 免除重定向到HTTPS\n\n3. SessionMiddleware - 会话中间件\n\n4. CsrfViewMiddleware - 防范跨站身份伪造中间件\n\n5. XFrameOptionsMiddleware - 防范点击劫持攻击中间件\n\n   ![](./res/click-jacking.png)\n\n![](./res/builtin-middlewares.png)\n\n### 表单\n\n1. 用法：通常不要用来生成页面上的表单控件（耦合度太高不容易定制），主要用来验证数据。\n2. Form的属性和方法：\n   - `is_valid()` / `is_multipart()`\n   - `errors` / `fields` / `is_bound` / `changed_data` / `cleaned_data`\n   - `add_error()` / `has_errors()` / `non_field_errors()`\n   - `clean()`\n3. Form.errors的方法：\n   - `as_data()` / `as_json()` / `get_json_data()`\n\n问题1：Django中的`Form`和`ModelForm`有什么作用？（通常不用来生成表单主要用来验证数据）\n\n问题2：表单上传文件时应该注意哪些问题？（表单的设置、多文件上传、图片预览（FileReader）、Ajax上传文件、上传后的文件如何存储、调用云存储（如[阿里云OSS](https://www.aliyun.com/product/oss)、[七牛云](https://www.qiniu.com/)、[LeanCloud](https://leancloud.cn/storage/)等））\n\n```HTML\n<form action=\"\" method=\"post\" enctype=\"multipart/form-data\">\n    <input type=\"file\" name=\"...\" multiple>\n    <input type=\"file\" name=\"foo\">\n    <input type=\"file\" name=\"foo\">\n    <input type=\"file\" name=\"foo\">\n</form>\n```\n\n> 说明：上传图片文件的预览效果可以通过HTML5的FileReader来实现。\n\n> 说明：使用云存储通常是比自己配置分布式文件系统这种方式更靠谱的做法，而且云存储通常成本并不太高，不仅如此大多数云存储还提供了如图片剪裁、生成水印、视频转码、CDN等服务。如果要自己做上传的视频文件转码，需要安装三方库ffmpeg，在程序中调用该三方库可以实现转码。\n\n### Cookie和Session\n\n问题1：使用Cookie能解决什么问题？（用户跟踪，解决HTTP协议无状态问题）\n\n1. URL重写\n\n   ```\n   http://www.abc.com/path/resource?foo=bar\n   ```\n\n2. 隐藏域（隐式表单域）- 埋点\n\n   ```HTML\n   <form action=\"\" method=\"post\">\n   \n       <input type=\"hidden\" name=\"foo\" value=\"bar\">\n       \n   </form>\n   ```\n\n3. Cookie - 浏览器中的临时文件（文本文件）- BASE64\n\n问题2：Cookie和Session之间关系是什么？（Session的标识通过Cookie保存和传输）\n\n#### Session的配置\n\n1. Session对应的中间件：`django.contrib.sessions.middleware.SessionMiddleware`。\n\n2. Session引擎。\n\n   - 基于数据库（默认方式）\n\n     ```Python\n     INSTALLED_APPS = [\n         'django.contrib.sessions',\n     ]\n     ```\n\n   - 基于缓存（推荐使用）\n\n     ```Python\n     SESSION_ENGINE = 'django.contrib.sessions.backends.cache'\n     SESSION_CACHE_ALIAS = 'session'\n     ```\n\n   - 基于文件（基本不考虑）\n\n   - 基于Cookie（不靠谱）\n\n     ```Python\n     SESSION_ENGINE = 'django.contrib.sessions.backends.signed_cookies'\n     ```\n\n3. Cookie相关的配置。\n\n   ```Python\n   SESSION_COOKIE_NAME = 'djang_session_id'\n   SESSION_COOKIE_AGE = 1209600\n   # 如果设置为True，Cookie就是基于浏览器窗口的Cookie，不会持久化\n   SESSION_EXPIRE_AT_BROWSER_CLOSE = False \n   SESSION_SAVE_EVERY_REQUEST = False\n   SESSION_COOKIE_HTTPONLY = True\n   ```\n\n4. session的属性和方法。\n\n   - `session_key` / `session_data` / `expire_date`\n   - `__getitem__` / `__setitem__` / `__delitem__` / `__contains__`\n   - `set_expiry()` / `get_expiry_age()` / `get_expiry_date()` - 设置/获取会话超期时间\n   - `flush()` - 销毁会话\n   - `set_test_cookie()` / `test_cookie_worked()` / `delete_test_cookie()` - 测试浏览器是否支持Cookie（提示用户如果浏览器禁用Cookie可能会影响网站的使用）\n\n5. session的序列化。\n\n   ```Python\n   SESSION_SERIALIZER = 'django.contrib.sessions.serializers.JSONSerializer'\n   ```\n\n   - JSONSerializer（1.6及以后默认）- 如果想将自定义的对象放到session中，会遇到“Object of type 'XXX' is not JSON serializable”的问题（如果配置使用Redis保存Session，django-redis使用了Pickle序列化，这个问题就不存在了）。\n   - PickleSerializer（1.6以前的默认）- 因为安全问题不推荐使用，但是只要不去反序列化用户构造的恶意的Payload其实也没有什么风险。关于这种方式的安全漏洞，可以参考《[Python Pickle的任意代码执行漏洞实践和Payload构造》](http://www.polaris-lab.com/index.php/archives/178/)一文或《软件架构-Python语言实现》上关于这个问题的讲解。\n\n     > 说明：如果使用了django_redis整合Redis作为session的存储引擎，那么由于django_redis又封装了一个PickleSerializer来提供序列化，所以不会存在上述的问题，且Redis中保存的value是pickle序列化之后的结果。\n\n\n### 缓存\n\n#### 配置缓存\n\n\n```Python\nCACHES = {\n    # 默认缓存\n    'default': {\n        'BACKEND': 'django_redis.cache.RedisCache',\n        'LOCATION': [\n            'redis://1.2.3.4:6379/0',\n        ],\n        'KEY_PREFIX': 'teamproject',\n        'OPTIONS': {\n            'CLIENT_CLASS': 'django_redis.client.DefaultClient',\n            'CONNECTION_POOL_KWARGS': {\n                'max_connections': 1000,\n            },\n            'PASSWORD': 'yourpass',\n        }\n    },\n    # 页面缓存\n    'page': {\n        'BACKEND': 'django_redis.cache.RedisCache',\n        'LOCATION': [\n            'redis://1.2.3.4:6379/1',\n        ],\n        'KEY_PREFIX': 'teamproject:page',\n        'OPTIONS': {\n            'CLIENT_CLASS': 'django_redis.client.DefaultClient',\n            'CONNECTION_POOL_KWARGS': {\n                'max_connections': 500,\n            },\n            'PASSWORD': 'yourpass',\n        }\n    },\n    # 会话缓存\n    'session': {\n        'BACKEND': 'django_redis.cache.RedisCache',\n        'LOCATION': [\n            'redis://1.2.3.4:6379/2',\n        ],\n        'KEY_PREFIX': 'teamproject:session',\n        'TIMEOUT': 1209600,\n        'OPTIONS': {\n            'CLIENT_CLASS': 'django_redis.client.DefaultClient',\n            'CONNECTION_POOL_KWARGS': {\n                'max_connections': 2000,\n            },\n            'PASSWORD': 'yourpass',\n        }\n    },\n    # 接口数据缓存\n    'api': {\n        'BACKEND': 'django_redis.cache.RedisCache',\n        'LOCATION': [\n            'redis://1.2.3.4:6379/3',\n        ],\n        'KEY_PREFIX': 'teamproject:api',\n        'OPTIONS': {\n            'CLIENT_CLASS': 'django_redis.client.DefaultClient',\n            'CONNECTION_POOL_KWARGS': {\n                'max_connections': 500,\n            },\n            'PASSWORD': 'yourpass',\n        }\n    },\n}\n```\n> 说明：通过Redis底层提供的多个数据库来隔离缓存数据有助于缓存数据的管理。如果配置了Redis的主从复制（读写分离），LOCATION列表中可以配置多个Redis连接，第一个被视为master用来进行写操作，后面的被视为slave用来进行读操作。\n\n#### 全站缓存\n\n```Python\nMIDDLEWARE_CLASSES = [\n    'django.middleware.cache.UpdateCacheMiddleware',\n    ...\n    'django.middleware.common.CommonMiddleware',\n    ...\n    'django.middleware.cache.FetchFromCacheMiddleware',\n]\n\nCACHE_MIDDLEWARE_ALIAS = 'default'\nCACHE_MIDDLEWARE_SECONDS = 300\nCACHE_MIDDLEWARE_KEY_PREFIX = 'djang:cache'\n```\n#### 视图层缓存\n\n```Python\nfrom django.views.decorators.cache import cache_page\nfrom django.views.decorators.vary import vary_on_cookie\n\n\n@cache_page(timeout=60 * 15, cache='page')\n@vary_on_cookie\ndef my_view(request):\n    pass\n```\n\n```Python\nfrom django.views.decorators.cache import cache_page\n\nurlpatterns = [\n    url(r'^foo/([0-9]{1,2})/$', cache_page(60 * 15)(my_view)),\n]\n```\n#### 其他内容\n\n1. 模板片段缓存。\n\n   - `{% load cache %}`\n   - `{% cache %}` / `{% endcache %}`\n\n2. 使用底层API访问缓存。\n\n   ```Python\n   >>> from django.core.cache import cache\n   >>>\n   >>> cache.set('my_key', 'hello, world!', 30)\n   >>> cache.get('my_key')\n   >>> cache.clear()\n   ```\n\n   ```Python\n   >>> from django.core.cache import caches\n   >>> cache1 = caches['page']\n   >>> cache2 = caches['page']\n   >>> cache1 is cache2\n   True\n   >>> cache3 = caches['session']\n   >>> cache2 is cache3\n   False\n   ```\n\n   ```Python\n   >>> from django_redis import get_redis_connection\n   >>>\n   >>> redis_client = get_redis_connection()\n   >>> redis_client.hgetall()\n   ```\n\n\n### 日志\n\n#### 日志级别\n\nNOTSET < DEBUG < INFO < WARNING < ERROR < CRITICAL\n\n#### 日志配置\n\n```Python\nLOGGING = {\n    'version': 1,\n    'disable_existing_loggers': False,\n    # 配置日志格式化器\n    'formatters': {\n        'simple': {\n            'format': '%(asctime)s %(module)s.%(funcName)s: %(message)s',\n            'datefmt': '%Y-%m-%d %H:%M:%S',\n        },\n        'verbose': {\n            'format': '%(asctime)s %(levelname)s [%(process)d-%(threadName)s] '\n                      '%(module)s.%(funcName)s line %(lineno)d: %(message)s',\n            'datefmt': '%Y-%m-%d %H:%M:%S',\n        }\n    },\n    # 配置日志过滤器\n    'filters': {\n        'require_debug_true': {\n            '()': 'django.utils.log.RequireDebugTrue',\n        },\n    },\n    # 配置日志处理器\n    'handlers': {\n        'console': {\n            'class': 'logging.StreamHandler',\n            'level': 'DEBUG',\n            'filters': ['require_debug_true'],\n            'formatter': 'simple',\n        },\n        'file1': {\n            'class': 'logging.handlers.TimedRotatingFileHandler',\n            'filename': 'access.log',\n            'when': 'W0',\n            'backupCount': 12,\n            'formatter': 'simple',\n            'level': 'INFO',\n        },\n        'file2': {\n            'class': 'logging.handlers.TimedRotatingFileHandler',\n            'filename': 'error.log',\n            'when': 'D',\n            'backupCount': 31,\n            'formatter': 'verbose',\n            'level': 'WARNING',\n        },\n    },\n    # 配置日志器\n    'loggers': {\n        'django': {\n            'handlers': ['console', 'file1', 'file2'],\n            'propagate': True,\n            'level': 'DEBUG',\n        },\n    }\n}\n```\n\n[日志配置官方示例](https://docs.djangoproject.com/zh-hans/2.0/topics/logging/#s-examples)。\n\n#### 日志分析\n\n1. Linux相关命令：head、tail、grep、awk、uniq、sort\n\n   ```Shell\n   tail -10000 access.log | awk '{print $1}' | uniq -c | sort -r\n   ```\n\n2. 实时日志文件分析：Python + 正则表达式 + Crontab\n\n3. [《Python日志分析工具》](https://github.com/jkklee/web_log_analyse)。\n\n4. [《集中式日志系统ELK》](https://www.ibm.com/developerworks/cn/opensource/os-cn-elk/index.html)。\n\n   - ElasticSearch：搜索引擎，实现全文检索。\n   - Logstash：负责从指定节点收集日志。\n   - Kibana：日志可视化工具。\n\n5. 大数据日志处理：Flume+Kafka日志采集、Storm / Spark实时数据处理、Impala实时查询。\n\n### RESTful\n\n问题1：RESTful架构到底解决了什么问题？（URL具有自描述性、资源表述与视图的解耦和、互操作性利用构建微服务以及集成第三方系统、无状态性提高水平扩展能力）\n\n问题2：项目在使用RESTful架构时有没有遇到一些问题或隐患？（对资源访问的限制、资源从属关系检查、避免泄露业务信息、防范可能的攻击）\n\n> 补充：下面的几个和安全性相关的响应头在前面讲中间件的时候提到过的。\n>\n> - X-Frame-Options: DENY\n> - X-Content-Type-Options: nosniff\n> - X-XSS-Protection: 1; mode=block;\n> - Strict­-Transport-­Security: max-age=31536000;\n\n问题3：如何保护API中的敏感信息以及防范重放攻击？（摘要和令牌）\n\n推荐阅读：[《如何有效防止API的重放攻击》](https://help.aliyun.com/knowledge_detail/50041.html)。\n\n#### 使用djangorestframework\n\n安装djangorestfrmework（为了描述方便，以下统一简称为DRF）。\n\n```Shell\npip install djangorestframework\n```\n\n配置DRF。\n\n```Python\nINSTALLED_APPS = [\n    \n    'rest_framework',\n    \n]\n\nREST_FRAMEWORK = {\n    # 配置默认页面大小\n    'PAGE_SIZE': 10,\n    # 配置默认的分页类\n    'DEFAULT_PAGINATION_CLASS': 'rest_framework.pagination.PageNumberPagination',\n    # 配置异常处理器\n    # 'EXCEPTION_HANDLER': 'api.exceptions.exception_handler',\n    # 配置默认解析器\n    # 'DEFAULT_PARSER_CLASSES': (\n    #     'rest_framework.parsers.JSONParser',\n    #     'rest_framework.parsers.FormParser',\n    #     'rest_framework.parsers.MultiPartParser',\n    # ),\n    # 配置默认限流类\n    # 'DEFAULT_THROTTLE_CLASSES': (),\n    # 配置默认授权类\n    # 'DEFAULT_PERMISSION_CLASSES': (\n    #     'rest_framework.permissions.IsAuthenticated',\n    # ),\n    # 配置默认认证类\n    # 'DEFAULT_AUTHENTICATION_CLASSES': (\n    #     'rest_framework_jwt.authentication.JSONWebTokenAuthentication',\n    # ),\n}\n```\n\n#### 编写序列化器\n\n```Python\nfrom rest_framework import serializers\nfrom rest_framework.serializers import ModelSerializer\n\nfrom common.models import District, HouseType, Estate, Agent\n\n\nclass DistrictSerializer(ModelSerializer):\n\n    class Meta:\n        model = District\n        fields = ('distid', 'name')\n\n\nclass HouseTypeSerializer(ModelSerializer):\n\n    class Meta:\n        model = HouseType\n        fields = '__all__'\n\n\nclass AgentSerializer(ModelSerializer):\n\n    class Meta:\n        model = Agent\n        fields = ('agentid', 'name', 'tel', 'servstar', 'certificated')\n\n\nclass EstateSerializer(ModelSerializer):\n    district = serializers.SerializerMethodField()\n    agents = serializers.SerializerMethodField()\n\n    @staticmethod\n    def get_agents(estate):\n        return AgentSerializer(estate.agents, many=True).data\n\n    @staticmethod\n    def get_district(estate):\n        return DistrictSerializer(estate.district).data\n\n    class Meta:\n        model = Estate\n        fields = '__all__'\n```\n\n#### 方法1：使用装饰器\n\n```Python\n@api_view(['GET'])\n@cache_page(timeout=None, cache='api')\ndef provinces(request):\n    queryset = District.objects.filter(parent__isnull=True)\n    serializer = DistrictSerializer(queryset, many=True)\n    return Response(serializer.data)\n\n\n@api_view(['GET'])\n@cache_page(timeout=300, cache='api')\ndef cities(request, provid):\n    queryset = District.objects.filter(parent__distid=provid)\n    serializer = DistrictSerializer(queryset, many=True)\n    return Response(serializer.data)\n```\n\n```Python\nurlpatterns = [\n    path('districts/', views.provinces, name='districts'),\n    path('districts/<int:provid>/', views.cities, name='cities'),\n]\n```\n\n> 说明：上面使用了Django自带的视图装饰器（@cache_page）来实现对API接口返回数据的缓存。\n\n#### 方法2：使用APIView及其子类\n\n更好的复用代码，不要重“复发明轮子”。\n\n```Python\nclass HouseTypeApiView(CacheResponseMixin, ListAPIView):\n    queryset = HouseType.objects.all()\n    serializer_class = HouseTypeSerializer\n```\n\n```Python\nurlpatterns = [\n    path('housetypes/', views.HouseTypeApiView.as_view(), name='housetypes'),\n]\n```\n\n> 说明：上面使用了drf_extensions提供的CacheResponseMixin混入类实现了对接口数据的缓存。如果重写了获取数据的方法，可以使用drf_extensions提供的@cache_response来实现对接口数据的缓存，也可以用自定义的函数来生成缓存中的key。当然还有一个选择就是通过Django提供的@method_decorator装饰器，将@cache_page装饰器处理为装饰方法的装饰器，这样也能提供使用缓存服务。\n\n`drf-extensions`配置如下所示。\n\n```Python\n# 配置DRF扩展来支持缓存API接口调用结果\nREST_FRAMEWORK_EXTENSIONS = {\n    'DEFAULT_CACHE_RESPONSE_TIMEOUT': 300,\n    'DEFAULT_USE_CACHE': 'default',\n    # 配置默认缓存单个对象的key函数\n    'DEFAULT_OBJECT_CACHE_KEY_FUNC': 'rest_framework_extensions.utils.default_object_cache_key_func',\n    # 配置默认缓存对象列表的key函数\n    'DEFAULT_LIST_CACHE_KEY_FUNC': 'rest_framework_extensions.utils.default_list_cache_key_func',\n}\n```\n\n#### 方法3：使用ViewSet及其子类\n\n```Python\nclass HouseTypeViewSet(CacheResponseMixin, viewsets.ModelViewSet):\n    queryset = HouseType.objects.all()\n    serializer_class = HouseTypeSerializer\n    pagination_class = None\n```\n\n```Python\nrouter = DefaultRouter()\nrouter.register('housetypes', views.HouseTypeViewSet)\n\nurlpatterns += router.urls\n```\n\ndjangorestframework提供了基于Bootstrap定制的页面来显示接口返回的JSON数据，当然也可以使用[POSTMAN](https://www.getpostman.com/)这样的工具对API接口进行测试。\n\n#### 补充说明\n\n在这里顺便提一下跟前端相关的几个问题。\n\n问题1：如何让浏览器能够发起DELETE/PUT/PATCH？\n\n```HTML\n<form method=\"post\">\n    \n    <input type=\"hidden\" name=\"_method\" value=\"delete\">\n    \n</form>\n```\n\n```Python\nif request.method == 'POST' and '_method' in request.POST:\n    request.method = request.POST['_method'].upper()\n```\n\n```HTML\n<script>\n    $.ajax({\n        'url': '/api/provinces',\n        'type': 'put',\n        'data': {},\n        'dataType': 'json',\n        'success': function(json) {\n            // Web = 标签(内容) + CSS(显示) + JS(行为)\n            // JavaScript = ES + BOM + DOM\n            // DOM操作实现页面的局部刷新\n        },\n        'error': function() {}\n    });\n    $.getJSON('/api/provinces', function(json) {\n        // DOM操作实现页面的局部刷新\n    });\n</script>\n```\n\n问题2：如何解决多个JavaScript库之间某个定义（如$函数）冲突的问题？\n\n```HTML\n<script src=\"js/jquery.min.js\"></script>\n<script src=\"js/abc.min.js\"></script>\n<script>\n    // $已经被后加载的JavaScript库占用了\n    // 但是可以直接用绑定在window对象上的jQuery去代替$\n    jQuery(function() {\n        jQuery('#okBtn').on('click', function() {});\n    });\n</script>\n```\n\n```HTML\n<script src=\"js/abc.min.js\"></script>\n<script src=\"js/jquery.min.js\"></script>\n<script>\n    // 将$让出给其他的JavaScript库使用\n\tjQuery.noConflict();\n\tjQuery(function() {\n        jQuery('#okBtn').on('click', function() {});\n    });\n</script>\n```\n\n问题3：jQuery对象与原生DOM对象之间如何转换？\n\n```HTML\n<button id=\"okBtn\">点我</button>\n<script src=\"js/jquery.min.js\"></script>\n<script>\n    var btn = document.getElementById('okBtn');\t// 原生JavaScript对象(使用相对麻烦)\n    var $btn = $('#okBtn');\t// jQuery对象(拥有更多的属性和方法而且没有浏览器兼容性问题)\n    $btn.on('click', function() {});\n    // $(btn)可以将原生JavaScript对象转成jQuery对象\n    // $btn.get(0)或$btn[0]可以获得原生的JavaScript对象\n</script>\n```\n\n#### 过滤数据\n\n如果需要过滤数据（对数据接口设置筛选条件、排序条件等），可以使用`django-filter`三方库来实现。\n\n```Shell\npip install django-filter\n```\n\n```Python\nINSTALLED_APPS = [\n    \n    'django_filters',\n\n]\nREST_FRAMEWORK = {\n  \t\n    'DEFAULT_FILTER_BACKENDS': (\n        'django_filters.rest_framework.DjangoFilterBackend',\n        'rest_framework.filters.OrderingFilter',\n    ),\n    \n}\n```\n\n```Python\nfrom django.utils.decorators import method_decorator\nfrom django.views.decorators.cache import cache_page\nfrom django_filters.rest_framework import DjangoFilterBackend\nfrom rest_framework.filters import OrderingFilter\nfrom rest_framework.generics import RetrieveAPIView, ListCreateAPIView\n\nfrom api.serializers import EstateSerializer\nfrom common.models import Estate\n\n\n@method_decorator(decorator=cache_page(timeout=120, cache='api', key_prefix='estates'), name='get')\nclass EstateView(RetrieveAPIView, ListCreateAPIView):\n    queryset = Estate.objects.all().select_related('district').prefetch_related('agents')\n    serializer_class = EstateSerializer\n    filter_backends = (DjangoFilterBackend, OrderingFilter)\n    filter_fields = ('name', 'district')\n    ordering = ('-hot', )\n    ordering_fields = ('hot', 'estateid')\n```\n\n```Python\nfrom django_filters import rest_framework as drf\nfrom common.models import HouseInfo\n\n\nclass HouseInfoFilter(drf.FilterSet):\n    \"\"\"自定义房源数据过滤器\"\"\"\n\n    title = drf.CharFilter(lookup_expr='starts')\n    dist = drf.NumberFilter(field_name='district')\n    min_price = drf.NumberFilter(field_name='price', lookup_expr='gte')\n    max_price = drf.NumberFilter(field_name='price', lookup_expr='lte')\n    type = drf.NumberFilter()\n\n    class Meta:\n        model = HouseInfo\n        fields = ('title', 'district', 'min_price', 'max_price', 'type')\n```\n\n```Python\nclass HouseInfoViewSet(CacheResponseMixin, ReadOnlyModelViewSet):\n    queryset = HouseInfo.objects.all() \\\n        .select_related('type', 'district', 'estate', 'agent') \\\n        .prefetch_related('tags').order_by('-pubdate')\n    serializer_class = HouseInfoSerializer\n    filter_backends = (DjangoFilterBackend, OrderingFilter)\n    filterset_class = HouseInfoFilter\n    ordering = ('price',)\n    ordering_fields = ('price', 'area')\n```\n\n#### 身份认证\n\n查看DRF中APIView类的代码可以看出，DRF默认的认证方案是 `DEFAULT_AUTHENTICATION_CLASSES`，如果修改authentication_classes就可以自行定制身份认证的方案。\n\n```Python\nclass APIView(View):\n\n    # The following policies may be set at either globally, or per-view.\n    renderer_classes = api_settings.DEFAULT_RENDERER_CLASSES\n    parser_classes = api_settings.DEFAULT_PARSER_CLASSES\n    authentication_classes = api_settings.DEFAULT_AUTHENTICATION_CLASSES\n    throttle_classes = api_settings.DEFAULT_THROTTLE_CLASSES\n    permission_classes = api_settings.DEFAULT_PERMISSION_CLASSES\n    content_negotiation_class = api_settings.DEFAULT_CONTENT_NEGOTIATION_CLASS\n    metadata_class = api_settings.DEFAULT_METADATA_CLASS\n    versioning_class = api_settings.DEFAULT_VERSIONING_CLASS\n\n   \t# 此处省略下面的代码\n```\n\n```Python\nDEFAULTS = {\n    # Base API policies\n    'DEFAULT_RENDERER_CLASSES': (\n        'rest_framework.renderers.JSONRenderer',\n        'rest_framework.renderers.BrowsableAPIRenderer',\n    ),\n    'DEFAULT_PARSER_CLASSES': (\n        'rest_framework.parsers.JSONParser',\n        'rest_framework.parsers.FormParser',\n        'rest_framework.parsers.MultiPartParser'\n    ),\n    'DEFAULT_AUTHENTICATION_CLASSES': (\n        'rest_framework.authentication.SessionAuthentication',\n        'rest_framework.authentication.BasicAuthentication'\n    ),\n    'DEFAULT_PERMISSION_CLASSES': (\n        'rest_framework.permissions.AllowAny',\n    ),\n    'DEFAULT_THROTTLE_CLASSES': (),\n    'DEFAULT_CONTENT_NEGOTIATION_CLASS': 'rest_framework.negotiation.DefaultContentNegotiation',\n    'DEFAULT_METADATA_CLASS': 'rest_framework.metadata.SimpleMetadata',\n    'DEFAULT_VERSIONING_CLASS': None,\n\n    # 此处省略下面的代码\n}\n```\n\n自定义认证类，继承`BaseAuthentication`并重写`authenticate(self, request)`方法，通过请求中的userid和token来确定用户身份。如果认证成功，该方法应返回一个二元组（用户和令牌的信息），否则产生异常。也可以重写 `authenticate_header(self, request)`方法来返回一个字符串，该字符串将用于`HTTP 401 Unauthorized`响应中的WWW-Authenticate响应头的值。如果未重写该方法，那么当未经身份验证的请求被拒绝访问时，身份验证方案将返回`HTTP 403 Forbidden`响应。\n\n```Python\nclass MyAuthentication(BaseAuthentication):\n    \"\"\"自定义用户身份认证类\"\"\"\n\n    def authenticate(self, request):\n        try:\n            token = request.GET['token'] or request.POST['token']\n            user_token = UserToken.objects.filter(token=token).first()\n            if user_token:\n                return user_token.user, user_token\n            else:\n                raise AuthenticationFailed('请提供有效的用户身份标识')\n        except KeyError:\n            raise AuthenticationFailed('请提供有效的用户身份标识')\n\n    def authenticate_header(self, request):\n        pass\n```\n\n使用自定义的认证类。\n\n```Python\nclass EstateViewSet(CacheResponseMixin, ModelViewSet):\n    # 通过queryset指定如何获取数据（资源）\n    queryset = Estate.objects.all().select_related('district').prefetch_related('agents')\n    # 通过serializer_class指定如何序列化数据\n    serializer_class = EstateSerializer\n    # 指定根据哪些字段进行数据筛选\n    filter_fields = ('district', 'name')\n    # 指定根据哪些字段对数据进行排序\n    ordering_fields = ('hot', )\n    # 指定用于进行用户身份验证的类\n    authentication_classes = (MyAuthentication, )\n```\n\n> 说明：也可以在Django配置文件中将自定义的认证类设置为默认认证方式。\n\n#### 授予权限\n\n权限检查总是在视图的最开始处运行，在任何其他代码被允许进行之前。最简单的权限是允许通过身份验证的用户访问，并拒绝未经身份验证的用户访问，这对应于dfr中的`IsAuthenticated`类，可以用它来取代默认的`AllowAny`类。权限策略可以在Django的DRF配置中用`DEFAULT_PERMISSION_CLASSES`全局设置。\n\n```Python\nREST_FRAMEWORK = {\n    'DEFAULT_PERMISSION_CLASSES': (\n        'rest_framework.permissions.IsAuthenticated',\n    )\n}\n```\n\n也可以在基于`APIView`类的视图上设置身份验证策略。\n\n```Python\nfrom rest_framework.permissions import IsAuthenticated\nfrom rest_framework.views import APIView\n\nclass ExampleView(APIView):\n    permission_classes = (IsAuthenticated, )\n    # 此处省略其他代码\n```\n\n或者在基于`@api_view`装饰器的视图函数上设置。\n\n```Python\nfrom rest_framework.decorators import api_view, permission_classes\nfrom rest_framework.permissions import IsAuthenticated\n\n@api_view(['GET'])\n@permission_classes((IsAuthenticated, ))\ndef example_view(request, format=None):\n    # 此处省略其他代码\n```\n\n自定义权限需要继承`BasePermission`并实现以下方法中的一个或两个，下面是BasePermission的代码。\n\n```Python\n@six.add_metaclass(BasePermissionMetaclass)\nclass BasePermission(object):\n    \"\"\"\n    A base class from which all permission classes should inherit.\n    \"\"\"\n\n    def has_permission(self, request, view):\n        \"\"\"\n        Return `True` if permission is granted, `False` otherwise.\n        \"\"\"\n        return True\n\n    def has_object_permission(self, request, view, obj):\n        \"\"\"\n        Return `True` if permission is granted, `False` otherwise.\n        \"\"\"\n        return True\n```\n\n如果请求被授予访问权限，则方法应该返回True，否则返False。下面的例子演示了阻止黑名单中的IP地址访问接口数据（这个在反爬虫的时候很有用哟）。\n\n```Python\nfrom rest_framework import permissions\n\n\nclass BlacklistPermission(permissions.BasePermission):\n    \"\"\"\n    Global permission check for blacklisted IPs.\n    \"\"\"\n\n    def has_permission(self, request, view):\n        ip_addr = request.META['REMOTE_ADDR']\n        blacklisted = Blacklist.objects.filter(ip_addr=ip_addr).exists()\n        return not blacklisted\n```\n\n如果要实现更为完整的权限验证，可以考虑RBAC或ACL。\n\n1. RBAC - 基于角色的访问控制，如下图所示。\n\n   ![](./res/rbac-basic.png)\n\n   ![](./res/rbac-full.png)\n\n2. ACL - 访问控制列表（每个用户绑定自己的访问白名单或黑名单）。\n\n#### 访问限流\n\n可以修改dfr配置的`DEFAULT_THROTTLE_CLASSES` 和 `DEFAULT_THROTTLE_RATES`两个值来设置全局默认限流策略。例如：\n\n```Python\nREST_FRAMEWORK = {\n    'DEFAULT_THROTTLE_CLASSES': (\n        'rest_framework.throttling.AnonRateThrottle',\n        'rest_framework.throttling.UserRateThrottle'\n    ),\n    'DEFAULT_THROTTLE_RATES': {\n        'anon': '3/min',\n        'user': '10000/day'\n    }\n}\n```\n\n`DEFAULT_THROTTLE_RATES`中使用的频率描述可能包括`second`、`minute`、`hour`或`day`。\n\n如果要为接口单独设置限流，可以在每个视图或视图集上设置限流策略，如下所示：\n\n```Python\nfrom rest_framework.throttling import UserRateThrottle\nfrom rest_framework.views import APIView\n\n\nclass ExampleView(APIView):\n    throttle_classes = (UserRateThrottle, )\n    # 此处省略下面的代码\n```\n\n或\n\n```Python\n@api_view(['GET'])\n@throttle_classes([UserRateThrottle, ])\ndef example_view(request, format=None):\n    # 此处省略下面的代码\n```\n\n当然也可以通过继承`SimpleRateThrottle`来自定义限流策略，通常需要重写`allow_request`和`wait`方法。\n\n### 异步任务和计划任务\n\n#### Celery的应用\n\nCelery 是一个简单、灵活且可靠的，处理大量消息的分布式系统，并且提供维护这样一个系统的必需工具。它是一个专注于实时处理的任务队列，同时也支持任务调度。\n\n推荐阅读：[《Celery官方文档中文版》](http://docs.jinkan.org/docs/celery/)，上面有极为详细的配置和使用指南。\n\n![](./res/celery_architecture.png)\n\nCelery是一个本身不提供队列服务，官方推荐使用RabbitMQ或Redis来实现消息队列服务，前者是更好的选择，它对AMQP（高级消息队列协议）做出了非常好的实现。\n\n1. 安装RabbitMQ。\n\n   ```Shell\n   docker pull rabbitmq\n   docker run -d -p 5672:5672 --name myrabbit rabbitmq\n   docker container exec -it myrabbit /bin/bash\n   ```\n\n2. 创建用户、资源以及分配操作权限。\n\n   ```Shell\n   rabbitmqctl add_user luohao 123456\n   rabbitmqctl set_user_tags luohao administrator\n   rabbitmqctl add_vhost vhost1\n   rabbitmqctl set_permissions -p vhost1 luohao \".*\" \".*\" \".*\"\n   ```\n\n3. 创建Celery实例。\n\n   ```Python\n   # 注册环境变量\n   os.environ.setdefault('DJANGO_SETTINGS_MODULE', '项目名.settings')\n   \n   # 创建Celery实例\n   app = celery.Celery(\n       'fangtx',\n       broker='amqp://luohao:123456@1.2.3.4:5672/vhost1'\n   )\n   \n   # 从项目的配置文件读取Celery配置信息\n   # app.config_from_object('django.conf:settings')\n   # 从指定的文件(例如celery_config.py)中读取Celery配置信息\n   # app.config_from_object('celery_config')\n   \n   # 让Celery自动从参数指定的应用中发现异步任务/定时任务\n   # app.autodiscover_tasks(['common', ])\n   # 让Celery自动从所有注册的应用中发现异步任务/定时任务\n   app.autodiscover_tasks(lambda: settings.INSTALLED_APPS)\n   ```\n\n4. 启动Celery创建woker（消息的消费者）。\n\n   ```Shell\n   celery -A <name> worker -l debug &\n   ```\n\n5. 执行异步任务。\n\n   ```Python\n   @app.task\n   def send_email(from_user, to_user, cc_user, subject, content):\n       pass\n   \n   \n   # 消息的生产者\n   send_email.delay('', [], [], '', '')\n   ```\n\n6. 创建定时任务。\n\n   ```Python\n   # 配置定时任务（计划任务）\n   app.conf.update(\n       timezone=settings.TIME_ZONE,\n       enable_utc=True,\n       # 定时任务（计划任务）相当于是消息的生产者\n       # 如果只有生产者没有消费者那么消息就会在消息队列中积压\n       # 将来实际部署项目的时候生产者、消费者、消息队列可能都是不同节点\n       beat_schedule={\n           'task1': {\n               'task': 'common.tasks.scheduled_task',\n               'schedule': crontab('*', '*', '*', '*', '*'),\n               'args': ('...', )\n           },\n       },\n   )\n   ```\n\n   ```Python\n   @app.task\n   def scheduled_task(*args, **kwargs):\n       pass\n   ```\n\n7. 启动Celery创建执行定时任务的beat（消息的生产者）。\n\n   ```Shell\n   celery -A <name> beat -l info\n   ```\n\n8. 检查消息队列状况。\n\n   ```Shell\n   rabbitmqctl list_queues -p vhost1\n   ```\n\n9. 监控Celery - 可以通过flower来对Celery进行监控。\n\n   ```Shell\n   pip install flower\n   celery flower --broker=amqp://luohao:123456@120.77.222.217:5672/vhost1\n   ```\n\n### 其他问题\n\n问题1：如何解决JavaScript跨域获取数据的问题？（django-cors-headers）\n\n```Python\nINSTALLED_APPS = [\n    'corsheaders',\n]\n\nMIDDLEWARE = [\n    'corsheaders.middleware.CorsMiddleware',\n]\n\nCORS_ORIGIN_ALLOW_ALL = True\n# 配置跨域白名单\n# CORS_ORIGIN_WHITELIST = ('www.abc.com', 'www.baidu.com')\n# CORS_ORIGIN_REGEX_WHITELIST = ('...', )\n# CORS_ALLOW_CREDENTIALS = True\n# CORS_ALLOW_METHODS = ('GET', 'POST', 'PUT', 'DELETE')\n```\n\n问题2：网站图片（水印、剪裁）和视频（截图、水印、转码）是如何处理的？（云存储、FFmpeg）\n\n问题3：网站如何架设（静态资源）文件系统？（FastDFS、云存储、CDN）\n\n### 安全保护\n\n问题1：什么是跨站脚本攻击（XSS)，如何防范？（对提交的内容进行消毒）\n\n问题2：什么是跨站身份伪造（CSRF），如何防范？（使用随机令牌）\n\n问题3：什么是SQL注射攻击（SQL Injection），如何防范？（不拼接SQL语句，避免使用单引号）\n\n问题4：什么是点击劫持攻击（Click-hacking），如何防范？（不允许`<iframe>`加载非同源站点内容）\n\n#### Django提供的安全措施\n\n签名数据的API\n\n   ```Python\n>>> from django.core.signing import Signer\n>>> signer = Signer()\n>>> value = signer.sign('hello, world!')\n>>> value\n'hello, world!:BYMlgvWMTSPLxC-DqxByleiMVXU'\n>>> signer.unsign(value)\n'hello, world!'\n>>>\n>>> signer = Signer(salt='yoursalt')\n>>> signer.sign('hello, world!')\n'hello, world!:9vEvG6EA05hjMDB5MtUr33nRA_M'\n>>>\n>>> from django.core.signing import TimestampSigner\n>>> signer = TimestampSigner()\n>>> value = signer.sign('hello, world!')\n>>> value\n'hello, world!:1fpmcQ:STwj464IFE6eUB-_-hyUVF3d2So'\n>>> signer.unsign(value, max_age=5)\nTraceback (most recent call last):\n    File \"<console>\", line 1, in <module>\n    File \"/Users/Hao/Desktop/fang.com/venv/lib/python3.6/site-packages/django/core/signing.py\", line 198, in unsign\n    'Signature age %s > %s seconds' % (age, max_age))\n    django.core.signing.SignatureExpired: Signature age 21.020604848861694 > 5 seconds\n>>> signer.unsign(value, max_age=120)\n'hello, world!'\n   ```\n\nCSRF令牌和小工具\n\n```HTML\n{% csrf_token %}\n```\n\n- @csrf_exempt：免除令牌 \n- @csrf_protect：提供令牌保护\n- @require_csrf_token：提供令牌保护\n- @ensure_csrf_cookie：强制视图发送带令牌的cookie\n\n> 说明：可以在Chrome浏览器中安装EditThisCookie插件来方便的查看Cookie。\n\n\n#### 用户敏感信息的保护\n\n1. 哈希摘要（签名）\n\n   ```Python\n   >>> import hashlib\n   >>> \n   >>> md5_hasher = hashlib.md5()\n   >>> md5_hasher.update('hello, world!'.encode())\n   >>> md5_hasher.hexdigest()\n   '3adbbad1791fbae3ec908894c4963870'\n   >>>\n   >>> sha1_hasher = hashlib.sha1()\n   >>> sha1_hasher.update('hello, world!'.encode())\n   >>> sha1_hasher.update('goodbye, world!'.encode())\n   >>> sha1_hasher.hexdigest()\n   '1f09d30c707d53f3d16c530dd73d70a6ce7596a9'\n   ```\n\n2. 加密和解密（对称加密和非对称加密）\n\n   ```Shell\n   pip install pycrypto\n   ```\n\n   AES对称加密：\n\n   ```Python\n   >>> from hashlib import md5\n   >>>\n   >>> from Crypto.Cipher import AES\n   >>> from Crypto import Random\n   >>>\n   >>> key = md5(b'mysecret').hexdigest()\n   >>> iv = Random.new().read(AES.block_size)\n   >>> str1 = '我爱你们！'\n   >>> str2 = AES.new(key, AES.MODE_CFB, iv).encrypt(str1)\n   b'p\\x96o\\x85\\x0bq\\xc4-Y\\xc4\\xbcp\\n)&'\n   >>> str3 = AES.new(key, AES.MODE_CFB, iv).decrypt(str2).decode()\n   '我爱你们！'\n   ```\n\n   RSA非对称加密：\n\n   ```Python\n   >>> from Crypto.PublicKey import RSA\n   >>> # 生成密钥对\n   >>> key_pair = RSA.generate(2048)\n   >>> # 导入公钥\n   >>> pub_key = RSA.importKey(key_pair.publickey().exportKey())\n   >>> # 导入私钥\n   >>> pri_key = RSA.importKey(key_pair.exportKey())\n   >>> # 明文\n   >>> message1 = 'hello, world!'.encode()\n   >>> # 加密数据\n   >>> message2 = pub_key.encrypt(message1, None)\n   (b'\\x03\\x86t\\xa0\\x00\\xc4\\xea\\xd2\\x80\\xed\\xa7YN7\\x07\\xff\\x88\\xaa\\x1eW\\x0cmH0\\x06\\xa7\\'\\xbc<w@q\\x8b\\xaf\\xf7:g\\x92{=\\xe2E\\xa5@\\x1as2\\xdd\\xcb\\x8e[\\x98\\x85\\xdf,X\\xecj.U\\xd6\\xa7W&u\\'Uz\"\\x0f\\x0e\\\\<\\xa4\\xfavC\\x93\\xa7\\xbcO\"\\xb9a\\x06]<.\\xc1\\r1}*\\xdf\\xccdqXML\\x93\\x1b\\xe9\\xda\\xdf\\xab|\\xf8\\x18\\xe4\\x99\\xbb\\x7f\\x18}\\xd9\\x9a\\x1e*J\\\\\\xca\\x1a\\xd1\\x85\\xf7t\\x81\\xd95{\\x19\\xc9\\x81\\xb6^}\\x9c5\\xca\\xfe\\xcf\\xc8\\xd8M\\x9a\\x8c-\\xf1t\\xee\\xf9\\x12\\x90\\x01\\xca\\x92~\\x00c5qg5g\\x95&\\x10\\xb1\\x0b\\x1fo\\x95\\xf2\\xbc\\x8d\\xf3f\"@\\xc5\\x188\\x0bX\\x9cfo\\xea\\x97\\x05@\\xe5\\xb2\\xda\\xb8\\x97a\\xa5w\\xa8\\x01\\x9a\\xa5N\\xc4\\x81\\x8d\\x0f<\\x96iU\\xd3\\x95\\xacJZs\\xab_ #\\xee\\xf9\\x0f\\xf2\\x12\\xdb\\xfc\\xf8g\\x18v\\x02k+\\xda\\x16Si\\xbf\\xbb\\xec\\xf7w\\x90\\xde\\xae\\x97\\t\\xed{}5\\xd0',)\n   >>> # 解密数据\n   >>> message3 = pri_key.decrypt(message2)\n   'hello, world!'\n   ```\n\n#### 安全相关建议\n\n1. 虽然 Django 自带了稳固的安全保护措施，但是依然要采用正确的方式部署应用程序，利用 Web 服务器、操作系统和其他组件提供的安全保护措施。\n2. 记得把 Python 代码放在 Web 服务器的文档根目录之外，避免代码意外泄露。\n3. 谨慎处理用户上传的文件。 \n4. Django本身没有对请求次数加以限制（包括验证用户身份的请求），为了防止暴力攻击和破解，可以考虑使用具有一次消费性的验证码或对这类请求的次数进行限制。  \n5. 将缓存系统、数据库服务器以及重要的资源服务器都放在第二级防火墙之后（不要放在DMZ）。 \n\n### 测试相关\n\n测试是发现和标记缺陷的过程。所谓的缺陷是指实际结果和期望结果之间的任何差别。有的地方，测试也被认为是执行以找出错误为目的的程序的过程。 测试是为了让产品达到以下目标： \n\n1. 满足需求用户满意\n2. 改善产品的市场占有率\n3. 树立对产品的信任\n4. 减少开发和维护的成本\n\n#### 功能测试\n\n如果一个软件单元的行为方式与它的开发规范完全一样，那么该软件单元就通过了它的功能测试。\n - 白盒测试：开发人员自己实现，最基本的形式是单元测试，还有集成测试和系统测试。\n - 黑盒测试：由开发团队之外的人执行，对测试代码没有可见性，将被测系统视为黑盒子。通常由测试人员或QA工程师来执行，Web应用可以通过Selenium这样的测试框架自动化实施。\n\n#### 性能测试\n\n软件在高工作负载下对其响应性和健壮性展开的测试。\n\n- 负载测试：在特定负载下执行的测试。\n\n - 压力测试：突发条件或极限条件下的性能测试。\n\n#### 安全性测试\n\n系统的敏感数据都是经过认证和授权之后才能访问。\n\n#### 其他测试\n\n易用性测试 / 安装测试 / 可访问性测试\n\n#### 单元测试\n\n测试函数和对象的方法（程序中最小最基本的单元）。通过对实际输出和预期输出的比对以及各种的断言条件来判定被测单元是否满足设计需求。\n\n- 测试用例\n- 测试固件 - 每次测试时都要使用的东西。\n- 测试套件（测试集）- 组合了多个测试用例而构成的集合。\n\n```Python\nclass UtilTest(unittest.TestCase):\n\n    def setUp(self):\n        self.pattern = re.compile(r'\\d{6}')\n\n    def test_gen_mobile_code(self):\n        for _ in range(100):\n            self.assertIsNotNone(self.pattern.match(gen_mobile_code()))\n\n    def test_to_md5_hex(self):\n        md5_dict = {\n            '123456': 'e10adc3949ba59abbe56e057f20f883e',\n            '123123123': 'f5bb0c8de146c67b44babbf4e6584cc0',\n            '1qaz2wsx': '1c63129ae9db9c60c3e8aa94d3e00495',\n        }\n        for key, value in md5_dict.items():\n            self.assertEqual(value, to_md5_hex(key))\n```\n\n`TestCase`的断言方法：\n\n- assertEqual / assertNotEqual\n- assertTrue / assertFalse / assertIsNot\n- assertRaise / assertRaiseRegexp\n- assertAlmostEqual / assertNotAlmostEqual\n- assertGreater / assertGreaterEqual / assertLess / assertLessEqual\n- assertRegexpMatches / assertNotRegexpMatches\n- assertListEqual / assertSetEqual / assertTupleEqual / assertDictEqual\n\n可以使用nose2或pytest来辅助执行单元测试，同时通过cov-core或pytest-cov可以对测试覆度进行评估。覆盖率由百分比表示。比如测试代码执行过了程序的每一行，那么覆盖率就是100%。这种时候，几乎不会出现新程序上线后突然无法运行的尴尬情况。覆盖率不关心代码内容究竟是什么，覆盖率是用来检查“测试代码不足、测试存在疏漏”的一个指标，“测试内容是否妥当”并不归它管。\n\n```Shell\npip install nose2 pytest cov-core pytest-cov\n```\n\n可以使用Selenium来实现Web应用的自动化测试，它还可以用于屏幕抓取与浏览器行为模拟，通过爬虫抓取页面上的动态数据也可以使用它。Selenium其实包括三个部分：\n\n- Selenium IDE：嵌入到浏览器的插件，可以录制和回放脚本。\n\n  ![](./res/selenium_ide.png)\n\n- Selenium WebDriver：支持多种语言可以操控浏览器的API。\n\n- Selenium Standalone Server：Selenium Grid、远程控制、分布式部署。\n\n```Shell\npip install selenium\n```\n\n```Python\nfrom selenium import webdriver\nimport pytest\nimport contextlib\n\n\n@pytest.fixture(scope='session')\ndef chrome():\n    # 设置使用无头浏览器(不会打开浏览器窗口)\n    options = webdriver.ChromeOptions()\n    options.add_argument('--headless')\n    driver = webdriver.Chrome(options=options)\n    yield driver\n    driver.quit()\n\n\ndef test_baidu_index(chrome):\n    chrome.get('https://www.baidu.com')\n    assert chrome.title == '百度一下，你就知道'\n```\n\n除了Selenium之外，还有一个Web自动化测试工具名叫Robot Framework。\n\n```Shell\nnose2 -v -C\npytest --cov\n```\n\n```Shell\nRan 7 tests in 0.002s\n\nOK\nName                       Stmts   Miss  Cover\n----------------------------------------------\nexample01.py                  15      0   100%\nexample02.py                  49     49     0%\nexample03.py                  22     22     0%\nexample04.py                  61     61     0%\nexample05.py                  29     29     0%\nexample06.py                  39     39     0%\nexample07.py                  19     19     0%\nexample08.py                  27     27     0%\nexample09.py                  18     18     0%\nexample10.py                  19     19     0%\nexample11.py                  22     22     0%\nexample12.py                  28     28     0%\nexample13.py                  28     28     0%\ntest_ddt_example.py           18      0   100%\ntest_pytest_example.py        11      6    45%\ntest_unittest_example.py      22      0   100%\n----------------------------------------------\nTOTAL                        427    367    14%\n```\n\n在测试过程中需要孤立各种外部依赖（数据库、外部接口调用、时间依赖），具体又包括两个方面：\n\n1. 数据源：数据本地化 / 置于内存中 / 测试之后回滚\n\n2. 资源虚拟化：存根/桩（stub）、仿制/模拟（mock）、伪造（fake）\n\n   - stub：测试期间为提供响应的函数生成的替代品\n   - mock：代替实际对象（以及该对象的API）的对象\n   - fake：没有达到生产级别的轻量级对象\n\n#### 集成测试\n\n集成多个函数或方法的输入输出的测试，测试时需要将多个测试对象组合在一起。\n\n - 测试组件互操作性 / 需求变更测试 / 外部依赖和API / 调试硬件问题 / 在代码路径中发现异常\n\n\n#### 系统测试\n\n对需求的测试，测试成品是否最终满足了所有需求，在客户验收项目时进行。\n\n#### 数据驱动测试\n\n使用外部数据源实现对输入值与期望值的参数化，避免在测试中使用硬编码的数据。\n\n被测函数：\n\n```Python\ndef add(x, y):\n    return x + y\n```\n\ndata.csv文件：\n\n```\n3,1,2\n0,1,-1\n100,50,50\n100,1,99\n15,7,8\n```\n\n测试代码：\n\n```Python\nimport csv\n\nfrom unittest import TestCase\nfrom ddt import ddt, data, unpack\n\n\n@ddt\nclass TestAdd(TestCase):\n\n    def load_data_from_csv(filename):\n        data_items = []\n        with open(filename, 'r', newline='') as fs:\n            reader = csv.reader(fs)\n            for row in reader:\n                data_items.append(list(map(int, row)))\n        return data_items\n\n\n    @data(*load_data_from_csv('data.csv'))\n    @unpack\n    def test_add(self, result, param1, param2):\n        self.assertEqual(result, add(param1, param2))\n```\n\n#### Django中的测试\n\n1. 测试Django视图 - Django中提供的`TestCase`扩展了`unittest`中的`TestCase`，绑定了一个名为`client`的属性，可以用来模拟浏览器发出的GET、POST、DELETE、PUT等请求。\n\n```Python\nclass SomeViewTest(TestCase):\n\n    def test_example_view(self):\n        resp = self.client.get(reverse('index'))\n        self.assertEqual(200, resp.status_code)\n        self.assertEqual(5, resp.context['num'])\n```\n\n2. 运行测试 - 配置测试数据库。\n\n```Python\nDATABASES = {\n    'default': {\n        'ENGINE': 'django.db.backends.mysql',\n        'HOST': 'localhost',\n        'PORT': 3306,\n        'NAME': 'DbName',\n        'USER': os.environ['DB_USER'],\n        'PASSWORD': os.environ['DB_PASS'],\n        'TEST': {\n            'NAME': 'DbName_for_testing',\n            'CHARSET': 'utf8',\n        },\n    }\n}\n```\n\n```Shell\npython manage.py test\npython manage.py test common\npython manage.py test common.tests.UtilsTest\npython manage.py test common.tests.UtilsTest.test_to_md5_hex\n```\n\n3. 评估测试覆盖度\n\n```Shell\npip install coverage\ncoverage run --source=<path1> --omit=<path2> manage.py test common\ncoverage report\n\nName                            Stmts   Miss  Cover\n---------------------------------------------------\ncommon/__init__.py                  0      0   100%\ncommon/admin.py                     1      0   100%\ncommon/apps.py                      3      3     0%\ncommon/forms.py                    16     16     0%\ncommon/helper.py                   32     32     0%\ncommon/middlewares.py              19     19     0%\ncommon/migrations/__init__.py       0      0   100%\ncommon/models.py                   71      2    97%\ncommon/serializers.py              14     14     0%\ncommon/tests.py                    14      8    43%\ncommon/urls_api.py                  3      3     0%\ncommon/urls_user.py                 3      3     0%\ncommon/utils.py                    22      7    68%\ncommon/views.py                    69     69     0%\n---------------------------------------------------\nTOTAL                             267    176    34%\n```\n\n#### 性能测试\n\n问题1：性能测试的指标有哪些？\n\n1. ab（ Apache Benchmark） / webbench / httpperf\n\n   ```Shell\n   yum -y install httpd\n   ab -c 10 -n 1000 http://www.baidu.com/\n   ...\n   Benchmarking www.baidu.com (be patient).....done\n   Server Software:        BWS/1.1\n   Server Hostname:        www.baidu.com\n   Server Port:            80\n   Document Path:          /\n   Document Length:        118005 bytes\n   Concurrency Level:      10\n   Time taken for tests:   0.397 seconds\n   Complete requests:      100\n   Failed requests:        98\n      (Connect: 0, Receive: 0, Length: 98, Exceptions: 0)\n   Write errors:           0\n   Total transferred:      11918306 bytes\n   HTML transferred:       11823480 bytes\n   Requests per second:    252.05 [#/sec] (mean)\n   Time per request:       39.675 [ms] (mean)\n   Time per request:       3.967 [ms] (mean, across all concurrent requests)\n   Transfer rate:          29335.93 [Kbytes/sec] received\n   Connection Times (ms)\n                 min  mean[+/-sd] median   max\n   Connect:        6    7   0.6      7       9\n   Processing:    20   27  22.7     24     250\n   Waiting:        8   11  21.7      9     226\n   Total:         26   34  22.8     32     258\n   Percentage of the requests served within a certain time (ms)\n     50%     32\n     66%     34\n     75%     34\n     80%     34\n     90%     36\n     95%     39\n     98%     51\n     99%    258\n    100%    258 (longest request)\n   ```\n\n2. mysqlslap\n\n   ```Shell\n   mysqlslap -a -c 100 -h 1.2.3.4 -u root -p\n   mysqlslap -a -c 100 --number-of-queries=1000 --auto-generate-sql-load-type=read -h <负载均衡服务器IP地址> -u root -p\n   mysqlslap -a --concurrency=50,100 --number-of-queries=1000 --debug-info --auto-generate-sql-load-type=mixed -h 1.2.3.4 -u root -p\n   ```\n\n3. sysbench\n\n   ```Shell\n   sysbench --test=threads --num-threads=64 --thread-yields=100 --thread-locks=2 run\n   sysbench --test=memory --num-threads=512 --memory-block-size=256M --memory-total-size=32G run\n   ```\n\n4. JMeter\n\n   请查看[《使用JMeter进行性能测试》](https://www.ibm.com/developerworks/cn/java/l-jmeter/index.html)。\n\n5. LoadRunner / QTP\n\n### 项目调试\n\n可以使用django-debug-toolbar来辅助项目调试。\n\n1. 安装\n\n   ```Shell\n   pip install django-debug-toolbar\n   ```\n\n2. 配置 - 修改settings.py。\n\n   ```Python\n   INSTALLED_APPS = [\n       'debug_toolbar',\n   ]\n   \n   MIDDLEWARE = [\n       'debug_toolbar.middleware.DebugToolbarMiddleware',\n   ]\n   \n   DEBUG_TOOLBAR_CONFIG = {\n       # 引入jQuery库\n       'JQUERY_URL': 'https://cdn.bootcss.com/jquery/3.3.1/jquery.min.js',\n       # 工具栏是否折叠\n       'SHOW_COLLAPSED': True,\n       # 是否显示工具栏\n       'SHOW_TOOLBAR_CALLBACK': lambda x: True,\n   }\n   ```\n\n3. 配置 - 修改urls.py。\n\n   ```Python\n   if settings.DEBUG:\n   \n       import debug_toolbar\n   \n       urlpatterns.insert(0, path('__debug__/', include(debug_toolbar.urls)))\n   ```\n\n4. 使用 - 在页面右侧可以看到一个调试工具栏，上面包括了执行时间、项目设置、请求头、SQL、静态资源、模板、缓存、信号等调试信息，查看起来非常的方便。\n\n5. 项目上线之前，请记住**去掉django-debug-toolbar相关的所有配置**。\n\n### 部署相关\n\n请参考[《项目部署上线和性能调优》](98.项目部署上线和性能调优.md)。\n\n### 性能相关\n\n#### 网站优化两大定律：\n\n1. 尽可能的使用缓存 - 牺牲空间换取时间（普适策略）。\n\n2. 能推迟的都推迟 - 使用消息队列将并行任务串行来缓解服务器压力。\n\n   - 服务器CPU利用率出现瞬时峰值 - 削峰（CPU利用率平缓的增长）\n   - 上下游节点解耦合（下订单和受理订单的系统通常是分离的）\n\n\n#### Django框架\n\n1. 配置缓存来缓解数据库的压力，并有合理的机制应对[缓存穿透和缓存雪崩](https://www.cnblogs.com/zhangweizhong/p/6258797.html)。\n\n2. 开启[模板缓存](https://docs.djangoproject.com/en/2.0/ref/templates/api/#django.template.loaders.cached.Loader)来加速模板的渲染。\n\n   ```Python\n   TEMPLATES = [\n       {\n           'BACKEND': 'django.template.backends.django.DjangoTemplates',\n           'DIRS': [os.path.join(BASE_DIR, 'templates'), ],\n           # 'APP_DIRS': True,\n           'OPTIONS': {\n               'context_processors': [\n                   'django.template.context_processors.debug',\n                   'django.template.context_processors.request',\n                   'django.contrib.auth.context_processors.auth',\n                   'django.contrib.messages.context_processors.messages',\n               ],\n               'loaders': [(\n                   'django.template.loaders.cached.Loader', [\n                       'django.template.loaders.filesystem.Loader',\n                       'django.template.loaders.app_directories.Loader',\n                   ], ),\n               ],\n           },\n       },\n   ]\n   ```\n\n3. 用惰性求值、迭代器、`defer()`、`only()`等缓解内存压力。\n\n4. 用`select_related()`和`prefetch_related()`执行预加载避免“1+N查询问题”。\n\n#### 数据库\n\n1. 用ID生成器代替自增主键（性能更好、适用于分布式环境）。\n\n   - 自定义ID生成器 - snowflake\n\n   - UUID\n\n   ```Python\n   >>> my_uuid = uuid.uuid1()\n   >>> my_uuid\n   UUID('63f859d0-a03a-11e8-b0ad-60f81da8d840')\n   >>> my_uuid.hex\n   '63f859d0a03a11e8b0ad60f81da8d840'\n   ```\n\n2. 避免不必要的外键列上的约束（除非必须保证参照完整性），更不要使用触发器之类的机制。\n\n3. 使用索引来优化查询性能（索引放在要用于查询的字段上）。InnoDB用的是BTREE索引，使用>、<、>=、<=、BETWEEN或者LIKE 'pattern'（pattern不以通配符开头）时都可以用到索引。因为建立索引需要额外的磁盘空间，而主键上是有默认的索引，所以主键要尽可能选择较短的数据类型来减少磁盘占用，提高索引的缓存效果。\n\n   ```SQL\n   create index idx_goods_name on tb_goods (gname(10));\n   ```\n\n   ```SQL\n   -- 无法使用索引\n   select * from tb_goods where gname like '%iPhone%';\n   -- 可以使用索引\n   select * from tb_goods where gname like 'iPhone%';\n   ```\n\n   ```Python\n   # 无法使用索引\n   Goods.objects.filter(name_icontains='iPhone')\n   # 可以使用索引\n   Goods.objects.filter(name__istartswith='iPhone');\n   ```\n\n4. 使用存储过程（存储在服务器端编译过的一组SQL语句）。\n\n   ```SQL\n   drop procedure if exists sp_avg_sal_by_dept;\n   \n   create procedure sp_avg_sal_by_dept(deptno integer, out avg_sal float)\n   begin \n       select avg(sal) into avg_sal from TbEmp where dno=deptno;\n   end;\n   \n   call sp_avg_sal_by_dept(10, @a);\n   \n   select @a;\n   ```\n\n   ```Python\n   >>> from django.db import connection\n   >>> cursor = connection.cursor()\n   >>> cursor.callproc('sp_avg_sal_by_dept', (10, 0))\n   >>> cursor.execute('select @_sp_avg_sal_by_dept_1')\n   >>> cursor.fetchone()\n   (2675.0,)\n   ```\n\n5. 使用数据分区。通过分区可以存储更多的数据、优化查询更大的吞吐量、可以快速删除过期的数据。关于这个知识点可以看看MySQL的[官方文档](https://dev.mysql.com/doc/refman/5.7/en/partitioning-overview.html)。\n\n   - RANGE分区：基于连续区间范围，把数据分配到不同的分区。\n   - LIST分区：基于枚举值的范围，把数据分配到不同的分区。\n   - HASH分区 / KEY分区：基于分区个数，把数据分配到不同的分区。\n\n   ```SQL\n   CREATE TABLE tb_emp (\n       eno INT NOT NULL,\n       ename VARCHAR(20) NOT NULL,\n       job VARCHAR(10) NOT NULL,\n       hiredate DATE NOT NULL,\n       dno INT NOT NULL\n   )\n   PARTITION BY HASH(dno)\n   PARTITIONS 4;\n   ```\n\n   ```SQL\n   CREATE TABLE tb_emp (\n       eno INT NOT NULL,\n       ename VARCHAR(20) NOT NULL,\n       job VARCHAR(10) NOT NULL,\n       hiredate DATE NOT NULL,\n       dno INT NOT NULL\n   )\n   PARTITION BY RANGE( YEAR(hiredate) ) (\n       PARTITION p0 VALUES LESS THAN (1960),\n       PARTITION p1 VALUES LESS THAN (1970),\n       PARTITION p2 VALUES LESS THAN (1980),\n       PARTITION p3 VALUES LESS THAN (1990),\n       PARTITION p4 VALUES LESS THAN MAXVALUE\n   );\n   ```\n\n6. 使用`explain`来分析查询性能 - 执行计划。\n\n   ```SQL\n   explain select * from ...;\n   ```\n\n   `explain`结果解析：\n\n   - select_type：表示select操作的类型，常见的值有SIMPLE（简单查询，没有使用子查询或者表连接查询）、PRIMARY（主查询，外层的查询）、UNION（并集操作中的第二个或者后面的查询）、SUBQUERY（子查询中的第一个SELECT）等。\n   - table：输出结果的表。\n   - type：MySQL在表中找到所需行的方式，也称为访问类型，常见的值有：\n     - ALL：全表扫描（遍历全表找到匹配的行）\n     - index：索引全扫描（遍历整个索引）\n     - range：索引范围扫描\n     - ref：非唯一索引扫描或唯一索引的前缀扫描\n     - eq_ref：唯一索引扫描\n     - const / system：表中最多有一行匹配\n     - NULL：不用访问表或者索引\n   - possible_keys：查询时可能用到的索引。\n   - key：实际使用的索引。\n   - key_len：使用到索引字段的长度。\n   - rows：扫描行的数量。\n   - Extra：额外的信息（执行情况的说明或描述）。\n\n   > 说明：关于MySQL更多的知识尤其是性能调优和运维方面的内容，推荐大家阅读网易出品的《深入浅出MySQL（第2版）》，网易出品必属精品。\n\n7. 使用慢查询日志来发现性能低下的查询。\n\n   ```SQL\n   mysql> show variables like 'slow_query%';\n   +---------------------------+----------------------------------+\n   | Variable_name             | Value                            |\n   +---------------------------+----------------------------------+\n   | slow_query_log            | OFF                              |\n   | slow_query_log_file       | /mysql/data/localhost-slow.log   |\n   +---------------------------+----------------------------------+\n   \n   mysql> show variables like 'long_query_time';\n   +-----------------+-----------+\n   | Variable_name   | Value     |\n   +-----------------+-----------+\n   | long_query_time | 10.000000 |\n   +-----------------+-----------+\n   ```\n\n   ```SQL\n   mysql> set global slow_query_log='ON'; \n   mysql> set global long_query_time=1;\n   ```\n\n   ```INI\n   [mysqld]\n   slow_query_log=ON\n   slow_query_log_file=/usr/local/mysql/data/slow.log\n   long_query_time=1\n   ```\n\n", "软件测试和自动化测试": "##  软件测试和自动化测试\n\n### 软件测试概述\n\n软件测试是一种用来促进鉴定软件的正确性、完整性、安全性和品质的过程，也就是在规定的条件下对程序进行操作以发现程序中的错误，衡量软件的品质并对其是否能满足设计要求进行评估的过程。\n\n#### 测试的方法\n\n黑盒测试：测试应用程序的功能，而不是其内部结构或运作。测试者不需具备应用程序的代码、内部结构和编程语言的专门知识。测试者只需知道什么是系统应该做的事，即当键入一个特定的输入，可得到一定的输出。测试案例是依应用系统应该做的功能，照规范、规格或要求等设计。测试者选择有效输入和无效输入来验证是否正确的输出。此测试方法可适合大部分的软件测试，例如集成测试和系统测试。\n\n白盒测试：测试应用程序的内部结构或运作，而不是测试应用程序的功能（即黑箱测试）。在白箱测试时，以编程语言的角度来设计测试案例。测试者输入数据验证数据流在程序中的流动路径，并确定适当的输出，类似测试电路中的节点。\n\n由于时间和成本的约束，软件测试中一个最为关键的问题就是：“**在所有可能的测试用例中，哪个子集能发现最多的错误？**”。所以在设计测试用例时，白盒测试看重程序逻辑覆盖的程度（语句覆盖、条件覆盖、分支覆盖），黑盒测试可以使用等价类划分、边界值分析、因果图分析、错误猜测等方法来设计测试用例。\n\n#### 测试的种类（阶段）\n\n单元测试：对软件组成单元进行测试，其目的是检验软件基本组成单位的正确性，测试的对象是软件设计的最小单位 - 函数。\n\n集成测试：将程序模块采用适当的集成策略组装起来，对系统的接口及集成后的功能进行正确性检测的测试工作。其主要目的是检查软件单位之间的接口是否正确，集成测试的对象是已经经过单元测试的模块。\n\n系统测试：系统测试主要包括功能测试、界面测试、可靠性测试、易用性测试、性能测试。 \n\n回归测试：为了检测代码修改而引入的错误所进行的测试活动。回归测试是软件维护阶段的重要工作，有研究表明，回归测试带来的耗费占软件生命周期的1/3总费用以上。\n\n#### 测试驱动开发（敏捷测试）\n\n测试驱动开发包括以下三个步骤：\n\n1. 为未实现的新功能或者改进编写自动化测试。\n2. 提供通过所有定义的测试的最小代码量。\n3. 重构代码以满足所需的质量标准。\n\n测试驱动开发的好处在于可以有效的防止软件回归以及提供更有质量的代码。还有就是验收测试应该由客户来进行，客户通过对使用场景来设计验收测试，对应用程序是否满足他们的要求进行客观、公正的确认。能够通过单元测试、甚至是系统测试的功能未必能够通过客户的验收测试。\n\n#### 互联网应用和移动应用的测试\n\n互联网应用的测试策略：\n\n1. 表示层测试（内容测试、站点结构测试、用户环境（浏览器、操作系统等））\n2. 业务层测试（性能、数据验证、事务、外部服务）\n3. 持久层测试（响应时间、数据完整性、容错性）\n\n移动应用的测试策略：\n\n1. 真机测试\n2. 基于模拟器的测试\n\n### 单元（模块）测试\n\nPython的标准库里有为编写单元测试而准备的unittest模块，执行测试时建议使用[pytest](https://docs.pytest.org/en/latest/)或nose2。pytest是一款能够自动搜索并执行测试的测试执行工具，并且会输出详细的错误报告。关于单元测试可以看看[《Python必会的单元测试框架 - unittest》](https://blog.csdn.net/huilan_same/article/details/52944782)。\n\n\n\n可以安装[testfixtures](https://pypi.org/project/testfixtures/)库来辅助单元测试，它整合了多种典型配置器，提供了生成目录、更改系统日期、生成mock对象的功能模块，这些模块能够帮助我们将单元测试与单元测试所依赖的环境分离开。[mock](https://pypi.org/project/mock/) 是将测试对象所依赖的对象替换为虚拟对象的库，在测试的时候，我们可以为虚拟对象指定其在被调用时的返回值以及是否发生异常等。\n\ntox能便捷地为我们准备好执行测试所需的环境。tox会在多个virtualenv环境中搭建测试 环境，然后在这些环境中执行测试并显示结果。它能够把测试工具的选项及环境变量等内容统 一起来，所以我们只需执行tox命令即能轻松完成所需的测试。 \n\n### 自动化测试\n\n#### UI自动化测试\n\n##### 桌面端 - [PyAutoGui](<https://pyautogui.readthedocs.io/en/latest/>)\n\n\n\n##### 移动端 - [Appnium](<http://appium.io/>)\n\n\n\n##### Web端 - [Selenium](<https://docs.seleniumhq.org/>)\n\nSelenium是实现Web应用程序的功能测试以及集成测试自动化的浏览器驱动测试工具群。和使用浏览器的用户相同，Selenium可以在浏览器进行的鼠标操作、在表单中输入文字、验证表单的值等，利用这一点就可以将手动操作变成自动化操作。\n\n1. Selenium优点\n\n  - 自动化测试用例制作简单。Selenium提供了Selenium IDE工具，该工具可以捕获鼠标、键盘的操作，然后通过重放功能来重复这些操作，这样就可以简单的制作测试用例。\n  - 支持多种浏览器和操作系统。\n\n2. Selenium的组件\n\n  - [Selenium IDE](https://www.seleniumhq.org/projects/ide/)\n  - [Selenium Remote Control](https://www.seleniumhq.org/projects/remote-control/)\n  - [Selenium WebDriver](https://www.seleniumhq.org/projects/webdriver/)\n\n3. 与持续集成工具协作\n\n   持续集成指的是频繁的将代码集成到主干。它的好处主要有两个：\n\n   - 快速发现错误。每完成一点更新，就集成到主干，可以快速发现错误，定位错误也比较容易。\n   - 防止分支大幅偏离主干。如果不是经常集成，主干又在不断更新，会导致以后集成的难度变大，甚至难以集成。\n\n   持续集成的目的，就是让产品可以快速迭代，同时还能保持高质量。它的核心措施是代码集成到主干之前，必须通过自动化测试，只要有一个测试用例失败，就不能集成。编程大师Martin Fowler曾经说过：“持续集成并不能消除Bug，而是让它们非常容易发现和改正。”\n\n   可以在Jenkins中安装“Seleniumhq Plugin”插件，这样就可以将Selenium IDE制作的测试用例保存为HTML格式并提供给Jenkins来使用，基本步骤是：\n\n   - 在执行测试的机器上，从版本控制系统中下载测试套件和测试用例。\n\n   - 在执行测试的机器上下载Selenium Server。\n\n   - 从Jenkins的“系统管理”中选择“插件管理”来安装“Seleniumhq Plugin”。\n\n   - 在Jenkins的“系统管理”中选择“系统设置”并配置“Selenium Remote Control”下的“HTMLSuite Runner”。\n\n   - 新建测试用的Jenkins任务并进行配置，配置的内容包括：浏览器、起始URL、测试套件和测试结果输出文件。\n\n   配置完成后，就可以执行Jenkins的“立即构建”了。  \n\n除了Selenium之外，[WebTest](https://pypi.org/project/WebTest/)、[Splinter](<https://splinter.readthedocs.io/en/latest/>)和[RobotFramework](<https://robotframework.org/>)也是Web端测试的选择，其中WebTest可以对WSGI应用执行模拟请求并获取结果，基本上所有WSGI应用的测试都可以用它；Splinter是对Selenium的二次封装，使用上更加方便简单。\n\n#### 接口测试自动化测试\n\n1. [requests](<https://cn.python-requests.org/zh_CN/latest/>)\n2. [HttpRunner](<https://docs.httprunner.org/>)\n3. [PyRestTest](<https://github.com/svanoort/pyresttest>)\n\n#### 其他方面的自动化测试\n\n1. [Locust](<https://www.locust.io/>)\n\n2. [pythem](<https://github.com/m4n3dw0lf/PytheM>)\n\n### 测试相关工具\n\n1. PostMan\n2. AB\n3. JMeter\n4. LoadRunner\n5. Benchmark Factory\n6. WAS\n\n\n", "电商网站技术要点剖析": "## 电商网站技术要点剖析\n\n### 商业模式\n\n1. B2B - 商家对商家，交易双方都是企业（商家），最典型的案例就是阿里巴巴。\n2. C2C - 个人对个人，例如：淘宝、人人车。\n3. B2C - 商家对个人，例如：唯品会，聚美优品。\n4. C2B - 个人对商家，先有消费者提出需求，后有商家按需求组织生产，例如： 尚品宅配。\n5. O2O - 线上到线下，将线下的商务机会与互联网结合，让互联网成为线下交易的平台，例如：美团外卖、饿了么。\n6. B2B2C - 商家对商家对个人，例如：天猫、京东。\n\n### 需求要点\n\n1. 用户端\n   - 首页（商品分类、广告轮播、滚动快讯、瀑布加载、推荐、折扣、热销、……）\n\n   - 用户（登录（第三方登录）、注册、注销、自服务（个人信息、浏览历史、收货地址、……））\n\n   - 商品（分类、列表、详情、搜索、热门搜索、搜索历史、添加到购物车、收藏、关注、评论、……）\n   - 购物车（查看、编辑（修改数量、删除商品、清空））\n   - 订单（提交订单（支付）、历史订单、订单详情、订单评价、……）\n2. 管理端\n   - 核心业务实体的CRUD\n   - 定时任务（周期性和非周期性，如处理未支付订单、采集数据对异常事件报警、……）\n   - 报表功能（导入导出Excel、PDF等以及前端ECharts统计图表展示）\n   - 权限控制（RBAC、白名单、黑名单、……）\n   - 业务流转（如发起退款流程，常用流程引擎有：Activity、Airflow、Spiff等）\n   - 三方服务（接入地图、短信、物流、支付、实名认证、天气、监控、云存储、……）\n\n### 物理模型设计\n\n首先要搞清楚两个概念：SPU（Standard Product Unit）和SKU（Stock Keeping Unit）。\n\n- SPU：iPhone 6s\n- SKU：iPhone 6s 64G 土豪金\n\n![](./res/shopping-pdm.png)\n\n### 第三方登录\n\n第三方登录是指利用第三方网站（通常是知名社交网站）的账号进行登录验证（主要是通过知名第三方网站获取到用户相关信息），比如国内的 QQ、微博，国外的Google、Facebook等。第三方登录大部分都是使用[OAuth](<https://en.wikipedia.org/wiki/OAuth>)协议，它是一个关于授权的开放网络标准（**数据的所有者告诉系统，同意授权第三方应用进入系统，获取这些数据。系统从而产生一个短期的进入令牌，用来代替密码，供第三方应用使用**），得到了广泛的应用，目前通常使用的是2.0版本。关于OAuth的基础知识，可以阅读阮一峰老师的[《理解OAuth 2.0》](http://www.ruanyifeng.com/blog/2014/05/oauth_2_0.html)。关于**令牌**和**密码**的区别，我们可以简单总结出以下三点差异：\n\n1. 令牌是短期的，到期会自动失效，用户自己无法修改。密码一般长期有效，用户不修改，就不会发生变化。\n2. 令牌可以被数据所有者撤销，会立即失效。以上例而言，屋主可以随时取消快递员的令牌。密码一般不允许被他人撤销。\n3. 令牌有权限范围（scope），比如只能进小区的二号门。对于网络服务来说，只读令牌就比读写令牌更安全。密码一般是完整权限。\n\n所以，通过令牌既可以让第三方应用获得权限，同时又随时可控，不会危及系统安全。这就是OAuth协议的优势。\n\n#### OAuth 2.0授权流程\n\n1. 用户打开客户端以后，客户端要求用户（资源所有者）给予授权。\n2. 用户（资源所有者）同意给予客户端授权。\n3. 客户端使用上一步获得的授权，向认证服务器申请访问令牌。\n4. 认证服务器对客户端进行认证以后，发放访问令牌。\n5. 客户端使用访问令牌向资源服务器申请获取资源。\n6. 资源服务器确认访问令牌无误，同意向客户端开放资源。\n\n![](./res/oauth2.png)\n\n如果使用微博登录进行接入，其具体步骤可以参考微博开放平台上的[“微博登录接入”](http://open.weibo.com/wiki/Connect/login)文档。使用QQ登录进行接入，需要首先注册成为QQ互联开发者并通过审核，具体的步骤可以参考QQ互联上的[“接入指南”](http://wiki.connect.qq.com/)，具体的步骤可以参考[“网站开发流程”](http://wiki.connect.qq.com/%E5%87%86%E5%A4%87%E5%B7%A5%E4%BD%9C_oauth2-0)。\n\n> 提示：在Gitbook上面有一本名为[《Django博客入门》](https://shenxgan.gitbooks.io/django/content/publish/2015-08-10-django-oauth-login.html)的书以Github为例介绍了第三方账号登录，有兴趣的可以自行阅读。\n\n通常电商网站在使用第三方登录时，会要求与网站账号进行绑定或者根据获取到的第三方账号信息（如：手机号）自动完成账号绑定。\n\n### 缓存预热和查询缓存\n\n#### 缓存预热\n\n所谓缓存预热，是指在启动服务器时将数据提前加载到缓存中，为此可以在Django应用的`apps.py`模块中编写`AppConfig`的子类并重写`ready()`方法，代码如下所示。\n\n```Python\nimport pymysql\n\nfrom django.apps import AppConfig\nfrom django.core.cache import cache\n\nSELECT_PROVINCE_SQL = 'select distid, name from tb_district where pid is null'\n\n\nclass CommonConfig(AppConfig):\n    name = 'common'\n\n    def ready(self):\n        conn = pymysql.connect(host='1.2.3.4', port=3306,\n                               user='root', password='pass',\n                               database='db', charset='utf8',\n                               cursorclass=pymysql.cursors.DictCursor)\n        try:\n            with conn.cursor() as cursor:\n                cursor.execute(SELECT_PROVINCE_SQL)\n                provinces = cursor.fetchall()\n                cache.set('provinces', provinces)\n        finally:\n            conn.close()\n```\n\n接下来，还需要在应用的`__init__.py`中编写下面的代码。\n\n```Python\ndefault_app_config = 'common.apps.CommonConfig'\n```\n\n或者在项目的`settings.py`文件中注册应用。\n\n```Python\nINSTALLED_APPS = [\n    ...\n    'common.apps.CommonConfig',\n    ...\n]\n```\n\n#### 查询缓存\n\n自定义装饰器实现查询结果的缓存。\n\n```Python\nfrom pickle import dumps, loads\n\nfrom django.core.cache import caches\n\nMODEL_CACHE_KEY = 'project:modelcache:%s'\n\n\ndef my_model_cache(key, section='default', timeout=None):\n    \"\"\"实现模型缓存的装饰器\"\"\"\n\n    def wrapper1(func):\n\n        def wrapper2(*args, **kwargs):\n            real_key = '%s:%s' % (MODEL_CACHE_KEY % key, ':'.join(map(str, args)))\n            serialized_data = caches[section].get(real_key)\n            if serialized_data:\n                data = loads(serialized_data)\n            else:\n                data = func(*args, **kwargs)\n                cache.set(real_key, dumps(data), timeout=timeout)\n            return data\n\n        return wrapper2\n\n    return wrapper1\n```\n\n```Python\n@my_model_cache(key='provinces')\ndef get_all_provinces():\n    return list(Province.objects.all())\n```\n\n### 购物车实现\n\n问题一：已登录用户的购物车放在哪里？未登录用户的购物车放在哪里？\n\n```Python\nclass CartItem(object):\n    \"\"\"购物车中的商品项\"\"\"\n\n    def __init__(self, sku, amount=1, selected=False):\n        self.sku = sku\n        self.amount = amount\n        self.selected = selected\n\n    @property\n    def total(self):\n        return self.sku.price * self.amount\n\n\nclass ShoppingCart(object):\n    \"\"\"购物车\"\"\"\n\n    def __init__(self):\n        self.items = {}\n        self.index = 0\n\n    def add_item(self, item):\n        if item.sku.id in self.items:\n            self.items[item.sku.id].amount += item.amount\n        else:\n            self.items[item.sku.id] = item\n\n    def remove_item(self, sku_id):\n        if sku_id in self.items:\n            self.items.remove(sku_id)\n\n    def clear_all_items(self):\n        self.items.clear()\n\n    @property\n    def cart_items(self):\n        return self.items.values()\n\n    @property\n    def cart_total(self):\n        total = 0\n        for item in self.items.values():\n            total += item.total\n        return total\n```\n\n已登录用户的购物车可以放在数据库中（可以先在Redis中缓存）；未登录用户的购物车可以保存在Cookie、localStorage或sessionStorage中（减少服务器端内存开销）。\n\n```JSON\n{\n    '1001': {sku: {...}, 'amount': 1, 'selected': True}, \n    '1002': {sku: {...}, 'amount': 2, 'selected': False},\n    '1003': {sku: {...}, 'amount': 3, 'selected': True},\n}\n```\n\n```Python\nrequest.get_signed_cookie('cart')\n\ncart_base64 = base64.base64encode(pickle.dumps(cart))\nresponse.set_signed_cookie('cart', cart_base64)\n```\n\n问题二：用户登录之后，如何合并购物车？（目前电商应用的购物车几乎都做了持久化处理，主要是方便在多个终端之间共享数据）\n\n### 集成支付功能\n\n问题一：支付信息如何持久化？（必须保证每笔交易都有记录）\n\n问题二：如何接入支付宝？（接入其他平台基本类似）\n\n1. [蚂蚁金服开放平台](https://open.alipay.com/platform/home.htm)。\n2. [入驻平台](https://open.alipay.com/platform/homeRoleSelection.htm)。\n3. [开发者中心](https://openhome.alipay.com/platform/appManage.htm#/apps)。\n4. [文档中心](https://docs.open.alipay.com/270/105899/)。\n5. [SDK集成](https://docs.open.alipay.com/54/103419) - [PYPI链接](https://pypi.org/project/alipay-sdk-python/)。\n6. [API列表](https://docs.open.alipay.com/270/105900/)。\n\n![](./res/alipay_web_developer.png)\n\n配置文件：\n\n```Python\nALIPAY_APPID = '......'\nALIPAY_URL = 'https://openapi.alipaydev.com/gateway.do'\nALIPAY_DEBUG = False\n```\n\n获得支付链接（发起支付）：\n\n```Python\n# 创建调用支付宝的对象\nalipay = AliPay(\n    # 在线创建应用时分配的ID\n    appid=settings.ALIPAY_APPID,\n    app_notify_url=None,\n    # 自己应用的私钥\n    app_private_key_path=os.path.join(\n        os.path.dirname(os.path.abspath(__file__)), \n        'keys/app_private_key.pem'),\n    # 支付宝的公钥\n    alipay_public_key_path=os.path.join(\n        os.path.dirname(os.path.abspath(__file__)), \n        'keys/alipay_public_key.pem'),\n    sign_type='RSA2',\n    debug=settings.ALIPAY_DEBUG\n)\n# 调用获取支付页面操作\norder_info = alipay.api_alipay_trade_page_pay(\n    out_trade_no='...',\n    total_amount='...',\n    subject='...',\n    return_url='http://...'\n)\n# 生成完整的支付页面URL\nalipay_url = settings.ALIPAY_URL + '?' + order_info\nreturn JsonResponse({'alipay_url': alipay_url})\n```\n\n通过上面返回的链接可以进入支付页面，支付完成后会自动跳转回上面代码中设定好的项目页面，在该页面中可以获得订单号（out_trade_no）、支付流水号（trade_no）、交易金额（total_amount）和对应的签名（sign）并请求后端验证和保存交易结果，代码如下所示：\n\n```Python\n# 创建调用支付宝的对象\nalipay = AliPay(\n    # 在线创建应用时分配的ID\n    appid=settings.ALIPAY_APPID,\n    app_notify_url=None,\n    # 自己应用的私钥\n    app_private_key_path=os.path.join(\n        os.path.dirname(os.path.abspath(__file__)), \n        'keys/app_private_key.pem'),\n    # 支付宝的公钥\n    alipay_public_key_path=os.path.join(\n        os.path.dirname(os.path.abspath(__file__)), \n        'keys/alipay_public_key.pem'),\n    sign_type='RSA2',\n    debug=settings.ALIPAY_DEBUG\n)\n# 请求参数（假设是POST请求）中包括订单号、支付流水号、交易金额和签名\nparams = request.POST.dict()\n# 调用验证操作\nif alipay.verify(params, params.pop('sign')):\n    # 对交易进行持久化操作\n```\n\n支付宝的支付API还提供了交易查询、交易结算、退款、退款查询等一系列的接口，可以根据业务需要进行调用，此处不再进行赘述。\n\n### 秒杀和超卖\n\n1. 秒杀：秒杀是通常意味着要在很短的时间处理极高的并发，系统在短时间需要承受平时百倍以上的流量，因此秒杀架构是一个比较复杂的问题，其核心思路是流量控制和性能优化，需要从前端（通过JavaScript实现倒计时、避免重复提交和限制频繁刷新）到后台各个环节的配合。流量控制主要是限制只有少部分流量进入服务后端（毕竟最终只有少部分用户能够秒杀成功），同时在物理架构上使用缓存（一方面是因为读操作多写操作少；另外可以将库存放在Redis中，利用DECR原语实现减库存；同时也可以利用Redis来进行限流，道理跟限制频繁发送手机验证码是一样的）和消息队列（消息队列最为重要的作用就是“削峰”和“上下游节点解耦合”）来进行优化；此外还要采用无状态服务设计，这样才便于进行水平扩展（通过增加设备来为系统扩容）。\n2. 超卖现象：比如某商品的库存为1，此时用户1和用户2并发购买该商品，用户1提交订单后该商品的库存被修改为0，而此时用户2并不知道的情况下提交订单，该商品的库存再次被修改为-1这就是超卖现象。解决超卖现象有三种常见的思路：\n   - 悲观锁控制：查询商品数量的时候就用`select ... for update`对数据加锁，这样的话用户1查询库存时，用户2因无法读取库存数量被阻塞，直到用户1提交或者回滚了更新库存的操作后才能继续，从而解决了超卖问题。但是这种做法对并发访问量很高的商品来说性能太过糟糕，实际开发中可以在库存小于某个值时才考虑加锁，但是总的来说这种做法不太可取。\n   - 乐观锁控制：查询商品数量不用加锁，更新库存的时候设定商品数量必须与之前查询数量相同才能更新，否则说明其他事务已经更新了库存，必须重新发出请求。\n   - 尝试减库存：将上面的查询（`select`）和更新（`update`）操作合并为一条SQL操作，更新库存的时候，在`where`筛选条件中加上`库存>=购买数量`或`库存-购买数量>=0`的条件，这种做法要求事务隔离级别为读提交（read committed）。\n\n> 提示：有兴趣的可以自己在知乎上看看关于这类问题的讨论。\n\n### 静态资源管理\n\n静态资源的管理可以自己架设文件服务器或者分布式文件服务器（FastDFS），但是一般的项目中没有必要这样做而且效果未必是最好的，我们建议使用云存储服务来管理网站的静态资源，国内外的云服务提供商如[亚马逊](<https://amazonaws-china.com/cn/>)、[阿里云](<https://www.aliyun.com/product/oss>)、[七牛](<https://www.qiniu.com/products/kodo>)、[LeanCloud](<https://leancloud.cn/storage/>)、[Bmob](<https://www.bmob.cn/cloud>)等都提供了非常优质的云存储服务，而且价格也是一般公司可以接受的，具体的操作可以参考官方文档，例如：阿里云的[对象存储 OSS开发人员指南](https://www.alibabacloud.com/zh/support/developer-resources)。\n\n### 全文检索\n\n####  方案选择\n\n1. 使用数据库的模糊查询功能 - 效率低，每次需要全表扫描，不支持分词。\n2. 使用数据库的全文检索功能 - MySQL 5.6以前只适用于MyISAM引擎，检索操作和其他的DML操作耦合在数据库中，可能导致检索操作非常缓慢，数据量达到百万级性能显著下降，查询时间很长。\n3. 使用开源搜索引擎 - 索引数据和原始数据分离，可以使用ElasticSearch或Solr来提供外置索引服务，如果不考虑高并发的全文检索需求，纯Python的Whoosh也可以考虑。\n\n#### ElasticSearch\n\nElasticSearch既是一个分布式文档数据库又是一个高可扩展的开源全文搜索和分析引擎，它允许存储、搜索和分析大量的数据，并且这个过程是近实时的。它通常被用作底层引擎和技术，为复杂的搜索功能和要求提供动力，大家熟知的维基百科、Stack-Overflow、Github都使用了ElasticSearch。\n\nElasticSearch的底层是开源搜索引擎[Lucene](https://lucene.apache.org/)，但是直接用Lucene会非常麻烦，必须自己编写代码去调用它的接口而且只支持Java语言。ElasticSearch相当于对Lucene进行了一次全面的封装，提供了REST风格的API接口，通过基于HTTP协议的访问方式屏蔽了编程语言的差异。ElasticSearch会为数据构建[倒排索引](https://zh.wikipedia.org/zh-hans/%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95)，但是ElasticSearch内置的分词器对中文分词的支持几乎为零，因此需要通过安装elasticsearch-analysis-ik插件来提供中文分词服务。\n\nElasticSearch的安装和配置可以参考[《ElasticSearch之Docker安装》](https://blog.csdn.net/jinyidong/article/details/80475320)。除了ElasticSearch之外，也可以使用Solr、Whoosh等来提供搜索引擎服务，基本上Django项目中可以考虑如下几种方案：\n\n- haystack（django-haystack / drf-haystack） + whoosh + Jieba\n- haystack （django-haystack / drf-haystack）+ elasticsearch\n- requests + elasticsearch\n- django-elasticsearch-dsl\n\n####安装和使用ElasticSearch\n\n1. 使用Docker安装ElasticSearch。\n\n   ```Shell\n   docker pull elasticsearch:7.6.0\n   docker run -d -p 9200:9200 -p 9300:9300 -e \"discovery.type=single-node\" -e ES_JAVA_OPTS=\"-Xms512m -Xmx512m\" --name es elasticsearch:7.6.0\n   ```\n\n   > 说明：上面创建容器时通过`-e`参数指定了使用单机模式和Java虚拟机最小最大可用堆空间的大小，堆空间大小可以根据服务器实际能够提供给ElasticSearch的内存大小来决定，默认为2G。\n\n2. 创建数据库。\n\n   请求：PUT - `http://1.2.3.4:9200/demo/`\n\n   响应：\n\n    ```JSON\n   {\n       \"acknowledged\": true,\n       \"shards_acknowledged\": true,\n       \"index\": \"demo\"\n   }\n    ```\n\n3. 查看创建的数据库。\n\n   请求：GET - `http://1.2.3.4:9200/demo/`\n\n   响应：\n\n   ```JSON\n   {\n       \"demo\": {\n           \"aliases\": {},\n           \"mappings\": {},\n           \"settings\": {\n               \"index\": {\n                   \"creation_date\": \"1552213970199\",\n                   \"number_of_shards\": \"5\",\n                   \"number_of_replicas\": \"1\",\n                   \"uuid\": \"ny3rCn10SAmCsqW6xPP1gw\",\n                   \"version\": {\n                       \"created\": \"6050399\"\n                   },\n                   \"provided_name\": \"demo\"\n               }\n           }\n       }\n   }\n   ```\n\n4. 插入数据。\n\n   请求：POST - `http://1.2.3.4:9200/demo/goods/1/`\n\n   请求头：Content-Type: application/json\n\n   参数：\n\n   ```JSON\n   {\n       \"no\": \"5089253\",\n       \"title\": \"Apple iPhone X (A1865) 64GB 深空灰色 移动联通电信4G手机\",\n       \"brand\": \"Apple\",\n       \"name\": \"Apple iPhone X\",\n       \"product\": \"中国大陆\",\n       \"resolution\": \"2436 x 1125\",\n       \"intro\": \"一直以来，Apple都心存一个设想，期待能够打造出这样一部iPhone：它有整面屏幕，能让你在使用时，完全沉浸其中，仿佛忘了它的存在。它是如此智能，哪怕轻轻一瞥，都能得到它心有灵犀的回应。而这个设想，终于随着iPhone X的到来成为了现实。现在，就跟未来见个面吧。\"\n   }\n   ```\n\n   响应：\n\n   ```JSON\n   {\n       \"_index\": \"demo\",\n       \"_type\": \"goods\",\n       \"_id\": \"1\",\n       \"_version\": 4,\n       \"result\": \"created\",\n       \"_shards\": {\n           \"total\": 2,\n           \"successful\": 1,\n           \"failed\": 0\n       },\n       \"_seq_no\": 3,\n       \"_primary_term\": 1\n   }\n   ```\n\n5. 删除数据。\n\n   请求：DELETE -  `http://1.2.3.4:9200/demo/goods/1/`\n\n   响应：\n\n   ```JSON\n   {\n       \"_index\": \"demo\",\n       \"_type\": \"goods\",\n       \"_id\": \"1\",\n       \"_version\": 2,\n       \"result\": \"deleted\",\n       \"_shards\": {\n           \"total\": 2,\n           \"successful\": 1,\n           \"failed\": 0\n       },\n       \"_seq_no\": 1,\n       \"_primary_term\": 1\n   }\n   ```\n\n6. 更新数据。\n\n   请求：PUT - `http://1.2.3.4:9200/demo/goods/1/_update`\n\n   请求头：Content-Type: application/json\n\n   参数：\n\n   ```JSON\n   {\n   \t\"doc\": {\n   \t\t\"no\": \"5089253\",\n       \t\"title\": \"Apple iPhone X (A1865) 64GB 深空灰色 移动联通电信4G手机\",\n       \t\"brand\": \"Apple(苹果)\",\n       \t\"name\": \"Apple iPhone X\",\n       \t\"product\": \"美国\",\n       \t\"resolution\": \"2436 x 1125\",\n       \t\"intro\": \"一直以来，Apple都心存一个设想，期待能够打造出这样一部iPhone：它有整面屏幕，能让你在使用时，完全沉浸其中，仿佛忘了它的存在。它是如此智能，哪怕轻轻一瞥，都能得到它心有灵犀的回应。而这个设想，终于随着iPhone X的到来成为了现实。现在，就跟未来见个面吧。\"\n       }\n   }\n   ```\n\n   响应：\n\n   ```JSON\n   {\n       \"_index\": \"demo\",\n       \"_type\": \"goods\",\n       \"_id\": \"1\",\n       \"_version\": 10,\n       \"result\": \"updated\",\n       \"_shards\": {\n           \"total\": 2,\n           \"successful\": 1,\n           \"failed\": 0\n       },\n       \"_seq_no\": 9,\n       \"_primary_term\": 1\n   }\n   ```\n\n7. 查询数据。\n\n   请求：GET - `http://1.2.3.4:9200/demo/goods/1/`\n\n   响应：\n\n   ```JSON\n   {\n       \"_index\": \"demo\",\n       \"_type\": \"goods\",\n       \"_id\": \"1\",\n       \"_version\": 10,\n       \"found\": true,\n       \"_source\": {\n           \"doc\": {\n               \"no\": \"5089253\",\n               \"title\": \"Apple iPhone X (A1865) 64GB 深空灰色 移动联通电信4G手机\",\n               \"brand\": \"Apple(苹果)\",\n               \"name\": \"Apple iPhone X\",\n               \"product\": \"美国\",\n               \"resolution\": \"2436 x 1125\",\n               \"intro\": \"一直以来，Apple都心存一个设想，期待能够打造出这样一部iPhone：它有整面屏幕，能让你在使用时，完全沉浸其中，仿佛忘了它的存在。它是如此智能，哪怕轻轻一瞥，都能得到它心有灵犀的回应。而这个设想，终于随着iPhone X的到来成为了现实。现在，就跟未来见个面吧。\"\n           }\n       }\n   }\n   ```\n\n#### 配置中文分词和拼音插件\n\n1. 进入Docker容器的plugins目录。\n\n   ```Shell\n   docker exec -it es /bin/bash\n   ```\n\n2. 下载和ElasticSearch版本对应的[ik](https://github.com/medcl/elasticsearch-analysis-ik)和[pinyin](https://github.com/medcl/elasticsearch-analysis-pinyin)插件。\n\n   ```Shell\n   yum install -y wget\n   cd plugins/\n   mkdir ik\n   cd ik\n   wget https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v7.6.0/elasticsearch-analysis-ik-7.6.0.zip\n   unzip elasticsearch-analysis-ik-7.6.0.zip\n   rm -f elasticsearch-analysis-ik-7.6.0.zip\n   cd ..\n   mkdir pinyin\n   cd pinyin\n   wget https://github.com/medcl/elasticsearch-analysis-pinyin/releases/download/v7.6.0/elasticsearch-analysis-pinyin-7.6.0.zip\n   unzip elasticsearch-analysis-pinyin-7.6.0.zip\n   rm -f elasticsearch-analysis-pinyin-7.6.0.zip\n   ```\n\n3. 退出容器，重启ElasticSearch。\n\n   ```Shell\n   docker restart es\n   ```\n\n4. 测试中文分词效果。\n\n   请求：POST - `http://1.2.3.4:9200/_analyze`\n\n   请求头：Content-Type: application/json\n\n   参数：\n\n   ```JSON\n   {\n     \"analyzer\": \"ik_smart\",\n     \"text\": \"中国男足在2022年卡塔尔世界杯预选赛中勇夺小组最后一名\"\n   }\n   ```\n\n   响应：\n\n   ```JSON\n   {\n       \"tokens\": [\n           {\n               \"token\": \"中国\",\n               \"start_offset\": 0,\n               \"end_offset\": 2,\n               \"type\": \"CN_WORD\",\n               \"position\": 0\n           },\n           {\n               \"token\": \"男足\",\n               \"start_offset\": 2,\n               \"end_offset\": 4,\n               \"type\": \"CN_WORD\",\n               \"position\": 1\n           },\n           {\n               \"token\": \"在\",\n               \"start_offset\": 4,\n               \"end_offset\": 5,\n               \"type\": \"CN_CHAR\",\n               \"position\": 2\n           },\n           {\n               \"token\": \"2022年\",\n               \"start_offset\": 5,\n               \"end_offset\": 10,\n               \"type\": \"TYPE_CQUAN\",\n               \"position\": 3\n           },\n           {\n               \"token\": \"卡塔尔\",\n               \"start_offset\": 10,\n               \"end_offset\": 13,\n               \"type\": \"CN_WORD\",\n               \"position\": 4\n           },\n           {\n               \"token\": \"世界杯\",\n               \"start_offset\": 13,\n               \"end_offset\": 16,\n               \"type\": \"CN_WORD\",\n               \"position\": 5\n           },\n           {\n               \"token\": \"预选赛\",\n               \"start_offset\": 16,\n               \"end_offset\": 19,\n               \"type\": \"CN_WORD\",\n               \"position\": 6\n           },\n           {\n               \"token\": \"中\",\n               \"start_offset\": 19,\n               \"end_offset\": 20,\n               \"type\": \"CN_CHAR\",\n               \"position\": 7\n           },\n           {\n               \"token\": \"勇夺\",\n               \"start_offset\": 20,\n               \"end_offset\": 22,\n               \"type\": \"CN_WORD\",\n               \"position\": 8\n           },\n           {\n               \"token\": \"小组\",\n               \"start_offset\": 22,\n               \"end_offset\": 24,\n               \"type\": \"CN_WORD\",\n               \"position\": 9\n           },\n           {\n               \"token\": \"最后\",\n               \"start_offset\": 24,\n               \"end_offset\": 26,\n               \"type\": \"CN_WORD\",\n               \"position\": 10\n           },\n           {\n               \"token\": \"一名\",\n               \"start_offset\": 26,\n               \"end_offset\": 28,\n               \"type\": \"CN_WORD\",\n               \"position\": 11\n           }\n       ]\n   }\n   ```\n\n5. 测试拼音分词效果。\n\n   请求：POST - `http://1.2.3.4:9200/_analyze`\n\n   请求头：Content-Type: application/json\n\n   参数：\n\n   ```JSON\n   {\n     \"analyzer\": \"pinyin\",\n     \"text\": \"张学友\"\n   }\n   ```\n\n   响应：\n\n   ```JSON\n   {\n       \"tokens\": [\n           {\n               \"token\": \"zhang\",\n               \"start_offset\": 0,\n               \"end_offset\": 0,\n               \"type\": \"word\",\n               \"position\": 0\n           },\n           {\n               \"token\": \"zxy\",\n               \"start_offset\": 0,\n               \"end_offset\": 0,\n               \"type\": \"word\",\n               \"position\": 0\n           },\n           {\n               \"token\": \"xue\",\n               \"start_offset\": 0,\n               \"end_offset\": 0,\n               \"type\": \"word\",\n               \"position\": 1\n           },\n           {\n               \"token\": \"you\",\n               \"start_offset\": 0,\n               \"end_offset\": 0,\n               \"type\": \"word\",\n               \"position\": 2\n           }\n       ]\n   }\n   ```\n\n#### 全文检索功能\n\n可以通过GET或者POST请求进行搜索，下面演示了搜索有“未来”关键词商品。\n\n1. GET - `http://120.77.222.217:9200/demo/goods/_search?q=未来`\n\n   > 注意：URL中的中文应该要处理成百分号编码。\n\n   ```JSON\n   {\n       \"took\": 19,\n       \"timed_out\": false,\n       \"_shards\": {\n           \"total\": 5,\n           \"successful\": 5,\n           \"skipped\": 0,\n           \"failed\": 0\n       },\n       \"hits\": {\n           \"total\": 2,\n           \"max_score\": 0.73975396,\n           \"hits\": [\n               {\n                   \"_index\": \"demo\",\n                   \"_type\": \"goods\",\n                   \"_id\": \"1\",\n                   \"_score\": 0.73975396,\n                   \"_source\": {\n                       \"doc\": {\n                           \"no\": \"5089253\",\n                           \"title\": \"Apple iPhone X (A1865) 64GB 深空灰色 移动联通电信4G手机\",\n                           \"brand\": \"Apple(苹果)\",\n                           \"name\": \"Apple iPhone X\",\n                           \"product\": \"美国\",\n                           \"resolution\": \"2436*1125\",\n                           \"intro\": \"一直以来，Apple都心存一个设想，期待能够打造出这样一部iPhone：它有整面屏幕，能让你在使用时，完全沉浸其中，仿佛忘了它的存在。它是如此智能，哪怕轻轻一瞥，都能得到它心有灵犀的回应。而这个设想，终于随着iPhone X的到来成为了现实。现在，就跟未来见个面吧。\"\n                       }\n                   }\n               },\n               {\n                   \"_index\": \"demo\",\n                   \"_type\": \"goods\",\n                   \"_id\": \"3\",\n                   \"_score\": 0.68324494,\n                   \"_source\": {\n                       \"no\": \"42417956432\",\n                       \"title\": \"小米9 透明尊享版 手机 透明尊享 全网通(12GB + 256GB)\",\n                       \"brand\": \"小米（MI）\",\n                       \"name\": \"小米（MI）小米9透明\",\n                       \"product\": \"中国大陆\",\n                       \"resolution\": \"2340*1080\",\n                       \"intro\": \"全面透明机身，独特科幻机甲风，来自未来的设计。\"\n                   }\n               }\n           ]\n       }\n   }\n   ```\n\n   URL中可用的搜索参数如下表所示：\n\n   | 参数             | 说明                                              |\n   | ---------------- | ------------------------------------------------- |\n   | q                | 查询字符串                                        |\n   | analyzer         | 分析查询字符串使用的分词器                        |\n   | analyze_wildcard | 通配符或者前缀查询是否被分析，默认为false         |\n   | default_operator | 多个条件之间的关系，默认为OR，可以修改为AND       |\n   | explain          | 在返回的结果中包含评分机制的解释                  |\n   | fields           | 只返回索引中指定的列，多个列中间用逗号隔开        |\n   | sort             | 排序参考的字段，可以用:asc和:desc来指定升序和降序 |\n   | timeout          | 超时时间                                          |\n   | from             | 匹配结果的开始值，默认为0                         |\n   | size             | 匹配结果的条数，默认为10                          |\n\n2. POST - `http://120.77.222.217:9200/demo/goods/_search`\n\n   请求头：Content-Type: application/json\n\n   参数：\n\n   ```JSON\n   {\n       \"query\": {\n           \"term\": {\n               \"type\": \"\"\n           }\n       }\n   }\n   ```\n\n   POST搜索是基于DSL的。\n\n\n#### Django对接ElasticSearch\n\nPython对接ElasticSearch的第三方库是HayStack，在Django项目中可以使用django-haystack，通过HayStack可以在不修改代码对接多种搜索引擎服务。\n\n```shell\npip install django-haystack elasticsearch\n```\n\n配置文件：\n\n```Python\nINSTALLED_APPS = [\n    ...\n    'haystack',\n    ...\n]\n\nHAYSTACK_CONNECTIONS = {\n    'default': {\n        # 引擎配置\n        'ENGINE': 'haystack.backends.elasticsearch_backend.ElasticsearchSearchEngine',\n        # 搜索引擎服务的URL\n        'URL': 'http://1.2.3.4:9200',\n        # 索引库的名称\n        'INDEX_NAME': 'goods',\n    },\n}\n\n# 添加/删除/更新数据时自动生成索引\nHAYSTACK_SIGNAL_PROCESSOR = 'haystack.signals.RealtimeSignalProcessor'\n```\n\n索引类：\n\n```Python\nfrom haystack import indexes\n\n\nclass GoodsIndex(indexes.SearchIndex, indexes.Indexable):\n    text = indexes.CharField(document=True, use_template=True)\n\n    def get_model(self):\n        return Goods\n\n    def index_queryset(self, using=None):\n        return self.get_model().objects.all()\n```\n\n编辑text字段的模板（需要放在templates/search/indexes/demo/goods_text.txt）：\n\n```\n{{object.title}}\n{{object.intro}}\n```\n\n配置URL：\n\n```Python\nurlpatterns = [\n    # ...\n    url('search/', include('haystack.urls')),\n]\n```\n\n生成初始索引：\n\n```Shell\npython manage.py rebuild_index\n```\n\n>  说明：可以参考[《Django Haystack 全文检索与关键词高亮》](https://www.zmrenwu.com/post/45/)一文来更深入的了解基于Haystack的全文检索操作。\n\n", "项目部署上线和性能调优": "## 项目部署上线指南\n\n### 准备上线\n\n1. 上线前的检查工作。\n\n   ```Shell\n   python manage.py check --deploy\n   ```\n\n2. 将DEBUG设置为False并配置ALLOWED_HOSTS。\n\n   ```Python\n   DEBUG = False\n   ALLOWED_HOSTS = ['*']\n   ```\n\n3. 安全相关的配置。\n\n   ```Python\n   # 保持HTTPS连接的时间\n   SECURE_HSTS_SECONDS = 3600\n   SECURE_HSTS_INCLUDE_SUBDOMAINS = True\n   SECURE_HSTS_PRELOAD = True\n   \n   # 自动重定向到安全连接\n   SECURE_SSL_REDIRECT = True\n   \n   # 避免浏览器自作聪明推断内容类型\n   SECURE_CONTENT_TYPE_NOSNIFF = True\n   \n   # 避免跨站脚本攻击\n   SECURE_BROWSER_XSS_FILTER = True\n   \n   # COOKIE只能通过HTTPS进行传输\n   SESSION_COOKIE_SECURE = True\n   CSRF_COOKIE_SECURE = True\n   \n   # 防止点击劫持攻击手段 - 修改HTTP协议响应头\n   # 当前网站是不允许使用<iframe>标签进行加载的\n   X_FRAME_OPTIONS = 'DENY'\n   ```\n\n4. 敏感信息放到环境变量或文件中。\n\n   ```Python\n   SECRET_KEY = os.environ['SECRET_KEY']\n   \n   DB_USER = os.environ['DB_USER']\n   DB_PASS = os.environ['DB_PASS']\n   \n   REDIS_AUTH = os.environ['REDIS_AUTH']\n   ```\n\n### 更新服务器Python环境到3.x\n\n> 说明：如果需要清除之前的安装，就删除对应的文件和文件夹即可\n\n1. 安装底层依赖库。\n\n   ```Shell\n   yum -y install zlib-devel bzip2-devel openssl-devel ncurses-devel sqlite-devel readline-devel tk-devel gdbm-devel libdb4-devel libpcap-devel xz-devel libffi-devel libxml2\n   ```\n\n2. 下载Python源代码。\n\n   ```Shell\n   wget https://www.python.org/ftp/python/3.7.6/Python-3.7.6.tar.xz\n   ```\n\n3. 验证下载文件。\n\n   ```Bash\n   md5sum Python-3.7.6.tar.xz\n   ```\n\n4. 解压缩和解归档。\n\n   ```Shell\n   xz -d Python-3.7.6.tar.xz\n   tar -xvf Python-3.7.6.tar\n   ```\n\n5. 执行安装前的配置（生成Makefile文件）。\n\n   ```Shell\n   cd Python-3.7.6\n   ./configure --prefix=/usr/local/python37 --enable-optimizations\n   ```\n\n6. 构建和安装。\n\n   ```Shell\n   make && make install\n   ```\n\n7. 配置PATH环境变量（用户或系统环境变量）并激活。\n\n   ```Shell\n   vim ~/.bash_profile\n   vim /etc/profile\n   ```\n\n   ```INI\n   ... 此处省略上面的代码...\n   \n   export PATH=$PATH:/usr/local/python37/bin\n   \n   ... 此处省略下面的代码...\n   ```\n\n    ```Shell\n   source ~/.bash_profile\n   source /etc/profile\n    ```\n\n8. 注册软链接（符号链接）- 这一步不是必须的，但通常会比较有用。\n\n   ```Shell\n   ln -s /usr/local/python37/bin/python3 /usr/bin/python3\n   ```\n\n9. 测试Python环境是否更新成功（安装Python 3一定不能破坏原来的Python 2）。\n\n   ```Shell\n   python3 --version\n   python --version\n   ```\n\n### 项目目录结构\n\n假设项目文件夹为`project`，下面的五个子目录分别是：`code`、`conf`、`logs`、`stat`和`venv`分别用来保存项目的代码、配置文件、日志文件、静态资源和虚拟环境。其中，`conf`目录下的子目录`cert`中保存了配置HTTPS需要使用的证书和密钥；`code`目录下的项目代码可以通过版本控制工具从代码仓库中检出；虚拟环境可以通过工具（如：venv、virtualenv、pyenv等）进行创建。\n\n```\nproject\n├── code\n│   └── fangtx\n│       ├── api\n│       ├── common\n│       ├── fangtx\n│       ├── forum\n│       ├── rent\n│       ├── user\n│       ├── manage.py\n│       ├── README.md\n│       ├── static\n│       └── templates\n├── conf\n│   ├── cert\n│   │   ├── 214915882850706.key\n│   │   └── 214915882850706.pem\n│   ├── nginx.conf\n│   └── uwsgi.ini\n├── logs\n│   ├── access.log\n│   ├── error.log\n│   └── uwsgi.log\n├── stat\n│   └── css\n│   └── images\n│   └── js\n└── venv\n    ├── bin\n    │   ├── activate\n    │   ├── activate.csh\n    │   ├── activate.fish\n    │   ├── celery\n    │   ├── celerybeat\n    │   ├── celeryd\n    │   ├── celeryd-multi\n    │   ├── coverage\n    │   ├── coverage3\n    │   ├── coverage-3.7\n    │   ├── django-admin\n    │   ├── django-admin.py\n    │   ├── easy_install\n    │   ├── easy_install-3.7\n    │   ├── pip\n    │   ├── pip3\n    │   ├── pip3.7\n    │   ├── __pycache__\n    │   ├── pyrsa-decrypt\n    │   ├── pyrsa-decrypt-bigfile\n    │   ├── pyrsa-encrypt\n    │   ├── pyrsa-encrypt-bigfile\n    │   ├── pyrsa-keygen\n    │   ├── pyrsa-priv2pub\n    │   ├── pyrsa-sign\n    │   ├── pyrsa-verify\n    │   ├── python -> python3\n    │   ├── python3 -> /usr/bin/python3\n    │   └── uwsgi\n    ├── include\n    ├── lib\n    │   └── python3.7\n    ├── lib64 -> lib\n    ├── pip-selfcheck.json\n    └── pyvenv.cfg\n```\n\n下面以阿里云为例，简单说明如何为项目注册域名、解析域名以及购买权威机构颁发的证书。\n\n1. [注册域名](https://wanwang.aliyun.com/domain/)。\n\n   ![](./res/aliyun-domain.png)\n\n2. [域名备案](https://beian.aliyun.com/)。\n\n   ![](./res/aliyun-keeprecord.png)\n\n3. [域名解析](https://dns.console.aliyun.com/#/dns/domainList)。\n\n   ![](./res/aliyun-dnslist.png)\n\n   ![](./res/aliyun-resolve-settings.png)\n\n4. [购买证书](https://www.aliyun.com/product/cas)。\n\n   ![](./res/aliyun-certificate.png)\n\n可以使用类似于sftp的工具将证书上传到`conf/cert`目录，然后使用git克隆项目代码到`code`目录。\n\n```Shell\ncd code\ngit clone <url>\n```\n\n回到项目目录，创建并激活虚拟环境。\n\n```Shell\npython3 -m venv venv\nsource venv/bin/activate\n```\n\n重建项目依赖项。\n\n```Shell\npip install -r code/teamproject/requirements.txt\n```\n\n### uWSGI的配置\n\n1. 安装uWSGI。\n\n   ```Shell\n   pip install uwsgi\n   ```\n\n2. 修改uWSGI的配置文件（`/root/project/conf/uwsgi.ini`）。\n\n   ```INI\n   [uwsgi]\n   # 配置前导路径\n   base=/root/project\n   # 配置项目名称\n   name=teamproject\n   # 守护进程\n   master=true\n   # 进程个数\n   processes=4\n   # 虚拟环境\n   pythonhome=%(base)/venv\n   # 项目地址\n   chdir=%(base)/code/%(name)\n   # 指定python解释器\n   pythonpath=%(pythonhome)/bin/python\n   # 指定uwsgi文件\n   module=%(name).wsgi\n   # 通信的地址和端口(自己服务器的IP地址和端口)\n   socket=172.18.61.250:8000\n   # 日志文件地址\n   logto=%(base)/logs/uwsgi.log\n   ```\n\n   > 说明：可以先将“通信的地址和端口”项等号前面改为http来进行测试，如果没有问题再改回    成socket，然后通过Nginx来实现项目的“动静分离”（静态资源交给Nginx处理，动态内容交给    uWSGI处理）。按照下面的方式可以启动uWSGI服务器。\n\n5. 启动服务器。\n\n   ```Shell\n   nohup uwsgi --ini conf/uwsgi.ini &\n   ```\n\n### Nginx的配置\n\n1. 安装Nginx。\n\n    ```Shell\n    yum -y install nginx\n    ```\n\n2. 修改全局配置文件（`/etc/nginx/nginx.conf`）。\n\n    ```Nginx\n    # 配置用户\n    user nginx;\n    # 工作进程数(建议跟CPU的核数量一致)\n    worker_processes auto;\n    # 错误日志\n    error_log /var/log/nginx/error.log;\n    # 进程文件\n    pid /run/nginx.pid;\n    # 包含其他的配置\n    include /usr/share/nginx/modules/*.conf;\n    # 工作模式(多路IO复用方式)和连接上限\n    events {\n        use epoll;\n        worker_connections 1024;\n    }\n    # HTTP服务器相关配置\n    http {\n        # 日志格式\n        log_format  main  '$remote_addr - $remote_user [$time_local] \"$request\" '\n                          '$status $body_bytes_sent \"$http_referer\" '\n                          '\"$http_user_agent\" \"$http_x_forwarded_for\"';\n        # 访问日志\n        access_log  /var/log/nginx/access.log  main;\n        # 开启高效文件传输模式\n        sendfile            on;\n        # 用sendfile传输文件时有利于改善性能\n        tcp_nopush          on;\n        # 禁用Nagle来解决交互性问题\n        tcp_nodelay         on;\n        # 客户端保持连接时间\n        keepalive_timeout   30;\n        types_hash_max_size 2048;\n        # 包含MIME类型的配置\n        include             /etc/nginx/mime.types;\n        # 默认使用二进制流格式\n        default_type        application/octet-stream;\n        # 包含其他配置文件\n        include /etc/nginx/conf.d/*.conf;\n        # 包含项目的Nginx配置文件\n        include /root/project/conf/*.conf;\n    }\n    ```\n\n3. 编辑局部配置文件（`/root/project/conf/nginx.conf`）。\n\n    ```Nginx\n    server {\n        listen      80;\n        server_name _;\n        access_log /root/project/logs/access.log;\n        error_log /root/project/logs/error.log;\n        location / {\n            include uwsgi_params;\n            uwsgi_pass 172.18.61.250:8000;\n        }\n        location /static/ {\n            alias /root/project/stat/;\n            expires 30d;\n        }\n    }\n    server {\n        listen      443;\n        server_name _;\n        ssl         on;\n        access_log /root/project/logs/access.log;\n        error_log /root/project/logs/error.log;\n        ssl_certificate     /root/project/conf/cert/214915882850706.pem;\n        ssl_certificate_key /root/project/conf/cert/214915882850706.key;\n        ssl_session_timeout 5m;\n        ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4;\n        ssl_protocols TLSv1 TLSv1.1 TLSv1.2;\n        ssl_prefer_server_ciphers on;\n        location / {\n            include uwsgi_params;\n            uwsgi_pass 172.18.61.250:8000;\n        }\n        location /static/ {\n            alias /root/project/static/;\n            expires 30d;\n        }\n    }\n    ```\n\n    到此为止，我们可以启动Nginx来访问我们的应用程序，HTTP和HTTPS都是没有问题的，如果Nginx已经运行，在修改配置文件后，我们可以用下面的命令重新启动Nginx。\n\n4. 重启Nginx服务器。\n\n    ```Shell\n    nginx -s reload\n    ```\n\n    或\n\n    ```Shell\n    systemctl restart nginx\n    ```\n\n> 说明：可以对Django项目使用`python manage.py collectstatic`命令将静态资源收集到指定目录下，要做到这点只需要在项目的配置文件`settings.py`中添加`STATIC_ROOT`配置即可。\n\n#### 负载均衡配置\n\n下面的配置中我们使用Nginx实现负载均衡，为另外的三个Nginx服务器（通过Docker创建）提供反向代理服务。\n\n```Shell\ndocker run -d -p 801:80 --name nginx1 nginx:latest\ndocker run -d -p 802:80 --name nginx2 nginx:latest\ndocker run -d -p 803:80 --name nginx3 nginx:latest\n```\n\n```Nginx\nuser root;\nworker_processes auto;\nerror_log /var/log/nginx/error.log;\npid /run/nginx.pid;\n\ninclude /usr/share/nginx/modules/*.conf;\n\nevents {\n    worker_connections 1024;\n}\n\n# 为HTTP服务配置负载均衡\nhttp {\n\tupstream xx {\n\t\tserver 192.168.1.100 weight=2;\n\t\tserver 192.168.1.101 weight=1;\n\t\tserver 192.168.1.102 weight=1;\n    }\n\n\tserver {\n\t\tlisten       80 default_server;\n\t\tlisten       [::]:80 default_server;\n\t\tlisten       443 ssl;\n\t\tlisten       [::]:443 ssl;\n\n        ssl on;\n\t\taccess_log /root/project/logs/access.log;\n\t\terror_log /root/project/logs/error.log;\n\t\tssl_certificate /root/project/conf/cert/214915882850706.pem;\n\t\tssl_certificate_key /root/project/conf/cert/214915882850706.key;\n\t\tssl_session_timeout 5m;\n\t\tssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4;\n\t\tssl_protocols TLSv1 TLSv1.1 TLSv1.2;\n\t\tssl_prefer_server_ciphers on;\n\n\t\tlocation / {\n\t\t\tproxy_set_header Host $host;\n\t\t\tproxy_set_header X-Forwarded-For $remote_addr;\n\t\t\t# proxy_set_header X-Real-IP $remote_addr;\n\t\t\t# proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n\t\t\tproxy_buffering off;\n\t\t\tproxy_pass http://fangtx;\n\t\t}\n\t}\n}\n```\n\n> 说明：Nginx在配置负载均衡时，默认使用WRR（加权轮询算法），除此之外还支持ip_hash、fair（需要安装upstream_fair模块）和url_hash算法。此外，在配置upstream模块时可以指定服务器的状态值，包括：backup（备份机器，其他服务器不可用时才将请求分配到该机器）、down、fail_timeout（请求失败达到max_fails后的暂停服务时间）、max_fails（允许请求失败的次数）和weight（轮询的权重）。\n\n### Keepalived\n\n当使用Nginx进行负载均衡配置时，要考虑负载均衡服务器宕机的情况。为此可以使用Keepalived来实现负载均衡主机和备机的热切换，从而保证系统的高可用性。Keepalived的配置还是比较复杂，通常由专门做运维的人进行配置，一个基本的配置可以参照[《Keepalived的配置和使用》](https://www.jianshu.com/p/dd93bc6d45f5)。\n\n### MySQL主从复制\n\n下面还是基于Docker来演示如何配置MySQL主从复制。我们事先准备好MySQL的配置文件以及保存MySQL数据和运行日志的目录，然后通过Docker的数据卷映射来指定容器的配置、数据和日志文件的位置。\n\n```Shell\nroot\n└── mysql\n    ├── master\n    │   ├── conf\n    |\t└── data\n    └── slave-1\n    |\t├── conf\n    |\t└── data\n    └── slave-2\n    |\t├── conf\n    |\t└── data\n    └── slave-3\n    \t├── conf\n    \t└── data\n```\n\n1. MySQL的配置文件（master和slave的配置文件需要不同的server-id）。\n   ```\n   [mysqld]\n   pid-file=/var/run/mysqld/mysqld.pid\n   socket=/var/run/mysqld/mysqld.sock\n   datadir=/var/lib/mysql\n   log-error=/var/log/mysql/error.log\n   server-id=1\n   log-bin=/var/log/mysql/mysql-bin.log\n   expire_logs_days=30\n   max_binlog_size=256M\n   symbolic-links=0\n   # slow_query_log=ON\n   # slow_query_log_file=/var/log/mysql/slow.log\n   # long_query_time=1\n   ```\n\n2. 创建和配置master。\n\n   ```Shell\n   docker run -d -p 3306:3306 --name mysql-master \\\n   -v /root/mysql/master/conf:/etc/mysql/mysql.conf.d \\\n   -v /root/mysql/master/data:/var/lib/mysql \\\n   -e MYSQL_ROOT_PASSWORD=123456 mysql:5.7\n   \n   docker exec -it mysql-master /bin/bash\n   ```\n\n   ```Shell\n   mysql -u root -p\n   Enter password:\n   Welcome to the MySQL monitor.  Commands end with ; or \\g.\n   Your MySQL connection id is 1\n   Server version: 5.7.23-log MySQL Community Server (GPL)\n   Copyright (c) 2000, 2018, Oracle and/or its affiliates. All rights reserved.\n   Oracle is a registered trademark of Oracle Corporation and/or its\n   affiliates. Other names may be trademarks of their respective\n   owners.\n   Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement.\n   \n   mysql> grant replication slave on *.* to 'slave'@'%' identified by 'iamslave';\n   Query OK, 0 rows affected, 1 warning (0.00 sec)\n   \n   mysql> flush privileges;\n   Query OK, 0 rows affected (0.00 sec)\n   \n   mysql> show master status;\n   +------------------+----------+--------------+------------------+-------------------+\n   | File             | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |\n   +------------------+----------+--------------+------------------+-------------------+\n   | mysql-bin.000003 |      590 |              |                  |                   |\n   +------------------+----------+--------------+------------------+-------------------+\n   1 row in set (0.00 sec)\n   \n   mysql> quit\n   Bye\n   exit\n   ```\n\n   上面创建Docker容器时使用的`-v`参数（`--volume`）表示映射数据卷，冒号前是宿主机的目录，冒号后是容器中的目录，这样相当于将宿主机中的目录挂载到了容器中。\n\n3. 备份主表中的数据（如果需要的话）。\n\n   ```SQL\n   mysql> flush table with read lock;\n   ```\n\n   ```Bash\n   mysqldump -u root -p 123456 -A -B > /root/backup/mysql/mybak$(date +\"%Y%m%d%H%M%S\").sql\n   ```\n\n   ```SQL\n   mysql> unlock table;\n   ```\n\n4. 创建和配置slave。\n\n   ```Shell\n   docker run -d -p 3308:3306 --name mysql-slave-1 \\\n   -v /root/mysql/slave-1/conf:/etc/mysql/mysql.conf.d \\\n   -v /root/mysql/slave-1/data:/var/lib/mysql \\\n   -e MYSQL_ROOT_PASSWORD=123456 \\\n   --link mysql-master:mysql-master mysql:5.7\n   \n   docker run -d -p 3309:3306 --name mysql-slave-2 \\\n   -v /root/mysql/slave-2/conf:/etc/mysql/mysql.conf.d \\\n   -v /root/mysql/slave-2/data:/var/lib/mysql \\\n   -e MYSQL_ROOT_PASSWORD=123456 \\\n   --link mysql-master:mysql-master mysql:5.7\n   \n   docker run -d -p 3310:3306 --name mysql-slave-3 \\\n   -v /root/mysql/slave-3/conf:/etc/mysql/mysql.conf.d \\\n   -v /root/mysql/slave-3/data:/var/lib/mysql \\\n   -e MYSQL_ROOT_PASSWORD=123456 \\\n   --link mysql-master:mysql-master mysql:5.7\n   \n   docker exec -it mysql-slave-1 /bin/bash\n   ```\n\n   ```Shell\n   mysql -u root -p\n   Enter password:\n   Welcome to the MySQL monitor.  Commands end with ; or \\g.\n   Your MySQL connection id is 2\n   Server version: 5.7.23-log MySQL Community Server (GPL)\n   Copyright (c) 2000, 2018, Oracle and/or its affiliates. All rights reserved.\n   Oracle is a registered trademark of Oracle Corporation and/or its\n   affiliates. Other names may be trademarks of their respective\n   owners.\n   Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement.\n   \n   mysql> reset slave;\n   Query OK, 0 rows affected (0.02 sec)\n   \n   mysql> change master to master_host='mysql-master', master_user='slave', master_password='iamslave', master_log_file='mysql-bin.000003', master_log_pos=590;\n   Query OK, 0 rows affected, 2 warnings (0.03 sec)\n   \n   mysql> start slave;\n   Query OK, 0 rows affected (0.01 sec)\n   \n   mysql> show slave status\\G\n   *************************** 1. row ***************************\n                  Slave_IO_State: Waiting for master to send event\n                     Master_Host: mysql57\n                     Master_User: slave\n                     Master_Port: 3306\n                   Connect_Retry: 60\n                 Master_Log_File: mysql-bin.000001\n             Read_Master_Log_Pos: 590\n                  Relay_Log_File: f352f05eb9d0-relay-bin.000002\n                   Relay_Log_Pos: 320\n           Relay_Master_Log_File: mysql-bin.000001\n                Slave_IO_Running: Yes\n               Slave_SQL_Running: Yes\n                Replicate_Do_DB:\n             Replicate_Ignore_DB:\n              Replicate_Do_Table:\n          Replicate_Ignore_Table:\n         Replicate_Wild_Do_Table:\n     Replicate_Wild_Ignore_Table:\n                      Last_Errno: 0\n                      Last_Error:\n                    Skip_Counter: 0\n             Exec_Master_Log_Pos: 590\n                 Relay_Log_Space: 534\n                 Until_Condition: None\n                  Until_Log_File:\n                   Until_Log_Pos: 0\n              Master_SSL_Allowed: No\n              Master_SSL_CA_File:\n              Master_SSL_CA_Path:\n                 Master_SSL_Cert:\n               Master_SSL_Cipher:\n                  Master_SSL_Key:\n           Seconds_Behind_Master: 0\n   Master_SSL_Verify_Server_Cert: No\n                   Last_IO_Errno: 0\n                   Last_IO_Error:\n                  Last_SQL_Errno: 0\n                  Last_SQL_Error:\n     Replicate_Ignore_Server_Ids:\n                Master_Server_Id: 1\n                     Master_UUID: 30c38043-ada1-11e8-8fa1-0242ac110002\n                Master_Info_File: /var/lib/mysql/master.info\n                       SQL_Delay: 0\n             SQL_Remaining_Delay: NULL\n         Slave_SQL_Running_State: Slave has read all relay log; waiting for more updates\n              Master_Retry_Count: 86400\n                     Master_Bind:\n         Last_IO_Error_Timestamp:\n        Last_SQL_Error_Timestamp:\n                  Master_SSL_Crl:\n              Master_SSL_Crlpath:\n              Retrieved_Gtid_Set:\n               Executed_Gtid_Set:\n                   Auto_Position: 0\n            Replicate_Rewrite_DB:\n                    Channel_Name:\n              Master_TLS_Version:\n   1 row in set (0.00 sec)\n   \n   mysql> quit\n   Bye\n   exit\n   ```\n\n   接下来可以如法炮制配置出slave2和slave3，这样就可以搭建起一个“一主带三从”的主从复制环境。上面创建创建容器时使用的`--link`参数用来配置容器在网络上的主机名（网络地址别名）。\n\n配置好主从复制后，写数据的操作应该master上执行，而读数据的操作应该在slave上完成。为此，在Django项目中需要配置DATABASE_ROUTERS并通过自定义的主从复制路由类来实现读写分离操作，如下所示：\n\n```Python\nDATABASE_ROUTERS = [\n    # 此处省略其他配置\n    'common.routers.MasterSlaveRouter',\n]\n```\n\n```Python\nclass MasterSlaveRouter(object):\n    \"\"\"主从复制路由\"\"\"\n\n    @staticmethod\n    def db_for_read(model, **hints):\n        \"\"\"\n        Attempts to read auth models go to auth_db.\n        \"\"\"\n        return random.choice(('slave1', 'slave2', 'slave3'))\n\n    @staticmethod\n    def db_for_write(model, **hints):\n        \"\"\"\n        Attempts to write auth models go to auth_db.\n        \"\"\"\n        return 'default'\n\n    @staticmethod\n    def allow_relation(obj1, obj2, **hints):\n        \"\"\"\n        Allow relations if a model in the auth app is involved.\n        \"\"\"\n        return None\n\n    @staticmethod\n    def allow_migrate(db, app_label, model_name=None, **hints):\n        \"\"\"\n        Make sure the auth app only appears in the 'auth_db'\n        database.\n        \"\"\"\n        return True\n```\n\n上面的内容参考了Django官方文档的[DATABASE_ROUTERS配置](https://docs.djangoproject.com/en/2.1/topics/db/multi-db/#topics-db-multi-db-routing)，对代码进行了适当的调整。\n\n### Docker\n\n事实上，项目上线中最为麻烦的事情就是配置软件运行环境，环境的差异会给软件的安装和部署带来诸多的麻烦，而Docker正好可以解决这个问题。关于Docker在之前的文档中我们已经介绍过了，接下来我们对Docker的知识做一些必要的补充。\n\n1. 创建镜像文件。\n\n   将容器保存成镜像：\n\n   ```Shell\n   docker commit -m \"...\" -a \"jackfrued\" <container-name> jackfrued/<image-name>\n   ```\n\n   使用Dockerfile构建镜像：\n\n   ```Dockerfile\n   # 指定基础镜像文件\n   FROM centos:latest\n   \n   # 指定维护者信息\n   MAINTAINER jackfrued\n   \n   # 执行命令\n   RUN yum -y install gcc\n   RUN cd ~\n   RUN mkdir -p project/code\n   RUN mkdir -p project/logs\n   \n   # 拷贝文件\n   COPY ...\n   \n   # 暴露端口\n   EXPOSE ...\n   \n   # 在容器启动时执行命令\n   CMD ~/init.sh\n   ```\n\n   ```Shell\n   docker build -t jackfrued/<image-name> .\n   ```\n\n2. 镜像的导入和导出。\n\n   ```Shell\n   docker save -o <file-name>.tar <image-name>:<version>\n   docker load -i <file-name>.tar\n   ```\n\n3. 推送到DockerHub服务器。\n\n   ```Shell\n   docker tag <image-name>:<version> jackfrued/<name>\n   docker login\n   docker push jackfrued/<name>\n   ```\n\n4. 容器之间的通信。\n\n   ```Shell\n   docker run --link <container-name>:<alias-name>\n   ```\n\n\n如果我们能够在Docker中完成项目的部署，并且将整个部署好的容器打包成镜像文件进行分发和安装，这样就可以解决项目在多个节点上进行部署时可能遇到的麻烦，而且整个部署可以在很短的时间内完成。\n\n### Supervisor\n\n[Supervisor](https://github.com/Supervisor/supervisor)是一个用Python写的进程管理工具，可以很方便的用来在类Unix系统下启动、重启（自动重启程序）和关闭进程，目前Supervisor暂时还没有提供对Python 3的支持，可以通过Python 2来安装和运行Supervisor，再通过Supervisor来管理Python 3的程序。\n\n> **提示**：还有一个和Supervisor功能类似的工具名为Circus，支持Python 3。\n\n1. 安装Supervisor。\n\n   ```Shell\n   virtualenv -p /usr/bin/python venv\n   source venv/bin/activate\n   pip install supervisor\n   ```\n   \n2. 查看Supervisor的配置文件。\n\n    ```Shell\n    vim /etc/supervisord.conf\n    ```\n\n    ```INI\n    ; 此处省略上面的代码\n    ; The [include] section can just contain the \"files\" setting.  This\n    ; setting can list multiple files (separated by whitespace or\n    ; newlines).  It can also contain wildcards.  The filenames are\n    ; interpreted as relative to this file.  Included files *cannot*\n    ; include files themselves.\n    [include]\n    files = supervisord.d/*.ini\n    ```\n\n    可以看出自定义的管理配置代码可以放在`/etc/supervisord.d`目录中，并且文件名以`ini`作为后缀即可。\n\n3. 编写自己的配置文件`fangtx.ini`并放在`/etc/supervisord.d`目录中。\n\n   ```INI\n   [program:project]\n   command=uwsgi --ini /root/project/conf/uwsgi.ini\n   stopsignal=QUIT\n   autostart=true\n   autorestart=true\n   redirect_stderr=true\n   \n   [program:celery]\n   ; Set full path to celery program if using virtualenv\n   command=/root/project/venv/bin/celery -A fangtx worker\n   user=root\n   numprocs=1\n   stdout_logfile=/var/log/supervisor/celery.log\n   stderr_logfile=/var/log/supervisor/celery_error.log\n   autostart=true\n   autorestart=true\n   startsecs=10\n   \n   ; Need to wait for currently executing tasks to finish at shutdown.\n   ; Increase this if you have very long running tasks.\n   ;stopwaitsecs = 600\n   \n   ; When resorting to send SIGKILL to the program to terminate it\n   ; send SIGKILL to its whole process group instead,\n   ; taking care of its children as well.\n   killasgroup=true\n   ; Set Celery priority higher than default (999)\n   ; so, if rabbitmq is supervised, it will start first.\n   priority=1000\n   ```\n\n4. 启动Supervisor。\n\n   ```Shell\n   supervisorctl -c /etc/supervisord.conf\n   ```\n\n\n### 其他服务\n\n1. 常用开源软件。\n\n   | 功能                | 开源方案                        |\n   | ------------------- | ------------------------------- |\n   | 版本控制工具        | Git、Mercurial、SVN             |\n   | 缺陷管理            | Redmine、Mantis                 |\n   | 负载均衡            | Nginx、LVS、HAProxy             |\n   | 邮件服务            | Postfix、Sendmail               |\n   | HTTP服务            | Nginx、Apache                   |\n   | 消息队列            | RabbitMQ、ZeroMQ、Redis、Kafka  |\n   | 文件系统            | FastDFS                         |\n   | 基于位置服务（LBS） | MongoDB、Redis                  |\n   | 监控服务            | Nagios、Zabbix                  |\n   | 关系型数据库        | MySQL、PostgreSQL               |\n   | 非关系型数据库      | MongoDB、Redis、Cassandra、TiDB |\n   | 搜索引擎            | ElasticSearch、Solr             |\n   | 缓存服务            | Mamcached、Redis                |\n\n2. 常用云服务。\n\n   | 功能           | 可用的云服务                           |\n   | -------------- | -------------------------------------- |\n   | 团队协作工具   | Teambition、钉钉                       |\n   | 代码托管平台   | Github、Gitee、CODING                  |\n   | 邮件服务       | SendCloud                              |\n   | 云存储（CDN）  | 七牛、OSS、LeanCloud、Bmob、又拍云、S3 |\n   | 移动端推送     | 极光、友盟、百度                       |\n   | 即时通信       | 环信、融云                             |\n   | 短信服务       | 云片、极光、Luosimao、又拍云           |\n   | 第三方登录     | 友盟、ShareSDK                         |\n   | 网站监控和统计 | 阿里云监控、监控宝、百度云观测、小鸟云 |\n\n", "面试中的公共问题": "## 面试中的公共问题\n\n### 计算机基础\n\n1. TCP/IP模型相关问题。\n\n   > 建议阅读阮一峰的[《互联网协议入门（一）》](http://www.ruanyifeng.com/blog/2012/05/internet_protocol_suite_part_i.html)和[《互联网协议入门（二）》](http://www.ruanyifeng.com/blog/2012/06/internet_protocol_suite_part_ii.html)。\n\n2. HTTP和HTTPS相关问题。\n\n   > 建议阅读阮一峰的[《HTTP 协议入门》](http://www.ruanyifeng.com/blog/2016/08/http.html)和[《SSL/TLS协议运行机制的概述》](http://www.ruanyifeng.com/blog/2014/02/ssl_tls.html)。\n\n3. Linux常用命令和服务。\n\n4. 进程和线程之间的关系。什么时候用多线程？什么时候用多进程？。\n\n5. 关系型数据库相关问题（ACID、事务隔离级别、锁、SQL优化）。\n\n6. 非关系型数据库相关问题（CAP/BASE、应用场景）。\n\n### Python基础\n\n1. 开发中用过哪些标准库和三方库。\n\n   > 标准库：sys / os / re / math / random / logging / json / pickle / shelve / socket / datetime / hashlib / configparser / urllib / itertools / collections / functools / threading / multiprocess / timeit / atexit / abc / asyncio / base64 / concurrent.futures / copy / csv / operator / enum / heapq / http / profile / pstats / ssl / unittest / uuid\n   >\n   > 三方库：openpyxl / xlrd / xlwt / PyPDF2 / ReportLab / PyYAML / jieba / pillow / requests / urllib3 / responses / aiohttp / BeautifulSoup4 / lxml / pyquery / PyMySQL / psycopg2 / redis / PyMongo / Peewee / SQLAlchemy / alipay / PyJWT / itsdangerous / celery / flower / elasticsearch-dsl-py / PyCrypto / Paramiko / logbook / nose / pytest / coverage / Selenium / lineprofiler / memoryprofiler / matplotlib / pygal / OpenCV\n\n2. 装饰器的作用、原理和实现。\n\n3. 使用过哪些魔法方法。\n\n   > 建议阅读[《Python魔术方法指南》](https://pycoders-weekly-chinese.readthedocs.io/en/latest/issue6/a-guide-to-pythons-magic-methods.html)。\n\n4. 生成式、生成器、迭代器的编写。\n\n5. 列表、集合、字典的底层实现。\n\n6. 垃圾回收相关问题。\n\n7. 并发编程的相关问题。\n\n8. 协程和异步I/O相关知识。\n\n### Django和Flask\n\n1. MVC架构（MTV）解决了什么问题。\n\n2. 中间件的执行流程以及如何自定义中间件。\n\n3. REST数据接口如何设计（URL、域名、版本、过滤、状态码、安全性）。\n\n   > 建议阅读阮一峰的[《RESTful API设计指南》](http://www.ruanyifeng.com/blog/2014/05/restful_api.html)。\n\n4. 使用ORM框架实现CRUD操作的相关问题。\n\n   - 如何实现多条件组合查询 / 如何执行原生的SQL / 如何避免N+1查询问题\n\n5. 如何执行异步任务和定时任务。\n\n6. 如何实现页面缓存和查询缓存？缓存如何预热？\n\n### 爬虫相关\n\n1. Scrapy框架的组件和数据处理流程。\n2. 爬取的目的（项目中哪些地方需要用到爬虫的数据）。\n3. 使用的工具（抓包、下载、清理、存储、分析、可视化）。\n4. 数据的来源（能够轻松的列举出10个网站）。\n5. 数据的构成（抓取的某个字段在项目中有什么用）。\n6. 反反爬措施（限速、请求头、Cookie池、代理池、Selenium WebDriver、RoboBrowser、TOR、OCR）。\n7. 数据的体量（最后抓取了多少数据，多少W条数据或多少个G的数据）。\n8. 后期数据处理（持久化、数据补全、归一化、格式化、转存、分类）。\n\n### 数据分析\n\n1. 科学运算函数库（SciPy和NumPy常用运算）。\n2. 数据分析库（Pandas中封装的常用算法）。\n3. 常用的模型及对应的场景（分类、回归、聚类）。\n4. 提取了哪些具体的指标。\n5. 如何评价模型的优劣。\n6. 每种模型实际操作的步骤，对结果如何评价。\n\n### 项目相关\n\n1. 项目团队构成以及自己在团队中扮演的角色（在项目中的职责）。\n2. 项目的业务架构（哪些模块及子模块）和技术架构（移动端、PC端、后端技术栈）。\n3. 软件控制管理相关工具（版本控制、问题管理、持续集成）。\n4. 核心业务实体及其属性，实体与实体之间的关系。\n5. 用到哪些依赖库，依赖库主要解决哪方面的问题。\n6. 项目如何部署上线以及项目的物理架构（Nginx、Gunicorn/uWSGI、Redis、MongoDB、MySQL、Supervisor等）。\n7. 如何对项目进行测试，有没有做过性能调优。\n8. 项目中遇到的困难有哪些，如何解决的。"}